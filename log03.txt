start
Fri Dec 30 01:42:56 CET 2022
2022-12-30 01:43:13.627223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-30 01:44:53,443 - modnet - INFO - Loaded <modnet.preprocessing.MODData object at 0x7f8dbc7f38b0> object, created with modnet version 0.1.12
        AtomicOrbitals|HOMO_character  ...  BondFractions|B - B bond frac.
id                                     ...                                
0                                 3.0  ...                             0.0
1                                 3.0  ...                             0.0
2                                 2.0  ...                             0.0
3                                 2.0  ...                             0.0
4                                 2.0  ...                             0.0
...                               ...  ...                             ...
106108                            3.0  ...                             0.0
106109                            2.0  ...                             0.0
106110                            3.0  ...                             0.0
106111                            3.0  ...                             0.0
106112                            1.0  ...                             0.0

[106113 rows x 1336 columns]
Shape of dataset to encode: (106113, 1264)
2022-12-30 01:44:55.656475: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense (Dense)               (None, 2780)              3516700   
                                                                 
 batch_normalization (BatchN  (None, 2780)             11120     
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 442)               1229202   
                                                                 
 batch_normalization_1 (Batc  (None, 442)              1768      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 442)               0         
                                                                 
 dense_1 (Dense)             (None, 2780)              1231540   
                                                                 
 batch_normalization_2 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 2780)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 9,516,634
Trainable params: 9,504,630
Non-trainable params: 12,004
_________________________________________________________________
Epoch 1/200
1493/1493 - 100s - loss: 0.0098 - val_loss: 0.0047 - 100s/epoch - 67ms/step
Epoch 2/200
1493/1493 - 98s - loss: 0.0032 - val_loss: 0.0033 - 98s/epoch - 66ms/step
Epoch 3/200
1493/1493 - 98s - loss: 0.0022 - val_loss: 0.0018 - 98s/epoch - 66ms/step
Epoch 4/200
1493/1493 - 98s - loss: 0.0018 - val_loss: 0.0039 - 98s/epoch - 65ms/step
Epoch 5/200
1493/1493 - 98s - loss: 0.0017 - val_loss: 0.0018 - 98s/epoch - 66ms/step
Epoch 6/200
1493/1493 - 98s - loss: 0.0015 - val_loss: 0.0014 - 98s/epoch - 66ms/step
Epoch 7/200
1493/1493 - 98s - loss: 0.0014 - val_loss: 0.0012 - 98s/epoch - 66ms/step
Epoch 8/200
1493/1493 - 98s - loss: 0.0013 - val_loss: 0.0011 - 98s/epoch - 66ms/step
Epoch 9/200
1493/1493 - 98s - loss: 0.0011 - val_loss: 0.0023 - 98s/epoch - 66ms/step
Epoch 10/200
1493/1493 - 98s - loss: 0.0012 - val_loss: 8.7524e-04 - 98s/epoch - 66ms/step
Epoch 11/200
1493/1493 - 98s - loss: 9.6595e-04 - val_loss: 7.7690e-04 - 98s/epoch - 66ms/step
Epoch 12/200
1493/1493 - 98s - loss: 8.3807e-04 - val_loss: 0.0012 - 98s/epoch - 66ms/step
Epoch 13/200
1493/1493 - 98s - loss: 8.0181e-04 - val_loss: 0.0013 - 98s/epoch - 66ms/step
Epoch 14/200
1493/1493 - 98s - loss: 7.9723e-04 - val_loss: 6.6147e-04 - 98s/epoch - 66ms/step
Epoch 15/200
1493/1493 - 98s - loss: 6.8937e-04 - val_loss: 6.5572e-04 - 98s/epoch - 66ms/step
Epoch 16/200
1493/1493 - 98s - loss: 6.2818e-04 - val_loss: 5.9701e-04 - 98s/epoch - 66ms/step
Epoch 17/200
1493/1493 - 98s - loss: 5.7082e-04 - val_loss: 7.0905e-04 - 98s/epoch - 66ms/step
Epoch 18/200
1493/1493 - 98s - loss: 5.5996e-04 - val_loss: 0.0011 - 98s/epoch - 66ms/step
Epoch 19/200
1493/1493 - 98s - loss: 5.5142e-04 - val_loss: 7.4418e-04 - 98s/epoch - 66ms/step
Epoch 20/200
1493/1493 - 98s - loss: 5.0705e-04 - val_loss: 4.6235e-04 - 98s/epoch - 66ms/step
Epoch 21/200
1493/1493 - 98s - loss: 4.6982e-04 - val_loss: 5.7232e-04 - 98s/epoch - 66ms/step
Epoch 22/200
1493/1493 - 98s - loss: 4.4654e-04 - val_loss: 5.7902e-04 - 98s/epoch - 66ms/step
Epoch 23/200
1493/1493 - 98s - loss: 4.3919e-04 - val_loss: 5.3639e-04 - 98s/epoch - 66ms/step
Epoch 24/200
1493/1493 - 98s - loss: 4.2305e-04 - val_loss: 4.0346e-04 - 98s/epoch - 66ms/step
Epoch 25/200
1493/1493 - 98s - loss: 3.8924e-04 - val_loss: 3.8221e-04 - 98s/epoch - 66ms/step
Epoch 26/200
1493/1493 - 98s - loss: 3.7323e-04 - val_loss: 4.3499e-04 - 98s/epoch - 66ms/step
Epoch 27/200
1493/1493 - 98s - loss: 3.6276e-04 - val_loss: 3.6264e-04 - 98s/epoch - 66ms/step
Epoch 28/200
1493/1493 - 98s - loss: 3.4228e-04 - val_loss: 6.4546e-04 - 98s/epoch - 66ms/step
Epoch 29/200
1493/1493 - 98s - loss: 3.4570e-04 - val_loss: 4.1003e-04 - 98s/epoch - 66ms/step
Epoch 30/200
1493/1493 - 98s - loss: 3.2946e-04 - val_loss: 3.8593e-04 - 98s/epoch - 66ms/step
Epoch 31/200
1493/1493 - 98s - loss: 3.1772e-04 - val_loss: 5.6855e-04 - 98s/epoch - 66ms/step
Epoch 32/200
1493/1493 - 98s - loss: 3.3941e-04 - val_loss: 4.1667e-04 - 98s/epoch - 66ms/step
Epoch 33/200
1493/1493 - 98s - loss: 3.1439e-04 - val_loss: 3.0464e-04 - 98s/epoch - 66ms/step
Epoch 34/200
1493/1493 - 98s - loss: 2.9722e-04 - val_loss: 2.8892e-04 - 98s/epoch - 66ms/step
Epoch 35/200
1493/1493 - 98s - loss: 2.8706e-04 - val_loss: 5.7543e-04 - 98s/epoch - 66ms/step
Epoch 36/200
1493/1493 - 98s - loss: 3.0807e-04 - val_loss: 3.5105e-04 - 98s/epoch - 66ms/step
Epoch 37/200
1493/1493 - 98s - loss: 2.9084e-04 - val_loss: 3.1851e-04 - 98s/epoch - 66ms/step
Epoch 38/200
1493/1493 - 98s - loss: 2.7728e-04 - val_loss: 2.8543e-04 - 98s/epoch - 66ms/step
Epoch 39/200
1493/1493 - 98s - loss: 2.6587e-04 - val_loss: 2.7010e-04 - 98s/epoch - 66ms/step
Epoch 40/200
1493/1493 - 98s - loss: 2.5818e-04 - val_loss: 3.1949e-04 - 98s/epoch - 66ms/step
Epoch 41/200
1493/1493 - 98s - loss: 2.5774e-04 - val_loss: 2.3419e-04 - 98s/epoch - 66ms/step
Epoch 42/200
1493/1493 - 98s - loss: 2.5382e-04 - val_loss: 2.5298e-04 - 98s/epoch - 66ms/step
Epoch 43/200
1493/1493 - 98s - loss: 2.5615e-04 - val_loss: 3.5054e-04 - 98s/epoch - 65ms/step
Epoch 44/200
1493/1493 - 98s - loss: 2.5599e-04 - val_loss: 5.5095e-04 - 98s/epoch - 66ms/step
Epoch 45/200
1493/1493 - 97s - loss: 2.8262e-04 - val_loss: 2.1666e-04 - 97s/epoch - 65ms/step
Epoch 46/200
1493/1493 - 98s - loss: 2.3978e-04 - val_loss: 2.2203e-04 - 98s/epoch - 66ms/step
Epoch 47/200
1493/1493 - 98s - loss: 2.3600e-04 - val_loss: 2.8027e-04 - 98s/epoch - 66ms/step
Epoch 48/200
1493/1493 - 98s - loss: 2.3335e-04 - val_loss: 2.9116e-04 - 98s/epoch - 66ms/step
Epoch 49/200
1493/1493 - 98s - loss: 2.3147e-04 - val_loss: 5.1439e-04 - 98s/epoch - 66ms/step
Epoch 50/200
1493/1493 - 98s - loss: 2.5667e-04 - val_loss: 4.0507e-04 - 98s/epoch - 66ms/step
Epoch 51/200
1493/1493 - 98s - loss: 2.3871e-04 - val_loss: 2.4721e-04 - 98s/epoch - 66ms/step
Epoch 52/200
1493/1493 - 98s - loss: 2.1863e-04 - val_loss: 2.3391e-04 - 98s/epoch - 66ms/step
Epoch 53/200
1493/1493 - 98s - loss: 2.1781e-04 - val_loss: 2.0854e-04 - 98s/epoch - 66ms/step
Epoch 54/200
1493/1493 - 98s - loss: 2.1426e-04 - val_loss: 2.6631e-04 - 98s/epoch - 66ms/step
Epoch 55/200
1493/1493 - 98s - loss: 2.1089e-04 - val_loss: 2.0961e-04 - 98s/epoch - 66ms/step
Epoch 56/200
1493/1493 - 98s - loss: 2.0768e-04 - val_loss: 2.4275e-04 - 98s/epoch - 66ms/step
Epoch 57/200
1493/1493 - 98s - loss: 2.0742e-04 - val_loss: 2.2023e-04 - 98s/epoch - 66ms/step
Epoch 58/200
1493/1493 - 98s - loss: 2.0341e-04 - val_loss: 2.0745e-04 - 98s/epoch - 66ms/step
Epoch 59/200
1493/1493 - 98s - loss: 1.9970e-04 - val_loss: 2.2399e-04 - 98s/epoch - 66ms/step
Epoch 60/200
1493/1493 - 98s - loss: 1.9780e-04 - val_loss: 4.0916e-04 - 98s/epoch - 66ms/step
Epoch 61/200
1493/1493 - 98s - loss: 3.7567e-04 - val_loss: 1.9135e-04 - 98s/epoch - 66ms/step
Epoch 62/200
1493/1493 - 98s - loss: 2.1118e-04 - val_loss: 2.1983e-04 - 98s/epoch - 66ms/step
Epoch 63/200
1493/1493 - 98s - loss: 1.9859e-04 - val_loss: 2.2968e-04 - 98s/epoch - 66ms/step
Epoch 64/200
1493/1493 - 98s - loss: 2.0263e-04 - val_loss: 0.0016 - 98s/epoch - 66ms/step
Epoch 65/200
1493/1493 - 98s - loss: 3.2430e-04 - val_loss: 3.6620e-04 - 98s/epoch - 66ms/step
Epoch 66/200
1493/1493 - 98s - loss: 2.1759e-04 - val_loss: 2.4741e-04 - 98s/epoch - 66ms/step
Epoch 67/200
1493/1493 - 98s - loss: 1.9701e-04 - val_loss: 1.9020e-04 - 98s/epoch - 66ms/step
Epoch 68/200
1493/1493 - 98s - loss: 1.9290e-04 - val_loss: 5.8031e-04 - 98s/epoch - 66ms/step
Epoch 69/200
1493/1493 - 98s - loss: 3.2217e-04 - val_loss: 3.3499e-04 - 98s/epoch - 66ms/step
Epoch 70/200
1493/1493 - 98s - loss: 2.0191e-04 - val_loss: 3.4177e-04 - 98s/epoch - 66ms/step
Epoch 71/200
1493/1493 - 98s - loss: 2.0206e-04 - val_loss: 1.8032e-04 - 98s/epoch - 66ms/step
Epoch 72/200
1493/1493 - 98s - loss: 1.9124e-04 - val_loss: 2.5524e-04 - 98s/epoch - 66ms/step
Epoch 73/200
1493/1493 - 98s - loss: 1.9258e-04 - val_loss: 1.8983e-04 - 98s/epoch - 66ms/step
Epoch 74/200
1493/1493 - 98s - loss: 1.8480e-04 - val_loss: 1.9910e-04 - 98s/epoch - 66ms/step
Epoch 75/200
1493/1493 - 98s - loss: 1.7883e-04 - val_loss: 1.8068e-04 - 98s/epoch - 66ms/step
Epoch 76/200
1493/1493 - 98s - loss: 1.7799e-04 - val_loss: 1.8225e-04 - 98s/epoch - 66ms/step
Epoch 77/200
1493/1493 - 98s - loss: 1.7292e-04 - val_loss: 3.6621e-04 - 98s/epoch - 66ms/step
Epoch 78/200
1493/1493 - 97s - loss: 1.9043e-04 - val_loss: 2.9016e-04 - 97s/epoch - 65ms/step
Epoch 79/200
1493/1493 - 98s - loss: 1.8812e-04 - val_loss: 2.1966e-04 - 98s/epoch - 66ms/step
Epoch 80/200
1493/1493 - 98s - loss: 1.7937e-04 - val_loss: 1.9791e-04 - 98s/epoch - 66ms/step
Epoch 81/200
1493/1493 - 98s - loss: 1.7576e-04 - val_loss: 3.9279e-04 - 98s/epoch - 66ms/step
Epoch 82/200
1493/1493 - 98s - loss: 1.7483e-04 - val_loss: 1.7864e-04 - 98s/epoch - 66ms/step
Epoch 83/200
1493/1493 - 98s - loss: 1.6616e-04 - val_loss: 1.7451e-04 - 98s/epoch - 66ms/step
Epoch 84/200
1493/1493 - 98s - loss: 1.6531e-04 - val_loss: 1.7980e-04 - 98s/epoch - 66ms/step
Epoch 85/200
1493/1493 - 98s - loss: 1.6712e-04 - val_loss: 2.3793e-04 - 98s/epoch - 66ms/step
Epoch 86/200
1493/1493 - 98s - loss: 1.7761e-04 - val_loss: 1.7637e-04 - 98s/epoch - 66ms/step
Epoch 87/200
1493/1493 - 98s - loss: 1.6326e-04 - val_loss: 1.7688e-04 - 98s/epoch - 66ms/step
Epoch 88/200
1493/1493 - 98s - loss: 1.6310e-04 - val_loss: 2.1177e-04 - 98s/epoch - 66ms/step
Epoch 89/200
1493/1493 - 98s - loss: 1.6809e-04 - val_loss: 1.7614e-04 - 98s/epoch - 66ms/step
Epoch 90/200
1493/1493 - 98s - loss: 1.5990e-04 - val_loss: 1.8225e-04 - 98s/epoch - 66ms/step
Epoch 91/200
1493/1493 - 98s - loss: 1.5746e-04 - val_loss: 1.7986e-04 - 98s/epoch - 66ms/step
Epoch 92/200
1493/1493 - 98s - loss: 1.5995e-04 - val_loss: 4.9024e-04 - 98s/epoch - 66ms/step
Epoch 93/200
1493/1493 - 98s - loss: 2.0687e-04 - val_loss: 1.7587e-04 - 98s/epoch - 66ms/step
Epoch 94/200
1493/1493 - 98s - loss: 1.6243e-04 - val_loss: 1.4372e-04 - 98s/epoch - 66ms/step
Epoch 95/200
1493/1493 - 96s - loss: 1.5717e-04 - val_loss: 3.2680e-04 - 96s/epoch - 64ms/step
Epoch 96/200
1493/1493 - 96s - loss: 1.7509e-04 - val_loss: 1.6387e-04 - 96s/epoch - 64ms/step
Epoch 97/200
1493/1493 - 98s - loss: 1.5682e-04 - val_loss: 1.4735e-04 - 98s/epoch - 66ms/step
Epoch 98/200
1493/1493 - 98s - loss: 1.5969e-04 - val_loss: 5.4828e-04 - 98s/epoch - 66ms/step
Epoch 99/200
1493/1493 - 98s - loss: 2.3147e-04 - val_loss: 1.4904e-04 - 98s/epoch - 66ms/step
Epoch 100/200
1493/1493 - 98s - loss: 1.6685e-04 - val_loss: 1.5400e-04 - 98s/epoch - 66ms/step
Epoch 101/200
1493/1493 - 98s - loss: 1.5568e-04 - val_loss: 1.9541e-04 - 98s/epoch - 66ms/step
Epoch 102/200
1493/1493 - 98s - loss: 1.5866e-04 - val_loss: 2.5500e-04 - 98s/epoch - 66ms/step
Epoch 103/200
1493/1493 - 98s - loss: 1.6235e-04 - val_loss: 1.5809e-04 - 98s/epoch - 66ms/step
Epoch 104/200
1493/1493 - 98s - loss: 1.5158e-04 - val_loss: 2.7231e-04 - 98s/epoch - 66ms/step
Epoch 105/200
1493/1493 - 98s - loss: 1.6123e-04 - val_loss: 1.3891e-04 - 98s/epoch - 66ms/step
Epoch 106/200
1493/1493 - 98s - loss: 1.4856e-04 - val_loss: 1.7095e-04 - 98s/epoch - 66ms/step
Epoch 107/200
1493/1493 - 98s - loss: 1.4842e-04 - val_loss: 1.8268e-04 - 98s/epoch - 66ms/step
Epoch 108/200
1493/1493 - 98s - loss: 1.5161e-04 - val_loss: 1.6562e-04 - 98s/epoch - 66ms/step
Epoch 109/200
1493/1493 - 98s - loss: 1.4744e-04 - val_loss: 1.5056e-04 - 98s/epoch - 66ms/step
Epoch 110/200
1493/1493 - 98s - loss: 1.4519e-04 - val_loss: 1.9148e-04 - 98s/epoch - 66ms/step
Epoch 111/200
1493/1493 - 98s - loss: 1.4597e-04 - val_loss: 2.2984e-04 - 98s/epoch - 66ms/step
Epoch 112/200
1493/1493 - 98s - loss: 1.6491e-04 - val_loss: 1.3510e-04 - 98s/epoch - 66ms/step
Epoch 113/200
1493/1493 - 98s - loss: 1.4822e-04 - val_loss: 4.5369e-04 - 98s/epoch - 66ms/step
Epoch 114/200
1493/1493 - 98s - loss: 2.0570e-04 - val_loss: 1.7918e-04 - 98s/epoch - 66ms/step
Epoch 115/200
1493/1493 - 98s - loss: 1.5851e-04 - val_loss: 2.0753e-04 - 98s/epoch - 66ms/step
Epoch 116/200
1493/1493 - 98s - loss: 1.4739e-04 - val_loss: 1.7706e-04 - 98s/epoch - 66ms/step
Epoch 117/200
1493/1493 - 98s - loss: 1.4405e-04 - val_loss: 2.0463e-04 - 98s/epoch - 66ms/step
Epoch 118/200
1493/1493 - 98s - loss: 1.4840e-04 - val_loss: 1.5121e-04 - 98s/epoch - 66ms/step
Epoch 119/200
1493/1493 - 98s - loss: 1.4241e-04 - val_loss: 1.5682e-04 - 98s/epoch - 66ms/step
Epoch 120/200
1493/1493 - 98s - loss: 1.4072e-04 - val_loss: 1.4772e-04 - 98s/epoch - 66ms/step
Epoch 121/200
1493/1493 - 98s - loss: 1.4089e-04 - val_loss: 2.1940e-04 - 98s/epoch - 66ms/step
Epoch 122/200
1493/1493 - 98s - loss: 1.4252e-04 - val_loss: 1.3930e-04 - 98s/epoch - 66ms/step
Epoch 123/200
1493/1493 - 98s - loss: 1.3932e-04 - val_loss: 1.5183e-04 - 98s/epoch - 66ms/step
Epoch 124/200
1493/1493 - 98s - loss: 1.3918e-04 - val_loss: 4.6932e-04 - 98s/epoch - 66ms/step
Epoch 125/200
1493/1493 - 98s - loss: 1.7095e-04 - val_loss: 1.7270e-04 - 98s/epoch - 66ms/step
Epoch 126/200
1493/1493 - 98s - loss: 1.4524e-04 - val_loss: 6.7691e-04 - 98s/epoch - 66ms/step
Epoch 127/200
1493/1493 - 98s - loss: 1.8860e-04 - val_loss: 4.3121e-04 - 98s/epoch - 66ms/step
Epoch 128/200
1493/1493 - 98s - loss: 1.8207e-04 - val_loss: 1.2133e-04 - 98s/epoch - 66ms/step
Epoch 129/200
1493/1493 - 98s - loss: 1.4139e-04 - val_loss: 1.3538e-04 - 98s/epoch - 66ms/step
Epoch 130/200
1493/1493 - 98s - loss: 1.3870e-04 - val_loss: 1.3486e-04 - 98s/epoch - 66ms/step
Epoch 131/200
1493/1493 - 98s - loss: 1.4163e-04 - val_loss: 2.8407e-04 - 98s/epoch - 66ms/step
Epoch 132/200
1493/1493 - 98s - loss: 1.5638e-04 - val_loss: 1.3817e-04 - 98s/epoch - 66ms/step
Epoch 133/200
1493/1493 - 98s - loss: 1.3640e-04 - val_loss: 1.6266e-04 - 98s/epoch - 66ms/step
Epoch 134/200
1493/1493 - 99s - loss: 1.3426e-04 - val_loss: 1.4649e-04 - 99s/epoch - 66ms/step
Epoch 135/200
1493/1493 - 98s - loss: 1.3309e-04 - val_loss: 1.3718e-04 - 98s/epoch - 66ms/step
Epoch 136/200
1493/1493 - 98s - loss: 1.3258e-04 - val_loss: 1.5076e-04 - 98s/epoch - 66ms/step
Epoch 137/200
1493/1493 - 98s - loss: 1.4125e-04 - val_loss: 2.0521e-04 - 98s/epoch - 66ms/step
Epoch 138/200
1493/1493 - 98s - loss: 1.4800e-04 - val_loss: 1.7892e-04 - 98s/epoch - 66ms/step
Epoch 139/200
1493/1493 - 98s - loss: 1.4242e-04 - val_loss: 2.1667e-04 - 98s/epoch - 66ms/step
Epoch 140/200
1493/1493 - 98s - loss: 1.4465e-04 - val_loss: 1.2775e-04 - 98s/epoch - 66ms/step
Epoch 141/200
1493/1493 - 98s - loss: 1.3324e-04 - val_loss: 2.4381e-04 - 98s/epoch - 66ms/step
Epoch 142/200
1493/1493 - 98s - loss: 1.4414e-04 - val_loss: 1.4054e-04 - 98s/epoch - 66ms/step
Epoch 143/200
1493/1493 - 98s - loss: 1.3165e-04 - val_loss: 1.4817e-04 - 98s/epoch - 66ms/step
Epoch 144/200
1493/1493 - 98s - loss: 1.3567e-04 - val_loss: 1.5185e-04 - 98s/epoch - 66ms/step
Epoch 145/200
1493/1493 - 98s - loss: 1.3034e-04 - val_loss: 1.2772e-04 - 98s/epoch - 66ms/step
Epoch 146/200
1493/1493 - 98s - loss: 1.2934e-04 - val_loss: 1.3829e-04 - 98s/epoch - 66ms/step
Epoch 147/200
1493/1493 - 98s - loss: 1.2749e-04 - val_loss: 1.4666e-04 - 98s/epoch - 66ms/step
Epoch 148/200
1493/1493 - 98s - loss: 1.2739e-04 - val_loss: 1.9173e-04 - 98s/epoch - 66ms/step
Epoch 149/200
1493/1493 - 98s - loss: 1.2632e-04 - val_loss: 1.3639e-04 - 98s/epoch - 66ms/step
Epoch 150/200
1493/1493 - 98s - loss: 1.2575e-04 - val_loss: 1.2694e-04 - 98s/epoch - 66ms/step
Epoch 151/200
1493/1493 - 98s - loss: 1.3106e-04 - val_loss: 1.5289e-04 - 98s/epoch - 66ms/step
Epoch 152/200
1493/1493 - 98s - loss: 1.2757e-04 - val_loss: 2.7809e-04 - 98s/epoch - 66ms/step
Epoch 153/200
1493/1493 - 98s - loss: 1.4812e-04 - val_loss: 1.4077e-04 - 98s/epoch - 66ms/step
Epoch 154/200
1493/1493 - 98s - loss: 1.2798e-04 - val_loss: 2.1276e-04 - 98s/epoch - 66ms/step
Epoch 155/200
1493/1493 - 98s - loss: 1.4870e-04 - val_loss: 1.3037e-04 - 98s/epoch - 66ms/step
Epoch 156/200
1493/1493 - 98s - loss: 1.2887e-04 - val_loss: 1.3145e-04 - 98s/epoch - 66ms/step
Epoch 157/200
1493/1493 - 98s - loss: 1.2464e-04 - val_loss: 1.4976e-04 - 98s/epoch - 66ms/step
Epoch 158/200
1493/1493 - 98s - loss: 1.2621e-04 - val_loss: 1.3397e-04 - 98s/epoch - 66ms/step
Epoch 159/200
1493/1493 - 98s - loss: 1.2418e-04 - val_loss: 1.2411e-04 - 98s/epoch - 66ms/step
Epoch 160/200
1493/1493 - 98s - loss: 1.2394e-04 - val_loss: 1.6355e-04 - 98s/epoch - 66ms/step
Epoch 161/200
1493/1493 - 98s - loss: 1.3313e-04 - val_loss: 1.2482e-04 - 98s/epoch - 66ms/step
Epoch 162/200
1493/1493 - 99s - loss: 1.2247e-04 - val_loss: 1.3335e-04 - 99s/epoch - 66ms/step
Epoch 163/200
1493/1493 - 98s - loss: 1.2270e-04 - val_loss: 1.8879e-04 - 98s/epoch - 66ms/step
Epoch 164/200
1493/1493 - 99s - loss: 1.3415e-04 - val_loss: 1.3440e-04 - 99s/epoch - 66ms/step
Epoch 165/200
1493/1493 - 98s - loss: 1.3581e-04 - val_loss: 1.2508e-04 - 98s/epoch - 66ms/step
Epoch 166/200
1493/1493 - 98s - loss: 1.2311e-04 - val_loss: 1.3416e-04 - 98s/epoch - 66ms/step
Epoch 167/200
1493/1493 - 96s - loss: 1.2218e-04 - val_loss: 1.2000e-04 - 96s/epoch - 64ms/step
Epoch 168/200
1493/1493 - 98s - loss: 1.2118e-04 - val_loss: 1.3469e-04 - 98s/epoch - 66ms/step
Epoch 169/200
1493/1493 - 98s - loss: 1.2106e-04 - val_loss: 1.5860e-04 - 98s/epoch - 66ms/step
Epoch 170/200
1493/1493 - 98s - loss: 1.2135e-04 - val_loss: 2.9995e-04 - 98s/epoch - 66ms/step
Epoch 171/200
1493/1493 - 98s - loss: 1.5459e-04 - val_loss: 2.0861e-04 - 98s/epoch - 66ms/step
Epoch 172/200
1493/1493 - 98s - loss: 1.3824e-04 - val_loss: 1.2345e-04 - 98s/epoch - 66ms/step
Epoch 173/200
1493/1493 - 98s - loss: 1.2274e-04 - val_loss: 1.1989e-04 - 98s/epoch - 66ms/step
Epoch 174/200
1493/1493 - 99s - loss: 1.1953e-04 - val_loss: 1.2248e-04 - 99s/epoch - 66ms/step
Epoch 175/200
1493/1493 - 100s - loss: 1.2044e-04 - val_loss: 1.3027e-04 - 100s/epoch - 67ms/step
Epoch 176/200
1493/1493 - 100s - loss: 1.2144e-04 - val_loss: 1.3684e-04 - 100s/epoch - 67ms/step
Epoch 177/200
1493/1493 - 100s - loss: 1.2149e-04 - val_loss: 1.1924e-04 - 100s/epoch - 67ms/step
Epoch 178/200
1493/1493 - 99s - loss: 1.1800e-04 - val_loss: 1.2028e-04 - 99s/epoch - 66ms/step
Epoch 179/200
1493/1493 - 99s - loss: 1.1705e-04 - val_loss: 1.3824e-04 - 99s/epoch - 66ms/step
Epoch 180/200
1493/1493 - 99s - loss: 1.1868e-04 - val_loss: 1.6733e-04 - 99s/epoch - 66ms/step
Epoch 181/200
1493/1493 - 99s - loss: 1.2351e-04 - val_loss: 1.5749e-04 - 99s/epoch - 66ms/step
Epoch 182/200
1493/1493 - 99s - loss: 1.1833e-04 - val_loss: 1.3123e-04 - 99s/epoch - 66ms/step
Epoch 183/200
1493/1493 - 99s - loss: 1.1964e-04 - val_loss: 1.4514e-04 - 99s/epoch - 66ms/step
Epoch 184/200
1493/1493 - 99s - loss: 1.1958e-04 - val_loss: 1.1443e-04 - 99s/epoch - 66ms/step
Epoch 185/200
1493/1493 - 99s - loss: 1.1437e-04 - val_loss: 1.5798e-04 - 99s/epoch - 66ms/step
Epoch 186/200
1493/1493 - 99s - loss: 1.1563e-04 - val_loss: 1.2781e-04 - 99s/epoch - 66ms/step
Epoch 187/200
1493/1493 - 99s - loss: 1.1446e-04 - val_loss: 1.2464e-04 - 99s/epoch - 66ms/step
Epoch 188/200
1493/1493 - 99s - loss: 1.1904e-04 - val_loss: 1.8077e-04 - 99s/epoch - 66ms/step
Epoch 189/200
1493/1493 - 99s - loss: 1.2113e-04 - val_loss: 1.2650e-04 - 99s/epoch - 66ms/step
Epoch 190/200
1493/1493 - 99s - loss: 1.1764e-04 - val_loss: 2.8533e-04 - 99s/epoch - 66ms/step
Epoch 191/200
1493/1493 - 99s - loss: 1.3710e-04 - val_loss: 1.5208e-04 - 99s/epoch - 66ms/step
Epoch 192/200
1493/1493 - 99s - loss: 1.1882e-04 - val_loss: 1.4007e-04 - 99s/epoch - 66ms/step
Epoch 193/200
1493/1493 - 99s - loss: 1.1906e-04 - val_loss: 3.0468e-04 - 99s/epoch - 66ms/step
Epoch 194/200
1493/1493 - 99s - loss: 1.3845e-04 - val_loss: 3.3861e-04 - 99s/epoch - 66ms/step
Epoch 195/200
1493/1493 - 99s - loss: 1.4324e-04 - val_loss: 1.7900e-04 - 99s/epoch - 66ms/step
Epoch 196/200
1493/1493 - 99s - loss: 1.2973e-04 - val_loss: 1.1119e-04 - 99s/epoch - 66ms/step
Epoch 197/200
1493/1493 - 99s - loss: 1.1712e-04 - val_loss: 1.1442e-04 - 99s/epoch - 66ms/step
Epoch 198/200
1493/1493 - 99s - loss: 1.1735e-04 - val_loss: 1.7348e-04 - 99s/epoch - 66ms/step
Epoch 199/200
1493/1493 - 99s - loss: 1.2101e-04 - val_loss: 1.0653e-04 - 99s/epoch - 66ms/step
Epoch 200/200
1493/1493 - 99s - loss: 1.1429e-04 - val_loss: 1.2824e-04 - 99s/epoch - 66ms/step
COMPRESSED VECTOR SIZE: 442
Loss in the autoencoder: 0.0001282418379560113
  1/332 [..............................] - ETA: 47s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 3s 36/332 [==>...........................] - ETA: 3s 41/332 [==>...........................] - ETA: 3s 46/332 [===>..........................] - ETA: 3s 51/332 [===>..........................] - ETA: 3s 56/332 [====>.........................] - ETA: 3s 61/332 [====>.........................] - ETA: 3s 66/332 [====>.........................] - ETA: 3s 71/332 [=====>........................] - ETA: 3s 76/332 [=====>........................] - ETA: 2s 81/332 [======>.......................] - ETA: 2s 86/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 96/332 [=======>......................] - ETA: 2s101/332 [========>.....................] - ETA: 2s106/332 [========>.....................] - ETA: 2s111/332 [=========>....................] - ETA: 2s116/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s131/332 [==========>...................] - ETA: 2s136/332 [===========>..................] - ETA: 2s141/332 [===========>..................] - ETA: 2s146/332 [============>.................] - ETA: 2s151/332 [============>.................] - ETA: 2s156/332 [=============>................] - ETA: 2s161/332 [=============>................] - ETA: 1s166/332 [==============>...............] - ETA: 1s171/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 1s196/332 [================>.............] - ETA: 1s201/332 [=================>............] - ETA: 1s206/332 [=================>............] - ETA: 1s211/332 [==================>...........] - ETA: 1s216/332 [==================>...........] - ETA: 1s221/332 [==================>...........] - ETA: 1s226/332 [===================>..........] - ETA: 1s231/332 [===================>..........] - ETA: 1s236/332 [====================>.........] - ETA: 1s241/332 [====================>.........] - ETA: 1s246/332 [=====================>........] - ETA: 1s251/332 [=====================>........] - ETA: 0s256/332 [======================>.......] - ETA: 0s261/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s271/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s286/332 [========================>.....] - ETA: 0s291/332 [=========================>....] - ETA: 0s296/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s306/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s316/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s326/332 [============================>.] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 12ms/step
correlation 0.0014626095081966327
cosine 0.0011523480162367117
MAE: 0.0062691025
RMSE: 0.011324388
r2: 0.9916814469956458
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 2780)              3516700   
                                                                 
 batch_normalization (BatchN  (None, 2780)             11120     
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 442)               1229202   
                                                                 
 batch_normalization_1 (Batc  (None, 442)              1768      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 442)               0         
                                                                 
 dense_1 (Dense)             (None, 2780)              1231540   
                                                                 
 batch_normalization_2 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 2780)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 9,516,634
Trainable params: 9,504,630
Non-trainable params: 12,004
_________________________________________________________________
Encoder
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 2780)              3516700   
                                                                 
 batch_normalization (BatchN  (None, 2780)             11120     
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 442)               1229202   
                                                                 
=================================================================
Total params: 4,757,022
Trainable params: 4,751,462
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 442)]             0         
                                                                 
 batch_normalization_1 (Batc  (None, 442)              1768      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 442)               0         
                                                                 
 dense_1 (Dense)             (None, 2780)              1231540   
                                                                 
 batch_normalization_2 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 2780)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 4,759,612
Trainable params: 4,753,168
Non-trainable params: 6,444
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.35, 442, 0.00011428669677115977, 0.0001282418379560113, 0.0014626095081966327, 0.0011523480162367117, 0.0062691024504601955, 0.011324387975037098, 0.9916814469956458, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_3 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_3 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 379)               1053999   
                                                                 
 batch_normalization_4 (Batc  (None, 379)              1516      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 379)               0         
                                                                 
 dense_4 (Dense)             (None, 2780)              1056400   
                                                                 
 batch_normalization_5 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2780)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 9,166,039
Trainable params: 9,154,161
Non-trainable params: 11,878
_________________________________________________________________
Epoch 1/200
1493/1493 - 96s - loss: 0.0098 - val_loss: 0.0043 - 96s/epoch - 64ms/step
Epoch 2/200
1493/1493 - 95s - loss: 0.0032 - val_loss: 0.0033 - 95s/epoch - 64ms/step
Epoch 3/200
1493/1493 - 95s - loss: 0.0023 - val_loss: 0.0021 - 95s/epoch - 64ms/step
Epoch 4/200
1493/1493 - 94s - loss: 0.0018 - val_loss: 0.0029 - 94s/epoch - 63ms/step
Epoch 5/200
1493/1493 - 94s - loss: 0.0018 - val_loss: 0.0018 - 94s/epoch - 63ms/step
Epoch 6/200
1493/1493 - 94s - loss: 0.0016 - val_loss: 0.0016 - 94s/epoch - 63ms/step
Epoch 7/200
1493/1493 - 94s - loss: 0.0015 - val_loss: 0.0013 - 94s/epoch - 63ms/step
Epoch 8/200
1493/1493 - 94s - loss: 0.0013 - val_loss: 0.0013 - 94s/epoch - 63ms/step
Epoch 9/200
1493/1493 - 94s - loss: 0.0012 - val_loss: 0.0013 - 94s/epoch - 63ms/step
Epoch 10/200
1493/1493 - 94s - loss: 0.0011 - val_loss: 9.1544e-04 - 94s/epoch - 63ms/step
Epoch 11/200
1493/1493 - 94s - loss: 9.7538e-04 - val_loss: 7.8996e-04 - 94s/epoch - 63ms/step
Epoch 12/200
1493/1493 - 94s - loss: 8.5780e-04 - val_loss: 0.0017 - 94s/epoch - 63ms/step
Epoch 13/200
1493/1493 - 94s - loss: 8.9277e-04 - val_loss: 0.0010 - 94s/epoch - 63ms/step
Epoch 14/200
1493/1493 - 94s - loss: 7.8321e-04 - val_loss: 6.9202e-04 - 94s/epoch - 63ms/step
Epoch 15/200
1493/1493 - 94s - loss: 7.2276e-04 - val_loss: 7.7268e-04 - 94s/epoch - 63ms/step
Epoch 16/200
1493/1493 - 94s - loss: 6.5136e-04 - val_loss: 5.7254e-04 - 94s/epoch - 63ms/step
Epoch 17/200
1493/1493 - 94s - loss: 6.0194e-04 - val_loss: 6.2949e-04 - 94s/epoch - 63ms/step
Epoch 18/200
1493/1493 - 94s - loss: 5.6136e-04 - val_loss: 6.6757e-04 - 94s/epoch - 63ms/step
Epoch 19/200
1493/1493 - 94s - loss: 5.4961e-04 - val_loss: 6.6551e-04 - 94s/epoch - 63ms/step
Epoch 20/200
1493/1493 - 94s - loss: 5.1883e-04 - val_loss: 4.7920e-04 - 94s/epoch - 63ms/step
Epoch 21/200
1493/1493 - 94s - loss: 4.8526e-04 - val_loss: 6.5773e-04 - 94s/epoch - 63ms/step
Epoch 22/200
1493/1493 - 94s - loss: 4.7348e-04 - val_loss: 5.6933e-04 - 94s/epoch - 63ms/step
Epoch 23/200
1493/1493 - 94s - loss: 4.8634e-04 - val_loss: 7.2622e-04 - 94s/epoch - 63ms/step
Epoch 24/200
1493/1493 - 94s - loss: 4.5108e-04 - val_loss: 4.0007e-04 - 94s/epoch - 63ms/step
Epoch 25/200
1493/1493 - 94s - loss: 4.1363e-04 - val_loss: 3.8690e-04 - 94s/epoch - 63ms/step
Epoch 26/200
1493/1493 - 94s - loss: 3.9693e-04 - val_loss: 4.4332e-04 - 94s/epoch - 63ms/step
Epoch 27/200
1493/1493 - 94s - loss: 3.8563e-04 - val_loss: 3.8536e-04 - 94s/epoch - 63ms/step
Epoch 28/200
1493/1493 - 94s - loss: 3.6581e-04 - val_loss: 7.2291e-04 - 94s/epoch - 63ms/step
Epoch 29/200
1493/1493 - 94s - loss: 3.6649e-04 - val_loss: 4.0561e-04 - 94s/epoch - 63ms/step
Epoch 30/200
1493/1493 - 93s - loss: 3.5638e-04 - val_loss: 3.9092e-04 - 93s/epoch - 62ms/step
Epoch 31/200
1493/1493 - 94s - loss: 3.3953e-04 - val_loss: 5.7999e-04 - 94s/epoch - 63ms/step
Epoch 32/200
1493/1493 - 94s - loss: 3.6912e-04 - val_loss: 3.4969e-04 - 94s/epoch - 63ms/step
Epoch 33/200
1493/1493 - 94s - loss: 3.3159e-04 - val_loss: 3.1595e-04 - 94s/epoch - 63ms/step
Epoch 34/200
1493/1493 - 94s - loss: 3.1892e-04 - val_loss: 3.1598e-04 - 94s/epoch - 63ms/step
Epoch 35/200
1493/1493 - 94s - loss: 3.0810e-04 - val_loss: 4.6609e-04 - 94s/epoch - 63ms/step
Epoch 36/200
1493/1493 - 94s - loss: 3.2734e-04 - val_loss: 3.3270e-04 - 94s/epoch - 63ms/step
Epoch 37/200
1493/1493 - 94s - loss: 3.0231e-04 - val_loss: 3.0634e-04 - 94s/epoch - 63ms/step
Epoch 38/200
1493/1493 - 94s - loss: 3.0081e-04 - val_loss: 3.1196e-04 - 94s/epoch - 63ms/step
Epoch 39/200
1493/1493 - 94s - loss: 2.8916e-04 - val_loss: 2.8617e-04 - 94s/epoch - 63ms/step
Epoch 40/200
1493/1493 - 94s - loss: 2.7838e-04 - val_loss: 3.3960e-04 - 94s/epoch - 63ms/step
Epoch 41/200
1493/1493 - 94s - loss: 2.7940e-04 - val_loss: 2.4765e-04 - 94s/epoch - 63ms/step
Epoch 42/200
1493/1493 - 94s - loss: 2.7547e-04 - val_loss: 2.5757e-04 - 94s/epoch - 63ms/step
Epoch 43/200
1493/1493 - 94s - loss: 2.7153e-04 - val_loss: 4.3256e-04 - 94s/epoch - 63ms/step
Epoch 44/200
1493/1493 - 94s - loss: 2.8541e-04 - val_loss: 0.0012 - 94s/epoch - 63ms/step
Epoch 45/200
1493/1493 - 94s - loss: 3.4624e-04 - val_loss: 2.3745e-04 - 94s/epoch - 63ms/step
Epoch 46/200
1493/1493 - 94s - loss: 2.5970e-04 - val_loss: 2.2838e-04 - 94s/epoch - 63ms/step
Epoch 47/200
1493/1493 - 94s - loss: 2.5428e-04 - val_loss: 3.6601e-04 - 94s/epoch - 63ms/step
Epoch 48/200
1493/1493 - 93s - loss: 2.5488e-04 - val_loss: 2.9358e-04 - 93s/epoch - 63ms/step
Epoch 49/200
1493/1493 - 95s - loss: 2.5259e-04 - val_loss: 9.3036e-04 - 95s/epoch - 63ms/step
Epoch 50/200
1493/1493 - 94s - loss: 3.5351e-04 - val_loss: 9.8873e-04 - 94s/epoch - 63ms/step
Epoch 51/200
1493/1493 - 94s - loss: 3.0294e-04 - val_loss: 2.3980e-04 - 94s/epoch - 63ms/step
Epoch 52/200
1493/1493 - 94s - loss: 2.4449e-04 - val_loss: 2.3947e-04 - 94s/epoch - 63ms/step
Epoch 53/200
1493/1493 - 94s - loss: 2.4326e-04 - val_loss: 2.2574e-04 - 94s/epoch - 63ms/step
Epoch 54/200
1493/1493 - 94s - loss: 2.3718e-04 - val_loss: 2.4627e-04 - 94s/epoch - 63ms/step
Epoch 55/200
1493/1493 - 94s - loss: 2.2987e-04 - val_loss: 2.2794e-04 - 94s/epoch - 63ms/step
Epoch 56/200
1493/1493 - 94s - loss: 2.2803e-04 - val_loss: 2.5322e-04 - 94s/epoch - 63ms/step
Epoch 57/200
1493/1493 - 94s - loss: 2.2498e-04 - val_loss: 2.4087e-04 - 94s/epoch - 63ms/step
Epoch 58/200
1493/1493 - 94s - loss: 2.2342e-04 - val_loss: 2.1498e-04 - 94s/epoch - 63ms/step
Epoch 59/200
1493/1493 - 94s - loss: 2.1889e-04 - val_loss: 2.3026e-04 - 94s/epoch - 63ms/step
Epoch 60/200
1493/1493 - 94s - loss: 2.1783e-04 - val_loss: 4.1807e-04 - 94s/epoch - 63ms/step
Epoch 61/200
1493/1493 - 94s - loss: 2.5280e-04 - val_loss: 2.1480e-04 - 94s/epoch - 63ms/step
Epoch 62/200
1493/1493 - 94s - loss: 2.1627e-04 - val_loss: 2.2715e-04 - 94s/epoch - 63ms/step
Epoch 63/200
1493/1493 - 94s - loss: 2.1166e-04 - val_loss: 2.5865e-04 - 94s/epoch - 63ms/step
Epoch 64/200
1493/1493 - 94s - loss: 2.1547e-04 - val_loss: 0.0014 - 94s/epoch - 63ms/step
Epoch 65/200
1493/1493 - 94s - loss: 3.4462e-04 - val_loss: 3.3666e-04 - 94s/epoch - 63ms/step
Epoch 66/200
1493/1493 - 94s - loss: 2.3104e-04 - val_loss: 2.5506e-04 - 94s/epoch - 63ms/step
Epoch 67/200
1493/1493 - 95s - loss: 2.1290e-04 - val_loss: 2.0294e-04 - 95s/epoch - 63ms/step
Epoch 68/200
1493/1493 - 95s - loss: 2.1034e-04 - val_loss: 7.1950e-04 - 95s/epoch - 64ms/step
Epoch 69/200
1493/1493 - 95s - loss: 2.8963e-04 - val_loss: 2.4101e-04 - 95s/epoch - 64ms/step
Epoch 70/200
1493/1493 - 95s - loss: 2.1471e-04 - val_loss: 5.8611e-04 - 95s/epoch - 64ms/step
Epoch 71/200
1493/1493 - 95s - loss: 2.6297e-04 - val_loss: 1.9600e-04 - 95s/epoch - 64ms/step
Epoch 72/200
1493/1493 - 95s - loss: 2.0989e-04 - val_loss: 2.0652e-04 - 95s/epoch - 64ms/step
Epoch 73/200
1493/1493 - 95s - loss: 2.0673e-04 - val_loss: 2.4186e-04 - 95s/epoch - 64ms/step
Epoch 74/200
1493/1493 - 95s - loss: 2.0894e-04 - val_loss: 2.0691e-04 - 95s/epoch - 64ms/step
Epoch 75/200
1493/1493 - 95s - loss: 1.9651e-04 - val_loss: 2.1010e-04 - 95s/epoch - 64ms/step
Epoch 76/200
1493/1493 - 95s - loss: 1.9529e-04 - val_loss: 1.9362e-04 - 95s/epoch - 63ms/step
Epoch 77/200
1493/1493 - 94s - loss: 1.9076e-04 - val_loss: 3.6764e-04 - 94s/epoch - 63ms/step
Epoch 78/200
1493/1493 - 94s - loss: 2.0995e-04 - val_loss: 2.2272e-04 - 94s/epoch - 63ms/step
Epoch 79/200
1493/1493 - 94s - loss: 1.9508e-04 - val_loss: 3.3419e-04 - 94s/epoch - 63ms/step
Epoch 80/200
1493/1493 - 94s - loss: 2.1127e-04 - val_loss: 2.1314e-04 - 94s/epoch - 63ms/step
Epoch 81/200
1493/1493 - 94s - loss: 1.9201e-04 - val_loss: 3.5513e-04 - 94s/epoch - 63ms/step
Epoch 82/200
1493/1493 - 94s - loss: 1.9107e-04 - val_loss: 1.8388e-04 - 94s/epoch - 63ms/step
Epoch 83/200
1493/1493 - 94s - loss: 1.8394e-04 - val_loss: 2.0389e-04 - 94s/epoch - 63ms/step
Epoch 84/200
1493/1493 - 94s - loss: 1.8360e-04 - val_loss: 2.1342e-04 - 94s/epoch - 63ms/step
Epoch 85/200
1493/1493 - 94s - loss: 1.8270e-04 - val_loss: 2.1005e-04 - 94s/epoch - 63ms/step
Epoch 86/200
1493/1493 - 94s - loss: 1.8163e-04 - val_loss: 2.1657e-04 - 94s/epoch - 63ms/step
Epoch 87/200
1493/1493 - 94s - loss: 1.7927e-04 - val_loss: 1.9526e-04 - 94s/epoch - 63ms/step
Epoch 88/200
1493/1493 - 94s - loss: 1.7835e-04 - val_loss: 2.0120e-04 - 94s/epoch - 63ms/step
Epoch 89/200
1493/1493 - 94s - loss: 1.8540e-04 - val_loss: 1.9499e-04 - 94s/epoch - 63ms/step
Epoch 90/200
1493/1493 - 94s - loss: 1.7604e-04 - val_loss: 1.9724e-04 - 94s/epoch - 63ms/step
Epoch 91/200
1493/1493 - 94s - loss: 1.7425e-04 - val_loss: 2.1094e-04 - 94s/epoch - 63ms/step
Epoch 92/200
1493/1493 - 94s - loss: 1.7512e-04 - val_loss: 4.9965e-04 - 94s/epoch - 63ms/step
Epoch 93/200
1493/1493 - 94s - loss: 2.1598e-04 - val_loss: 2.2168e-04 - 94s/epoch - 63ms/step
Epoch 94/200
1493/1493 - 94s - loss: 1.7969e-04 - val_loss: 1.6238e-04 - 94s/epoch - 63ms/step
Epoch 95/200
1493/1493 - 94s - loss: 1.7295e-04 - val_loss: 2.2335e-04 - 94s/epoch - 63ms/step
Epoch 96/200
1493/1493 - 94s - loss: 1.7704e-04 - val_loss: 1.9419e-04 - 94s/epoch - 63ms/step
Epoch 97/200
1493/1493 - 94s - loss: 1.7035e-04 - val_loss: 1.6405e-04 - 94s/epoch - 63ms/step
Epoch 98/200
1493/1493 - 95s - loss: 1.7684e-04 - val_loss: 4.5751e-04 - 95s/epoch - 63ms/step
Epoch 99/200
1493/1493 - 95s - loss: 2.4106e-04 - val_loss: 1.6769e-04 - 95s/epoch - 64ms/step
Epoch 100/200
1493/1493 - 95s - loss: 1.8030e-04 - val_loss: 1.6568e-04 - 95s/epoch - 64ms/step
Epoch 101/200
1493/1493 - 95s - loss: 1.7090e-04 - val_loss: 2.2313e-04 - 95s/epoch - 64ms/step
Epoch 102/200
1493/1493 - 95s - loss: 1.7516e-04 - val_loss: 2.0658e-04 - 95s/epoch - 64ms/step
Epoch 103/200
1493/1493 - 95s - loss: 1.7526e-04 - val_loss: 1.7743e-04 - 95s/epoch - 64ms/step
Epoch 104/200
1493/1493 - 95s - loss: 1.6742e-04 - val_loss: 4.0735e-04 - 95s/epoch - 64ms/step
Epoch 105/200
1493/1493 - 95s - loss: 1.8625e-04 - val_loss: 2.0232e-04 - 95s/epoch - 64ms/step
Epoch 106/200
1493/1493 - 95s - loss: 1.6711e-04 - val_loss: 1.7299e-04 - 95s/epoch - 64ms/step
Epoch 107/200
1493/1493 - 95s - loss: 1.6456e-04 - val_loss: 1.7993e-04 - 95s/epoch - 64ms/step
Epoch 108/200
1493/1493 - 95s - loss: 1.7155e-04 - val_loss: 1.6915e-04 - 95s/epoch - 64ms/step
Epoch 109/200
1493/1493 - 97s - loss: 1.6408e-04 - val_loss: 1.9349e-04 - 97s/epoch - 65ms/step
Epoch 110/200
1493/1493 - 96s - loss: 1.6076e-04 - val_loss: 1.8990e-04 - 96s/epoch - 65ms/step
Epoch 111/200
1493/1493 - 97s - loss: 1.6069e-04 - val_loss: 2.0884e-04 - 97s/epoch - 65ms/step
Epoch 112/200
1493/1493 - 96s - loss: 1.6428e-04 - val_loss: 1.6294e-04 - 96s/epoch - 64ms/step
Epoch 113/200
1493/1493 - 96s - loss: 1.5995e-04 - val_loss: 4.1908e-04 - 96s/epoch - 65ms/step
Epoch 114/200
1493/1493 - 96s - loss: 2.0310e-04 - val_loss: 2.0243e-04 - 96s/epoch - 65ms/step
Epoch 115/200
1493/1493 - 96s - loss: 1.7500e-04 - val_loss: 2.1129e-04 - 96s/epoch - 65ms/step
Epoch 116/200
1493/1493 - 97s - loss: 1.6045e-04 - val_loss: 1.8960e-04 - 97s/epoch - 65ms/step
Epoch 117/200
1493/1493 - 97s - loss: 1.5926e-04 - val_loss: 2.6395e-04 - 97s/epoch - 65ms/step
Epoch 118/200
1493/1493 - 97s - loss: 1.7214e-04 - val_loss: 1.6274e-04 - 97s/epoch - 65ms/step
Epoch 119/200
1493/1493 - 96s - loss: 1.5846e-04 - val_loss: 1.5835e-04 - 96s/epoch - 65ms/step
Epoch 120/200
1493/1493 - 96s - loss: 1.5588e-04 - val_loss: 1.5990e-04 - 96s/epoch - 65ms/step
Epoch 121/200
1493/1493 - 96s - loss: 1.5620e-04 - val_loss: 2.5494e-04 - 96s/epoch - 64ms/step
Epoch 122/200
1493/1493 - 96s - loss: 1.5631e-04 - val_loss: 1.5487e-04 - 96s/epoch - 65ms/step
Epoch 123/200
1493/1493 - 96s - loss: 1.5367e-04 - val_loss: 1.7759e-04 - 96s/epoch - 65ms/step
Epoch 124/200
1493/1493 - 97s - loss: 1.5390e-04 - val_loss: 3.9103e-04 - 97s/epoch - 65ms/step
Epoch 125/200
1493/1493 - 96s - loss: 1.8965e-04 - val_loss: 1.7237e-04 - 96s/epoch - 64ms/step
Epoch 126/200
1493/1493 - 96s - loss: 1.5883e-04 - val_loss: 5.6356e-04 - 96s/epoch - 65ms/step
Epoch 127/200
1493/1493 - 96s - loss: 1.9707e-04 - val_loss: 2.3990e-04 - 96s/epoch - 65ms/step
Epoch 128/200
1493/1493 - 96s - loss: 1.6104e-04 - val_loss: 1.5040e-04 - 96s/epoch - 65ms/step
Epoch 129/200
1493/1493 - 96s - loss: 1.5279e-04 - val_loss: 1.6609e-04 - 96s/epoch - 65ms/step
Epoch 130/200
1493/1493 - 96s - loss: 1.5188e-04 - val_loss: 1.4969e-04 - 96s/epoch - 65ms/step
Epoch 131/200
1493/1493 - 96s - loss: 1.5397e-04 - val_loss: 2.3617e-04 - 96s/epoch - 65ms/step
Epoch 132/200
1493/1493 - 96s - loss: 1.7649e-04 - val_loss: 1.5948e-04 - 96s/epoch - 64ms/step
Epoch 133/200
1493/1493 - 96s - loss: 1.5253e-04 - val_loss: 1.7737e-04 - 96s/epoch - 65ms/step
Epoch 134/200
1493/1493 - 96s - loss: 1.5062e-04 - val_loss: 1.5377e-04 - 96s/epoch - 64ms/step
Epoch 135/200
1493/1493 - 96s - loss: 1.4834e-04 - val_loss: 1.4909e-04 - 96s/epoch - 65ms/step
Epoch 136/200
1493/1493 - 96s - loss: 1.4847e-04 - val_loss: 1.9202e-04 - 96s/epoch - 65ms/step
Epoch 137/200
1493/1493 - 96s - loss: 1.6476e-04 - val_loss: 1.8271e-04 - 96s/epoch - 65ms/step
Epoch 138/200
1493/1493 - 96s - loss: 1.5405e-04 - val_loss: 1.4955e-04 - 96s/epoch - 65ms/step
Epoch 139/200
1493/1493 - 97s - loss: 1.5010e-04 - val_loss: 1.8274e-04 - 97s/epoch - 65ms/step
Epoch 140/200
1493/1493 - 97s - loss: 1.5988e-04 - val_loss: 1.4027e-04 - 97s/epoch - 65ms/step
Epoch 141/200
1493/1493 - 96s - loss: 1.4706e-04 - val_loss: 2.4704e-04 - 96s/epoch - 64ms/step
Epoch 142/200
1493/1493 - 96s - loss: 1.5699e-04 - val_loss: 1.5626e-04 - 96s/epoch - 65ms/step
Epoch 143/200
1493/1493 - 96s - loss: 1.4567e-04 - val_loss: 1.9288e-04 - 96s/epoch - 65ms/step
Epoch 144/200
1493/1493 - 95s - loss: 1.5079e-04 - val_loss: 1.5523e-04 - 95s/epoch - 64ms/step
Epoch 145/200
1493/1493 - 96s - loss: 1.4389e-04 - val_loss: 1.4931e-04 - 96s/epoch - 65ms/step
Epoch 146/200
1493/1493 - 96s - loss: 1.4404e-04 - val_loss: 1.5405e-04 - 96s/epoch - 65ms/step
Epoch 147/200
1493/1493 - 95s - loss: 1.4184e-04 - val_loss: 2.0544e-04 - 95s/epoch - 64ms/step
Epoch 148/200
1493/1493 - 95s - loss: 1.4353e-04 - val_loss: 2.7854e-04 - 95s/epoch - 64ms/step
Epoch 149/200
1493/1493 - 96s - loss: 1.4142e-04 - val_loss: 1.5270e-04 - 96s/epoch - 64ms/step
Epoch 150/200
1493/1493 - 96s - loss: 1.4033e-04 - val_loss: 1.3554e-04 - 96s/epoch - 65ms/step
Epoch 151/200
1493/1493 - 96s - loss: 1.4149e-04 - val_loss: 1.4731e-04 - 96s/epoch - 64ms/step
Epoch 152/200
1493/1493 - 96s - loss: 1.4061e-04 - val_loss: 2.4068e-04 - 96s/epoch - 65ms/step
Epoch 153/200
1493/1493 - 96s - loss: 1.4748e-04 - val_loss: 1.6275e-04 - 96s/epoch - 64ms/step
Epoch 154/200
1493/1493 - 96s - loss: 1.4338e-04 - val_loss: 3.4076e-04 - 96s/epoch - 65ms/step
Epoch 155/200
1493/1493 - 96s - loss: 1.7830e-04 - val_loss: 1.5127e-04 - 96s/epoch - 64ms/step
Epoch 156/200
1493/1493 - 96s - loss: 1.4410e-04 - val_loss: 1.6116e-04 - 96s/epoch - 64ms/step
Epoch 157/200
1493/1493 - 96s - loss: 1.3961e-04 - val_loss: 1.6536e-04 - 96s/epoch - 64ms/step
Epoch 158/200
1493/1493 - 96s - loss: 1.4227e-04 - val_loss: 1.4916e-04 - 96s/epoch - 64ms/step
Epoch 159/200
1493/1493 - 96s - loss: 1.3862e-04 - val_loss: 1.5712e-04 - 96s/epoch - 65ms/step
Epoch 160/200
1493/1493 - 96s - loss: 1.3816e-04 - val_loss: 1.6223e-04 - 96s/epoch - 64ms/step
Epoch 161/200
1493/1493 - 96s - loss: 1.4536e-04 - val_loss: 1.4445e-04 - 96s/epoch - 65ms/step
Epoch 162/200
1493/1493 - 96s - loss: 1.3692e-04 - val_loss: 1.5972e-04 - 96s/epoch - 64ms/step
Epoch 163/200
1493/1493 - 96s - loss: 1.3897e-04 - val_loss: 2.7178e-04 - 96s/epoch - 64ms/step
Epoch 164/200
1493/1493 - 96s - loss: 1.6152e-04 - val_loss: 1.4185e-04 - 96s/epoch - 65ms/step
Epoch 165/200
1493/1493 - 96s - loss: 1.4499e-04 - val_loss: 1.4063e-04 - 96s/epoch - 64ms/step
Epoch 166/200
1493/1493 - 96s - loss: 1.3789e-04 - val_loss: 1.5138e-04 - 96s/epoch - 64ms/step
Epoch 167/200
1493/1493 - 96s - loss: 1.3680e-04 - val_loss: 1.3610e-04 - 96s/epoch - 65ms/step
Epoch 168/200
1493/1493 - 96s - loss: 1.3576e-04 - val_loss: 1.5551e-04 - 96s/epoch - 64ms/step
Epoch 169/200
1493/1493 - 96s - loss: 1.3592e-04 - val_loss: 2.0225e-04 - 96s/epoch - 64ms/step
Epoch 170/200
1493/1493 - 96s - loss: 1.3621e-04 - val_loss: 2.7128e-04 - 96s/epoch - 64ms/step
Epoch 171/200
1493/1493 - 96s - loss: 1.6411e-04 - val_loss: 2.9398e-04 - 96s/epoch - 64ms/step
Epoch 172/200
1493/1493 - 96s - loss: 1.5840e-04 - val_loss: 1.6178e-04 - 96s/epoch - 64ms/step
Epoch 173/200
1493/1493 - 96s - loss: 1.3904e-04 - val_loss: 1.4042e-04 - 96s/epoch - 64ms/step
Epoch 174/200
1493/1493 - 96s - loss: 1.3465e-04 - val_loss: 1.4019e-04 - 96s/epoch - 64ms/step
Epoch 175/200
1493/1493 - 96s - loss: 1.3573e-04 - val_loss: 1.4287e-04 - 96s/epoch - 64ms/step
Epoch 176/200
1493/1493 - 96s - loss: 1.3640e-04 - val_loss: 1.4777e-04 - 96s/epoch - 65ms/step
Epoch 177/200
1493/1493 - 96s - loss: 1.3875e-04 - val_loss: 1.3163e-04 - 96s/epoch - 65ms/step
Epoch 178/200
1493/1493 - 96s - loss: 1.3350e-04 - val_loss: 1.4682e-04 - 96s/epoch - 64ms/step
Epoch 179/200
1493/1493 - 96s - loss: 1.3177e-04 - val_loss: 1.4498e-04 - 96s/epoch - 64ms/step
Epoch 180/200
1493/1493 - 96s - loss: 1.3294e-04 - val_loss: 1.7196e-04 - 96s/epoch - 64ms/step
Epoch 181/200
1493/1493 - 96s - loss: 1.4058e-04 - val_loss: 1.7898e-04 - 96s/epoch - 64ms/step
Epoch 182/200
1493/1493 - 96s - loss: 1.3477e-04 - val_loss: 1.5731e-04 - 96s/epoch - 64ms/step
Epoch 183/200
1493/1493 - 96s - loss: 1.3557e-04 - val_loss: 1.8469e-04 - 96s/epoch - 64ms/step
Epoch 184/200
1493/1493 - 96s - loss: 1.3417e-04 - val_loss: 1.3804e-04 - 96s/epoch - 64ms/step
Epoch 185/200
1493/1493 - 96s - loss: 1.2930e-04 - val_loss: 1.6166e-04 - 96s/epoch - 64ms/step
Epoch 186/200
1493/1493 - 96s - loss: 1.3118e-04 - val_loss: 1.4191e-04 - 96s/epoch - 64ms/step
Epoch 187/200
1493/1493 - 96s - loss: 1.2954e-04 - val_loss: 1.3587e-04 - 96s/epoch - 64ms/step
Epoch 188/200
1493/1493 - 96s - loss: 1.3248e-04 - val_loss: 1.6447e-04 - 96s/epoch - 64ms/step
Epoch 189/200
1493/1493 - 96s - loss: 1.3117e-04 - val_loss: 1.4048e-04 - 96s/epoch - 64ms/step
Epoch 190/200
1493/1493 - 96s - loss: 1.3072e-04 - val_loss: 1.7275e-04 - 96s/epoch - 64ms/step
Epoch 191/200
1493/1493 - 96s - loss: 1.3876e-04 - val_loss: 1.6375e-04 - 96s/epoch - 64ms/step
Epoch 192/200
1493/1493 - 96s - loss: 1.3079e-04 - val_loss: 1.5638e-04 - 96s/epoch - 64ms/step
Epoch 193/200
1493/1493 - 96s - loss: 1.3375e-04 - val_loss: 2.9672e-04 - 96s/epoch - 64ms/step
Epoch 194/200
1493/1493 - 96s - loss: 1.6106e-04 - val_loss: 4.0510e-04 - 96s/epoch - 64ms/step
Epoch 195/200
1493/1493 - 96s - loss: 1.7978e-04 - val_loss: 2.0609e-04 - 96s/epoch - 64ms/step
Epoch 196/200
1493/1493 - 96s - loss: 1.4869e-04 - val_loss: 1.2195e-04 - 96s/epoch - 64ms/step
Epoch 197/200
1493/1493 - 96s - loss: 1.3284e-04 - val_loss: 1.3193e-04 - 96s/epoch - 64ms/step
Epoch 198/200
1493/1493 - 96s - loss: 1.3244e-04 - val_loss: 1.9915e-04 - 96s/epoch - 64ms/step
Epoch 199/200
1493/1493 - 96s - loss: 1.3829e-04 - val_loss: 1.2562e-04 - 96s/epoch - 64ms/step
Epoch 200/200
1493/1493 - 96s - loss: 1.2940e-04 - val_loss: 1.4365e-04 - 96s/epoch - 64ms/step
COMPRESSED VECTOR SIZE: 379
Loss in the autoencoder: 0.00014365273818839341
  1/332 [..............................] - ETA: 39s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 3s 36/332 [==>...........................] - ETA: 3s 41/332 [==>...........................] - ETA: 3s 46/332 [===>..........................] - ETA: 3s 51/332 [===>..........................] - ETA: 3s 56/332 [====>.........................] - ETA: 3s 61/332 [====>.........................] - ETA: 3s 66/332 [====>.........................] - ETA: 2s 71/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 2s 81/332 [======>.......................] - ETA: 2s 86/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 96/332 [=======>......................] - ETA: 2s101/332 [========>.....................] - ETA: 2s106/332 [========>.....................] - ETA: 2s111/332 [=========>....................] - ETA: 2s116/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s131/332 [==========>...................] - ETA: 2s136/332 [===========>..................] - ETA: 2s141/332 [===========>..................] - ETA: 2s146/332 [============>.................] - ETA: 2s151/332 [============>.................] - ETA: 2s156/332 [=============>................] - ETA: 1s161/332 [=============>................] - ETA: 1s166/332 [==============>...............] - ETA: 1s171/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 1s196/332 [================>.............] - ETA: 1s201/332 [=================>............] - ETA: 1s206/332 [=================>............] - ETA: 1s211/332 [==================>...........] - ETA: 1s216/332 [==================>...........] - ETA: 1s221/332 [==================>...........] - ETA: 1s226/332 [===================>..........] - ETA: 1s231/332 [===================>..........] - ETA: 1s236/332 [====================>.........] - ETA: 1s241/332 [====================>.........] - ETA: 1s246/332 [=====================>........] - ETA: 0s251/332 [=====================>........] - ETA: 0s256/332 [======================>.......] - ETA: 0s261/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s271/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s286/332 [========================>.....] - ETA: 0s291/332 [=========================>....] - ETA: 0s296/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s306/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s316/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s326/332 [============================>.] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 11ms/step
correlation 0.0016341691944134536
cosine 0.001287530109291925
MAE: 0.006624467
RMSE: 0.011985517
r2: 0.9906815776181207
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_3 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 379)               1053999   
                                                                 
 batch_normalization_4 (Batc  (None, 379)              1516      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 379)               0         
                                                                 
 dense_4 (Dense)             (None, 2780)              1056400   
                                                                 
 batch_normalization_5 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2780)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 9,166,039
Trainable params: 9,154,161
Non-trainable params: 11,878
_________________________________________________________________
Encoder
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_3 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 379)               1053999   
                                                                 
=================================================================
Total params: 4,581,819
Trainable params: 4,576,259
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 379)]             0         
                                                                 
 batch_normalization_4 (Batc  (None, 379)              1516      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 379)               0         
                                                                 
 dense_4 (Dense)             (None, 2780)              1056400   
                                                                 
 batch_normalization_5 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2780)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 4,584,220
Trainable params: 4,577,902
Non-trainable params: 6,318
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.3, 379, 0.0001294043759116903, 0.00014365273818839341, 0.0016341691944134536, 0.001287530109291925, 0.006624467205256224, 0.011985517106950283, 0.9906815776181207, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_6 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_6 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 316)               878796    
                                                                 
 batch_normalization_7 (Batc  (None, 316)              1264      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 316)               0         
                                                                 
 dense_7 (Dense)             (None, 2780)              881260    
                                                                 
 batch_normalization_8 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2780)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,815,444
Trainable params: 8,803,692
Non-trainable params: 11,752
_________________________________________________________________
Epoch 1/200
1493/1493 - 89s - loss: 0.0100 - val_loss: 0.0044 - 89s/epoch - 60ms/step
Epoch 2/200
1493/1493 - 88s - loss: 0.0033 - val_loss: 0.0034 - 88s/epoch - 59ms/step
Epoch 3/200
1493/1493 - 88s - loss: 0.0024 - val_loss: 0.0023 - 88s/epoch - 59ms/step
Epoch 4/200
1493/1493 - 88s - loss: 0.0020 - val_loss: 0.0038 - 88s/epoch - 59ms/step
Epoch 5/200
1493/1493 - 88s - loss: 0.0019 - val_loss: 0.0015 - 88s/epoch - 59ms/step
Epoch 6/200
1493/1493 - 88s - loss: 0.0017 - val_loss: 0.0019 - 88s/epoch - 59ms/step
Epoch 7/200
1493/1493 - 88s - loss: 0.0015 - val_loss: 0.0014 - 88s/epoch - 59ms/step
Epoch 8/200
1493/1493 - 88s - loss: 0.0014 - val_loss: 0.0016 - 88s/epoch - 59ms/step
Epoch 9/200
1493/1493 - 88s - loss: 0.0013 - val_loss: 0.0012 - 88s/epoch - 59ms/step
Epoch 10/200
1493/1493 - 88s - loss: 0.0012 - val_loss: 9.9625e-04 - 88s/epoch - 59ms/step
Epoch 11/200
1493/1493 - 88s - loss: 0.0010 - val_loss: 8.8599e-04 - 88s/epoch - 59ms/step
Epoch 12/200
1493/1493 - 88s - loss: 9.0085e-04 - val_loss: 0.0013 - 88s/epoch - 59ms/step
Epoch 13/200
1493/1493 - 88s - loss: 8.6359e-04 - val_loss: 0.0029 - 88s/epoch - 59ms/step
Epoch 14/200
1493/1493 - 88s - loss: 0.0011 - val_loss: 7.7084e-04 - 88s/epoch - 59ms/step
Epoch 15/200
1493/1493 - 88s - loss: 7.7614e-04 - val_loss: 7.0908e-04 - 88s/epoch - 59ms/step
Epoch 16/200
1493/1493 - 88s - loss: 6.9393e-04 - val_loss: 6.1016e-04 - 88s/epoch - 59ms/step
Epoch 17/200
1493/1493 - 88s - loss: 6.3700e-04 - val_loss: 0.0012 - 88s/epoch - 59ms/step
Epoch 18/200
1493/1493 - 88s - loss: 6.5857e-04 - val_loss: 7.9856e-04 - 88s/epoch - 59ms/step
Epoch 19/200
1493/1493 - 88s - loss: 6.0446e-04 - val_loss: 6.3729e-04 - 88s/epoch - 59ms/step
Epoch 20/200
1493/1493 - 88s - loss: 5.5686e-04 - val_loss: 5.3258e-04 - 88s/epoch - 59ms/step
Epoch 21/200
1493/1493 - 88s - loss: 5.3205e-04 - val_loss: 6.7910e-04 - 88s/epoch - 59ms/step
Epoch 22/200
1493/1493 - 88s - loss: 5.1110e-04 - val_loss: 7.4161e-04 - 88s/epoch - 59ms/step
Epoch 23/200
1493/1493 - 88s - loss: 5.4756e-04 - val_loss: 0.0012 - 88s/epoch - 59ms/step
Epoch 24/200
1493/1493 - 88s - loss: 5.9745e-04 - val_loss: 4.6182e-04 - 88s/epoch - 59ms/step
Epoch 25/200
1493/1493 - 90s - loss: 4.5949e-04 - val_loss: 4.6708e-04 - 90s/epoch - 60ms/step
Epoch 26/200
1493/1493 - 90s - loss: 4.4355e-04 - val_loss: 5.7115e-04 - 90s/epoch - 60ms/step
Epoch 27/200
1493/1493 - 90s - loss: 4.2840e-04 - val_loss: 4.1066e-04 - 90s/epoch - 60ms/step
Epoch 28/200
1493/1493 - 90s - loss: 4.0704e-04 - val_loss: 6.2793e-04 - 90s/epoch - 60ms/step
Epoch 29/200
1493/1493 - 90s - loss: 4.0187e-04 - val_loss: 4.9480e-04 - 90s/epoch - 60ms/step
Epoch 30/200
1493/1493 - 91s - loss: 4.0056e-04 - val_loss: 3.8509e-04 - 91s/epoch - 61ms/step
Epoch 31/200
1493/1493 - 91s - loss: 3.7756e-04 - val_loss: 5.0582e-04 - 91s/epoch - 61ms/step
Epoch 32/200
1493/1493 - 91s - loss: 3.9477e-04 - val_loss: 4.0180e-04 - 91s/epoch - 61ms/step
Epoch 33/200
1493/1493 - 91s - loss: 3.6655e-04 - val_loss: 3.4965e-04 - 91s/epoch - 61ms/step
Epoch 34/200
1493/1493 - 91s - loss: 3.5228e-04 - val_loss: 3.6107e-04 - 91s/epoch - 61ms/step
Epoch 35/200
1493/1493 - 91s - loss: 3.4008e-04 - val_loss: 6.3472e-04 - 91s/epoch - 61ms/step
Epoch 36/200
1493/1493 - 90s - loss: 3.6684e-04 - val_loss: 3.8494e-04 - 90s/epoch - 61ms/step
Epoch 37/200
1493/1493 - 90s - loss: 3.3514e-04 - val_loss: 4.6611e-04 - 90s/epoch - 60ms/step
Epoch 38/200
1493/1493 - 90s - loss: 3.5359e-04 - val_loss: 3.2321e-04 - 90s/epoch - 60ms/step
Epoch 39/200
1493/1493 - 90s - loss: 3.2043e-04 - val_loss: 3.1782e-04 - 90s/epoch - 60ms/step
Epoch 40/200
1493/1493 - 90s - loss: 3.1037e-04 - val_loss: 3.5813e-04 - 90s/epoch - 60ms/step
Epoch 41/200
1493/1493 - 90s - loss: 3.0998e-04 - val_loss: 2.8981e-04 - 90s/epoch - 60ms/step
Epoch 42/200
1493/1493 - 90s - loss: 3.0501e-04 - val_loss: 2.8728e-04 - 90s/epoch - 60ms/step
Epoch 43/200
1493/1493 - 88s - loss: 2.9908e-04 - val_loss: 4.2706e-04 - 88s/epoch - 59ms/step
Epoch 44/200
1493/1493 - 89s - loss: 3.2797e-04 - val_loss: 4.8997e-04 - 89s/epoch - 60ms/step
Epoch 45/200
1493/1493 - 89s - loss: 3.1202e-04 - val_loss: 2.6327e-04 - 89s/epoch - 60ms/step
Epoch 46/200
1493/1493 - 89s - loss: 2.9112e-04 - val_loss: 2.7096e-04 - 89s/epoch - 60ms/step
Epoch 47/200
1493/1493 - 89s - loss: 2.8616e-04 - val_loss: 3.3405e-04 - 89s/epoch - 60ms/step
Epoch 48/200
1493/1493 - 89s - loss: 2.8245e-04 - val_loss: 3.5081e-04 - 89s/epoch - 60ms/step
Epoch 49/200
1493/1493 - 89s - loss: 2.8288e-04 - val_loss: 5.2656e-04 - 89s/epoch - 60ms/step
Epoch 50/200
1493/1493 - 89s - loss: 3.0429e-04 - val_loss: 3.5957e-04 - 89s/epoch - 60ms/step
Epoch 51/200
1493/1493 - 89s - loss: 2.8005e-04 - val_loss: 2.7034e-04 - 89s/epoch - 60ms/step
Epoch 52/200
1493/1493 - 89s - loss: 2.6508e-04 - val_loss: 2.6940e-04 - 89s/epoch - 60ms/step
Epoch 53/200
1493/1493 - 89s - loss: 2.6684e-04 - val_loss: 2.6018e-04 - 89s/epoch - 60ms/step
Epoch 54/200
1493/1493 - 89s - loss: 2.6320e-04 - val_loss: 2.8859e-04 - 89s/epoch - 60ms/step
Epoch 55/200
1493/1493 - 89s - loss: 2.5445e-04 - val_loss: 2.6660e-04 - 89s/epoch - 60ms/step
Epoch 56/200
1493/1493 - 89s - loss: 2.5359e-04 - val_loss: 2.8250e-04 - 89s/epoch - 60ms/step
Epoch 57/200
1493/1493 - 89s - loss: 2.4965e-04 - val_loss: 2.7151e-04 - 89s/epoch - 60ms/step
Epoch 58/200
1493/1493 - 89s - loss: 2.4879e-04 - val_loss: 2.3069e-04 - 89s/epoch - 60ms/step
Epoch 59/200
1493/1493 - 89s - loss: 2.4445e-04 - val_loss: 2.6633e-04 - 89s/epoch - 60ms/step
Epoch 60/200
1493/1493 - 89s - loss: 2.4569e-04 - val_loss: 4.8398e-04 - 89s/epoch - 60ms/step
Epoch 61/200
1493/1493 - 89s - loss: 3.1058e-04 - val_loss: 2.3578e-04 - 89s/epoch - 60ms/step
Epoch 62/200
1493/1493 - 90s - loss: 2.5055e-04 - val_loss: 2.3999e-04 - 90s/epoch - 60ms/step
Epoch 63/200
1493/1493 - 88s - loss: 2.3888e-04 - val_loss: 2.9046e-04 - 88s/epoch - 59ms/step
Epoch 64/200
1493/1493 - 89s - loss: 2.4018e-04 - val_loss: 0.0010 - 89s/epoch - 60ms/step
Epoch 65/200
1493/1493 - 89s - loss: 3.2133e-04 - val_loss: 3.4443e-04 - 89s/epoch - 60ms/step
Epoch 66/200
1493/1493 - 89s - loss: 2.5250e-04 - val_loss: 2.3885e-04 - 89s/epoch - 60ms/step
Epoch 67/200
1493/1493 - 89s - loss: 2.3584e-04 - val_loss: 2.2652e-04 - 89s/epoch - 60ms/step
Epoch 68/200
1493/1493 - 89s - loss: 2.3029e-04 - val_loss: 2.8762e-04 - 89s/epoch - 60ms/step
Epoch 69/200
1493/1493 - 89s - loss: 2.3892e-04 - val_loss: 2.4578e-04 - 89s/epoch - 60ms/step
Epoch 70/200
1493/1493 - 89s - loss: 2.2874e-04 - val_loss: 4.7199e-04 - 89s/epoch - 60ms/step
Epoch 71/200
1493/1493 - 89s - loss: 2.8060e-04 - val_loss: 2.1093e-04 - 89s/epoch - 60ms/step
Epoch 72/200
1493/1493 - 89s - loss: 2.3092e-04 - val_loss: 2.4649e-04 - 89s/epoch - 60ms/step
Epoch 73/200
1493/1493 - 89s - loss: 2.2932e-04 - val_loss: 2.3422e-04 - 89s/epoch - 60ms/step
Epoch 74/200
1493/1493 - 89s - loss: 2.2624e-04 - val_loss: 2.3357e-04 - 89s/epoch - 60ms/step
Epoch 75/200
1493/1493 - 89s - loss: 2.1948e-04 - val_loss: 2.1388e-04 - 89s/epoch - 60ms/step
Epoch 76/200
1493/1493 - 89s - loss: 2.1804e-04 - val_loss: 2.2053e-04 - 89s/epoch - 60ms/step
Epoch 77/200
1493/1493 - 89s - loss: 2.1761e-04 - val_loss: 3.1008e-04 - 89s/epoch - 59ms/step
Epoch 78/200
1493/1493 - 89s - loss: 2.2491e-04 - val_loss: 2.4863e-04 - 89s/epoch - 60ms/step
Epoch 79/200
1493/1493 - 89s - loss: 2.2044e-04 - val_loss: 2.9583e-04 - 89s/epoch - 60ms/step
Epoch 80/200
1493/1493 - 89s - loss: 2.3125e-04 - val_loss: 2.3131e-04 - 89s/epoch - 60ms/step
Epoch 81/200
1493/1493 - 89s - loss: 2.1427e-04 - val_loss: 3.4444e-04 - 89s/epoch - 60ms/step
Epoch 82/200
1493/1493 - 89s - loss: 2.1127e-04 - val_loss: 2.1665e-04 - 89s/epoch - 60ms/step
Epoch 83/200
1493/1493 - 89s - loss: 2.0689e-04 - val_loss: 2.1715e-04 - 89s/epoch - 60ms/step
Epoch 84/200
1493/1493 - 89s - loss: 2.0708e-04 - val_loss: 2.2407e-04 - 89s/epoch - 60ms/step
Epoch 85/200
1493/1493 - 89s - loss: 2.2018e-04 - val_loss: 2.4724e-04 - 89s/epoch - 60ms/step
Epoch 86/200
1493/1493 - 89s - loss: 2.1298e-04 - val_loss: 2.0352e-04 - 89s/epoch - 60ms/step
Epoch 87/200
1493/1493 - 89s - loss: 2.0297e-04 - val_loss: 1.9230e-04 - 89s/epoch - 60ms/step
Epoch 88/200
1493/1493 - 89s - loss: 2.0163e-04 - val_loss: 2.7367e-04 - 89s/epoch - 60ms/step
Epoch 89/200
1493/1493 - 89s - loss: 2.1505e-04 - val_loss: 2.1878e-04 - 89s/epoch - 60ms/step
Epoch 90/200
1493/1493 - 89s - loss: 1.9913e-04 - val_loss: 2.1833e-04 - 89s/epoch - 60ms/step
Epoch 91/200
1493/1493 - 89s - loss: 1.9747e-04 - val_loss: 2.2571e-04 - 89s/epoch - 60ms/step
Epoch 92/200
1493/1493 - 89s - loss: 1.9987e-04 - val_loss: 4.7942e-04 - 89s/epoch - 60ms/step
Epoch 93/200
1493/1493 - 89s - loss: 2.5739e-04 - val_loss: 1.9541e-04 - 89s/epoch - 60ms/step
Epoch 94/200
1493/1493 - 89s - loss: 2.0166e-04 - val_loss: 1.8554e-04 - 89s/epoch - 60ms/step
Epoch 95/200
1493/1493 - 89s - loss: 1.9696e-04 - val_loss: 2.1745e-04 - 89s/epoch - 60ms/step
Epoch 96/200
1493/1493 - 89s - loss: 1.9678e-04 - val_loss: 2.2325e-04 - 89s/epoch - 60ms/step
Epoch 97/200
1493/1493 - 89s - loss: 1.9434e-04 - val_loss: 2.0127e-04 - 89s/epoch - 60ms/step
Epoch 98/200
1493/1493 - 89s - loss: 2.0114e-04 - val_loss: 6.1101e-04 - 89s/epoch - 60ms/step
Epoch 99/200
1493/1493 - 89s - loss: 2.8475e-04 - val_loss: 1.9118e-04 - 89s/epoch - 60ms/step
Epoch 100/200
1493/1493 - 89s - loss: 2.0571e-04 - val_loss: 1.8952e-04 - 89s/epoch - 60ms/step
Epoch 101/200
1493/1493 - 89s - loss: 1.9538e-04 - val_loss: 2.1901e-04 - 89s/epoch - 60ms/step
Epoch 102/200
1493/1493 - 89s - loss: 1.9921e-04 - val_loss: 2.4524e-04 - 89s/epoch - 60ms/step
Epoch 103/200
1493/1493 - 89s - loss: 1.9696e-04 - val_loss: 1.9176e-04 - 89s/epoch - 60ms/step
Epoch 104/200
1493/1493 - 89s - loss: 1.9069e-04 - val_loss: 4.1632e-04 - 89s/epoch - 60ms/step
Epoch 105/200
1493/1493 - 90s - loss: 2.1372e-04 - val_loss: 1.8277e-04 - 90s/epoch - 60ms/step
Epoch 106/200
1493/1493 - 90s - loss: 1.8825e-04 - val_loss: 2.1286e-04 - 90s/epoch - 60ms/step
Epoch 107/200
1493/1493 - 90s - loss: 1.8697e-04 - val_loss: 2.5562e-04 - 90s/epoch - 60ms/step
Epoch 108/200
1493/1493 - 89s - loss: 1.8977e-04 - val_loss: 2.0643e-04 - 89s/epoch - 60ms/step
Epoch 109/200
1493/1493 - 89s - loss: 1.8649e-04 - val_loss: 1.9891e-04 - 89s/epoch - 60ms/step
Epoch 110/200
1493/1493 - 89s - loss: 1.8395e-04 - val_loss: 2.0134e-04 - 89s/epoch - 60ms/step
Epoch 111/200
1493/1493 - 89s - loss: 1.8326e-04 - val_loss: 2.0681e-04 - 89s/epoch - 60ms/step
Epoch 112/200
1493/1493 - 89s - loss: 1.9146e-04 - val_loss: 1.8634e-04 - 89s/epoch - 60ms/step
Epoch 113/200
1493/1493 - 89s - loss: 1.8419e-04 - val_loss: 4.0817e-04 - 89s/epoch - 60ms/step
Epoch 114/200
1493/1493 - 89s - loss: 2.3640e-04 - val_loss: 1.9547e-04 - 89s/epoch - 60ms/step
Epoch 115/200
1493/1493 - 89s - loss: 1.8872e-04 - val_loss: 2.3617e-04 - 89s/epoch - 60ms/step
Epoch 116/200
1493/1493 - 89s - loss: 1.8223e-04 - val_loss: 2.0738e-04 - 89s/epoch - 60ms/step
Epoch 117/200
1493/1493 - 89s - loss: 1.8032e-04 - val_loss: 2.3322e-04 - 89s/epoch - 60ms/step
Epoch 118/200
1493/1493 - 89s - loss: 1.8796e-04 - val_loss: 1.7469e-04 - 89s/epoch - 60ms/step
Epoch 119/200
1493/1493 - 90s - loss: 1.7976e-04 - val_loss: 1.8670e-04 - 90s/epoch - 60ms/step
Epoch 120/200
1493/1493 - 90s - loss: 1.7814e-04 - val_loss: 1.8785e-04 - 90s/epoch - 60ms/step
Epoch 121/200
1493/1493 - 90s - loss: 1.7863e-04 - val_loss: 2.4553e-04 - 90s/epoch - 60ms/step
Epoch 122/200
1493/1493 - 90s - loss: 1.7962e-04 - val_loss: 1.7739e-04 - 90s/epoch - 60ms/step
Epoch 123/200
1493/1493 - 89s - loss: 1.7548e-04 - val_loss: 1.9223e-04 - 89s/epoch - 60ms/step
Epoch 124/200
1493/1493 - 89s - loss: 1.7647e-04 - val_loss: 4.7495e-04 - 89s/epoch - 60ms/step
Epoch 125/200
1493/1493 - 90s - loss: 2.0901e-04 - val_loss: 1.9091e-04 - 90s/epoch - 60ms/step
Epoch 126/200
1493/1493 - 90s - loss: 2.0345e-04 - val_loss: 0.0011 - 90s/epoch - 60ms/step
Epoch 127/200
1493/1493 - 90s - loss: 2.8110e-04 - val_loss: 2.8905e-04 - 90s/epoch - 60ms/step
Epoch 128/200
1493/1493 - 89s - loss: 2.0121e-04 - val_loss: 1.6679e-04 - 89s/epoch - 60ms/step
Epoch 129/200
1493/1493 - 90s - loss: 1.8021e-04 - val_loss: 1.7163e-04 - 90s/epoch - 60ms/step
Epoch 130/200
1493/1493 - 89s - loss: 1.7791e-04 - val_loss: 1.6870e-04 - 89s/epoch - 60ms/step
Epoch 131/200
1493/1493 - 89s - loss: 1.7949e-04 - val_loss: 3.5268e-04 - 89s/epoch - 60ms/step
Epoch 132/200
1493/1493 - 89s - loss: 2.1635e-04 - val_loss: 1.6578e-04 - 89s/epoch - 60ms/step
Epoch 133/200
1493/1493 - 90s - loss: 1.7928e-04 - val_loss: 1.6992e-04 - 90s/epoch - 60ms/step
Epoch 134/200
1493/1493 - 89s - loss: 1.7406e-04 - val_loss: 1.9753e-04 - 89s/epoch - 60ms/step
Epoch 135/200
1493/1493 - 90s - loss: 1.7320e-04 - val_loss: 1.6966e-04 - 90s/epoch - 60ms/step
Epoch 136/200
1493/1493 - 90s - loss: 1.7185e-04 - val_loss: 1.8262e-04 - 90s/epoch - 60ms/step
Epoch 137/200
1493/1493 - 89s - loss: 1.7794e-04 - val_loss: 2.4307e-04 - 89s/epoch - 60ms/step
Epoch 138/200
1493/1493 - 90s - loss: 1.8775e-04 - val_loss: 2.0161e-04 - 90s/epoch - 60ms/step
Epoch 139/200
1493/1493 - 89s - loss: 1.8296e-04 - val_loss: 2.4033e-04 - 89s/epoch - 60ms/step
Epoch 140/200
1493/1493 - 90s - loss: 2.0299e-04 - val_loss: 1.7229e-04 - 90s/epoch - 60ms/step
Epoch 141/200
1493/1493 - 89s - loss: 1.7350e-04 - val_loss: 2.6109e-04 - 89s/epoch - 60ms/step
Epoch 142/200
1493/1493 - 90s - loss: 1.9083e-04 - val_loss: 1.7072e-04 - 90s/epoch - 60ms/step
Epoch 143/200
1493/1493 - 88s - loss: 1.6980e-04 - val_loss: 1.8743e-04 - 88s/epoch - 59ms/step
Epoch 144/200
1493/1493 - 89s - loss: 1.7438e-04 - val_loss: 1.7397e-04 - 89s/epoch - 59ms/step
Epoch 145/200
1493/1493 - 89s - loss: 1.6860e-04 - val_loss: 1.7596e-04 - 89s/epoch - 59ms/step
Epoch 146/200
1493/1493 - 89s - loss: 1.6705e-04 - val_loss: 1.6529e-04 - 89s/epoch - 59ms/step
Epoch 147/200
1493/1493 - 89s - loss: 1.6485e-04 - val_loss: 1.7263e-04 - 89s/epoch - 60ms/step
Epoch 148/200
1493/1493 - 89s - loss: 1.6525e-04 - val_loss: 2.4459e-04 - 89s/epoch - 59ms/step
Epoch 149/200
1493/1493 - 89s - loss: 1.6428e-04 - val_loss: 1.7616e-04 - 89s/epoch - 60ms/step
Epoch 150/200
1493/1493 - 89s - loss: 1.6287e-04 - val_loss: 1.6193e-04 - 89s/epoch - 59ms/step
Epoch 151/200
1493/1493 - 89s - loss: 1.8006e-04 - val_loss: 1.7354e-04 - 89s/epoch - 60ms/step
Epoch 152/200
1493/1493 - 89s - loss: 1.6674e-04 - val_loss: 2.4629e-04 - 89s/epoch - 59ms/step
Epoch 153/200
1493/1493 - 88s - loss: 1.7181e-04 - val_loss: 1.7876e-04 - 88s/epoch - 59ms/step
Epoch 154/200
1493/1493 - 86s - loss: 1.6332e-04 - val_loss: 2.2572e-04 - 86s/epoch - 57ms/step
Epoch 155/200
1493/1493 - 86s - loss: 1.7475e-04 - val_loss: 1.7586e-04 - 86s/epoch - 57ms/step
Epoch 156/200
1493/1493 - 86s - loss: 1.6393e-04 - val_loss: 1.7988e-04 - 86s/epoch - 57ms/step
Epoch 157/200
1493/1493 - 86s - loss: 1.6063e-04 - val_loss: 1.9219e-04 - 86s/epoch - 58ms/step
Epoch 158/200
1493/1493 - 86s - loss: 1.6423e-04 - val_loss: 1.6624e-04 - 86s/epoch - 58ms/step
Epoch 159/200
1493/1493 - 86s - loss: 1.5988e-04 - val_loss: 1.6325e-04 - 86s/epoch - 57ms/step
Epoch 160/200
1493/1493 - 86s - loss: 1.6008e-04 - val_loss: 2.0041e-04 - 86s/epoch - 58ms/step
Epoch 161/200
1493/1493 - 86s - loss: 1.7407e-04 - val_loss: 1.6960e-04 - 86s/epoch - 58ms/step
Epoch 162/200
1493/1493 - 86s - loss: 1.5904e-04 - val_loss: 1.5690e-04 - 86s/epoch - 58ms/step
Epoch 163/200
1493/1493 - 87s - loss: 1.6129e-04 - val_loss: 2.3427e-04 - 87s/epoch - 58ms/step
Epoch 164/200
1493/1493 - 87s - loss: 1.7690e-04 - val_loss: 1.6027e-04 - 87s/epoch - 58ms/step
Epoch 165/200
1493/1493 - 86s - loss: 1.8481e-04 - val_loss: 1.5982e-04 - 86s/epoch - 58ms/step
Epoch 166/200
1493/1493 - 86s - loss: 1.6028e-04 - val_loss: 1.6366e-04 - 86s/epoch - 57ms/step
Epoch 167/200
1493/1493 - 86s - loss: 1.5919e-04 - val_loss: 1.5401e-04 - 86s/epoch - 57ms/step
Epoch 168/200
1493/1493 - 86s - loss: 1.5804e-04 - val_loss: 1.7028e-04 - 86s/epoch - 58ms/step
Epoch 169/200
1493/1493 - 86s - loss: 1.5806e-04 - val_loss: 1.9812e-04 - 86s/epoch - 58ms/step
Epoch 170/200
1493/1493 - 86s - loss: 1.5602e-04 - val_loss: 1.9945e-04 - 86s/epoch - 57ms/step
Epoch 171/200
1493/1493 - 86s - loss: 1.6891e-04 - val_loss: 3.1168e-04 - 86s/epoch - 57ms/step
Epoch 172/200
1493/1493 - 86s - loss: 1.9094e-04 - val_loss: 2.7008e-04 - 86s/epoch - 57ms/step
Epoch 173/200
1493/1493 - 86s - loss: 1.7040e-04 - val_loss: 1.5068e-04 - 86s/epoch - 57ms/step
Epoch 174/200
1493/1493 - 86s - loss: 1.5692e-04 - val_loss: 1.5206e-04 - 86s/epoch - 57ms/step
Epoch 175/200
1493/1493 - 86s - loss: 1.5768e-04 - val_loss: 1.6581e-04 - 86s/epoch - 57ms/step
Epoch 176/200
1493/1493 - 86s - loss: 1.5863e-04 - val_loss: 1.7799e-04 - 86s/epoch - 57ms/step
Epoch 177/200
1493/1493 - 86s - loss: 1.6150e-04 - val_loss: 1.5467e-04 - 86s/epoch - 58ms/step
Epoch 178/200
1493/1493 - 86s - loss: 1.5505e-04 - val_loss: 1.5772e-04 - 86s/epoch - 57ms/step
Epoch 179/200
1493/1493 - 86s - loss: 1.5382e-04 - val_loss: 1.5953e-04 - 86s/epoch - 57ms/step
Epoch 180/200
1493/1493 - 86s - loss: 1.5359e-04 - val_loss: 1.7624e-04 - 86s/epoch - 58ms/step
Epoch 181/200
1493/1493 - 86s - loss: 1.5381e-04 - val_loss: 1.9084e-04 - 86s/epoch - 58ms/step
Epoch 182/200
1493/1493 - 86s - loss: 1.5834e-04 - val_loss: 1.7210e-04 - 86s/epoch - 58ms/step
Epoch 183/200
1493/1493 - 86s - loss: 1.5440e-04 - val_loss: 1.9357e-04 - 86s/epoch - 58ms/step
Epoch 184/200
1493/1493 - 86s - loss: 1.5531e-04 - val_loss: 1.5410e-04 - 86s/epoch - 58ms/step
Epoch 185/200
1493/1493 - 86s - loss: 1.5041e-04 - val_loss: 1.9460e-04 - 86s/epoch - 58ms/step
Epoch 186/200
1493/1493 - 87s - loss: 1.5236e-04 - val_loss: 1.7307e-04 - 87s/epoch - 58ms/step
Epoch 187/200
1493/1493 - 87s - loss: 1.5565e-04 - val_loss: 3.1184e-04 - 87s/epoch - 58ms/step
Epoch 188/200
1493/1493 - 87s - loss: 2.0601e-04 - val_loss: 2.1557e-04 - 87s/epoch - 58ms/step
Epoch 189/200
1493/1493 - 86s - loss: 1.6916e-04 - val_loss: 1.5167e-04 - 86s/epoch - 58ms/step
Epoch 190/200
1493/1493 - 86s - loss: 1.5752e-04 - val_loss: 1.6968e-04 - 86s/epoch - 58ms/step
Epoch 191/200
1493/1493 - 87s - loss: 1.5523e-04 - val_loss: 2.0497e-04 - 87s/epoch - 58ms/step
Epoch 192/200
1493/1493 - 87s - loss: 1.6435e-04 - val_loss: 1.7758e-04 - 87s/epoch - 58ms/step
Epoch 193/200
1493/1493 - 87s - loss: 1.6345e-04 - val_loss: 2.7627e-04 - 87s/epoch - 58ms/step
Epoch 194/200
1493/1493 - 87s - loss: 1.9036e-04 - val_loss: 4.6821e-04 - 87s/epoch - 58ms/step
Epoch 195/200
1493/1493 - 87s - loss: 2.1352e-04 - val_loss: 3.7135e-04 - 87s/epoch - 58ms/step
Epoch 196/200
1493/1493 - 87s - loss: 2.0051e-04 - val_loss: 1.4720e-04 - 87s/epoch - 58ms/step
Epoch 197/200
1493/1493 - 87s - loss: 1.6027e-04 - val_loss: 1.9175e-04 - 87s/epoch - 58ms/step
Epoch 198/200
1493/1493 - 87s - loss: 1.6274e-04 - val_loss: 1.6725e-04 - 87s/epoch - 58ms/step
Epoch 199/200
1493/1493 - 87s - loss: 1.5755e-04 - val_loss: 1.5068e-04 - 87s/epoch - 58ms/step
Epoch 200/200
1493/1493 - 87s - loss: 1.5313e-04 - val_loss: 1.6425e-04 - 87s/epoch - 58ms/step
COMPRESSED VECTOR SIZE: 316
Loss in the autoencoder: 0.00016424787463620305
  1/332 [..............................] - ETA: 40s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 3s 36/332 [==>...........................] - ETA: 3s 41/332 [==>...........................] - ETA: 3s 46/332 [===>..........................] - ETA: 3s 51/332 [===>..........................] - ETA: 3s 56/332 [====>.........................] - ETA: 3s 61/332 [====>.........................] - ETA: 2s 66/332 [====>.........................] - ETA: 2s 71/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 2s 81/332 [======>.......................] - ETA: 2s 86/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 96/332 [=======>......................] - ETA: 2s101/332 [========>.....................] - ETA: 2s106/332 [========>.....................] - ETA: 2s111/332 [=========>....................] - ETA: 2s116/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s131/332 [==========>...................] - ETA: 2s136/332 [===========>..................] - ETA: 2s141/332 [===========>..................] - ETA: 2s146/332 [============>.................] - ETA: 2s151/332 [============>.................] - ETA: 1s156/332 [=============>................] - ETA: 1s161/332 [=============>................] - ETA: 1s166/332 [==============>...............] - ETA: 1s171/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 1s196/332 [================>.............] - ETA: 1s201/332 [=================>............] - ETA: 1s206/332 [=================>............] - ETA: 1s211/332 [==================>...........] - ETA: 1s216/332 [==================>...........] - ETA: 1s221/332 [==================>...........] - ETA: 1s226/332 [===================>..........] - ETA: 1s231/332 [===================>..........] - ETA: 1s236/332 [====================>.........] - ETA: 1s241/332 [====================>.........] - ETA: 0s246/332 [=====================>........] - ETA: 0s251/332 [=====================>........] - ETA: 0s256/332 [======================>.......] - ETA: 0s261/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s271/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s286/332 [========================>.....] - ETA: 0s291/332 [=========================>....] - ETA: 0s296/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s306/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s316/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s326/332 [============================>.] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 11ms/step
correlation 0.001890127468100144
cosine 0.0014886732174233135
MAE: 0.006962026
RMSE: 0.012815917
r2: 0.9893456367981057
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_6 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 316)               878796    
                                                                 
 batch_normalization_7 (Batc  (None, 316)              1264      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 316)               0         
                                                                 
 dense_7 (Dense)             (None, 2780)              881260    
                                                                 
 batch_normalization_8 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2780)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,815,444
Trainable params: 8,803,692
Non-trainable params: 11,752
_________________________________________________________________
Encoder
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_6 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 316)               878796    
                                                                 
=================================================================
Total params: 4,406,616
Trainable params: 4,401,056
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 316)]             0         
                                                                 
 batch_normalization_7 (Batc  (None, 316)              1264      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 316)               0         
                                                                 
 dense_7 (Dense)             (None, 2780)              881260    
                                                                 
 batch_normalization_8 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2780)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 4,408,828
Trainable params: 4,402,636
Non-trainable params: 6,192
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.25, 316, 0.00015312973118852824, 0.00016424787463620305, 0.001890127468100144, 0.0014886732174233135, 0.0069620260037481785, 0.012815916910767555, 0.9893456367981057, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_9 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_9 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 252)               700812    
                                                                 
 batch_normalization_10 (Bat  (None, 252)              1008      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 252)               0         
                                                                 
 dense_10 (Dense)            (None, 2780)              703340    
                                                                 
 batch_normalization_11 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2780)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,459,284
Trainable params: 8,447,660
Non-trainable params: 11,624
_________________________________________________________________
Epoch 1/200
1493/1493 - 83s - loss: 0.0102 - val_loss: 0.0050 - 83s/epoch - 56ms/step
Epoch 2/200
1493/1493 - 82s - loss: 0.0035 - val_loss: 0.0035 - 82s/epoch - 55ms/step
Epoch 3/200
1493/1493 - 82s - loss: 0.0026 - val_loss: 0.0021 - 82s/epoch - 55ms/step
Epoch 4/200
1493/1493 - 82s - loss: 0.0021 - val_loss: 0.0039 - 82s/epoch - 55ms/step
Epoch 5/200
1493/1493 - 82s - loss: 0.0020 - val_loss: 0.0018 - 82s/epoch - 55ms/step
Epoch 6/200
1493/1493 - 82s - loss: 0.0018 - val_loss: 0.0017 - 82s/epoch - 55ms/step
Epoch 7/200
1493/1493 - 82s - loss: 0.0017 - val_loss: 0.0014 - 82s/epoch - 55ms/step
Epoch 8/200
1493/1493 - 82s - loss: 0.0015 - val_loss: 0.0015 - 82s/epoch - 55ms/step
Epoch 9/200
1493/1493 - 82s - loss: 0.0013 - val_loss: 0.0011 - 82s/epoch - 55ms/step
Epoch 10/200
1493/1493 - 82s - loss: 0.0012 - val_loss: 0.0011 - 82s/epoch - 55ms/step
Epoch 11/200
1493/1493 - 82s - loss: 0.0011 - val_loss: 8.9594e-04 - 82s/epoch - 55ms/step
Epoch 12/200
1493/1493 - 82s - loss: 9.5300e-04 - val_loss: 0.0014 - 82s/epoch - 55ms/step
Epoch 13/200
1493/1493 - 82s - loss: 9.0774e-04 - val_loss: 0.0011 - 82s/epoch - 55ms/step
Epoch 14/200
1493/1493 - 82s - loss: 8.7482e-04 - val_loss: 7.0481e-04 - 82s/epoch - 55ms/step
Epoch 15/200
1493/1493 - 82s - loss: 7.8665e-04 - val_loss: 7.7708e-04 - 82s/epoch - 55ms/step
Epoch 16/200
1493/1493 - 82s - loss: 7.3286e-04 - val_loss: 6.2429e-04 - 82s/epoch - 55ms/step
Epoch 17/200
1493/1493 - 82s - loss: 6.7857e-04 - val_loss: 7.1289e-04 - 82s/epoch - 55ms/step
Epoch 18/200
1493/1493 - 82s - loss: 6.4239e-04 - val_loss: 8.1061e-04 - 82s/epoch - 55ms/step
Epoch 19/200
1493/1493 - 82s - loss: 6.1910e-04 - val_loss: 8.2101e-04 - 82s/epoch - 55ms/step
Epoch 20/200
1493/1493 - 82s - loss: 6.0524e-04 - val_loss: 5.3230e-04 - 82s/epoch - 55ms/step
Epoch 21/200
1493/1493 - 82s - loss: 5.6229e-04 - val_loss: 6.6217e-04 - 82s/epoch - 55ms/step
Epoch 22/200
1493/1493 - 82s - loss: 5.5850e-04 - val_loss: 5.9755e-04 - 82s/epoch - 55ms/step
Epoch 23/200
1493/1493 - 82s - loss: 5.3321e-04 - val_loss: 6.2137e-04 - 82s/epoch - 55ms/step
Epoch 24/200
1493/1493 - 82s - loss: 5.3663e-04 - val_loss: 4.8970e-04 - 82s/epoch - 55ms/step
Epoch 25/200
1493/1493 - 82s - loss: 4.8972e-04 - val_loss: 4.6215e-04 - 82s/epoch - 55ms/step
Epoch 26/200
1493/1493 - 82s - loss: 4.7015e-04 - val_loss: 5.9272e-04 - 82s/epoch - 55ms/step
Epoch 27/200
1493/1493 - 82s - loss: 4.6443e-04 - val_loss: 4.4805e-04 - 82s/epoch - 55ms/step
Epoch 28/200
1493/1493 - 82s - loss: 4.4434e-04 - val_loss: 5.4587e-04 - 82s/epoch - 55ms/step
Epoch 29/200
1493/1493 - 82s - loss: 4.3368e-04 - val_loss: 6.4021e-04 - 82s/epoch - 55ms/step
Epoch 30/200
1493/1493 - 82s - loss: 4.7178e-04 - val_loss: 4.4665e-04 - 82s/epoch - 55ms/step
Epoch 31/200
1493/1493 - 82s - loss: 4.1887e-04 - val_loss: 4.6283e-04 - 82s/epoch - 55ms/step
Epoch 32/200
1493/1493 - 82s - loss: 4.1272e-04 - val_loss: 3.9765e-04 - 82s/epoch - 55ms/step
Epoch 33/200
1493/1493 - 82s - loss: 3.9970e-04 - val_loss: 3.6930e-04 - 82s/epoch - 55ms/step
Epoch 34/200
1493/1493 - 82s - loss: 3.9092e-04 - val_loss: 3.8525e-04 - 82s/epoch - 55ms/step
Epoch 35/200
1493/1493 - 83s - loss: 3.7968e-04 - val_loss: 7.1576e-04 - 83s/epoch - 56ms/step
Epoch 36/200
1493/1493 - 83s - loss: 4.1142e-04 - val_loss: 4.1526e-04 - 83s/epoch - 56ms/step
Epoch 37/200
1493/1493 - 83s - loss: 3.7657e-04 - val_loss: 5.4289e-04 - 83s/epoch - 56ms/step
Epoch 38/200
1493/1493 - 83s - loss: 3.9056e-04 - val_loss: 3.6268e-04 - 83s/epoch - 56ms/step
Epoch 39/200
1493/1493 - 83s - loss: 3.5899e-04 - val_loss: 3.4855e-04 - 83s/epoch - 56ms/step
Epoch 40/200
1493/1493 - 83s - loss: 3.4888e-04 - val_loss: 3.7532e-04 - 83s/epoch - 56ms/step
Epoch 41/200
1493/1493 - 83s - loss: 3.4805e-04 - val_loss: 3.1148e-04 - 83s/epoch - 56ms/step
Epoch 42/200
1493/1493 - 83s - loss: 3.4495e-04 - val_loss: 3.2703e-04 - 83s/epoch - 56ms/step
Epoch 43/200
1493/1493 - 83s - loss: 3.4036e-04 - val_loss: 4.4602e-04 - 83s/epoch - 56ms/step
Epoch 44/200
1493/1493 - 83s - loss: 3.5015e-04 - val_loss: 7.2701e-04 - 83s/epoch - 56ms/step
Epoch 45/200
1493/1493 - 83s - loss: 3.7371e-04 - val_loss: 2.9331e-04 - 83s/epoch - 56ms/step
Epoch 46/200
1493/1493 - 83s - loss: 3.2524e-04 - val_loss: 3.0245e-04 - 83s/epoch - 56ms/step
Epoch 47/200
1493/1493 - 83s - loss: 3.2552e-04 - val_loss: 3.4052e-04 - 83s/epoch - 56ms/step
Epoch 48/200
1493/1493 - 83s - loss: 3.1799e-04 - val_loss: 3.4300e-04 - 83s/epoch - 56ms/step
Epoch 49/200
1493/1493 - 83s - loss: 3.1502e-04 - val_loss: 6.2902e-04 - 83s/epoch - 56ms/step
Epoch 50/200
1493/1493 - 83s - loss: 3.4447e-04 - val_loss: 3.9814e-04 - 83s/epoch - 56ms/step
Epoch 51/200
1493/1493 - 83s - loss: 3.2377e-04 - val_loss: 3.1100e-04 - 83s/epoch - 56ms/step
Epoch 52/200
1493/1493 - 83s - loss: 3.0233e-04 - val_loss: 2.9696e-04 - 83s/epoch - 56ms/step
Epoch 53/200
1493/1493 - 83s - loss: 3.0207e-04 - val_loss: 2.8255e-04 - 83s/epoch - 56ms/step
Epoch 54/200
1493/1493 - 83s - loss: 2.9749e-04 - val_loss: 3.0898e-04 - 83s/epoch - 56ms/step
Epoch 55/200
1493/1493 - 82s - loss: 2.9170e-04 - val_loss: 2.8582e-04 - 82s/epoch - 55ms/step
Epoch 56/200
1493/1493 - 83s - loss: 2.8917e-04 - val_loss: 2.9413e-04 - 83s/epoch - 56ms/step
Epoch 57/200
1493/1493 - 82s - loss: 2.8631e-04 - val_loss: 2.9270e-04 - 82s/epoch - 55ms/step
Epoch 58/200
1493/1493 - 82s - loss: 2.8500e-04 - val_loss: 2.7845e-04 - 82s/epoch - 55ms/step
Epoch 59/200
1493/1493 - 82s - loss: 2.8180e-04 - val_loss: 3.0282e-04 - 82s/epoch - 55ms/step
Epoch 60/200
1493/1493 - 82s - loss: 2.7935e-04 - val_loss: 4.3069e-04 - 82s/epoch - 55ms/step
Epoch 61/200
1493/1493 - 82s - loss: 3.9823e-04 - val_loss: 2.6777e-04 - 82s/epoch - 55ms/step
Epoch 62/200
1493/1493 - 82s - loss: 2.8394e-04 - val_loss: 2.9257e-04 - 82s/epoch - 55ms/step
Epoch 63/200
1493/1493 - 82s - loss: 2.7486e-04 - val_loss: 3.0479e-04 - 82s/epoch - 55ms/step
Epoch 64/200
1493/1493 - 82s - loss: 2.7839e-04 - val_loss: 0.0018 - 82s/epoch - 55ms/step
Epoch 65/200
1493/1493 - 82s - loss: 3.9363e-04 - val_loss: 0.0012 - 82s/epoch - 55ms/step
Epoch 66/200
1493/1493 - 82s - loss: 4.1331e-04 - val_loss: 2.6967e-04 - 82s/epoch - 55ms/step
Epoch 67/200
1493/1493 - 82s - loss: 2.8214e-04 - val_loss: 2.5405e-04 - 82s/epoch - 55ms/step
Epoch 68/200
1493/1493 - 82s - loss: 2.7592e-04 - val_loss: 5.1140e-04 - 82s/epoch - 55ms/step
Epoch 69/200
1493/1493 - 82s - loss: 3.2578e-04 - val_loss: 2.8991e-04 - 82s/epoch - 55ms/step
Epoch 70/200
1493/1493 - 82s - loss: 2.7266e-04 - val_loss: 3.2850e-04 - 82s/epoch - 55ms/step
Epoch 71/200
1493/1493 - 82s - loss: 2.7531e-04 - val_loss: 2.5340e-04 - 82s/epoch - 55ms/step
Epoch 72/200
1493/1493 - 82s - loss: 2.6820e-04 - val_loss: 2.7021e-04 - 82s/epoch - 55ms/step
Epoch 73/200
1493/1493 - 82s - loss: 2.6718e-04 - val_loss: 2.9257e-04 - 82s/epoch - 55ms/step
Epoch 74/200
1493/1493 - 82s - loss: 2.6821e-04 - val_loss: 2.6244e-04 - 82s/epoch - 55ms/step
Epoch 75/200
1493/1493 - 82s - loss: 2.5714e-04 - val_loss: 2.5938e-04 - 82s/epoch - 55ms/step
Epoch 76/200
1493/1493 - 82s - loss: 2.5385e-04 - val_loss: 2.6755e-04 - 82s/epoch - 55ms/step
Epoch 77/200
1493/1493 - 83s - loss: 2.5067e-04 - val_loss: 6.0674e-04 - 83s/epoch - 56ms/step
Epoch 78/200
1493/1493 - 82s - loss: 2.9162e-04 - val_loss: 3.3602e-04 - 82s/epoch - 55ms/step
Epoch 79/200
1493/1493 - 82s - loss: 2.7086e-04 - val_loss: 3.5871e-04 - 82s/epoch - 55ms/step
Epoch 80/200
1493/1493 - 82s - loss: 2.7929e-04 - val_loss: 2.5910e-04 - 82s/epoch - 55ms/step
Epoch 81/200
1493/1493 - 82s - loss: 2.5429e-04 - val_loss: 3.1662e-04 - 82s/epoch - 55ms/step
Epoch 82/200
1493/1493 - 82s - loss: 2.4911e-04 - val_loss: 2.5361e-04 - 82s/epoch - 55ms/step
Epoch 83/200
1493/1493 - 82s - loss: 2.4416e-04 - val_loss: 2.6057e-04 - 82s/epoch - 55ms/step
Epoch 84/200
1493/1493 - 82s - loss: 2.4403e-04 - val_loss: 2.6250e-04 - 82s/epoch - 55ms/step
Epoch 85/200
1493/1493 - 82s - loss: 2.4186e-04 - val_loss: 2.7759e-04 - 82s/epoch - 55ms/step
Epoch 86/200
1493/1493 - 82s - loss: 2.4185e-04 - val_loss: 2.6266e-04 - 82s/epoch - 55ms/step
Epoch 87/200
1493/1493 - 82s - loss: 2.4014e-04 - val_loss: 2.7722e-04 - 82s/epoch - 55ms/step
Epoch 88/200
1493/1493 - 82s - loss: 2.4037e-04 - val_loss: 2.8605e-04 - 82s/epoch - 55ms/step
Epoch 89/200
1493/1493 - 82s - loss: 2.4641e-04 - val_loss: 2.4860e-04 - 82s/epoch - 55ms/step
Epoch 90/200
1493/1493 - 82s - loss: 2.3439e-04 - val_loss: 2.4480e-04 - 82s/epoch - 55ms/step
Epoch 91/200
1493/1493 - 82s - loss: 2.3210e-04 - val_loss: 2.6345e-04 - 82s/epoch - 55ms/step
Epoch 92/200
1493/1493 - 82s - loss: 2.3516e-04 - val_loss: 5.5027e-04 - 82s/epoch - 55ms/step
Epoch 93/200
1493/1493 - 82s - loss: 2.8527e-04 - val_loss: 2.4393e-04 - 82s/epoch - 55ms/step
Epoch 94/200
1493/1493 - 82s - loss: 2.3678e-04 - val_loss: 2.1793e-04 - 82s/epoch - 55ms/step
Epoch 95/200
1493/1493 - 82s - loss: 2.3184e-04 - val_loss: 2.5775e-04 - 82s/epoch - 55ms/step
Epoch 96/200
1493/1493 - 83s - loss: 2.3174e-04 - val_loss: 2.5168e-04 - 83s/epoch - 56ms/step
Epoch 97/200
1493/1493 - 83s - loss: 2.2855e-04 - val_loss: 2.1676e-04 - 83s/epoch - 56ms/step
Epoch 98/200
1493/1493 - 83s - loss: 2.3360e-04 - val_loss: 5.3075e-04 - 83s/epoch - 56ms/step
Epoch 99/200
1493/1493 - 84s - loss: 2.9842e-04 - val_loss: 2.3394e-04 - 84s/epoch - 56ms/step
Epoch 100/200
1493/1493 - 83s - loss: 2.3972e-04 - val_loss: 2.1772e-04 - 83s/epoch - 56ms/step
Epoch 101/200
1493/1493 - 83s - loss: 2.2755e-04 - val_loss: 4.5967e-04 - 83s/epoch - 56ms/step
Epoch 102/200
1493/1493 - 82s - loss: 2.5266e-04 - val_loss: 3.0635e-04 - 82s/epoch - 55ms/step
Epoch 103/200
1493/1493 - 83s - loss: 2.3764e-04 - val_loss: 2.2841e-04 - 83s/epoch - 56ms/step
Epoch 104/200
1493/1493 - 83s - loss: 2.2746e-04 - val_loss: 5.6944e-04 - 83s/epoch - 56ms/step
Epoch 105/200
1493/1493 - 83s - loss: 2.8108e-04 - val_loss: 2.1921e-04 - 83s/epoch - 56ms/step
Epoch 106/200
1493/1493 - 83s - loss: 2.2783e-04 - val_loss: 2.2753e-04 - 83s/epoch - 56ms/step
Epoch 107/200
1493/1493 - 83s - loss: 2.2379e-04 - val_loss: 2.4612e-04 - 83s/epoch - 56ms/step
Epoch 108/200
1493/1493 - 83s - loss: 2.2667e-04 - val_loss: 2.1622e-04 - 83s/epoch - 56ms/step
Epoch 109/200
1493/1493 - 83s - loss: 2.2226e-04 - val_loss: 2.2845e-04 - 83s/epoch - 56ms/step
Epoch 110/200
1493/1493 - 84s - loss: 2.1839e-04 - val_loss: 2.3802e-04 - 84s/epoch - 56ms/step
Epoch 111/200
1493/1493 - 84s - loss: 2.1796e-04 - val_loss: 3.3266e-04 - 84s/epoch - 56ms/step
Epoch 112/200
1493/1493 - 84s - loss: 2.3927e-04 - val_loss: 2.0701e-04 - 84s/epoch - 56ms/step
Epoch 113/200
1493/1493 - 83s - loss: 2.1511e-04 - val_loss: 3.2320e-04 - 83s/epoch - 56ms/step
Epoch 114/200
1493/1493 - 83s - loss: 2.3653e-04 - val_loss: 2.5373e-04 - 83s/epoch - 56ms/step
Epoch 115/200
1493/1493 - 84s - loss: 2.2291e-04 - val_loss: 2.7318e-04 - 84s/epoch - 56ms/step
Epoch 116/200
1493/1493 - 83s - loss: 2.1638e-04 - val_loss: 2.4198e-04 - 83s/epoch - 56ms/step
Epoch 117/200
1493/1493 - 83s - loss: 2.1354e-04 - val_loss: 2.7434e-04 - 83s/epoch - 56ms/step
Epoch 118/200
1493/1493 - 83s - loss: 2.2052e-04 - val_loss: 2.2011e-04 - 83s/epoch - 55ms/step
Epoch 119/200
1493/1493 - 84s - loss: 2.1315e-04 - val_loss: 2.2847e-04 - 84s/epoch - 56ms/step
Epoch 120/200
1493/1493 - 84s - loss: 2.1025e-04 - val_loss: 2.1933e-04 - 84s/epoch - 56ms/step
Epoch 121/200
1493/1493 - 84s - loss: 2.1074e-04 - val_loss: 2.7689e-04 - 84s/epoch - 56ms/step
Epoch 122/200
1493/1493 - 84s - loss: 2.0932e-04 - val_loss: 2.1024e-04 - 84s/epoch - 56ms/step
Epoch 123/200
1493/1493 - 84s - loss: 2.0705e-04 - val_loss: 2.2401e-04 - 84s/epoch - 56ms/step
Epoch 124/200
1493/1493 - 84s - loss: 2.0944e-04 - val_loss: 3.6752e-04 - 84s/epoch - 56ms/step
Epoch 125/200
1493/1493 - 84s - loss: 2.4671e-04 - val_loss: 2.1340e-04 - 84s/epoch - 56ms/step
Epoch 126/200
1493/1493 - 84s - loss: 2.1004e-04 - val_loss: 4.9038e-04 - 84s/epoch - 57ms/step
Epoch 127/200
1493/1493 - 84s - loss: 2.4088e-04 - val_loss: 4.5326e-04 - 84s/epoch - 56ms/step
Epoch 128/200
1493/1493 - 84s - loss: 2.3416e-04 - val_loss: 1.9285e-04 - 84s/epoch - 57ms/step
Epoch 129/200
1493/1493 - 84s - loss: 2.0802e-04 - val_loss: 2.1816e-04 - 84s/epoch - 57ms/step
Epoch 130/200
1493/1493 - 84s - loss: 2.0683e-04 - val_loss: 2.0088e-04 - 84s/epoch - 57ms/step
Epoch 131/200
1493/1493 - 84s - loss: 2.0667e-04 - val_loss: 2.7535e-04 - 84s/epoch - 57ms/step
Epoch 132/200
1493/1493 - 84s - loss: 2.2434e-04 - val_loss: 2.1353e-04 - 84s/epoch - 56ms/step
Epoch 133/200
1493/1493 - 84s - loss: 2.0487e-04 - val_loss: 2.2022e-04 - 84s/epoch - 56ms/step
Epoch 134/200
1493/1493 - 84s - loss: 2.0267e-04 - val_loss: 2.1604e-04 - 84s/epoch - 56ms/step
Epoch 135/200
1493/1493 - 84s - loss: 2.0143e-04 - val_loss: 2.0863e-04 - 84s/epoch - 56ms/step
Epoch 136/200
1493/1493 - 84s - loss: 2.0214e-04 - val_loss: 3.0650e-04 - 84s/epoch - 56ms/step
Epoch 137/200
1493/1493 - 84s - loss: 2.2696e-04 - val_loss: 2.6157e-04 - 84s/epoch - 56ms/step
Epoch 138/200
1493/1493 - 84s - loss: 2.3791e-04 - val_loss: 3.0521e-04 - 84s/epoch - 56ms/step
Epoch 139/200
1493/1493 - 84s - loss: 2.2847e-04 - val_loss: 3.7071e-04 - 84s/epoch - 56ms/step
Epoch 140/200
1493/1493 - 83s - loss: 2.4600e-04 - val_loss: 1.9393e-04 - 83s/epoch - 56ms/step
Epoch 141/200
1493/1493 - 84s - loss: 2.0713e-04 - val_loss: 3.0560e-04 - 84s/epoch - 56ms/step
Epoch 142/200
1493/1493 - 83s - loss: 2.2207e-04 - val_loss: 2.0081e-04 - 83s/epoch - 56ms/step
Epoch 143/200
1493/1493 - 84s - loss: 2.0209e-04 - val_loss: 2.3122e-04 - 84s/epoch - 56ms/step
Epoch 144/200
1493/1493 - 83s - loss: 2.0439e-04 - val_loss: 2.0865e-04 - 83s/epoch - 56ms/step
Epoch 145/200
1493/1493 - 84s - loss: 1.9934e-04 - val_loss: 2.1615e-04 - 84s/epoch - 56ms/step
Epoch 146/200
1493/1493 - 83s - loss: 1.9777e-04 - val_loss: 2.0085e-04 - 83s/epoch - 56ms/step
Epoch 147/200
1493/1493 - 84s - loss: 1.9580e-04 - val_loss: 2.0607e-04 - 84s/epoch - 56ms/step
Epoch 148/200
1493/1493 - 84s - loss: 1.9650e-04 - val_loss: 3.0372e-04 - 84s/epoch - 56ms/step
Epoch 149/200
1493/1493 - 84s - loss: 1.9435e-04 - val_loss: 2.1033e-04 - 84s/epoch - 56ms/step
Epoch 150/200
1493/1493 - 83s - loss: 1.9342e-04 - val_loss: 1.8853e-04 - 83s/epoch - 56ms/step
Epoch 151/200
1493/1493 - 83s - loss: 1.9631e-04 - val_loss: 2.0448e-04 - 83s/epoch - 56ms/step
Epoch 152/200
1493/1493 - 83s - loss: 1.9513e-04 - val_loss: 2.7708e-04 - 83s/epoch - 56ms/step
Epoch 153/200
1493/1493 - 83s - loss: 2.0791e-04 - val_loss: 1.9526e-04 - 83s/epoch - 56ms/step
Epoch 154/200
1493/1493 - 83s - loss: 1.9769e-04 - val_loss: 3.3353e-04 - 83s/epoch - 56ms/step
Epoch 155/200
1493/1493 - 84s - loss: 2.4598e-04 - val_loss: 2.0827e-04 - 84s/epoch - 56ms/step
Epoch 156/200
1493/1493 - 84s - loss: 1.9930e-04 - val_loss: 2.0754e-04 - 84s/epoch - 56ms/step
Epoch 157/200
1493/1493 - 83s - loss: 1.9379e-04 - val_loss: 2.2363e-04 - 83s/epoch - 56ms/step
Epoch 158/200
1493/1493 - 84s - loss: 1.9782e-04 - val_loss: 2.0857e-04 - 84s/epoch - 56ms/step
Epoch 159/200
1493/1493 - 82s - loss: 1.9146e-04 - val_loss: 1.9404e-04 - 82s/epoch - 55ms/step
Epoch 160/200
1493/1493 - 83s - loss: 1.9190e-04 - val_loss: 2.3723e-04 - 83s/epoch - 55ms/step
Epoch 161/200
1493/1493 - 83s - loss: 2.0904e-04 - val_loss: 1.9471e-04 - 83s/epoch - 56ms/step
Epoch 162/200
1493/1493 - 83s - loss: 1.8982e-04 - val_loss: 2.1086e-04 - 83s/epoch - 56ms/step
Epoch 163/200
1493/1493 - 83s - loss: 1.9238e-04 - val_loss: 3.2730e-04 - 83s/epoch - 56ms/step
Epoch 164/200
1493/1493 - 83s - loss: 2.1990e-04 - val_loss: 2.0045e-04 - 83s/epoch - 56ms/step
Epoch 165/200
1493/1493 - 83s - loss: 2.0938e-04 - val_loss: 1.8481e-04 - 83s/epoch - 56ms/step
Epoch 166/200
1493/1493 - 83s - loss: 1.9150e-04 - val_loss: 1.9971e-04 - 83s/epoch - 55ms/step
Epoch 167/200
1493/1493 - 83s - loss: 1.9002e-04 - val_loss: 1.9035e-04 - 83s/epoch - 55ms/step
Epoch 168/200
1493/1493 - 82s - loss: 1.8823e-04 - val_loss: 2.0272e-04 - 82s/epoch - 55ms/step
Epoch 169/200
1493/1493 - 83s - loss: 1.8869e-04 - val_loss: 2.3589e-04 - 83s/epoch - 55ms/step
Epoch 170/200
1493/1493 - 82s - loss: 1.9104e-04 - val_loss: 3.7303e-04 - 82s/epoch - 55ms/step
Epoch 171/200
1493/1493 - 83s - loss: 2.3872e-04 - val_loss: 5.0714e-04 - 83s/epoch - 55ms/step
Epoch 172/200
1493/1493 - 82s - loss: 2.4889e-04 - val_loss: 2.1780e-04 - 82s/epoch - 55ms/step
Epoch 173/200
1493/1493 - 82s - loss: 1.9836e-04 - val_loss: 1.7685e-04 - 82s/epoch - 55ms/step
Epoch 174/200
1493/1493 - 83s - loss: 1.8995e-04 - val_loss: 1.9396e-04 - 83s/epoch - 55ms/step
Epoch 175/200
1493/1493 - 82s - loss: 1.8954e-04 - val_loss: 1.8625e-04 - 82s/epoch - 55ms/step
Epoch 176/200
1493/1493 - 83s - loss: 1.9045e-04 - val_loss: 2.0279e-04 - 83s/epoch - 55ms/step
Epoch 177/200
1493/1493 - 82s - loss: 1.9005e-04 - val_loss: 1.8398e-04 - 82s/epoch - 55ms/step
Epoch 178/200
1493/1493 - 82s - loss: 1.8577e-04 - val_loss: 2.1214e-04 - 82s/epoch - 55ms/step
Epoch 179/200
1493/1493 - 83s - loss: 1.8369e-04 - val_loss: 2.0438e-04 - 83s/epoch - 55ms/step
Epoch 180/200
1493/1493 - 83s - loss: 1.8566e-04 - val_loss: 2.7419e-04 - 83s/epoch - 55ms/step
Epoch 181/200
1493/1493 - 82s - loss: 2.0569e-04 - val_loss: 2.0273e-04 - 82s/epoch - 55ms/step
Epoch 182/200
1493/1493 - 83s - loss: 1.8594e-04 - val_loss: 1.8964e-04 - 83s/epoch - 55ms/step
Epoch 183/200
1493/1493 - 82s - loss: 1.8952e-04 - val_loss: 2.4536e-04 - 82s/epoch - 55ms/step
Epoch 184/200
1493/1493 - 82s - loss: 1.9236e-04 - val_loss: 1.7908e-04 - 82s/epoch - 55ms/step
Epoch 185/200
1493/1493 - 83s - loss: 1.8142e-04 - val_loss: 2.2329e-04 - 83s/epoch - 55ms/step
Epoch 186/200
1493/1493 - 83s - loss: 1.8282e-04 - val_loss: 1.8468e-04 - 83s/epoch - 56ms/step
Epoch 187/200
1493/1493 - 83s - loss: 1.8105e-04 - val_loss: 1.9103e-04 - 83s/epoch - 56ms/step
Epoch 188/200
1493/1493 - 83s - loss: 1.8489e-04 - val_loss: 2.3274e-04 - 83s/epoch - 56ms/step
Epoch 189/200
1493/1493 - 83s - loss: 1.8305e-04 - val_loss: 1.9089e-04 - 83s/epoch - 56ms/step
Epoch 190/200
1493/1493 - 83s - loss: 1.8355e-04 - val_loss: 2.3283e-04 - 83s/epoch - 56ms/step
Epoch 191/200
1493/1493 - 83s - loss: 1.8717e-04 - val_loss: 2.0152e-04 - 83s/epoch - 56ms/step
Epoch 192/200
1493/1493 - 83s - loss: 1.8251e-04 - val_loss: 1.9863e-04 - 83s/epoch - 56ms/step
Epoch 193/200
1493/1493 - 83s - loss: 1.8745e-04 - val_loss: 2.7744e-04 - 83s/epoch - 56ms/step
Epoch 194/200
1493/1493 - 83s - loss: 2.0550e-04 - val_loss: 3.9752e-04 - 83s/epoch - 55ms/step
Epoch 195/200
1493/1493 - 83s - loss: 2.5163e-04 - val_loss: 3.5771e-04 - 83s/epoch - 55ms/step
Epoch 196/200
1493/1493 - 83s - loss: 2.3549e-04 - val_loss: 1.8019e-04 - 83s/epoch - 56ms/step
Epoch 197/200
1493/1493 - 83s - loss: 1.8762e-04 - val_loss: 1.8842e-04 - 83s/epoch - 56ms/step
Epoch 198/200
1493/1493 - 83s - loss: 1.8618e-04 - val_loss: 2.2061e-04 - 83s/epoch - 56ms/step
Epoch 199/200
1493/1493 - 84s - loss: 1.8950e-04 - val_loss: 1.7417e-04 - 84s/epoch - 56ms/step
Epoch 200/200
1493/1493 - 83s - loss: 1.8153e-04 - val_loss: 1.8502e-04 - 83s/epoch - 56ms/step
COMPRESSED VECTOR SIZE: 252
Loss in the autoencoder: 0.00018501804152037948
  1/332 [..............................] - ETA: 39s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 3s 36/332 [==>...........................] - ETA: 3s 41/332 [==>...........................] - ETA: 3s 46/332 [===>..........................] - ETA: 3s 51/332 [===>..........................] - ETA: 2s 56/332 [====>.........................] - ETA: 2s 61/332 [====>.........................] - ETA: 2s 66/332 [====>.........................] - ETA: 2s 71/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 2s 81/332 [======>.......................] - ETA: 2s 86/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 96/332 [=======>......................] - ETA: 2s101/332 [========>.....................] - ETA: 2s106/332 [========>.....................] - ETA: 2s111/332 [=========>....................] - ETA: 2s116/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s131/332 [==========>...................] - ETA: 2s136/332 [===========>..................] - ETA: 2s141/332 [===========>..................] - ETA: 2s146/332 [============>.................] - ETA: 1s151/332 [============>.................] - ETA: 1s156/332 [=============>................] - ETA: 1s161/332 [=============>................] - ETA: 1s166/332 [==============>...............] - ETA: 1s171/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 1s196/332 [================>.............] - ETA: 1s201/332 [=================>............] - ETA: 1s206/332 [=================>............] - ETA: 1s211/332 [==================>...........] - ETA: 1s216/332 [==================>...........] - ETA: 1s221/332 [==================>...........] - ETA: 1s226/332 [===================>..........] - ETA: 1s231/332 [===================>..........] - ETA: 1s236/332 [====================>.........] - ETA: 1s241/332 [====================>.........] - ETA: 0s246/332 [=====================>........] - ETA: 0s251/332 [=====================>........] - ETA: 0s256/332 [======================>.......] - ETA: 0s261/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s271/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s286/332 [========================>.....] - ETA: 0s291/332 [=========================>....] - ETA: 0s296/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s306/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s316/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s326/332 [============================>.] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 11ms/step
correlation 0.0021240231656506968
cosine 0.001671410369684325
MAE: 0.007387795
RMSE: 0.013602128
r2: 0.9879981188457637
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_9 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 252)               700812    
                                                                 
 batch_normalization_10 (Bat  (None, 252)              1008      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 252)               0         
                                                                 
 dense_10 (Dense)            (None, 2780)              703340    
                                                                 
 batch_normalization_11 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2780)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,459,284
Trainable params: 8,447,660
Non-trainable params: 11,624
_________________________________________________________________
Encoder
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 2780)              3516700   
                                                                 
 batch_normalization_9 (Batc  (None, 2780)             11120     
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 252)               700812    
                                                                 
=================================================================
Total params: 4,228,632
Trainable params: 4,223,072
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 252)]             0         
                                                                 
 batch_normalization_10 (Bat  (None, 252)              1008      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 252)               0         
                                                                 
 dense_10 (Dense)            (None, 2780)              703340    
                                                                 
 batch_normalization_11 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2780)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 4,230,652
Trainable params: 4,224,588
Non-trainable params: 6,064
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.2, 252, 0.00018152584380004555, 0.00018501804152037948, 0.0021240231656506968, 0.001671410369684325, 0.007387795019894838, 0.013602128252387047, 0.9879981188457637, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_12 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_12 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 189)               525609    
                                                                 
 batch_normalization_13 (Bat  (None, 189)              756       
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 189)               0         
                                                                 
 dense_13 (Dense)            (None, 2780)              528200    
                                                                 
 batch_normalization_14 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2780)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,108,689
Trainable params: 8,097,191
Non-trainable params: 11,498
_________________________________________________________________
Epoch 1/200
1493/1493 - 80s - loss: 0.0102 - val_loss: 0.0053 - 80s/epoch - 54ms/step
Epoch 2/200
1493/1493 - 79s - loss: 0.0037 - val_loss: 0.0032 - 79s/epoch - 53ms/step
Epoch 3/200
1493/1493 - 79s - loss: 0.0028 - val_loss: 0.0028 - 79s/epoch - 53ms/step
Epoch 4/200
1493/1493 - 79s - loss: 0.0024 - val_loss: 0.0036 - 79s/epoch - 53ms/step
Epoch 5/200
1493/1493 - 79s - loss: 0.0022 - val_loss: 0.0019 - 79s/epoch - 53ms/step
Epoch 6/200
1493/1493 - 79s - loss: 0.0020 - val_loss: 0.0018 - 79s/epoch - 53ms/step
Epoch 7/200
1493/1493 - 79s - loss: 0.0019 - val_loss: 0.0015 - 79s/epoch - 53ms/step
Epoch 8/200
1493/1493 - 79s - loss: 0.0016 - val_loss: 0.0017 - 79s/epoch - 53ms/step
Epoch 9/200
1493/1493 - 79s - loss: 0.0015 - val_loss: 0.0014 - 79s/epoch - 53ms/step
Epoch 10/200
1493/1493 - 79s - loss: 0.0013 - val_loss: 0.0011 - 79s/epoch - 53ms/step
Epoch 11/200
1493/1493 - 79s - loss: 0.0012 - val_loss: 0.0010 - 79s/epoch - 53ms/step
Epoch 12/200
1493/1493 - 79s - loss: 0.0011 - val_loss: 0.0011 - 79s/epoch - 53ms/step
Epoch 13/200
1493/1493 - 79s - loss: 9.9585e-04 - val_loss: 0.0012 - 79s/epoch - 53ms/step
Epoch 14/200
1493/1493 - 79s - loss: 9.5340e-04 - val_loss: 8.7047e-04 - 79s/epoch - 53ms/step
Epoch 15/200
1493/1493 - 79s - loss: 8.8901e-04 - val_loss: 8.1529e-04 - 79s/epoch - 53ms/step
Epoch 16/200
1493/1493 - 79s - loss: 8.1390e-04 - val_loss: 7.4895e-04 - 79s/epoch - 53ms/step
Epoch 17/200
1493/1493 - 79s - loss: 7.6964e-04 - val_loss: 8.4360e-04 - 79s/epoch - 53ms/step
Epoch 18/200
1493/1493 - 79s - loss: 7.4608e-04 - val_loss: 0.0010 - 79s/epoch - 53ms/step
Epoch 19/200
1493/1493 - 79s - loss: 7.3230e-04 - val_loss: 7.4377e-04 - 79s/epoch - 53ms/step
Epoch 20/200
1493/1493 - 79s - loss: 6.8515e-04 - val_loss: 6.1278e-04 - 79s/epoch - 53ms/step
Epoch 21/200
1493/1493 - 79s - loss: 6.5219e-04 - val_loss: 7.3139e-04 - 79s/epoch - 53ms/step
Epoch 22/200
1493/1493 - 79s - loss: 6.4137e-04 - val_loss: 9.1999e-04 - 79s/epoch - 53ms/step
Epoch 23/200
1493/1493 - 79s - loss: 6.8662e-04 - val_loss: 0.0016 - 79s/epoch - 53ms/step
Epoch 24/200
1493/1493 - 79s - loss: 7.5983e-04 - val_loss: 5.7935e-04 - 79s/epoch - 53ms/step
Epoch 25/200
1493/1493 - 79s - loss: 5.8778e-04 - val_loss: 5.3914e-04 - 79s/epoch - 53ms/step
Epoch 26/200
1493/1493 - 79s - loss: 5.6889e-04 - val_loss: 6.9458e-04 - 79s/epoch - 53ms/step
Epoch 27/200
1493/1493 - 79s - loss: 5.5073e-04 - val_loss: 5.2037e-04 - 79s/epoch - 53ms/step
Epoch 28/200
1493/1493 - 79s - loss: 5.2919e-04 - val_loss: 6.3860e-04 - 79s/epoch - 53ms/step
Epoch 29/200
1493/1493 - 79s - loss: 5.2956e-04 - val_loss: 4.9277e-04 - 79s/epoch - 53ms/step
Epoch 30/200
1493/1493 - 79s - loss: 5.0888e-04 - val_loss: 5.1318e-04 - 79s/epoch - 53ms/step
Epoch 31/200
1493/1493 - 79s - loss: 4.9776e-04 - val_loss: 5.8808e-04 - 79s/epoch - 53ms/step
Epoch 32/200
1493/1493 - 79s - loss: 5.2549e-04 - val_loss: 4.8179e-04 - 79s/epoch - 53ms/step
Epoch 33/200
1493/1493 - 79s - loss: 4.9209e-04 - val_loss: 4.5750e-04 - 79s/epoch - 53ms/step
Epoch 34/200
1493/1493 - 79s - loss: 4.6980e-04 - val_loss: 4.5529e-04 - 79s/epoch - 53ms/step
Epoch 35/200
1493/1493 - 79s - loss: 4.5708e-04 - val_loss: 6.0960e-04 - 79s/epoch - 53ms/step
Epoch 36/200
1493/1493 - 79s - loss: 4.7973e-04 - val_loss: 4.8049e-04 - 79s/epoch - 53ms/step
Epoch 37/200
1493/1493 - 79s - loss: 4.5014e-04 - val_loss: 4.3307e-04 - 79s/epoch - 53ms/step
Epoch 38/200
1493/1493 - 79s - loss: 4.4541e-04 - val_loss: 4.3009e-04 - 79s/epoch - 53ms/step
Epoch 39/200
1493/1493 - 79s - loss: 4.3464e-04 - val_loss: 4.0794e-04 - 79s/epoch - 53ms/step
Epoch 40/200
1493/1493 - 79s - loss: 4.2319e-04 - val_loss: 4.2819e-04 - 79s/epoch - 53ms/step
Epoch 41/200
1493/1493 - 79s - loss: 4.2113e-04 - val_loss: 3.8476e-04 - 79s/epoch - 53ms/step
Epoch 42/200
1493/1493 - 79s - loss: 4.1866e-04 - val_loss: 4.0411e-04 - 79s/epoch - 53ms/step
Epoch 43/200
1493/1493 - 79s - loss: 4.1618e-04 - val_loss: 4.8292e-04 - 79s/epoch - 53ms/step
Epoch 44/200
1493/1493 - 79s - loss: 4.1817e-04 - val_loss: 9.1723e-04 - 79s/epoch - 53ms/step
Epoch 45/200
1493/1493 - 80s - loss: 4.5861e-04 - val_loss: 3.6526e-04 - 80s/epoch - 54ms/step
Epoch 46/200
1493/1493 - 81s - loss: 4.0008e-04 - val_loss: 3.6330e-04 - 81s/epoch - 54ms/step
Epoch 47/200
1493/1493 - 80s - loss: 3.9455e-04 - val_loss: 4.0310e-04 - 80s/epoch - 54ms/step
Epoch 48/200
1493/1493 - 81s - loss: 3.8952e-04 - val_loss: 3.8703e-04 - 81s/epoch - 54ms/step
Epoch 49/200
1493/1493 - 81s - loss: 3.8934e-04 - val_loss: 4.7696e-04 - 81s/epoch - 54ms/step
Epoch 50/200
1493/1493 - 81s - loss: 4.0917e-04 - val_loss: 4.1549e-04 - 81s/epoch - 54ms/step
Epoch 51/200
1493/1493 - 80s - loss: 3.9186e-04 - val_loss: 3.6340e-04 - 80s/epoch - 54ms/step
Epoch 52/200
1493/1493 - 81s - loss: 3.7066e-04 - val_loss: 3.5333e-04 - 81s/epoch - 54ms/step
Epoch 53/200
1493/1493 - 81s - loss: 3.7194e-04 - val_loss: 3.4780e-04 - 81s/epoch - 54ms/step
Epoch 54/200
1493/1493 - 81s - loss: 3.6587e-04 - val_loss: 3.7537e-04 - 81s/epoch - 54ms/step
Epoch 55/200
1493/1493 - 81s - loss: 3.5931e-04 - val_loss: 3.4537e-04 - 81s/epoch - 54ms/step
Epoch 56/200
1493/1493 - 81s - loss: 3.5707e-04 - val_loss: 3.5622e-04 - 81s/epoch - 54ms/step
Epoch 57/200
1493/1493 - 81s - loss: 3.5532e-04 - val_loss: 3.6021e-04 - 81s/epoch - 54ms/step
Epoch 58/200
1493/1493 - 81s - loss: 3.5171e-04 - val_loss: 3.3680e-04 - 81s/epoch - 54ms/step
Epoch 59/200
1493/1493 - 81s - loss: 3.4670e-04 - val_loss: 3.5431e-04 - 81s/epoch - 54ms/step
Epoch 60/200
1493/1493 - 81s - loss: 3.4689e-04 - val_loss: 4.8560e-04 - 81s/epoch - 54ms/step
Epoch 61/200
1493/1493 - 81s - loss: 4.6902e-04 - val_loss: 3.3161e-04 - 81s/epoch - 54ms/step
Epoch 62/200
1493/1493 - 81s - loss: 3.5246e-04 - val_loss: 3.4382e-04 - 81s/epoch - 54ms/step
Epoch 63/200
1493/1493 - 81s - loss: 3.4088e-04 - val_loss: 3.4299e-04 - 81s/epoch - 54ms/step
Epoch 64/200
1493/1493 - 80s - loss: 3.4478e-04 - val_loss: 0.0011 - 80s/epoch - 54ms/step
Epoch 65/200
1493/1493 - 81s - loss: 4.3526e-04 - val_loss: 0.0010 - 81s/epoch - 54ms/step
Epoch 66/200
1493/1493 - 81s - loss: 4.0337e-04 - val_loss: 3.4720e-04 - 81s/epoch - 54ms/step
Epoch 67/200
1493/1493 - 81s - loss: 3.3959e-04 - val_loss: 3.2055e-04 - 81s/epoch - 54ms/step
Epoch 68/200
1493/1493 - 80s - loss: 3.3750e-04 - val_loss: 5.7261e-04 - 80s/epoch - 54ms/step
Epoch 69/200
1493/1493 - 81s - loss: 3.9623e-04 - val_loss: 3.2586e-04 - 81s/epoch - 54ms/step
Epoch 70/200
1493/1493 - 81s - loss: 3.3622e-04 - val_loss: 5.4541e-04 - 81s/epoch - 54ms/step
Epoch 71/200
1493/1493 - 81s - loss: 3.8109e-04 - val_loss: 3.1315e-04 - 81s/epoch - 54ms/step
Epoch 72/200
1493/1493 - 81s - loss: 3.3597e-04 - val_loss: 3.2761e-04 - 81s/epoch - 54ms/step
Epoch 73/200
1493/1493 - 80s - loss: 3.3190e-04 - val_loss: 3.4558e-04 - 80s/epoch - 54ms/step
Epoch 74/200
1493/1493 - 81s - loss: 3.3470e-04 - val_loss: 3.1964e-04 - 81s/epoch - 54ms/step
Epoch 75/200
1493/1493 - 81s - loss: 3.2124e-04 - val_loss: 3.2221e-04 - 81s/epoch - 54ms/step
Epoch 76/200
1493/1493 - 81s - loss: 3.1914e-04 - val_loss: 3.1564e-04 - 81s/epoch - 54ms/step
Epoch 77/200
1493/1493 - 81s - loss: 3.1436e-04 - val_loss: 4.6789e-04 - 81s/epoch - 54ms/step
Epoch 78/200
1493/1493 - 81s - loss: 3.3820e-04 - val_loss: 3.6472e-04 - 81s/epoch - 54ms/step
Epoch 79/200
1493/1493 - 80s - loss: 3.2829e-04 - val_loss: 3.8950e-04 - 80s/epoch - 54ms/step
Epoch 80/200
1493/1493 - 81s - loss: 3.3504e-04 - val_loss: 3.1429e-04 - 81s/epoch - 54ms/step
Epoch 81/200
1493/1493 - 81s - loss: 3.1772e-04 - val_loss: 3.3371e-04 - 81s/epoch - 54ms/step
Epoch 82/200
1493/1493 - 81s - loss: 3.1145e-04 - val_loss: 3.0754e-04 - 81s/epoch - 54ms/step
Epoch 83/200
1493/1493 - 81s - loss: 3.0614e-04 - val_loss: 3.0721e-04 - 81s/epoch - 54ms/step
Epoch 84/200
1493/1493 - 79s - loss: 3.0639e-04 - val_loss: 2.9489e-04 - 79s/epoch - 53ms/step
Epoch 85/200
1493/1493 - 79s - loss: 3.1707e-04 - val_loss: 3.2067e-04 - 79s/epoch - 53ms/step
Epoch 86/200
1493/1493 - 79s - loss: 3.0917e-04 - val_loss: 2.9145e-04 - 79s/epoch - 53ms/step
Epoch 87/200
1493/1493 - 79s - loss: 3.0017e-04 - val_loss: 2.8715e-04 - 79s/epoch - 53ms/step
Epoch 88/200
1493/1493 - 79s - loss: 2.9755e-04 - val_loss: 3.1316e-04 - 79s/epoch - 53ms/step
Epoch 89/200
1493/1493 - 79s - loss: 3.2157e-04 - val_loss: 2.8908e-04 - 79s/epoch - 53ms/step
Epoch 90/200
1493/1493 - 79s - loss: 2.9750e-04 - val_loss: 2.9123e-04 - 79s/epoch - 53ms/step
Epoch 91/200
1493/1493 - 79s - loss: 2.9473e-04 - val_loss: 3.1040e-04 - 79s/epoch - 53ms/step
Epoch 92/200
1493/1493 - 79s - loss: 2.9697e-04 - val_loss: 5.2062e-04 - 79s/epoch - 53ms/step
Epoch 93/200
1493/1493 - 79s - loss: 3.5455e-04 - val_loss: 2.7868e-04 - 79s/epoch - 53ms/step
Epoch 94/200
1493/1493 - 79s - loss: 2.9739e-04 - val_loss: 2.7744e-04 - 79s/epoch - 53ms/step
Epoch 95/200
1493/1493 - 79s - loss: 2.9355e-04 - val_loss: 2.9109e-04 - 79s/epoch - 53ms/step
Epoch 96/200
1493/1493 - 79s - loss: 2.9337e-04 - val_loss: 2.9296e-04 - 79s/epoch - 53ms/step
Epoch 97/200
1493/1493 - 79s - loss: 2.9039e-04 - val_loss: 2.8110e-04 - 79s/epoch - 53ms/step
Epoch 98/200
1493/1493 - 79s - loss: 2.9523e-04 - val_loss: 4.9982e-04 - 79s/epoch - 53ms/step
Epoch 99/200
1493/1493 - 79s - loss: 3.5215e-04 - val_loss: 2.7479e-04 - 79s/epoch - 53ms/step
Epoch 100/200
1493/1493 - 79s - loss: 2.9642e-04 - val_loss: 2.7409e-04 - 79s/epoch - 53ms/step
Epoch 101/200
1493/1493 - 79s - loss: 2.8783e-04 - val_loss: 3.1447e-04 - 79s/epoch - 53ms/step
Epoch 102/200
1493/1493 - 79s - loss: 2.9588e-04 - val_loss: 3.2821e-04 - 79s/epoch - 53ms/step
Epoch 103/200
1493/1493 - 79s - loss: 2.9534e-04 - val_loss: 2.7100e-04 - 79s/epoch - 53ms/step
Epoch 104/200
1493/1493 - 80s - loss: 2.8602e-04 - val_loss: 4.3509e-04 - 80s/epoch - 54ms/step
Epoch 105/200
1493/1493 - 79s - loss: 3.1954e-04 - val_loss: 2.6874e-04 - 79s/epoch - 53ms/step
Epoch 106/200
1493/1493 - 81s - loss: 2.8366e-04 - val_loss: 2.7276e-04 - 81s/epoch - 54ms/step
Epoch 107/200
1493/1493 - 81s - loss: 2.8188e-04 - val_loss: 2.6850e-04 - 81s/epoch - 54ms/step
Epoch 108/200
1493/1493 - 80s - loss: 2.8993e-04 - val_loss: 2.7013e-04 - 80s/epoch - 54ms/step
Epoch 109/200
1493/1493 - 81s - loss: 2.8017e-04 - val_loss: 2.8405e-04 - 81s/epoch - 54ms/step
Epoch 110/200
1493/1493 - 81s - loss: 2.7737e-04 - val_loss: 2.7574e-04 - 81s/epoch - 54ms/step
Epoch 111/200
1493/1493 - 80s - loss: 2.7630e-04 - val_loss: 2.8833e-04 - 80s/epoch - 54ms/step
Epoch 112/200
1493/1493 - 80s - loss: 2.8348e-04 - val_loss: 2.8148e-04 - 80s/epoch - 54ms/step
Epoch 113/200
1493/1493 - 80s - loss: 2.7933e-04 - val_loss: 3.9743e-04 - 80s/epoch - 54ms/step
Epoch 114/200
1493/1493 - 81s - loss: 3.3743e-04 - val_loss: 2.8763e-04 - 81s/epoch - 54ms/step
Epoch 115/200
1493/1493 - 81s - loss: 2.9160e-04 - val_loss: 2.7310e-04 - 81s/epoch - 54ms/step
Epoch 116/200
1493/1493 - 81s - loss: 2.7612e-04 - val_loss: 2.8185e-04 - 81s/epoch - 54ms/step
Epoch 117/200
1493/1493 - 81s - loss: 2.7408e-04 - val_loss: 2.9355e-04 - 81s/epoch - 54ms/step
Epoch 118/200
1493/1493 - 81s - loss: 2.8249e-04 - val_loss: 2.6171e-04 - 81s/epoch - 54ms/step
Epoch 119/200
1493/1493 - 81s - loss: 2.7328e-04 - val_loss: 2.7196e-04 - 81s/epoch - 54ms/step
Epoch 120/200
1493/1493 - 81s - loss: 2.7049e-04 - val_loss: 2.7442e-04 - 81s/epoch - 54ms/step
Epoch 121/200
1493/1493 - 80s - loss: 2.7394e-04 - val_loss: 3.3176e-04 - 80s/epoch - 54ms/step
Epoch 122/200
1493/1493 - 80s - loss: 2.7758e-04 - val_loss: 2.5927e-04 - 80s/epoch - 54ms/step
Epoch 123/200
1493/1493 - 81s - loss: 2.6891e-04 - val_loss: 2.6175e-04 - 81s/epoch - 54ms/step
Epoch 124/200
1493/1493 - 80s - loss: 2.6900e-04 - val_loss: 4.1373e-04 - 80s/epoch - 54ms/step
Epoch 125/200
1493/1493 - 80s - loss: 3.0946e-04 - val_loss: 2.6364e-04 - 80s/epoch - 53ms/step
Epoch 126/200
1493/1493 - 80s - loss: 2.7131e-04 - val_loss: 3.4205e-04 - 80s/epoch - 54ms/step
Epoch 127/200
1493/1493 - 81s - loss: 2.8873e-04 - val_loss: 2.6556e-04 - 81s/epoch - 54ms/step
Epoch 128/200
1493/1493 - 80s - loss: 2.6549e-04 - val_loss: 2.6078e-04 - 80s/epoch - 54ms/step
Epoch 129/200
1493/1493 - 81s - loss: 2.6426e-04 - val_loss: 2.6119e-04 - 81s/epoch - 54ms/step
Epoch 130/200
1493/1493 - 79s - loss: 2.6400e-04 - val_loss: 2.6818e-04 - 79s/epoch - 53ms/step
Epoch 131/200
1493/1493 - 79s - loss: 2.6616e-04 - val_loss: 3.5807e-04 - 79s/epoch - 53ms/step
Epoch 132/200
1493/1493 - 79s - loss: 2.9492e-04 - val_loss: 2.5756e-04 - 79s/epoch - 53ms/step
Epoch 133/200
1493/1493 - 79s - loss: 2.6424e-04 - val_loss: 2.5443e-04 - 79s/epoch - 53ms/step
Epoch 134/200
1493/1493 - 79s - loss: 2.6112e-04 - val_loss: 2.6682e-04 - 79s/epoch - 53ms/step
Epoch 135/200
1493/1493 - 79s - loss: 2.5927e-04 - val_loss: 2.5741e-04 - 79s/epoch - 53ms/step
Epoch 136/200
1493/1493 - 79s - loss: 2.6013e-04 - val_loss: 2.9441e-04 - 79s/epoch - 53ms/step
Epoch 137/200
1493/1493 - 79s - loss: 2.8411e-04 - val_loss: 3.0378e-04 - 79s/epoch - 53ms/step
Epoch 138/200
1493/1493 - 79s - loss: 2.8420e-04 - val_loss: 2.7123e-04 - 79s/epoch - 53ms/step
Epoch 139/200
1493/1493 - 79s - loss: 2.6694e-04 - val_loss: 2.9222e-04 - 79s/epoch - 53ms/step
Epoch 140/200
1493/1493 - 79s - loss: 2.8052e-04 - val_loss: 2.5278e-04 - 79s/epoch - 53ms/step
Epoch 141/200
1493/1493 - 79s - loss: 2.6051e-04 - val_loss: 3.1245e-04 - 79s/epoch - 53ms/step
Epoch 142/200
1493/1493 - 79s - loss: 2.7748e-04 - val_loss: 2.5009e-04 - 79s/epoch - 53ms/step
Epoch 143/200
1493/1493 - 79s - loss: 2.5702e-04 - val_loss: 2.6940e-04 - 79s/epoch - 53ms/step
Epoch 144/200
1493/1493 - 79s - loss: 2.6198e-04 - val_loss: 2.5259e-04 - 79s/epoch - 53ms/step
Epoch 145/200
1493/1493 - 79s - loss: 2.5592e-04 - val_loss: 2.5213e-04 - 79s/epoch - 53ms/step
Epoch 146/200
1493/1493 - 79s - loss: 2.5400e-04 - val_loss: 2.4147e-04 - 79s/epoch - 53ms/step
Epoch 147/200
1493/1493 - 79s - loss: 2.5225e-04 - val_loss: 2.7980e-04 - 79s/epoch - 53ms/step
Epoch 148/200
1493/1493 - 79s - loss: 2.6024e-04 - val_loss: 3.2242e-04 - 79s/epoch - 53ms/step
Epoch 149/200
1493/1493 - 79s - loss: 2.5150e-04 - val_loss: 2.5036e-04 - 79s/epoch - 53ms/step
Epoch 150/200
1493/1493 - 80s - loss: 2.5049e-04 - val_loss: 2.4374e-04 - 80s/epoch - 54ms/step
Epoch 151/200
1493/1493 - 80s - loss: 2.5194e-04 - val_loss: 2.5078e-04 - 80s/epoch - 54ms/step
Epoch 152/200
1493/1493 - 79s - loss: 2.5133e-04 - val_loss: 3.4938e-04 - 79s/epoch - 53ms/step
Epoch 153/200
1493/1493 - 79s - loss: 2.7200e-04 - val_loss: 2.4715e-04 - 79s/epoch - 53ms/step
Epoch 154/200
1493/1493 - 79s - loss: 2.5057e-04 - val_loss: 2.9577e-04 - 79s/epoch - 53ms/step
Epoch 155/200
1493/1493 - 79s - loss: 2.6553e-04 - val_loss: 2.4550e-04 - 79s/epoch - 53ms/step
Epoch 156/200
1493/1493 - 79s - loss: 2.5057e-04 - val_loss: 2.6188e-04 - 79s/epoch - 53ms/step
Epoch 157/200
1493/1493 - 79s - loss: 2.4794e-04 - val_loss: 2.7322e-04 - 79s/epoch - 53ms/step
Epoch 158/200
1493/1493 - 79s - loss: 2.5552e-04 - val_loss: 2.4902e-04 - 79s/epoch - 53ms/step
Epoch 159/200
1493/1493 - 79s - loss: 2.4655e-04 - val_loss: 2.4199e-04 - 79s/epoch - 53ms/step
Epoch 160/200
1493/1493 - 79s - loss: 2.4570e-04 - val_loss: 2.5340e-04 - 79s/epoch - 53ms/step
Epoch 161/200
1493/1493 - 79s - loss: 2.4779e-04 - val_loss: 2.4029e-04 - 79s/epoch - 53ms/step
Epoch 162/200
1493/1493 - 79s - loss: 2.4429e-04 - val_loss: 2.4842e-04 - 79s/epoch - 53ms/step
Epoch 163/200
1493/1493 - 79s - loss: 2.4775e-04 - val_loss: 3.2907e-04 - 79s/epoch - 53ms/step
Epoch 164/200
1493/1493 - 79s - loss: 2.7727e-04 - val_loss: 2.4828e-04 - 79s/epoch - 53ms/step
Epoch 165/200
1493/1493 - 79s - loss: 2.6003e-04 - val_loss: 2.4338e-04 - 79s/epoch - 53ms/step
Epoch 166/200
1493/1493 - 79s - loss: 2.4598e-04 - val_loss: 2.4142e-04 - 79s/epoch - 53ms/step
Epoch 167/200
1493/1493 - 79s - loss: 2.4560e-04 - val_loss: 2.3905e-04 - 79s/epoch - 53ms/step
Epoch 168/200
1493/1493 - 79s - loss: 2.4370e-04 - val_loss: 2.3842e-04 - 79s/epoch - 53ms/step
Epoch 169/200
1493/1493 - 79s - loss: 2.4414e-04 - val_loss: 2.7008e-04 - 79s/epoch - 53ms/step
Epoch 170/200
1493/1493 - 80s - loss: 2.4619e-04 - val_loss: 3.3138e-04 - 80s/epoch - 53ms/step
Epoch 171/200
1493/1493 - 81s - loss: 2.9646e-04 - val_loss: 4.3487e-04 - 81s/epoch - 54ms/step
Epoch 172/200
1493/1493 - 81s - loss: 3.0554e-04 - val_loss: 2.8077e-04 - 81s/epoch - 54ms/step
Epoch 173/200
1493/1493 - 81s - loss: 2.5484e-04 - val_loss: 2.2894e-04 - 81s/epoch - 54ms/step
Epoch 174/200
1493/1493 - 81s - loss: 2.4467e-04 - val_loss: 2.4502e-04 - 81s/epoch - 54ms/step
Epoch 175/200
1493/1493 - 81s - loss: 2.4486e-04 - val_loss: 2.3764e-04 - 81s/epoch - 54ms/step
Epoch 176/200
1493/1493 - 81s - loss: 2.4582e-04 - val_loss: 2.4688e-04 - 81s/epoch - 54ms/step
Epoch 177/200
1493/1493 - 81s - loss: 2.4642e-04 - val_loss: 2.3235e-04 - 81s/epoch - 54ms/step
Epoch 178/200
1493/1493 - 81s - loss: 2.4093e-04 - val_loss: 2.2886e-04 - 81s/epoch - 54ms/step
Epoch 179/200
1493/1493 - 80s - loss: 2.3859e-04 - val_loss: 2.5316e-04 - 80s/epoch - 54ms/step
Epoch 180/200
1493/1493 - 81s - loss: 2.4912e-04 - val_loss: 2.6659e-04 - 81s/epoch - 54ms/step
Epoch 181/200
1493/1493 - 81s - loss: 2.5840e-04 - val_loss: 2.6133e-04 - 81s/epoch - 54ms/step
Epoch 182/200
1493/1493 - 80s - loss: 2.4134e-04 - val_loss: 2.3928e-04 - 80s/epoch - 54ms/step
Epoch 183/200
1493/1493 - 80s - loss: 2.4458e-04 - val_loss: 2.7777e-04 - 80s/epoch - 54ms/step
Epoch 184/200
1493/1493 - 81s - loss: 2.4402e-04 - val_loss: 2.3140e-04 - 81s/epoch - 54ms/step
Epoch 185/200
1493/1493 - 81s - loss: 2.3603e-04 - val_loss: 2.4415e-04 - 81s/epoch - 54ms/step
Epoch 186/200
1493/1493 - 81s - loss: 2.3810e-04 - val_loss: 2.2864e-04 - 81s/epoch - 54ms/step
Epoch 187/200
1493/1493 - 81s - loss: 2.3545e-04 - val_loss: 2.3990e-04 - 81s/epoch - 54ms/step
Epoch 188/200
1493/1493 - 81s - loss: 2.4172e-04 - val_loss: 3.3470e-04 - 81s/epoch - 54ms/step
Epoch 189/200
1493/1493 - 81s - loss: 2.6196e-04 - val_loss: 2.3334e-04 - 81s/epoch - 54ms/step
Epoch 190/200
1493/1493 - 81s - loss: 2.4113e-04 - val_loss: 2.3448e-04 - 81s/epoch - 54ms/step
Epoch 191/200
1493/1493 - 79s - loss: 2.3639e-04 - val_loss: 2.5218e-04 - 79s/epoch - 53ms/step
Epoch 192/200
1493/1493 - 81s - loss: 2.3886e-04 - val_loss: 2.4678e-04 - 81s/epoch - 54ms/step
Epoch 193/200
1493/1493 - 81s - loss: 2.4314e-04 - val_loss: 3.0980e-04 - 81s/epoch - 54ms/step
Epoch 194/200
1493/1493 - 81s - loss: 2.7560e-04 - val_loss: 5.0856e-04 - 81s/epoch - 54ms/step
Epoch 195/200
1493/1493 - 81s - loss: 3.0706e-04 - val_loss: 4.0103e-04 - 81s/epoch - 54ms/step
Epoch 196/200
1493/1493 - 81s - loss: 2.8125e-04 - val_loss: 2.2795e-04 - 81s/epoch - 54ms/step
Epoch 197/200
1493/1493 - 81s - loss: 2.4224e-04 - val_loss: 2.5158e-04 - 81s/epoch - 54ms/step
Epoch 198/200
1493/1493 - 81s - loss: 2.4477e-04 - val_loss: 3.0151e-04 - 81s/epoch - 54ms/step
Epoch 199/200
1493/1493 - 81s - loss: 2.5715e-04 - val_loss: 2.2086e-04 - 81s/epoch - 54ms/step
Epoch 200/200
1493/1493 - 81s - loss: 2.3763e-04 - val_loss: 2.3249e-04 - 81s/epoch - 54ms/step
COMPRESSED VECTOR SIZE: 189
Loss in the autoencoder: 0.00023249372316058725
  1/332 [..............................] - ETA: 49s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 3s 36/332 [==>...........................] - ETA: 3s 41/332 [==>...........................] - ETA: 2s 46/332 [===>..........................] - ETA: 2s 51/332 [===>..........................] - ETA: 2s 56/332 [====>.........................] - ETA: 2s 61/332 [====>.........................] - ETA: 2s 66/332 [====>.........................] - ETA: 2s 71/332 [=====>........................] - ETA: 2s 75/332 [=====>........................] - ETA: 2s 80/332 [======>.......................] - ETA: 2s 85/332 [======>.......................] - ETA: 2s 90/332 [=======>......................] - ETA: 2s 95/332 [=======>......................] - ETA: 2s100/332 [========>.....................] - ETA: 2s105/332 [========>.....................] - ETA: 2s110/332 [========>.....................] - ETA: 2s115/332 [=========>....................] - ETA: 2s120/332 [=========>....................] - ETA: 2s125/332 [==========>...................] - ETA: 2s130/332 [==========>...................] - ETA: 2s135/332 [===========>..................] - ETA: 2s140/332 [===========>..................] - ETA: 1s145/332 [============>.................] - ETA: 1s150/332 [============>.................] - ETA: 1s155/332 [=============>................] - ETA: 1s160/332 [=============>................] - ETA: 1s165/332 [=============>................] - ETA: 1s170/332 [==============>...............] - ETA: 1s175/332 [==============>...............] - ETA: 1s180/332 [===============>..............] - ETA: 1s185/332 [===============>..............] - ETA: 1s190/332 [================>.............] - ETA: 1s195/332 [================>.............] - ETA: 1s200/332 [=================>............] - ETA: 1s205/332 [=================>............] - ETA: 1s210/332 [=================>............] - ETA: 1s215/332 [==================>...........] - ETA: 1s220/332 [==================>...........] - ETA: 1s225/332 [===================>..........] - ETA: 1s230/332 [===================>..........] - ETA: 1s235/332 [====================>.........] - ETA: 0s240/332 [====================>.........] - ETA: 0s245/332 [=====================>........] - ETA: 0s250/332 [=====================>........] - ETA: 0s255/332 [======================>.......] - ETA: 0s260/332 [======================>.......] - ETA: 0s265/332 [======================>.......] - ETA: 0s270/332 [=======================>......] - ETA: 0s275/332 [=======================>......] - ETA: 0s280/332 [========================>.....] - ETA: 0s285/332 [========================>.....] - ETA: 0s290/332 [=========================>....] - ETA: 0s295/332 [=========================>....] - ETA: 0s300/332 [==========================>...] - ETA: 0s305/332 [==========================>...] - ETA: 0s310/332 [===========================>..] - ETA: 0s315/332 [===========================>..] - ETA: 0s320/332 [===========================>..] - ETA: 0s325/332 [============================>.] - ETA: 0s330/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 10ms/step
correlation 0.0026765233541137085
cosine 0.0021079230423113825
MAE: 0.008094473
RMSE: 0.015247739
r2: 0.9849181797195237
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_12 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 189)               525609    
                                                                 
 batch_normalization_13 (Bat  (None, 189)              756       
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 189)               0         
                                                                 
 dense_13 (Dense)            (None, 2780)              528200    
                                                                 
 batch_normalization_14 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2780)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 8,108,689
Trainable params: 8,097,191
Non-trainable params: 11,498
_________________________________________________________________
Encoder
Model: "model_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_14 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_12 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 189)               525609    
                                                                 
=================================================================
Total params: 4,053,429
Trainable params: 4,047,869
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_15 (InputLayer)       [(None, 189)]             0         
                                                                 
 batch_normalization_13 (Bat  (None, 189)              756       
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 189)               0         
                                                                 
 dense_13 (Dense)            (None, 2780)              528200    
                                                                 
 batch_normalization_14 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2780)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 4,055,260
Trainable params: 4,049,322
Non-trainable params: 5,938
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.15, 189, 0.0002376273478148505, 0.00023249372316058725, 0.0026765233541137085, 0.0021079230423113825, 0.00809447281062603, 0.015247738920152187, 0.9849181797195237, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_15 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_15 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 126)               350406    
                                                                 
 batch_normalization_16 (Bat  (None, 126)              504       
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 126)               0         
                                                                 
 dense_16 (Dense)            (None, 2780)              353060    
                                                                 
 batch_normalization_17 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2780)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 7,758,094
Trainable params: 7,746,722
Non-trainable params: 11,372
_________________________________________________________________
Epoch 1/200
1493/1493 - 76s - loss: 0.0107 - val_loss: 0.0057 - 76s/epoch - 51ms/step
Epoch 2/200
1493/1493 - 75s - loss: 0.0041 - val_loss: 0.0034 - 75s/epoch - 50ms/step
Epoch 3/200
1493/1493 - 75s - loss: 0.0031 - val_loss: 0.0028 - 75s/epoch - 50ms/step
Epoch 4/200
1493/1493 - 75s - loss: 0.0027 - val_loss: 0.0052 - 75s/epoch - 50ms/step
Epoch 5/200
1493/1493 - 75s - loss: 0.0026 - val_loss: 0.0021 - 75s/epoch - 50ms/step
Epoch 6/200
1493/1493 - 75s - loss: 0.0022 - val_loss: 0.0022 - 75s/epoch - 50ms/step
Epoch 7/200
1493/1493 - 75s - loss: 0.0020 - val_loss: 0.0018 - 75s/epoch - 50ms/step
Epoch 8/200
1493/1493 - 75s - loss: 0.0018 - val_loss: 0.0018 - 75s/epoch - 50ms/step
Epoch 9/200
1493/1493 - 75s - loss: 0.0016 - val_loss: 0.0018 - 75s/epoch - 50ms/step
Epoch 10/200
1493/1493 - 75s - loss: 0.0015 - val_loss: 0.0013 - 75s/epoch - 50ms/step
Epoch 11/200
1493/1493 - 75s - loss: 0.0013 - val_loss: 0.0012 - 75s/epoch - 50ms/step
Epoch 12/200
1493/1493 - 75s - loss: 0.0012 - val_loss: 0.0012 - 75s/epoch - 50ms/step
Epoch 13/200
1493/1493 - 75s - loss: 0.0011 - val_loss: 0.0013 - 75s/epoch - 50ms/step
Epoch 14/200
1493/1493 - 75s - loss: 0.0011 - val_loss: 9.5403e-04 - 75s/epoch - 50ms/step
Epoch 15/200
1493/1493 - 75s - loss: 0.0010 - val_loss: 9.2439e-04 - 75s/epoch - 50ms/step
Epoch 16/200
1493/1493 - 75s - loss: 9.3207e-04 - val_loss: 8.2197e-04 - 75s/epoch - 50ms/step
Epoch 17/200
1493/1493 - 75s - loss: 8.8643e-04 - val_loss: 9.1083e-04 - 75s/epoch - 50ms/step
Epoch 18/200
1493/1493 - 75s - loss: 8.4910e-04 - val_loss: 0.0011 - 75s/epoch - 50ms/step
Epoch 19/200
1493/1493 - 75s - loss: 8.5032e-04 - val_loss: 8.5155e-04 - 75s/epoch - 50ms/step
Epoch 20/200
1493/1493 - 75s - loss: 8.0033e-04 - val_loss: 7.2129e-04 - 75s/epoch - 50ms/step
Epoch 21/200
1493/1493 - 75s - loss: 7.7207e-04 - val_loss: 0.0011 - 75s/epoch - 50ms/step
Epoch 22/200
1493/1493 - 75s - loss: 7.5935e-04 - val_loss: 8.1510e-04 - 75s/epoch - 50ms/step
Epoch 23/200
1493/1493 - 75s - loss: 7.6203e-04 - val_loss: 7.6626e-04 - 75s/epoch - 50ms/step
Epoch 24/200
1493/1493 - 75s - loss: 7.3173e-04 - val_loss: 6.6054e-04 - 75s/epoch - 50ms/step
Epoch 25/200
1493/1493 - 75s - loss: 6.9710e-04 - val_loss: 6.5518e-04 - 75s/epoch - 50ms/step
Epoch 26/200
1493/1493 - 75s - loss: 6.7245e-04 - val_loss: 7.4849e-04 - 75s/epoch - 50ms/step
Epoch 27/200
1493/1493 - 75s - loss: 6.5502e-04 - val_loss: 6.1417e-04 - 75s/epoch - 50ms/step
Epoch 28/200
1493/1493 - 75s - loss: 6.3317e-04 - val_loss: 6.7928e-04 - 75s/epoch - 50ms/step
Epoch 29/200
1493/1493 - 75s - loss: 6.2694e-04 - val_loss: 6.6660e-04 - 75s/epoch - 50ms/step
Epoch 30/200
1493/1493 - 75s - loss: 6.2596e-04 - val_loss: 5.8049e-04 - 75s/epoch - 50ms/step
Epoch 31/200
1493/1493 - 75s - loss: 6.0387e-04 - val_loss: 6.8413e-04 - 75s/epoch - 50ms/step
Epoch 32/200
1493/1493 - 75s - loss: 6.3210e-04 - val_loss: 5.5987e-04 - 75s/epoch - 50ms/step
Epoch 33/200
1493/1493 - 75s - loss: 5.8990e-04 - val_loss: 5.4695e-04 - 75s/epoch - 50ms/step
Epoch 34/200
1493/1493 - 75s - loss: 5.7400e-04 - val_loss: 5.3092e-04 - 75s/epoch - 50ms/step
Epoch 35/200
1493/1493 - 75s - loss: 5.6380e-04 - val_loss: 7.0534e-04 - 75s/epoch - 50ms/step
Epoch 36/200
1493/1493 - 75s - loss: 5.9633e-04 - val_loss: 5.6986e-04 - 75s/epoch - 50ms/step
Epoch 37/200
1493/1493 - 75s - loss: 5.5465e-04 - val_loss: 5.5392e-04 - 75s/epoch - 50ms/step
Epoch 38/200
1493/1493 - 75s - loss: 5.5030e-04 - val_loss: 5.3300e-04 - 75s/epoch - 50ms/step
Epoch 39/200
1493/1493 - 75s - loss: 5.3816e-04 - val_loss: 5.0809e-04 - 75s/epoch - 50ms/step
Epoch 40/200
1493/1493 - 75s - loss: 5.2667e-04 - val_loss: 5.5708e-04 - 75s/epoch - 50ms/step
Epoch 41/200
1493/1493 - 75s - loss: 5.2517e-04 - val_loss: 4.9019e-04 - 75s/epoch - 50ms/step
Epoch 42/200
1493/1493 - 75s - loss: 5.2167e-04 - val_loss: 4.9819e-04 - 75s/epoch - 50ms/step
Epoch 43/200
1493/1493 - 75s - loss: 5.1301e-04 - val_loss: 5.6499e-04 - 75s/epoch - 50ms/step
Epoch 44/200
1493/1493 - 75s - loss: 5.3682e-04 - val_loss: 9.5912e-04 - 75s/epoch - 50ms/step
Epoch 45/200
1493/1493 - 75s - loss: 5.6292e-04 - val_loss: 4.7119e-04 - 75s/epoch - 50ms/step
Epoch 46/200
1493/1493 - 74s - loss: 5.0205e-04 - val_loss: 4.7922e-04 - 74s/epoch - 50ms/step
Epoch 47/200
1493/1493 - 75s - loss: 4.9754e-04 - val_loss: 4.7737e-04 - 75s/epoch - 50ms/step
Epoch 48/200
1493/1493 - 75s - loss: 4.9523e-04 - val_loss: 4.8467e-04 - 75s/epoch - 50ms/step
Epoch 49/200
1493/1493 - 75s - loss: 4.9578e-04 - val_loss: 8.3026e-04 - 75s/epoch - 50ms/step
Epoch 50/200
1493/1493 - 75s - loss: 5.6537e-04 - val_loss: 8.3449e-04 - 75s/epoch - 50ms/step
Epoch 51/200
1493/1493 - 75s - loss: 5.2246e-04 - val_loss: 4.4879e-04 - 75s/epoch - 50ms/step
Epoch 52/200
1493/1493 - 75s - loss: 4.7733e-04 - val_loss: 4.5093e-04 - 75s/epoch - 50ms/step
Epoch 53/200
1493/1493 - 75s - loss: 4.7894e-04 - val_loss: 4.4478e-04 - 75s/epoch - 50ms/step
Epoch 54/200
1493/1493 - 75s - loss: 4.6935e-04 - val_loss: 4.7581e-04 - 75s/epoch - 50ms/step
Epoch 55/200
1493/1493 - 75s - loss: 4.6318e-04 - val_loss: 4.5356e-04 - 75s/epoch - 50ms/step
Epoch 56/200
1493/1493 - 75s - loss: 4.6092e-04 - val_loss: 4.5964e-04 - 75s/epoch - 50ms/step
Epoch 57/200
1493/1493 - 75s - loss: 4.5695e-04 - val_loss: 4.4048e-04 - 75s/epoch - 50ms/step
Epoch 58/200
1493/1493 - 75s - loss: 4.5401e-04 - val_loss: 4.3260e-04 - 75s/epoch - 50ms/step
Epoch 59/200
1493/1493 - 75s - loss: 4.5040e-04 - val_loss: 4.4095e-04 - 75s/epoch - 50ms/step
Epoch 60/200
1493/1493 - 75s - loss: 4.5311e-04 - val_loss: 6.7830e-04 - 75s/epoch - 50ms/step
Epoch 61/200
1493/1493 - 75s - loss: 7.0068e-04 - val_loss: 4.4231e-04 - 75s/epoch - 50ms/step
Epoch 62/200
1493/1493 - 75s - loss: 4.6858e-04 - val_loss: 4.4267e-04 - 75s/epoch - 50ms/step
Epoch 63/200
1493/1493 - 75s - loss: 4.5187e-04 - val_loss: 4.3146e-04 - 75s/epoch - 50ms/step
Epoch 64/200
1493/1493 - 75s - loss: 4.4817e-04 - val_loss: 7.1341e-04 - 75s/epoch - 50ms/step
Epoch 65/200
1493/1493 - 75s - loss: 4.9504e-04 - val_loss: 6.1082e-04 - 75s/epoch - 50ms/step
Epoch 66/200
1493/1493 - 75s - loss: 4.6810e-04 - val_loss: 4.4181e-04 - 75s/epoch - 50ms/step
Epoch 67/200
1493/1493 - 75s - loss: 4.4069e-04 - val_loss: 4.2928e-04 - 75s/epoch - 50ms/step
Epoch 68/200
1493/1493 - 75s - loss: 4.3810e-04 - val_loss: 6.1112e-04 - 75s/epoch - 50ms/step
Epoch 69/200
1493/1493 - 75s - loss: 4.9552e-04 - val_loss: 4.1854e-04 - 75s/epoch - 50ms/step
Epoch 70/200
1493/1493 - 75s - loss: 4.3862e-04 - val_loss: 7.3789e-04 - 75s/epoch - 50ms/step
Epoch 71/200
1493/1493 - 75s - loss: 5.1178e-04 - val_loss: 4.0409e-04 - 75s/epoch - 50ms/step
Epoch 72/200
1493/1493 - 75s - loss: 4.3857e-04 - val_loss: 4.2125e-04 - 75s/epoch - 50ms/step
Epoch 73/200
1493/1493 - 75s - loss: 4.3203e-04 - val_loss: 4.3153e-04 - 75s/epoch - 50ms/step
Epoch 74/200
1493/1493 - 75s - loss: 4.3158e-04 - val_loss: 4.1781e-04 - 75s/epoch - 50ms/step
Epoch 75/200
1493/1493 - 75s - loss: 4.2124e-04 - val_loss: 4.1715e-04 - 75s/epoch - 50ms/step
Epoch 76/200
1493/1493 - 75s - loss: 4.1764e-04 - val_loss: 4.1417e-04 - 75s/epoch - 50ms/step
Epoch 77/200
1493/1493 - 75s - loss: 4.1484e-04 - val_loss: 5.2232e-04 - 75s/epoch - 50ms/step
Epoch 78/200
1493/1493 - 75s - loss: 4.3861e-04 - val_loss: 4.0582e-04 - 75s/epoch - 50ms/step
Epoch 79/200
1493/1493 - 75s - loss: 4.1665e-04 - val_loss: 5.0982e-04 - 75s/epoch - 50ms/step
Epoch 80/200
1493/1493 - 75s - loss: 4.4125e-04 - val_loss: 3.9762e-04 - 75s/epoch - 50ms/step
Epoch 81/200
1493/1493 - 75s - loss: 4.1698e-04 - val_loss: 4.0314e-04 - 75s/epoch - 50ms/step
Epoch 82/200
1493/1493 - 75s - loss: 4.1000e-04 - val_loss: 3.9695e-04 - 75s/epoch - 50ms/step
Epoch 83/200
1493/1493 - 75s - loss: 4.0447e-04 - val_loss: 4.0600e-04 - 75s/epoch - 50ms/step
Epoch 84/200
1493/1493 - 75s - loss: 4.0647e-04 - val_loss: 3.9349e-04 - 75s/epoch - 50ms/step
Epoch 85/200
1493/1493 - 75s - loss: 4.1342e-04 - val_loss: 4.0282e-04 - 75s/epoch - 50ms/step
Epoch 86/200
1493/1493 - 75s - loss: 4.0588e-04 - val_loss: 3.9176e-04 - 75s/epoch - 50ms/step
Epoch 87/200
1493/1493 - 75s - loss: 3.9709e-04 - val_loss: 3.8600e-04 - 75s/epoch - 50ms/step
Epoch 88/200
1493/1493 - 75s - loss: 3.9460e-04 - val_loss: 4.4600e-04 - 75s/epoch - 50ms/step
Epoch 89/200
1493/1493 - 75s - loss: 4.2821e-04 - val_loss: 3.8377e-04 - 75s/epoch - 50ms/step
Epoch 90/200
1493/1493 - 75s - loss: 3.9559e-04 - val_loss: 3.8336e-04 - 75s/epoch - 50ms/step
Epoch 91/200
1493/1493 - 75s - loss: 3.9219e-04 - val_loss: 4.0527e-04 - 75s/epoch - 50ms/step
Epoch 92/200
1493/1493 - 75s - loss: 3.9404e-04 - val_loss: 6.0532e-04 - 75s/epoch - 50ms/step
Epoch 93/200
1493/1493 - 75s - loss: 4.5039e-04 - val_loss: 3.8149e-04 - 75s/epoch - 50ms/step
Epoch 94/200
1493/1493 - 75s - loss: 3.9311e-04 - val_loss: 3.8113e-04 - 75s/epoch - 50ms/step
Epoch 95/200
1493/1493 - 75s - loss: 3.9042e-04 - val_loss: 3.8522e-04 - 75s/epoch - 50ms/step
Epoch 96/200
1493/1493 - 75s - loss: 3.9045e-04 - val_loss: 3.8117e-04 - 75s/epoch - 50ms/step
Epoch 97/200
1493/1493 - 75s - loss: 3.8887e-04 - val_loss: 3.6840e-04 - 75s/epoch - 50ms/step
Epoch 98/200
1493/1493 - 75s - loss: 3.8949e-04 - val_loss: 5.1102e-04 - 75s/epoch - 50ms/step
Epoch 99/200
1493/1493 - 75s - loss: 4.4616e-04 - val_loss: 3.8221e-04 - 75s/epoch - 50ms/step
Epoch 100/200
1493/1493 - 75s - loss: 3.9794e-04 - val_loss: 3.7455e-04 - 75s/epoch - 50ms/step
Epoch 101/200
1493/1493 - 75s - loss: 3.8232e-04 - val_loss: 3.8000e-04 - 75s/epoch - 50ms/step
Epoch 102/200
1493/1493 - 75s - loss: 3.8782e-04 - val_loss: 4.1815e-04 - 75s/epoch - 50ms/step
Epoch 103/200
1493/1493 - 75s - loss: 3.9821e-04 - val_loss: 3.6141e-04 - 75s/epoch - 50ms/step
Epoch 104/200
1493/1493 - 75s - loss: 3.8196e-04 - val_loss: 4.8711e-04 - 75s/epoch - 50ms/step
Epoch 105/200
1493/1493 - 75s - loss: 4.0651e-04 - val_loss: 3.5956e-04 - 75s/epoch - 50ms/step
Epoch 106/200
1493/1493 - 75s - loss: 3.7825e-04 - val_loss: 3.6523e-04 - 75s/epoch - 50ms/step
Epoch 107/200
1493/1493 - 75s - loss: 3.7736e-04 - val_loss: 3.7578e-04 - 75s/epoch - 50ms/step
Epoch 108/200
1493/1493 - 75s - loss: 3.8117e-04 - val_loss: 3.7494e-04 - 75s/epoch - 50ms/step
Epoch 109/200
1493/1493 - 75s - loss: 3.7732e-04 - val_loss: 3.6924e-04 - 75s/epoch - 50ms/step
Epoch 110/200
1493/1493 - 75s - loss: 3.7340e-04 - val_loss: 3.8162e-04 - 75s/epoch - 50ms/step
Epoch 111/200
1493/1493 - 75s - loss: 3.7232e-04 - val_loss: 4.2197e-04 - 75s/epoch - 50ms/step
Epoch 112/200
1493/1493 - 75s - loss: 4.0198e-04 - val_loss: 3.4991e-04 - 75s/epoch - 50ms/step
Epoch 113/200
1493/1493 - 75s - loss: 3.7505e-04 - val_loss: 5.4055e-04 - 75s/epoch - 50ms/step
Epoch 114/200
1493/1493 - 75s - loss: 4.2976e-04 - val_loss: 3.6872e-04 - 75s/epoch - 50ms/step
Epoch 115/200
1493/1493 - 75s - loss: 3.8018e-04 - val_loss: 3.9914e-04 - 75s/epoch - 50ms/step
Epoch 116/200
1493/1493 - 75s - loss: 3.7308e-04 - val_loss: 3.7333e-04 - 75s/epoch - 50ms/step
Epoch 117/200
1493/1493 - 75s - loss: 3.6843e-04 - val_loss: 3.8078e-04 - 75s/epoch - 50ms/step
Epoch 118/200
1493/1493 - 75s - loss: 3.7615e-04 - val_loss: 3.5566e-04 - 75s/epoch - 50ms/step
Epoch 119/200
1493/1493 - 75s - loss: 3.6687e-04 - val_loss: 3.5521e-04 - 75s/epoch - 50ms/step
Epoch 120/200
1493/1493 - 75s - loss: 3.6519e-04 - val_loss: 3.5451e-04 - 75s/epoch - 50ms/step
Epoch 121/200
1493/1493 - 75s - loss: 3.6587e-04 - val_loss: 3.8238e-04 - 75s/epoch - 50ms/step
Epoch 122/200
1493/1493 - 75s - loss: 3.7132e-04 - val_loss: 3.4947e-04 - 75s/epoch - 50ms/step
Epoch 123/200
1493/1493 - 75s - loss: 3.6145e-04 - val_loss: 3.5865e-04 - 75s/epoch - 50ms/step
Epoch 124/200
1493/1493 - 75s - loss: 3.6432e-04 - val_loss: 4.7343e-04 - 75s/epoch - 50ms/step
Epoch 125/200
1493/1493 - 75s - loss: 4.0209e-04 - val_loss: 3.5250e-04 - 75s/epoch - 50ms/step
Epoch 126/200
1493/1493 - 75s - loss: 3.8219e-04 - val_loss: 5.5571e-04 - 75s/epoch - 50ms/step
Epoch 127/200
1493/1493 - 75s - loss: 4.0550e-04 - val_loss: 3.7820e-04 - 75s/epoch - 50ms/step
Epoch 128/200
1493/1493 - 75s - loss: 3.6723e-04 - val_loss: 3.4591e-04 - 75s/epoch - 50ms/step
Epoch 129/200
1493/1493 - 75s - loss: 3.6213e-04 - val_loss: 3.4857e-04 - 75s/epoch - 50ms/step
Epoch 130/200
1493/1493 - 75s - loss: 3.6100e-04 - val_loss: 3.5950e-04 - 75s/epoch - 50ms/step
Epoch 131/200
1493/1493 - 75s - loss: 3.6582e-04 - val_loss: 4.9656e-04 - 75s/epoch - 50ms/step
Epoch 132/200
1493/1493 - 75s - loss: 4.0076e-04 - val_loss: 3.4140e-04 - 75s/epoch - 50ms/step
Epoch 133/200
1493/1493 - 75s - loss: 3.5917e-04 - val_loss: 3.4482e-04 - 75s/epoch - 50ms/step
Epoch 134/200
1493/1493 - 75s - loss: 3.5657e-04 - val_loss: 3.4674e-04 - 75s/epoch - 50ms/step
Epoch 135/200
1493/1493 - 75s - loss: 3.5380e-04 - val_loss: 3.4432e-04 - 75s/epoch - 50ms/step
Epoch 136/200
1493/1493 - 75s - loss: 3.5412e-04 - val_loss: 3.5878e-04 - 75s/epoch - 50ms/step
Epoch 137/200
1493/1493 - 75s - loss: 3.6883e-04 - val_loss: 4.2340e-04 - 75s/epoch - 50ms/step
Epoch 138/200
1493/1493 - 75s - loss: 3.8382e-04 - val_loss: 3.8610e-04 - 75s/epoch - 50ms/step
Epoch 139/200
1493/1493 - 75s - loss: 3.7594e-04 - val_loss: 4.5895e-04 - 75s/epoch - 50ms/step
Epoch 140/200
1493/1493 - 75s - loss: 3.9908e-04 - val_loss: 3.4569e-04 - 75s/epoch - 50ms/step
Epoch 141/200
1493/1493 - 75s - loss: 3.5889e-04 - val_loss: 4.2810e-04 - 75s/epoch - 50ms/step
Epoch 142/200
1493/1493 - 75s - loss: 3.8649e-04 - val_loss: 3.3396e-04 - 75s/epoch - 50ms/step
Epoch 143/200
1493/1493 - 75s - loss: 3.5436e-04 - val_loss: 3.5491e-04 - 75s/epoch - 50ms/step
Epoch 144/200
1493/1493 - 75s - loss: 3.5685e-04 - val_loss: 3.5575e-04 - 75s/epoch - 50ms/step
Epoch 145/200
1493/1493 - 75s - loss: 3.5113e-04 - val_loss: 3.3856e-04 - 75s/epoch - 50ms/step
Epoch 146/200
1493/1493 - 75s - loss: 3.4859e-04 - val_loss: 3.4205e-04 - 75s/epoch - 50ms/step
Epoch 147/200
1493/1493 - 75s - loss: 3.4639e-04 - val_loss: 3.4828e-04 - 75s/epoch - 50ms/step
Epoch 148/200
1493/1493 - 75s - loss: 3.4823e-04 - val_loss: 4.1878e-04 - 75s/epoch - 50ms/step
Epoch 149/200
1493/1493 - 75s - loss: 3.4437e-04 - val_loss: 3.3855e-04 - 75s/epoch - 50ms/step
Epoch 150/200
1493/1493 - 75s - loss: 3.4424e-04 - val_loss: 3.3209e-04 - 75s/epoch - 50ms/step
Epoch 151/200
1493/1493 - 75s - loss: 3.5680e-04 - val_loss: 3.4121e-04 - 75s/epoch - 50ms/step
Epoch 152/200
1493/1493 - 75s - loss: 3.5050e-04 - val_loss: 5.4294e-04 - 75s/epoch - 50ms/step
Epoch 153/200
1493/1493 - 75s - loss: 3.9141e-04 - val_loss: 3.3499e-04 - 75s/epoch - 50ms/step
Epoch 154/200
1493/1493 - 75s - loss: 3.4707e-04 - val_loss: 3.5728e-04 - 75s/epoch - 50ms/step
Epoch 155/200
1493/1493 - 75s - loss: 3.4946e-04 - val_loss: 3.3926e-04 - 75s/epoch - 50ms/step
Epoch 156/200
1493/1493 - 75s - loss: 3.4556e-04 - val_loss: 3.4488e-04 - 75s/epoch - 50ms/step
Epoch 157/200
1493/1493 - 75s - loss: 3.4224e-04 - val_loss: 3.5394e-04 - 75s/epoch - 50ms/step
Epoch 158/200
1493/1493 - 75s - loss: 3.4919e-04 - val_loss: 3.4168e-04 - 75s/epoch - 50ms/step
Epoch 159/200
1493/1493 - 75s - loss: 3.3973e-04 - val_loss: 3.3187e-04 - 75s/epoch - 50ms/step
Epoch 160/200
1493/1493 - 75s - loss: 3.4162e-04 - val_loss: 3.9462e-04 - 75s/epoch - 50ms/step
Epoch 161/200
1493/1493 - 75s - loss: 3.8095e-04 - val_loss: 3.4184e-04 - 75s/epoch - 50ms/step
Epoch 162/200
1493/1493 - 75s - loss: 3.4127e-04 - val_loss: 3.3713e-04 - 75s/epoch - 50ms/step
Epoch 163/200
1493/1493 - 75s - loss: 3.3976e-04 - val_loss: 3.3733e-04 - 75s/epoch - 50ms/step
Epoch 164/200
1493/1493 - 75s - loss: 3.4181e-04 - val_loss: 3.3785e-04 - 75s/epoch - 50ms/step
Epoch 165/200
1493/1493 - 75s - loss: 3.7777e-04 - val_loss: 3.3387e-04 - 75s/epoch - 50ms/step
Epoch 166/200
1493/1493 - 75s - loss: 3.4015e-04 - val_loss: 3.3848e-04 - 75s/epoch - 50ms/step
Epoch 167/200
1493/1493 - 75s - loss: 3.3848e-04 - val_loss: 3.2426e-04 - 75s/epoch - 50ms/step
Epoch 168/200
1493/1493 - 75s - loss: 3.3662e-04 - val_loss: 3.2994e-04 - 75s/epoch - 50ms/step
Epoch 169/200
1493/1493 - 75s - loss: 3.3637e-04 - val_loss: 3.6834e-04 - 75s/epoch - 50ms/step
Epoch 170/200
1493/1493 - 75s - loss: 3.3987e-04 - val_loss: 3.9937e-04 - 75s/epoch - 50ms/step
Epoch 171/200
1493/1493 - 75s - loss: 3.8684e-04 - val_loss: 5.8933e-04 - 75s/epoch - 50ms/step
Epoch 172/200
1493/1493 - 75s - loss: 4.1106e-04 - val_loss: 3.3820e-04 - 75s/epoch - 50ms/step
Epoch 173/200
1493/1493 - 75s - loss: 3.4558e-04 - val_loss: 3.2509e-04 - 75s/epoch - 50ms/step
Epoch 174/200
1493/1493 - 75s - loss: 3.3712e-04 - val_loss: 3.4285e-04 - 75s/epoch - 50ms/step
Epoch 175/200
1493/1493 - 75s - loss: 3.3734e-04 - val_loss: 3.2251e-04 - 75s/epoch - 50ms/step
Epoch 176/200
1493/1493 - 75s - loss: 3.3861e-04 - val_loss: 3.3699e-04 - 75s/epoch - 50ms/step
Epoch 177/200
1493/1493 - 75s - loss: 3.3912e-04 - val_loss: 3.3228e-04 - 75s/epoch - 50ms/step
Epoch 178/200
1493/1493 - 75s - loss: 3.3328e-04 - val_loss: 3.2181e-04 - 75s/epoch - 50ms/step
Epoch 179/200
1493/1493 - 75s - loss: 3.3109e-04 - val_loss: 3.2995e-04 - 75s/epoch - 50ms/step
Epoch 180/200
1493/1493 - 75s - loss: 3.3453e-04 - val_loss: 3.5172e-04 - 75s/epoch - 50ms/step
Epoch 181/200
1493/1493 - 75s - loss: 3.4535e-04 - val_loss: 3.3170e-04 - 75s/epoch - 50ms/step
Epoch 182/200
1493/1493 - 75s - loss: 3.3120e-04 - val_loss: 3.3553e-04 - 75s/epoch - 50ms/step
Epoch 183/200
1493/1493 - 75s - loss: 3.3424e-04 - val_loss: 3.8899e-04 - 75s/epoch - 50ms/step
Epoch 184/200
1493/1493 - 75s - loss: 3.3232e-04 - val_loss: 3.2372e-04 - 75s/epoch - 50ms/step
Epoch 185/200
1493/1493 - 75s - loss: 3.2658e-04 - val_loss: 3.3802e-04 - 75s/epoch - 50ms/step
Epoch 186/200
1493/1493 - 75s - loss: 3.3250e-04 - val_loss: 3.1979e-04 - 75s/epoch - 50ms/step
Epoch 187/200
1493/1493 - 75s - loss: 3.2901e-04 - val_loss: 3.6887e-04 - 75s/epoch - 50ms/step
Epoch 188/200
1493/1493 - 75s - loss: 3.4782e-04 - val_loss: 3.3725e-04 - 75s/epoch - 50ms/step
Epoch 189/200
1493/1493 - 75s - loss: 3.3174e-04 - val_loss: 3.2476e-04 - 75s/epoch - 50ms/step
Epoch 190/200
1493/1493 - 75s - loss: 3.3120e-04 - val_loss: 3.3232e-04 - 75s/epoch - 50ms/step
Epoch 191/200
1493/1493 - 75s - loss: 3.3083e-04 - val_loss: 3.4418e-04 - 75s/epoch - 50ms/step
Epoch 192/200
1493/1493 - 75s - loss: 3.3268e-04 - val_loss: 3.2045e-04 - 75s/epoch - 50ms/step
Epoch 193/200
1493/1493 - 75s - loss: 3.3074e-04 - val_loss: 4.1726e-04 - 75s/epoch - 50ms/step
Epoch 194/200
1493/1493 - 75s - loss: 3.6287e-04 - val_loss: 5.3152e-04 - 75s/epoch - 50ms/step
Epoch 195/200
1493/1493 - 75s - loss: 3.8145e-04 - val_loss: 4.1848e-04 - 75s/epoch - 50ms/step
Epoch 196/200
1493/1493 - 75s - loss: 3.6257e-04 - val_loss: 3.1592e-04 - 75s/epoch - 50ms/step
Epoch 197/200
1493/1493 - 75s - loss: 3.3091e-04 - val_loss: 3.3473e-04 - 75s/epoch - 50ms/step
Epoch 198/200
1493/1493 - 75s - loss: 3.3165e-04 - val_loss: 3.4220e-04 - 75s/epoch - 50ms/step
Epoch 199/200
1493/1493 - 75s - loss: 3.3020e-04 - val_loss: 3.1707e-04 - 75s/epoch - 50ms/step
Epoch 200/200
1493/1493 - 75s - loss: 3.2624e-04 - val_loss: 3.2374e-04 - 75s/epoch - 50ms/step
COMPRESSED VECTOR SIZE: 126
Loss in the autoencoder: 0.0003237362252548337
  1/332 [..............................] - ETA: 40s  7/332 [..............................] - ETA: 3s  13/332 [>.............................] - ETA: 3s 19/332 [>.............................] - ETA: 3s 25/332 [=>............................] - ETA: 3s 31/332 [=>............................] - ETA: 2s 37/332 [==>...........................] - ETA: 2s 43/332 [==>...........................] - ETA: 2s 49/332 [===>..........................] - ETA: 2s 55/332 [===>..........................] - ETA: 2s 61/332 [====>.........................] - ETA: 2s 67/332 [=====>........................] - ETA: 2s 73/332 [=====>........................] - ETA: 2s 79/332 [======>.......................] - ETA: 2s 85/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 97/332 [=======>......................] - ETA: 2s103/332 [========>.....................] - ETA: 2s109/332 [========>.....................] - ETA: 2s115/332 [=========>....................] - ETA: 2s120/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s132/332 [==========>...................] - ETA: 1s138/332 [===========>..................] - ETA: 1s144/332 [============>.................] - ETA: 1s150/332 [============>.................] - ETA: 1s156/332 [=============>................] - ETA: 1s162/332 [=============>................] - ETA: 1s168/332 [==============>...............] - ETA: 1s174/332 [==============>...............] - ETA: 1s180/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s192/332 [================>.............] - ETA: 1s198/332 [================>.............] - ETA: 1s204/332 [=================>............] - ETA: 1s210/332 [=================>............] - ETA: 1s216/332 [==================>...........] - ETA: 1s222/332 [===================>..........] - ETA: 1s228/332 [===================>..........] - ETA: 1s234/332 [====================>.........] - ETA: 0s240/332 [====================>.........] - ETA: 0s246/332 [=====================>........] - ETA: 0s252/332 [=====================>........] - ETA: 0s258/332 [======================>.......] - ETA: 0s264/332 [======================>.......] - ETA: 0s270/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s282/332 [========================>.....] - ETA: 0s288/332 [=========================>....] - ETA: 0s294/332 [=========================>....] - ETA: 0s299/332 [==========================>...] - ETA: 0s305/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s317/332 [===========================>..] - ETA: 0s323/332 [============================>.] - ETA: 0s329/332 [============================>.] - ETA: 0s332/332 [==============================] - 3s 10ms/step
correlation 0.003755319536383809
cosine 0.0029600554374402933
MAE: 0.009452158
RMSE: 0.017992664
r2: 0.9789991851831441
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_15 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 126)               350406    
                                                                 
 batch_normalization_16 (Bat  (None, 126)              504       
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 126)               0         
                                                                 
 dense_16 (Dense)            (None, 2780)              353060    
                                                                 
 batch_normalization_17 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2780)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 7,758,094
Trainable params: 7,746,722
Non-trainable params: 11,372
_________________________________________________________________
Encoder
Model: "model_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_17 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_15 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 126)               350406    
                                                                 
=================================================================
Total params: 3,878,226
Trainable params: 3,872,666
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_18 (InputLayer)       [(None, 126)]             0         
                                                                 
 batch_normalization_16 (Bat  (None, 126)              504       
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 126)               0         
                                                                 
 dense_16 (Dense)            (None, 2780)              353060    
                                                                 
 batch_normalization_17 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2780)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 3,879,868
Trainable params: 3,874,056
Non-trainable params: 5,812
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.1, 126, 0.00032624456798657775, 0.0003237362252548337, 0.003755319536383809, 0.0029600554374402933, 0.009452157653868198, 0.017992664128541946, 0.9789991851831441, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_2.2final3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_18 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_18 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 63)                175203    
                                                                 
 batch_normalization_19 (Bat  (None, 63)               252       
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 63)                0         
                                                                 
 dense_19 (Dense)            (None, 2780)              177920    
                                                                 
 batch_normalization_20 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2780)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 7,407,499
Trainable params: 7,396,253
Non-trainable params: 11,246
_________________________________________________________________
Epoch 1/200
1493/1493 - 72s - loss: 0.0107 - val_loss: 0.0058 - 72s/epoch - 48ms/step
Epoch 2/200
1493/1493 - 71s - loss: 0.0050 - val_loss: 0.0052 - 71s/epoch - 48ms/step
Epoch 3/200
1493/1493 - 71s - loss: 0.0040 - val_loss: 0.0035 - 71s/epoch - 48ms/step
Epoch 4/200
1493/1493 - 71s - loss: 0.0036 - val_loss: 0.0062 - 71s/epoch - 48ms/step
Epoch 5/200
1493/1493 - 71s - loss: 0.0034 - val_loss: 0.0027 - 71s/epoch - 48ms/step
Epoch 6/200
1493/1493 - 71s - loss: 0.0028 - val_loss: 0.0028 - 71s/epoch - 48ms/step
Epoch 7/200
1493/1493 - 71s - loss: 0.0025 - val_loss: 0.0020 - 71s/epoch - 48ms/step
Epoch 8/200
1493/1493 - 71s - loss: 0.0022 - val_loss: 0.0021 - 71s/epoch - 48ms/step
Epoch 9/200
1493/1493 - 71s - loss: 0.0020 - val_loss: 0.0018 - 71s/epoch - 48ms/step
Epoch 10/200
1493/1493 - 71s - loss: 0.0018 - val_loss: 0.0016 - 71s/epoch - 48ms/step
Epoch 11/200
1493/1493 - 71s - loss: 0.0017 - val_loss: 0.0015 - 71s/epoch - 48ms/step
Epoch 12/200
1493/1493 - 71s - loss: 0.0016 - val_loss: 0.0016 - 71s/epoch - 48ms/step
Epoch 13/200
1493/1493 - 71s - loss: 0.0015 - val_loss: 0.0016 - 71s/epoch - 48ms/step
Epoch 14/200
1493/1493 - 71s - loss: 0.0014 - val_loss: 0.0013 - 71s/epoch - 48ms/step
Epoch 15/200
1493/1493 - 71s - loss: 0.0014 - val_loss: 0.0015 - 71s/epoch - 48ms/step
Epoch 16/200
1493/1493 - 71s - loss: 0.0013 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 17/200
1493/1493 - 71s - loss: 0.0012 - val_loss: 0.0012 - 71s/epoch - 48ms/step
Epoch 18/200
1493/1493 - 71s - loss: 0.0012 - val_loss: 0.0014 - 71s/epoch - 47ms/step
Epoch 19/200
1493/1493 - 71s - loss: 0.0012 - val_loss: 0.0012 - 71s/epoch - 48ms/step
Epoch 20/200
1493/1493 - 71s - loss: 0.0011 - val_loss: 0.0010 - 71s/epoch - 48ms/step
Epoch 21/200
1493/1493 - 71s - loss: 0.0011 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 22/200
1493/1493 - 71s - loss: 0.0011 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 23/200
1493/1493 - 71s - loss: 0.0011 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 24/200
1493/1493 - 71s - loss: 0.0011 - val_loss: 9.8299e-04 - 71s/epoch - 48ms/step
Epoch 25/200
1493/1493 - 71s - loss: 0.0010 - val_loss: 9.6760e-04 - 71s/epoch - 48ms/step
Epoch 26/200
1493/1493 - 71s - loss: 9.9220e-04 - val_loss: 0.0010 - 71s/epoch - 48ms/step
Epoch 27/200
1493/1493 - 71s - loss: 9.7054e-04 - val_loss: 9.2144e-04 - 71s/epoch - 48ms/step
Epoch 28/200
1493/1493 - 71s - loss: 9.4955e-04 - val_loss: 9.3451e-04 - 71s/epoch - 48ms/step
Epoch 29/200
1493/1493 - 71s - loss: 9.3748e-04 - val_loss: 8.8142e-04 - 71s/epoch - 48ms/step
Epoch 30/200
1493/1493 - 71s - loss: 9.2660e-04 - val_loss: 9.0562e-04 - 71s/epoch - 48ms/step
Epoch 31/200
1493/1493 - 71s - loss: 9.4465e-04 - val_loss: 9.5700e-04 - 71s/epoch - 48ms/step
Epoch 32/200
1493/1493 - 71s - loss: 9.0327e-04 - val_loss: 9.2866e-04 - 71s/epoch - 48ms/step
Epoch 33/200
1493/1493 - 71s - loss: 8.9683e-04 - val_loss: 8.5443e-04 - 71s/epoch - 48ms/step
Epoch 34/200
1493/1493 - 71s - loss: 8.8416e-04 - val_loss: 8.3505e-04 - 71s/epoch - 48ms/step
Epoch 35/200
1493/1493 - 71s - loss: 8.7234e-04 - val_loss: 8.9168e-04 - 71s/epoch - 48ms/step
Epoch 36/200
1493/1493 - 71s - loss: 8.8386e-04 - val_loss: 9.3135e-04 - 71s/epoch - 48ms/step
Epoch 37/200
1493/1493 - 71s - loss: 8.6142e-04 - val_loss: 9.5214e-04 - 71s/epoch - 48ms/step
Epoch 38/200
1493/1493 - 71s - loss: 8.7363e-04 - val_loss: 8.1839e-04 - 71s/epoch - 48ms/step
Epoch 39/200
1493/1493 - 71s - loss: 8.4450e-04 - val_loss: 8.1615e-04 - 71s/epoch - 48ms/step
Epoch 40/200
1493/1493 - 71s - loss: 8.3102e-04 - val_loss: 8.1604e-04 - 71s/epoch - 48ms/step
Epoch 41/200
1493/1493 - 71s - loss: 8.3334e-04 - val_loss: 7.8768e-04 - 71s/epoch - 48ms/step
Epoch 42/200
1493/1493 - 71s - loss: 8.2974e-04 - val_loss: 7.9454e-04 - 71s/epoch - 48ms/step
Epoch 43/200
1493/1493 - 71s - loss: 8.1552e-04 - val_loss: 9.4212e-04 - 71s/epoch - 48ms/step
Epoch 44/200
1493/1493 - 71s - loss: 8.5121e-04 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 45/200
1493/1493 - 71s - loss: 8.9126e-04 - val_loss: 7.7571e-04 - 71s/epoch - 48ms/step
Epoch 46/200
1493/1493 - 71s - loss: 8.0770e-04 - val_loss: 7.8069e-04 - 71s/epoch - 48ms/step
Epoch 47/200
1493/1493 - 71s - loss: 8.0661e-04 - val_loss: 8.0489e-04 - 71s/epoch - 48ms/step
Epoch 48/200
1493/1493 - 71s - loss: 7.9628e-04 - val_loss: 8.3903e-04 - 71s/epoch - 48ms/step
Epoch 49/200
1493/1493 - 71s - loss: 7.9871e-04 - val_loss: 9.2267e-04 - 71s/epoch - 48ms/step
Epoch 50/200
1493/1493 - 71s - loss: 8.2684e-04 - val_loss: 8.2084e-04 - 71s/epoch - 48ms/step
Epoch 51/200
1493/1493 - 71s - loss: 8.0097e-04 - val_loss: 7.7074e-04 - 71s/epoch - 48ms/step
Epoch 52/200
1493/1493 - 71s - loss: 7.7428e-04 - val_loss: 7.5668e-04 - 71s/epoch - 48ms/step
Epoch 53/200
1493/1493 - 71s - loss: 7.7504e-04 - val_loss: 7.7558e-04 - 71s/epoch - 48ms/step
Epoch 54/200
1493/1493 - 71s - loss: 7.7674e-04 - val_loss: 8.0224e-04 - 71s/epoch - 48ms/step
Epoch 55/200
1493/1493 - 71s - loss: 7.6160e-04 - val_loss: 7.4051e-04 - 71s/epoch - 48ms/step
Epoch 56/200
1493/1493 - 71s - loss: 7.5848e-04 - val_loss: 7.5518e-04 - 71s/epoch - 48ms/step
Epoch 57/200
1493/1493 - 71s - loss: 7.6185e-04 - val_loss: 7.5034e-04 - 71s/epoch - 48ms/step
Epoch 58/200
1493/1493 - 71s - loss: 7.5037e-04 - val_loss: 7.3963e-04 - 71s/epoch - 48ms/step
Epoch 59/200
1493/1493 - 71s - loss: 7.4660e-04 - val_loss: 7.4291e-04 - 71s/epoch - 48ms/step
Epoch 60/200
1493/1493 - 71s - loss: 7.4700e-04 - val_loss: 9.2370e-04 - 71s/epoch - 48ms/step
Epoch 61/200
1493/1493 - 71s - loss: 8.7007e-04 - val_loss: 7.1517e-04 - 71s/epoch - 48ms/step
Epoch 62/200
1493/1493 - 71s - loss: 7.4819e-04 - val_loss: 7.2086e-04 - 71s/epoch - 48ms/step
Epoch 63/200
1493/1493 - 71s - loss: 7.3450e-04 - val_loss: 7.2342e-04 - 71s/epoch - 48ms/step
Epoch 64/200
1493/1493 - 71s - loss: 7.4402e-04 - val_loss: 0.0011 - 71s/epoch - 48ms/step
Epoch 65/200
1493/1493 - 71s - loss: 8.4292e-04 - val_loss: 9.6265e-04 - 71s/epoch - 48ms/step
Epoch 66/200
1493/1493 - 71s - loss: 7.8096e-04 - val_loss: 7.1055e-04 - 71s/epoch - 48ms/step
Epoch 67/200
1493/1493 - 71s - loss: 7.3414e-04 - val_loss: 7.0608e-04 - 71s/epoch - 48ms/step
Epoch 68/200
1493/1493 - 71s - loss: 7.3207e-04 - val_loss: 9.1660e-04 - 71s/epoch - 48ms/step
Epoch 69/200
1493/1493 - 71s - loss: 7.9743e-04 - val_loss: 7.2339e-04 - 71s/epoch - 48ms/step
Epoch 70/200
1493/1493 - 71s - loss: 7.3211e-04 - val_loss: 8.8274e-04 - 71s/epoch - 48ms/step
Epoch 71/200
1493/1493 - 71s - loss: 7.8018e-04 - val_loss: 7.0122e-04 - 71s/epoch - 48ms/step
Epoch 72/200
1493/1493 - 71s - loss: 7.2862e-04 - val_loss: 7.4302e-04 - 71s/epoch - 48ms/step
Epoch 73/200
1493/1493 - 71s - loss: 7.3145e-04 - val_loss: 7.2616e-04 - 71s/epoch - 48ms/step
Epoch 74/200
1493/1493 - 71s - loss: 7.2721e-04 - val_loss: 7.0104e-04 - 71s/epoch - 48ms/step
Epoch 75/200
1493/1493 - 71s - loss: 7.1227e-04 - val_loss: 7.1076e-04 - 71s/epoch - 48ms/step
Epoch 76/200
1493/1493 - 71s - loss: 7.0998e-04 - val_loss: 7.2813e-04 - 71s/epoch - 48ms/step
Epoch 77/200
1493/1493 - 71s - loss: 7.0384e-04 - val_loss: 7.6708e-04 - 71s/epoch - 48ms/step
Epoch 78/200
1493/1493 - 71s - loss: 7.4357e-04 - val_loss: 7.0699e-04 - 71s/epoch - 48ms/step
Epoch 79/200
1493/1493 - 71s - loss: 7.0997e-04 - val_loss: 7.9843e-04 - 71s/epoch - 48ms/step
Epoch 80/200
1493/1493 - 71s - loss: 7.5199e-04 - val_loss: 6.8310e-04 - 71s/epoch - 48ms/step
Epoch 81/200
1493/1493 - 71s - loss: 7.0721e-04 - val_loss: 7.0377e-04 - 71s/epoch - 48ms/step
Epoch 82/200
1493/1493 - 71s - loss: 6.9851e-04 - val_loss: 6.7155e-04 - 71s/epoch - 48ms/step
Epoch 83/200
1493/1493 - 71s - loss: 6.9526e-04 - val_loss: 6.8158e-04 - 71s/epoch - 48ms/step
Epoch 84/200
1493/1493 - 71s - loss: 6.9420e-04 - val_loss: 6.7858e-04 - 71s/epoch - 48ms/step
Epoch 85/200
1493/1493 - 71s - loss: 6.9141e-04 - val_loss: 7.0761e-04 - 71s/epoch - 48ms/step
Epoch 86/200
1493/1493 - 71s - loss: 7.0350e-04 - val_loss: 6.6469e-04 - 71s/epoch - 48ms/step
Epoch 87/200
1493/1493 - 71s - loss: 6.8203e-04 - val_loss: 6.7802e-04 - 71s/epoch - 48ms/step
Epoch 88/200
1493/1493 - 71s - loss: 6.8157e-04 - val_loss: 6.7740e-04 - 71s/epoch - 48ms/step
Epoch 89/200
1493/1493 - 71s - loss: 7.2125e-04 - val_loss: 6.8009e-04 - 71s/epoch - 48ms/step
Epoch 90/200
1493/1493 - 71s - loss: 6.8461e-04 - val_loss: 6.5266e-04 - 71s/epoch - 48ms/step
Epoch 91/200
1493/1493 - 71s - loss: 6.7549e-04 - val_loss: 7.1689e-04 - 71s/epoch - 48ms/step
Epoch 92/200
1493/1493 - 71s - loss: 6.7732e-04 - val_loss: 7.8216e-04 - 71s/epoch - 48ms/step
Epoch 93/200
1493/1493 - 71s - loss: 7.0651e-04 - val_loss: 6.7642e-04 - 71s/epoch - 48ms/step
Epoch 94/200
1493/1493 - 71s - loss: 6.7559e-04 - val_loss: 6.6208e-04 - 71s/epoch - 48ms/step
Epoch 95/200
1493/1493 - 71s - loss: 6.7235e-04 - val_loss: 6.9077e-04 - 71s/epoch - 48ms/step
Epoch 96/200
1493/1493 - 71s - loss: 6.8785e-04 - val_loss: 7.4399e-04 - 71s/epoch - 48ms/step
Epoch 97/200
1493/1493 - 71s - loss: 7.1163e-04 - val_loss: 6.7005e-04 - 71s/epoch - 48ms/step
Epoch 98/200
1493/1493 - 71s - loss: 6.7518e-04 - val_loss: 9.1983e-04 - 71s/epoch - 48ms/step
Epoch 99/200
1493/1493 - 71s - loss: 7.3205e-04 - val_loss: 6.6265e-04 - 71s/epoch - 48ms/step
Epoch 100/200
1493/1493 - 71s - loss: 6.7966e-04 - val_loss: 6.5555e-04 - 71s/epoch - 48ms/step
Epoch 101/200
1493/1493 - 71s - loss: 6.6347e-04 - val_loss: 6.9038e-04 - 71s/epoch - 48ms/step
Epoch 102/200
1493/1493 - 71s - loss: 6.8254e-04 - val_loss: 7.3207e-04 - 71s/epoch - 48ms/step
Epoch 103/200
1493/1493 - 71s - loss: 7.0455e-04 - val_loss: 6.5256e-04 - 71s/epoch - 48ms/step
Epoch 104/200
1493/1493 - 71s - loss: 6.6640e-04 - val_loss: 7.6518e-04 - 71s/epoch - 48ms/step
Epoch 105/200
1493/1493 - 71s - loss: 6.9785e-04 - val_loss: 6.6239e-04 - 71s/epoch - 48ms/step
Epoch 106/200
1493/1493 - 71s - loss: 6.6196e-04 - val_loss: 6.5075e-04 - 71s/epoch - 48ms/step
Epoch 107/200
1493/1493 - 71s - loss: 6.6040e-04 - val_loss: 6.5066e-04 - 71s/epoch - 48ms/step
Epoch 108/200
1493/1493 - 71s - loss: 6.6341e-04 - val_loss: 6.4410e-04 - 71s/epoch - 48ms/step
Epoch 109/200
1493/1493 - 71s - loss: 6.5918e-04 - val_loss: 6.6233e-04 - 71s/epoch - 48ms/step
Epoch 110/200
1493/1493 - 71s - loss: 6.5358e-04 - val_loss: 6.4532e-04 - 71s/epoch - 48ms/step
Epoch 111/200
1493/1493 - 71s - loss: 6.5256e-04 - val_loss: 6.7867e-04 - 71s/epoch - 48ms/step
Epoch 112/200
1493/1493 - 71s - loss: 6.6209e-04 - val_loss: 6.5048e-04 - 71s/epoch - 48ms/step
Epoch 113/200
1493/1493 - 71s - loss: 6.4949e-04 - val_loss: 7.3358e-04 - 71s/epoch - 48ms/step
Epoch 114/200
1493/1493 - 71s - loss: 6.8561e-04 - val_loss: 6.6154e-04 - 71s/epoch - 48ms/step
Epoch 115/200
1493/1493 - 71s - loss: 6.5838e-04 - val_loss: 6.5586e-04 - 71s/epoch - 48ms/step
Epoch 116/200
1493/1493 - 71s - loss: 6.4744e-04 - val_loss: 6.4212e-04 - 71s/epoch - 48ms/step
Epoch 117/200
1493/1493 - 71s - loss: 6.4650e-04 - val_loss: 6.5806e-04 - 71s/epoch - 48ms/step
Epoch 118/200
1493/1493 - 71s - loss: 6.5459e-04 - val_loss: 6.5560e-04 - 71s/epoch - 48ms/step
Epoch 119/200
1493/1493 - 71s - loss: 6.4449e-04 - val_loss: 6.3571e-04 - 71s/epoch - 48ms/step
Epoch 120/200
1493/1493 - 71s - loss: 6.4299e-04 - val_loss: 6.7132e-04 - 71s/epoch - 48ms/step
Epoch 121/200
1493/1493 - 71s - loss: 6.4543e-04 - val_loss: 6.5292e-04 - 71s/epoch - 48ms/step
Epoch 122/200
1493/1493 - 71s - loss: 6.4493e-04 - val_loss: 6.2836e-04 - 71s/epoch - 48ms/step
Epoch 123/200
1493/1493 - 71s - loss: 6.3729e-04 - val_loss: 6.2980e-04 - 71s/epoch - 48ms/step
Epoch 124/200
1493/1493 - 71s - loss: 6.4052e-04 - val_loss: 7.0742e-04 - 71s/epoch - 48ms/step
Epoch 125/200
1493/1493 - 71s - loss: 6.8124e-04 - val_loss: 6.3626e-04 - 71s/epoch - 48ms/step
Epoch 126/200
1493/1493 - 71s - loss: 6.3715e-04 - val_loss: 6.3336e-04 - 71s/epoch - 48ms/step
Epoch 127/200
1493/1493 - 71s - loss: 6.3446e-04 - val_loss: 6.4793e-04 - 71s/epoch - 48ms/step
Epoch 128/200
1493/1493 - 71s - loss: 6.3434e-04 - val_loss: 6.2322e-04 - 71s/epoch - 48ms/step
Epoch 129/200
1493/1493 - 71s - loss: 6.3310e-04 - val_loss: 6.4793e-04 - 71s/epoch - 48ms/step
Epoch 130/200
1493/1493 - 71s - loss: 6.3181e-04 - val_loss: 6.3243e-04 - 71s/epoch - 48ms/step
Epoch 131/200
1493/1493 - 71s - loss: 6.3718e-04 - val_loss: 7.3822e-04 - 71s/epoch - 48ms/step
Epoch 132/200
1493/1493 - 71s - loss: 6.7877e-04 - val_loss: 6.3006e-04 - 71s/epoch - 48ms/step
Epoch 133/200
1493/1493 - 71s - loss: 6.3565e-04 - val_loss: 6.1882e-04 - 71s/epoch - 48ms/step
Epoch 134/200
1493/1493 - 71s - loss: 6.3334e-04 - val_loss: 6.3183e-04 - 71s/epoch - 48ms/step
Epoch 135/200
1493/1493 - 71s - loss: 6.2760e-04 - val_loss: 6.2590e-04 - 71s/epoch - 47ms/step
Epoch 136/200
1493/1493 - 71s - loss: 6.3567e-04 - val_loss: 7.1856e-04 - 71s/epoch - 48ms/step
Epoch 137/200
1493/1493 - 71s - loss: 6.9086e-04 - val_loss: 6.3029e-04 - 71s/epoch - 48ms/step
Epoch 138/200
1493/1493 - 71s - loss: 6.3417e-04 - val_loss: 6.2561e-04 - 71s/epoch - 48ms/step
Epoch 139/200
1493/1493 - 71s - loss: 6.2899e-04 - val_loss: 6.3463e-04 - 71s/epoch - 48ms/step
Epoch 140/200
1493/1493 - 71s - loss: 6.2871e-04 - val_loss: 6.1516e-04 - 71s/epoch - 48ms/step
Epoch 141/200
1493/1493 - 71s - loss: 6.2525e-04 - val_loss: 6.7240e-04 - 71s/epoch - 48ms/step
Epoch 142/200
1493/1493 - 71s - loss: 6.4188e-04 - val_loss: 6.1935e-04 - 71s/epoch - 48ms/step
Epoch 143/200
1493/1493 - 71s - loss: 6.2205e-04 - val_loss: 6.3234e-04 - 71s/epoch - 48ms/step
Epoch 144/200
1493/1493 - 71s - loss: 6.2981e-04 - val_loss: 6.3296e-04 - 71s/epoch - 48ms/step
Epoch 145/200
1493/1493 - 71s - loss: 6.2191e-04 - val_loss: 6.1259e-04 - 71s/epoch - 48ms/step
Epoch 146/200
1493/1493 - 71s - loss: 6.1854e-04 - val_loss: 6.1743e-04 - 71s/epoch - 48ms/step
Epoch 147/200
1493/1493 - 71s - loss: 6.1583e-04 - val_loss: 6.1687e-04 - 71s/epoch - 48ms/step
Epoch 148/200
1493/1493 - 71s - loss: 6.2019e-04 - val_loss: 6.4362e-04 - 71s/epoch - 48ms/step
Epoch 149/200
1493/1493 - 71s - loss: 6.1466e-04 - val_loss: 6.2215e-04 - 71s/epoch - 48ms/step
Epoch 150/200
1493/1493 - 71s - loss: 6.1447e-04 - val_loss: 6.0919e-04 - 71s/epoch - 48ms/step
Epoch 151/200
1493/1493 - 71s - loss: 6.1627e-04 - val_loss: 6.3517e-04 - 71s/epoch - 48ms/step
Epoch 152/200
1493/1493 - 71s - loss: 6.3219e-04 - val_loss: 7.2694e-04 - 71s/epoch - 48ms/step
Epoch 153/200
1493/1493 - 71s - loss: 6.6939e-04 - val_loss: 6.0941e-04 - 71s/epoch - 48ms/step
Epoch 154/200
1493/1493 - 71s - loss: 6.1588e-04 - val_loss: 6.0600e-04 - 71s/epoch - 48ms/step
Epoch 155/200
1493/1493 - 71s - loss: 6.1144e-04 - val_loss: 6.2025e-04 - 71s/epoch - 48ms/step
Epoch 156/200
1493/1493 - 71s - loss: 6.1464e-04 - val_loss: 6.1039e-04 - 71s/epoch - 48ms/step
Epoch 157/200
1493/1493 - 71s - loss: 6.1357e-04 - val_loss: 6.7046e-04 - 71s/epoch - 48ms/step
Epoch 158/200
1493/1493 - 71s - loss: 6.3358e-04 - val_loss: 6.0503e-04 - 71s/epoch - 48ms/step
Epoch 159/200
1493/1493 - 71s - loss: 6.1036e-04 - val_loss: 5.9907e-04 - 71s/epoch - 48ms/step
Epoch 160/200
1493/1493 - 71s - loss: 6.1140e-04 - val_loss: 6.6022e-04 - 71s/epoch - 48ms/step
Epoch 161/200
1493/1493 - 71s - loss: 6.5664e-04 - val_loss: 6.0367e-04 - 71s/epoch - 48ms/step
Epoch 162/200
1493/1493 - 71s - loss: 6.1075e-04 - val_loss: 5.9974e-04 - 71s/epoch - 48ms/step
Epoch 163/200
1493/1493 - 71s - loss: 6.1008e-04 - val_loss: 6.3905e-04 - 71s/epoch - 48ms/step
Epoch 164/200
1493/1493 - 71s - loss: 6.2297e-04 - val_loss: 5.9445e-04 - 71s/epoch - 48ms/step
Epoch 165/200
1493/1493 - 71s - loss: 6.7062e-04 - val_loss: 6.1408e-04 - 71s/epoch - 48ms/step
Epoch 166/200
1493/1493 - 71s - loss: 6.1053e-04 - val_loss: 6.0505e-04 - 71s/epoch - 48ms/step
Epoch 167/200
1493/1493 - 71s - loss: 6.0906e-04 - val_loss: 6.0708e-04 - 71s/epoch - 48ms/step
Epoch 168/200
1493/1493 - 71s - loss: 6.0624e-04 - val_loss: 6.0226e-04 - 71s/epoch - 48ms/step
Epoch 169/200
1493/1493 - 71s - loss: 6.0726e-04 - val_loss: 6.2855e-04 - 71s/epoch - 48ms/step
Epoch 170/200
1493/1493 - 71s - loss: 6.0605e-04 - val_loss: 6.5371e-04 - 71s/epoch - 48ms/step
Epoch 171/200
1493/1493 - 71s - loss: 6.3325e-04 - val_loss: 7.0079e-04 - 71s/epoch - 48ms/step
Epoch 172/200
1493/1493 - 71s - loss: 6.2903e-04 - val_loss: 5.9278e-04 - 71s/epoch - 48ms/step
Epoch 173/200
1493/1493 - 71s - loss: 6.0328e-04 - val_loss: 6.0101e-04 - 71s/epoch - 48ms/step
Epoch 174/200
1493/1493 - 71s - loss: 6.0033e-04 - val_loss: 6.2173e-04 - 71s/epoch - 48ms/step
Epoch 175/200
1493/1493 - 71s - loss: 6.0536e-04 - val_loss: 6.0438e-04 - 71s/epoch - 48ms/step
Epoch 176/200
1493/1493 - 71s - loss: 6.0381e-04 - val_loss: 5.9739e-04 - 71s/epoch - 48ms/step
Epoch 177/200
1493/1493 - 71s - loss: 6.0965e-04 - val_loss: 5.9384e-04 - 71s/epoch - 48ms/step
Epoch 178/200
1493/1493 - 71s - loss: 5.9898e-04 - val_loss: 5.9174e-04 - 71s/epoch - 48ms/step
Epoch 179/200
1493/1493 - 71s - loss: 5.9620e-04 - val_loss: 6.1305e-04 - 71s/epoch - 48ms/step
Epoch 180/200
1493/1493 - 71s - loss: 5.9973e-04 - val_loss: 5.8726e-04 - 71s/epoch - 48ms/step
Epoch 181/200
1493/1493 - 71s - loss: 5.9997e-04 - val_loss: 6.1306e-04 - 71s/epoch - 48ms/step
Epoch 182/200
1493/1493 - 71s - loss: 5.9739e-04 - val_loss: 6.0458e-04 - 71s/epoch - 48ms/step
Epoch 183/200
1493/1493 - 71s - loss: 6.0278e-04 - val_loss: 6.5227e-04 - 71s/epoch - 48ms/step
Epoch 184/200
1493/1493 - 71s - loss: 5.9786e-04 - val_loss: 5.8552e-04 - 71s/epoch - 48ms/step
Epoch 185/200
1493/1493 - 71s - loss: 5.9556e-04 - val_loss: 6.7619e-04 - 71s/epoch - 48ms/step
Epoch 186/200
1493/1493 - 71s - loss: 6.0669e-04 - val_loss: 5.9306e-04 - 71s/epoch - 48ms/step
Epoch 187/200
1493/1493 - 71s - loss: 5.9479e-04 - val_loss: 6.0584e-04 - 71s/epoch - 48ms/step
Epoch 188/200
1493/1493 - 71s - loss: 5.9581e-04 - val_loss: 6.3075e-04 - 71s/epoch - 48ms/step
Epoch 189/200
1493/1493 - 71s - loss: 6.0165e-04 - val_loss: 5.9104e-04 - 71s/epoch - 48ms/step
Epoch 190/200
1493/1493 - 71s - loss: 5.9740e-04 - val_loss: 6.0655e-04 - 71s/epoch - 48ms/step
Epoch 191/200
1493/1493 - 71s - loss: 5.9770e-04 - val_loss: 6.1400e-04 - 71s/epoch - 48ms/step
Epoch 192/200
1493/1493 - 71s - loss: 5.9594e-04 - val_loss: 6.0093e-04 - 71s/epoch - 48ms/step
Epoch 193/200
1493/1493 - 71s - loss: 5.9660e-04 - val_loss: 6.7069e-04 - 71s/epoch - 48ms/step
Epoch 194/200
1493/1493 - 71s - loss: 6.4829e-04 - val_loss: 8.0347e-04 - 71s/epoch - 48ms/step
Epoch 195/200
1493/1493 - 71s - loss: 6.8817e-04 - val_loss: 6.3089e-04 - 71s/epoch - 48ms/step
Epoch 196/200
1493/1493 - 71s - loss: 6.2195e-04 - val_loss: 5.8583e-04 - 71s/epoch - 48ms/step
Epoch 197/200
1493/1493 - 71s - loss: 5.9461e-04 - val_loss: 5.9789e-04 - 71s/epoch - 48ms/step
Epoch 198/200
1493/1493 - 71s - loss: 5.9721e-04 - val_loss: 6.1437e-04 - 71s/epoch - 48ms/step
Epoch 199/200
1493/1493 - 71s - loss: 6.0020e-04 - val_loss: 5.9115e-04 - 71s/epoch - 48ms/step
Epoch 200/200
1493/1493 - 71s - loss: 5.9153e-04 - val_loss: 5.8740e-04 - 71s/epoch - 48ms/step
COMPRESSED VECTOR SIZE: 63
Loss in the autoencoder: 0.000587396789342165
  1/332 [..............................] - ETA: 41s  7/332 [..............................] - ETA: 3s  13/332 [>.............................] - ETA: 3s 19/332 [>.............................] - ETA: 2s 25/332 [=>............................] - ETA: 2s 31/332 [=>............................] - ETA: 2s 37/332 [==>...........................] - ETA: 2s 43/332 [==>...........................] - ETA: 2s 49/332 [===>..........................] - ETA: 2s 55/332 [===>..........................] - ETA: 2s 61/332 [====>.........................] - ETA: 2s 67/332 [=====>........................] - ETA: 2s 73/332 [=====>........................] - ETA: 2s 79/332 [======>.......................] - ETA: 2s 85/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 97/332 [=======>......................] - ETA: 2s103/332 [========>.....................] - ETA: 2s109/332 [========>.....................] - ETA: 2s115/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s127/332 [==========>...................] - ETA: 1s133/332 [===========>..................] - ETA: 1s139/332 [===========>..................] - ETA: 1s145/332 [============>.................] - ETA: 1s151/332 [============>.................] - ETA: 1s157/332 [=============>................] - ETA: 1s163/332 [=============>................] - ETA: 1s169/332 [==============>...............] - ETA: 1s175/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s192/332 [================>.............] - ETA: 1s198/332 [================>.............] - ETA: 1s204/332 [=================>............] - ETA: 1s210/332 [=================>............] - ETA: 1s216/332 [==================>...........] - ETA: 1s222/332 [===================>..........] - ETA: 1s228/332 [===================>..........] - ETA: 0s234/332 [====================>.........] - ETA: 0s240/332 [====================>.........] - ETA: 0s246/332 [=====================>........] - ETA: 0s252/332 [=====================>........] - ETA: 0s258/332 [======================>.......] - ETA: 0s264/332 [======================>.......] - ETA: 0s270/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s282/332 [========================>.....] - ETA: 0s288/332 [=========================>....] - ETA: 0s294/332 [=========================>....] - ETA: 0s299/332 [==========================>...] - ETA: 0s305/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s317/332 [===========================>..] - ETA: 0s323/332 [============================>.] - ETA: 0s329/332 [============================>.] - ETA: 0s332/332 [==============================] - 3s 10ms/step
correlation 0.006856216778406502
cosine 0.005403283336141897
MAE: 0.012396275
RMSE: 0.024236256
r2: 0.9618947393887771
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_18 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 63)                175203    
                                                                 
 batch_normalization_19 (Bat  (None, 63)               252       
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 63)                0         
                                                                 
 dense_19 (Dense)            (None, 2780)              177920    
                                                                 
 batch_normalization_20 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2780)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 7,407,499
Trainable params: 7,396,253
Non-trainable params: 11,246
_________________________________________________________________
Encoder
Model: "model_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_20 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_18 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 63)                175203    
                                                                 
=================================================================
Total params: 3,703,023
Trainable params: 3,697,463
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_21 (InputLayer)       [(None, 63)]              0         
                                                                 
 batch_normalization_19 (Bat  (None, 63)               252       
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 63)                0         
                                                                 
 dense_19 (Dense)            (None, 2780)              177920    
                                                                 
 batch_normalization_20 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2780)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 3,704,476
Trainable params: 3,698,790
Non-trainable params: 5,686
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.05, 63, 0.0005915309302508831, 0.000587396789342165, 0.006856216778406502, 0.005403283336141897, 0.01239627506583929, 0.024236256256699562, 0.9618947393887771, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Sat Dec 31 10:34:24 CET 2022
done
