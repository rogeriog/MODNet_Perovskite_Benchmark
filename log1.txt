start
Thu Dec 29 23:35:32 CET 2022
2022-12-29 23:35:33.388562: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-29 23:35:33.457574: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-12-29 23:36:08,100 - modnet - INFO - Loaded <modnet.preprocessing.MODData object at 0x7f12c43c0760> object, created with modnet version 0.1.12
        AtomicOrbitals|HOMO_character  ...  BondFractions|B - B bond frac.
id                                     ...                                
0                                 3.0  ...                             0.0
1                                 3.0  ...                             0.0
2                                 2.0  ...                             0.0
3                                 2.0  ...                             0.0
4                                 2.0  ...                             0.0
...                               ...  ...                             ...
106108                            3.0  ...                             0.0
106109                            2.0  ...                             0.0
106110                            3.0  ...                             0.0
106111                            3.0  ...                             0.0
106112                            1.0  ...                             0.0

[106113 rows x 1336 columns]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep100_loss_mse_lr0.0005_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep100_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep100_loss_mse_lr0.002_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep200_loss_mse_lr0.0005_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep200_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep200_loss_mse_lr0.002_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep300_loss_mse_lr0.0005_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep300_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs16_ep300_loss_mse_lr0.002_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep100_loss_mse_lr0.0005_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep100_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep100_loss_mse_lr0.002_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep200_loss_mse_lr0.0005_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep200_loss_mse_lr0.001_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
File MP_GapFeats_n_b_cr0.5_bs32_ep200_loss_mse_lr0.002_AutoEncoder.h5 exists in folder already, skiping this calculation.
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
2022-12-29 23:36:25.652148: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense (Dense)               (None, 1264)              1598960   
                                                                 
 batch_normalization (BatchN  (None, 1264)             5056      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_1 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 632)               0         
                                                                 
 dense_1 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_2 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1264)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
2985/2985 - 59s - loss: 0.0080 - val_loss: 0.0035 - 59s/epoch - 20ms/step
Epoch 2/300
2985/2985 - 59s - loss: 0.0028 - val_loss: 0.0020 - 59s/epoch - 20ms/step
Epoch 3/300
2985/2985 - 59s - loss: 0.0022 - val_loss: 0.0015 - 59s/epoch - 20ms/step
Epoch 4/300
2985/2985 - 59s - loss: 0.0018 - val_loss: 0.0013 - 59s/epoch - 20ms/step
Epoch 5/300
2985/2985 - 59s - loss: 0.0016 - val_loss: 0.0010 - 59s/epoch - 20ms/step
Epoch 6/300
2985/2985 - 58s - loss: 0.0014 - val_loss: 0.0013 - 58s/epoch - 20ms/step
Epoch 7/300
2985/2985 - 59s - loss: 0.0012 - val_loss: 9.3471e-04 - 59s/epoch - 20ms/step
Epoch 8/300
2985/2985 - 59s - loss: 0.0011 - val_loss: 8.1460e-04 - 59s/epoch - 20ms/step
Epoch 9/300
2985/2985 - 59s - loss: 0.0010 - val_loss: 7.4787e-04 - 59s/epoch - 20ms/step
Epoch 10/300
2985/2985 - 58s - loss: 9.1432e-04 - val_loss: 7.3087e-04 - 58s/epoch - 20ms/step
Epoch 11/300
2985/2985 - 58s - loss: 8.5846e-04 - val_loss: 7.5594e-04 - 58s/epoch - 20ms/step
Epoch 12/300
2985/2985 - 59s - loss: 7.8344e-04 - val_loss: 6.9044e-04 - 59s/epoch - 20ms/step
Epoch 13/300
2985/2985 - 58s - loss: 7.4208e-04 - val_loss: 6.1879e-04 - 58s/epoch - 20ms/step
Epoch 14/300
2985/2985 - 59s - loss: 6.9764e-04 - val_loss: 5.7085e-04 - 59s/epoch - 20ms/step
Epoch 15/300
2985/2985 - 59s - loss: 6.6739e-04 - val_loss: 5.3218e-04 - 59s/epoch - 20ms/step
Epoch 16/300
2985/2985 - 59s - loss: 6.2000e-04 - val_loss: 5.7192e-04 - 59s/epoch - 20ms/step
Epoch 17/300
2985/2985 - 58s - loss: 5.8908e-04 - val_loss: 4.9969e-04 - 58s/epoch - 20ms/step
Epoch 18/300
2985/2985 - 59s - loss: 5.6719e-04 - val_loss: 5.2676e-04 - 59s/epoch - 20ms/step
Epoch 19/300
2985/2985 - 59s - loss: 5.3836e-04 - val_loss: 4.9738e-04 - 59s/epoch - 20ms/step
Epoch 20/300
2985/2985 - 59s - loss: 5.2921e-04 - val_loss: 4.8795e-04 - 59s/epoch - 20ms/step
Epoch 21/300
2985/2985 - 59s - loss: 5.0448e-04 - val_loss: 4.9351e-04 - 59s/epoch - 20ms/step
Epoch 22/300
2985/2985 - 58s - loss: 4.8756e-04 - val_loss: 5.1144e-04 - 58s/epoch - 20ms/step
Epoch 23/300
2985/2985 - 59s - loss: 4.9554e-04 - val_loss: 4.8055e-04 - 59s/epoch - 20ms/step
Epoch 24/300
2985/2985 - 59s - loss: 4.6120e-04 - val_loss: 4.2906e-04 - 59s/epoch - 20ms/step
Epoch 25/300
2985/2985 - 59s - loss: 4.5224e-04 - val_loss: 4.0602e-04 - 59s/epoch - 20ms/step
Epoch 26/300
2985/2985 - 59s - loss: 4.4101e-04 - val_loss: 3.4913e-04 - 59s/epoch - 20ms/step
Epoch 27/300
2985/2985 - 58s - loss: 4.3122e-04 - val_loss: 3.7358e-04 - 58s/epoch - 20ms/step
Epoch 28/300
2985/2985 - 59s - loss: 4.1902e-04 - val_loss: 3.7217e-04 - 59s/epoch - 20ms/step
Epoch 29/300
2985/2985 - 59s - loss: 4.0858e-04 - val_loss: 3.3378e-04 - 59s/epoch - 20ms/step
Epoch 30/300
2985/2985 - 59s - loss: 4.0053e-04 - val_loss: 3.5688e-04 - 59s/epoch - 20ms/step
Epoch 31/300
2985/2985 - 59s - loss: 3.9110e-04 - val_loss: 3.7748e-04 - 59s/epoch - 20ms/step
Epoch 32/300
2985/2985 - 59s - loss: 4.0277e-04 - val_loss: 3.0859e-04 - 59s/epoch - 20ms/step
Epoch 33/300
2985/2985 - 58s - loss: 3.7881e-04 - val_loss: 3.0615e-04 - 58s/epoch - 20ms/step
Epoch 34/300
2985/2985 - 59s - loss: 3.7308e-04 - val_loss: 3.1912e-04 - 59s/epoch - 20ms/step
Epoch 35/300
2985/2985 - 59s - loss: 3.6117e-04 - val_loss: 3.3431e-04 - 59s/epoch - 20ms/step
Epoch 36/300
2985/2985 - 59s - loss: 3.7115e-04 - val_loss: 3.1235e-04 - 59s/epoch - 20ms/step
Epoch 37/300
2985/2985 - 59s - loss: 3.6945e-04 - val_loss: 3.5580e-04 - 59s/epoch - 20ms/step
Epoch 38/300
2985/2985 - 58s - loss: 3.4885e-04 - val_loss: 2.9838e-04 - 58s/epoch - 20ms/step
Epoch 39/300
2985/2985 - 58s - loss: 3.5802e-04 - val_loss: 2.7850e-04 - 58s/epoch - 20ms/step
Epoch 40/300
2985/2985 - 59s - loss: 3.4075e-04 - val_loss: 6.4220e-04 - 59s/epoch - 20ms/step
Epoch 41/300
2985/2985 - 59s - loss: 3.6647e-04 - val_loss: 2.7984e-04 - 59s/epoch - 20ms/step
Epoch 42/300
2985/2985 - 59s - loss: 3.3991e-04 - val_loss: 2.7523e-04 - 59s/epoch - 20ms/step
Epoch 43/300
2985/2985 - 58s - loss: 3.3404e-04 - val_loss: 2.7149e-04 - 58s/epoch - 20ms/step
Epoch 44/300
2985/2985 - 59s - loss: 3.2657e-04 - val_loss: 4.4982e-04 - 59s/epoch - 20ms/step
Epoch 45/300
2985/2985 - 59s - loss: 3.3833e-04 - val_loss: 2.6281e-04 - 59s/epoch - 20ms/step
Epoch 46/300
2985/2985 - 59s - loss: 3.2127e-04 - val_loss: 2.7803e-04 - 59s/epoch - 20ms/step
Epoch 47/300
2985/2985 - 59s - loss: 3.1441e-04 - val_loss: 3.4908e-04 - 59s/epoch - 20ms/step
Epoch 48/300
2985/2985 - 59s - loss: 3.0975e-04 - val_loss: 3.0342e-04 - 59s/epoch - 20ms/step
Epoch 49/300
2985/2985 - 58s - loss: 3.1231e-04 - val_loss: 3.0152e-04 - 58s/epoch - 20ms/step
Epoch 50/300
2985/2985 - 59s - loss: 3.0608e-04 - val_loss: 2.7891e-04 - 59s/epoch - 20ms/step
Epoch 51/300
2985/2985 - 59s - loss: 3.0220e-04 - val_loss: 2.5430e-04 - 59s/epoch - 20ms/step
Epoch 52/300
2985/2985 - 59s - loss: 2.9630e-04 - val_loss: 2.5843e-04 - 59s/epoch - 20ms/step
Epoch 53/300
2985/2985 - 59s - loss: 2.9653e-04 - val_loss: 2.6520e-04 - 59s/epoch - 20ms/step
Epoch 54/300
2985/2985 - 58s - loss: 2.9119e-04 - val_loss: 2.6360e-04 - 58s/epoch - 20ms/step
Epoch 55/300
2985/2985 - 59s - loss: 2.8956e-04 - val_loss: 2.4758e-04 - 59s/epoch - 20ms/step
Epoch 56/300
2985/2985 - 59s - loss: 3.0084e-04 - val_loss: 2.4606e-04 - 59s/epoch - 20ms/step
Epoch 57/300
2985/2985 - 59s - loss: 2.8942e-04 - val_loss: 2.8337e-04 - 59s/epoch - 20ms/step
Epoch 58/300
2985/2985 - 59s - loss: 2.8521e-04 - val_loss: 2.6398e-04 - 59s/epoch - 20ms/step
Epoch 59/300
2985/2985 - 58s - loss: 2.8138e-04 - val_loss: 2.5184e-04 - 58s/epoch - 20ms/step
Epoch 60/300
2985/2985 - 59s - loss: 2.9828e-04 - val_loss: 2.4891e-04 - 59s/epoch - 20ms/step
Epoch 61/300
2985/2985 - 59s - loss: 2.8027e-04 - val_loss: 2.2486e-04 - 59s/epoch - 20ms/step
Epoch 62/300
2985/2985 - 59s - loss: 2.7405e-04 - val_loss: 2.7892e-04 - 59s/epoch - 20ms/step
Epoch 63/300
2985/2985 - 59s - loss: 2.7555e-04 - val_loss: 2.4529e-04 - 59s/epoch - 20ms/step
Epoch 64/300
2985/2985 - 59s - loss: 2.7199e-04 - val_loss: 2.4374e-04 - 59s/epoch - 20ms/step
Epoch 65/300
2985/2985 - 58s - loss: 2.7019e-04 - val_loss: 2.8885e-04 - 58s/epoch - 20ms/step
Epoch 66/300
2985/2985 - 59s - loss: 2.8946e-04 - val_loss: 2.2829e-04 - 59s/epoch - 20ms/step
Epoch 67/300
2985/2985 - 59s - loss: 2.8129e-04 - val_loss: 2.3234e-04 - 59s/epoch - 20ms/step
Epoch 68/300
2985/2985 - 59s - loss: 2.7057e-04 - val_loss: 2.6538e-04 - 59s/epoch - 20ms/step
Epoch 69/300
2985/2985 - 59s - loss: 2.7296e-04 - val_loss: 2.4495e-04 - 59s/epoch - 20ms/step
Epoch 70/300
2985/2985 - 58s - loss: 2.6536e-04 - val_loss: 3.4576e-04 - 58s/epoch - 20ms/step
Epoch 71/300
2985/2985 - 59s - loss: 2.6250e-04 - val_loss: 2.4085e-04 - 59s/epoch - 20ms/step
Epoch 72/300
2985/2985 - 59s - loss: 2.6546e-04 - val_loss: 2.7927e-04 - 59s/epoch - 20ms/step
Epoch 73/300
2985/2985 - 59s - loss: 2.6102e-04 - val_loss: 2.3692e-04 - 59s/epoch - 20ms/step
Epoch 74/300
2985/2985 - 59s - loss: 2.6136e-04 - val_loss: 2.1101e-04 - 59s/epoch - 20ms/step
Epoch 75/300
2985/2985 - 58s - loss: 2.6634e-04 - val_loss: 2.9378e-04 - 58s/epoch - 20ms/step
Epoch 76/300
2985/2985 - 59s - loss: 2.5554e-04 - val_loss: 2.3104e-04 - 59s/epoch - 20ms/step
Epoch 77/300
2985/2985 - 59s - loss: 2.5714e-04 - val_loss: 5.4965e-04 - 59s/epoch - 20ms/step
Epoch 78/300
2985/2985 - 59s - loss: 2.6968e-04 - val_loss: 2.1976e-04 - 59s/epoch - 20ms/step
Epoch 79/300
2985/2985 - 59s - loss: 2.5068e-04 - val_loss: 3.4544e-04 - 59s/epoch - 20ms/step
Epoch 80/300
2985/2985 - 59s - loss: 2.6242e-04 - val_loss: 2.7027e-04 - 59s/epoch - 20ms/step
Epoch 81/300
2985/2985 - 58s - loss: 2.5234e-04 - val_loss: 2.4239e-04 - 58s/epoch - 20ms/step
Epoch 82/300
2985/2985 - 59s - loss: 2.5007e-04 - val_loss: 2.3870e-04 - 59s/epoch - 20ms/step
Epoch 83/300
2985/2985 - 59s - loss: 2.4940e-04 - val_loss: 2.3815e-04 - 59s/epoch - 20ms/step
Epoch 84/300
2985/2985 - 59s - loss: 2.4573e-04 - val_loss: 2.2480e-04 - 59s/epoch - 20ms/step
Epoch 85/300
2985/2985 - 59s - loss: 2.5087e-04 - val_loss: 2.0393e-04 - 59s/epoch - 20ms/step
Epoch 86/300
2985/2985 - 58s - loss: 2.4398e-04 - val_loss: 2.1451e-04 - 58s/epoch - 20ms/step
Epoch 87/300
2985/2985 - 59s - loss: 2.4049e-04 - val_loss: 2.3666e-04 - 59s/epoch - 20ms/step
Epoch 88/300
2985/2985 - 59s - loss: 2.4237e-04 - val_loss: 2.2278e-04 - 59s/epoch - 20ms/step
Epoch 89/300
2985/2985 - 59s - loss: 2.6624e-04 - val_loss: 2.6629e-04 - 59s/epoch - 20ms/step
Epoch 90/300
2985/2985 - 59s - loss: 2.4307e-04 - val_loss: 2.0801e-04 - 59s/epoch - 20ms/step
Epoch 91/300
2985/2985 - 58s - loss: 2.3849e-04 - val_loss: 2.2750e-04 - 58s/epoch - 20ms/step
Epoch 92/300
2985/2985 - 59s - loss: 2.4416e-04 - val_loss: 3.1726e-04 - 59s/epoch - 20ms/step
Epoch 93/300
2985/2985 - 59s - loss: 2.4120e-04 - val_loss: 2.1676e-04 - 59s/epoch - 20ms/step
Epoch 94/300
2985/2985 - 59s - loss: 2.3350e-04 - val_loss: 2.3642e-04 - 59s/epoch - 20ms/step
Epoch 95/300
2985/2985 - 59s - loss: 2.3811e-04 - val_loss: 2.2197e-04 - 59s/epoch - 20ms/step
Epoch 96/300
2985/2985 - 59s - loss: 2.3669e-04 - val_loss: 2.5862e-04 - 59s/epoch - 20ms/step
Epoch 97/300
2985/2985 - 58s - loss: 2.3633e-04 - val_loss: 2.1294e-04 - 58s/epoch - 20ms/step
Epoch 98/300
2985/2985 - 59s - loss: 2.3171e-04 - val_loss: 2.3191e-04 - 59s/epoch - 20ms/step
Epoch 99/300
2985/2985 - 59s - loss: 2.3071e-04 - val_loss: 2.2683e-04 - 59s/epoch - 20ms/step
Epoch 100/300
2985/2985 - 59s - loss: 2.3314e-04 - val_loss: 2.3558e-04 - 59s/epoch - 20ms/step
Epoch 101/300
2985/2985 - 59s - loss: 2.2931e-04 - val_loss: 2.2802e-04 - 59s/epoch - 20ms/step
Epoch 102/300
2985/2985 - 58s - loss: 2.4661e-04 - val_loss: 2.0718e-04 - 58s/epoch - 20ms/step
Epoch 103/300
2985/2985 - 59s - loss: 2.3369e-04 - val_loss: 2.1978e-04 - 59s/epoch - 20ms/step
Epoch 104/300
2985/2985 - 59s - loss: 2.3002e-04 - val_loss: 3.5647e-04 - 59s/epoch - 20ms/step
Epoch 105/300
2985/2985 - 59s - loss: 2.5763e-04 - val_loss: 2.3774e-04 - 59s/epoch - 20ms/step
Epoch 106/300
2985/2985 - 59s - loss: 2.2835e-04 - val_loss: 2.2333e-04 - 59s/epoch - 20ms/step
Epoch 107/300
2985/2985 - 58s - loss: 2.2569e-04 - val_loss: 2.2875e-04 - 58s/epoch - 20ms/step
Epoch 108/300
2985/2985 - 59s - loss: 2.2415e-04 - val_loss: 2.5808e-04 - 59s/epoch - 20ms/step
Epoch 109/300
2985/2985 - 59s - loss: 2.2315e-04 - val_loss: 2.4531e-04 - 59s/epoch - 20ms/step
Epoch 110/300
2985/2985 - 59s - loss: 2.3290e-04 - val_loss: 2.0973e-04 - 59s/epoch - 20ms/step
Epoch 111/300
2985/2985 - 59s - loss: 2.2550e-04 - val_loss: 2.0346e-04 - 59s/epoch - 20ms/step
Epoch 112/300
2985/2985 - 59s - loss: 2.2632e-04 - val_loss: 2.7145e-04 - 59s/epoch - 20ms/step
Epoch 113/300
2985/2985 - 58s - loss: 2.2334e-04 - val_loss: 2.2660e-04 - 58s/epoch - 20ms/step
Epoch 114/300
2985/2985 - 59s - loss: 2.2324e-04 - val_loss: 1.9160e-04 - 59s/epoch - 20ms/step
Epoch 115/300
2985/2985 - 59s - loss: 2.1949e-04 - val_loss: 2.4969e-04 - 59s/epoch - 20ms/step
Epoch 116/300
2985/2985 - 59s - loss: 2.2126e-04 - val_loss: 2.2181e-04 - 59s/epoch - 20ms/step
Epoch 117/300
2985/2985 - 59s - loss: 2.1870e-04 - val_loss: 2.0167e-04 - 59s/epoch - 20ms/step
Epoch 118/300
2985/2985 - 58s - loss: 2.2080e-04 - val_loss: 2.1180e-04 - 58s/epoch - 20ms/step
Epoch 119/300
2985/2985 - 59s - loss: 2.1796e-04 - val_loss: 2.2370e-04 - 59s/epoch - 20ms/step
Epoch 120/300
2985/2985 - 59s - loss: 2.1799e-04 - val_loss: 2.0598e-04 - 59s/epoch - 20ms/step
Epoch 121/300
2985/2985 - 59s - loss: 2.2619e-04 - val_loss: 2.5785e-04 - 59s/epoch - 20ms/step
Epoch 122/300
2985/2985 - 59s - loss: 2.2478e-04 - val_loss: 2.1664e-04 - 59s/epoch - 20ms/step
Epoch 123/300
2985/2985 - 58s - loss: 2.1812e-04 - val_loss: 2.1517e-04 - 58s/epoch - 20ms/step
Epoch 124/300
2985/2985 - 59s - loss: 2.1800e-04 - val_loss: 2.1134e-04 - 59s/epoch - 20ms/step
Epoch 125/300
2985/2985 - 59s - loss: 2.1546e-04 - val_loss: 1.8802e-04 - 59s/epoch - 20ms/step
Epoch 126/300
2985/2985 - 59s - loss: 2.1670e-04 - val_loss: 2.3228e-04 - 59s/epoch - 20ms/step
Epoch 127/300
2985/2985 - 59s - loss: 2.1381e-04 - val_loss: 2.0477e-04 - 59s/epoch - 20ms/step
Epoch 128/300
2985/2985 - 59s - loss: 2.1449e-04 - val_loss: 1.8513e-04 - 59s/epoch - 20ms/step
Epoch 129/300
2985/2985 - 58s - loss: 2.2123e-04 - val_loss: 2.0512e-04 - 58s/epoch - 20ms/step
Epoch 130/300
2985/2985 - 59s - loss: 2.2339e-04 - val_loss: 1.8414e-04 - 59s/epoch - 20ms/step
Epoch 131/300
2985/2985 - 59s - loss: 2.2734e-04 - val_loss: 2.1367e-04 - 59s/epoch - 20ms/step
Epoch 132/300
2985/2985 - 59s - loss: 2.1312e-04 - val_loss: 1.9826e-04 - 59s/epoch - 20ms/step
Epoch 133/300
2985/2985 - 59s - loss: 2.1176e-04 - val_loss: 1.9453e-04 - 59s/epoch - 20ms/step
Epoch 134/300
2985/2985 - 58s - loss: 2.1068e-04 - val_loss: 1.9855e-04 - 58s/epoch - 20ms/step
Epoch 135/300
2985/2985 - 59s - loss: 2.1049e-04 - val_loss: 1.9474e-04 - 59s/epoch - 20ms/step
Epoch 136/300
2985/2985 - 59s - loss: 2.2951e-04 - val_loss: 1.8281e-04 - 59s/epoch - 20ms/step
Epoch 137/300
2985/2985 - 59s - loss: 2.0932e-04 - val_loss: 2.0365e-04 - 59s/epoch - 20ms/step
Epoch 138/300
2985/2985 - 59s - loss: 2.1084e-04 - val_loss: 2.2892e-04 - 59s/epoch - 20ms/step
Epoch 139/300
2985/2985 - 58s - loss: 2.1004e-04 - val_loss: 2.1948e-04 - 58s/epoch - 20ms/step
Epoch 140/300
2985/2985 - 59s - loss: 2.1184e-04 - val_loss: 1.8914e-04 - 59s/epoch - 20ms/step
Epoch 141/300
2985/2985 - 59s - loss: 2.0705e-04 - val_loss: 2.8008e-04 - 59s/epoch - 20ms/step
Epoch 142/300
2985/2985 - 59s - loss: 2.2538e-04 - val_loss: 2.2086e-04 - 59s/epoch - 20ms/step
Epoch 143/300
2985/2985 - 59s - loss: 2.1314e-04 - val_loss: 1.9461e-04 - 59s/epoch - 20ms/step
Epoch 144/300
2985/2985 - 59s - loss: 2.0976e-04 - val_loss: 1.8307e-04 - 59s/epoch - 20ms/step
Epoch 145/300
2985/2985 - 58s - loss: 2.1567e-04 - val_loss: 1.9273e-04 - 58s/epoch - 20ms/step
Epoch 146/300
2985/2985 - 59s - loss: 2.0841e-04 - val_loss: 1.8392e-04 - 59s/epoch - 20ms/step
Epoch 147/300
2985/2985 - 59s - loss: 2.0463e-04 - val_loss: 2.0443e-04 - 59s/epoch - 20ms/step
Epoch 148/300
2985/2985 - 59s - loss: 2.0929e-04 - val_loss: 2.2767e-04 - 59s/epoch - 20ms/step
Epoch 149/300
2985/2985 - 59s - loss: 2.0342e-04 - val_loss: 2.1522e-04 - 59s/epoch - 20ms/step
Epoch 150/300
2985/2985 - 58s - loss: 2.0648e-04 - val_loss: 1.7331e-04 - 58s/epoch - 20ms/step
Epoch 151/300
2985/2985 - 59s - loss: 2.0193e-04 - val_loss: 2.3602e-04 - 59s/epoch - 20ms/step
Epoch 152/300
2985/2985 - 59s - loss: 2.1536e-04 - val_loss: 1.8371e-04 - 59s/epoch - 20ms/step
Epoch 153/300
2985/2985 - 59s - loss: 2.0413e-04 - val_loss: 1.9893e-04 - 59s/epoch - 20ms/step
Epoch 154/300
2985/2985 - 59s - loss: 2.0392e-04 - val_loss: 2.2645e-04 - 59s/epoch - 20ms/step
Epoch 155/300
2985/2985 - 58s - loss: 2.0284e-04 - val_loss: 1.9817e-04 - 58s/epoch - 20ms/step
Epoch 156/300
2985/2985 - 59s - loss: 2.0142e-04 - val_loss: 1.9841e-04 - 59s/epoch - 20ms/step
Epoch 157/300
2985/2985 - 59s - loss: 2.0050e-04 - val_loss: 2.1583e-04 - 59s/epoch - 20ms/step
Epoch 158/300
2985/2985 - 59s - loss: 2.0357e-04 - val_loss: 2.0512e-04 - 59s/epoch - 20ms/step
Epoch 159/300
2985/2985 - 59s - loss: 1.9884e-04 - val_loss: 1.7074e-04 - 59s/epoch - 20ms/step
Epoch 160/300
2985/2985 - 59s - loss: 2.0946e-04 - val_loss: 1.7204e-04 - 59s/epoch - 20ms/step
Epoch 161/300
2985/2985 - 58s - loss: 2.0001e-04 - val_loss: 1.9601e-04 - 58s/epoch - 20ms/step
Epoch 162/300
2985/2985 - 59s - loss: 2.0204e-04 - val_loss: 2.0205e-04 - 59s/epoch - 20ms/step
Epoch 163/300
2985/2985 - 59s - loss: 1.9777e-04 - val_loss: 1.8508e-04 - 59s/epoch - 20ms/step
Epoch 164/300
2985/2985 - 59s - loss: 2.0329e-04 - val_loss: 2.4080e-04 - 59s/epoch - 20ms/step
Epoch 165/300
2985/2985 - 59s - loss: 1.9744e-04 - val_loss: 2.1088e-04 - 59s/epoch - 20ms/step
Epoch 166/300
2985/2985 - 58s - loss: 2.1017e-04 - val_loss: 1.9724e-04 - 58s/epoch - 20ms/step
Epoch 167/300
2985/2985 - 59s - loss: 1.9923e-04 - val_loss: 1.9814e-04 - 59s/epoch - 20ms/step
Epoch 168/300
2985/2985 - 59s - loss: 1.9714e-04 - val_loss: 1.9777e-04 - 59s/epoch - 20ms/step
Epoch 169/300
2985/2985 - 59s - loss: 1.9571e-04 - val_loss: 2.0026e-04 - 59s/epoch - 20ms/step
Epoch 170/300
2985/2985 - 59s - loss: 2.0709e-04 - val_loss: 2.3070e-04 - 59s/epoch - 20ms/step
Epoch 171/300
2985/2985 - 58s - loss: 2.0403e-04 - val_loss: 1.9281e-04 - 58s/epoch - 20ms/step
Epoch 172/300
2985/2985 - 59s - loss: 1.9552e-04 - val_loss: 1.8758e-04 - 59s/epoch - 20ms/step
Epoch 173/300
2985/2985 - 59s - loss: 1.9846e-04 - val_loss: 1.8622e-04 - 59s/epoch - 20ms/step
Epoch 174/300
2985/2985 - 59s - loss: 1.9532e-04 - val_loss: 1.8417e-04 - 59s/epoch - 20ms/step
Epoch 175/300
2985/2985 - 59s - loss: 1.9598e-04 - val_loss: 1.7853e-04 - 59s/epoch - 20ms/step
Epoch 176/300
2985/2985 - 58s - loss: 1.9951e-04 - val_loss: 1.7912e-04 - 58s/epoch - 20ms/step
Epoch 177/300
2985/2985 - 59s - loss: 1.9725e-04 - val_loss: 1.5805e-04 - 59s/epoch - 20ms/step
Epoch 178/300
2985/2985 - 59s - loss: 1.9367e-04 - val_loss: 1.7582e-04 - 59s/epoch - 20ms/step
Epoch 179/300
2985/2985 - 59s - loss: 1.9599e-04 - val_loss: 1.8381e-04 - 59s/epoch - 20ms/step
Epoch 180/300
2985/2985 - 59s - loss: 1.9555e-04 - val_loss: 1.9241e-04 - 59s/epoch - 20ms/step
Epoch 181/300
2985/2985 - 59s - loss: 1.9221e-04 - val_loss: 1.9647e-04 - 59s/epoch - 20ms/step
Epoch 182/300
2985/2985 - 58s - loss: 1.9947e-04 - val_loss: 1.9598e-04 - 58s/epoch - 20ms/step
Epoch 183/300
2985/2985 - 59s - loss: 1.9397e-04 - val_loss: 1.8318e-04 - 59s/epoch - 20ms/step
Epoch 184/300
2985/2985 - 59s - loss: 1.9469e-04 - val_loss: 1.7403e-04 - 59s/epoch - 20ms/step
Epoch 185/300
2985/2985 - 59s - loss: 1.9598e-04 - val_loss: 2.3761e-04 - 59s/epoch - 20ms/step
Epoch 186/300
2985/2985 - 59s - loss: 1.9210e-04 - val_loss: 1.6772e-04 - 59s/epoch - 20ms/step
Epoch 187/300
2985/2985 - 58s - loss: 1.9358e-04 - val_loss: 1.9133e-04 - 58s/epoch - 20ms/step
Epoch 188/300
2985/2985 - 59s - loss: 1.9044e-04 - val_loss: 1.7174e-04 - 59s/epoch - 20ms/step
Epoch 189/300
2985/2985 - 59s - loss: 1.9902e-04 - val_loss: 1.9777e-04 - 59s/epoch - 20ms/step
Epoch 190/300
2985/2985 - 59s - loss: 1.9133e-04 - val_loss: 1.7828e-04 - 59s/epoch - 20ms/step
Epoch 191/300
2985/2985 - 59s - loss: 1.9382e-04 - val_loss: 1.8182e-04 - 59s/epoch - 20ms/step
Epoch 192/300
2985/2985 - 58s - loss: 1.9333e-04 - val_loss: 2.6332e-04 - 58s/epoch - 20ms/step
Epoch 193/300
2985/2985 - 59s - loss: 1.9376e-04 - val_loss: 1.8514e-04 - 59s/epoch - 20ms/step
Epoch 194/300
2985/2985 - 59s - loss: 1.8870e-04 - val_loss: 2.0743e-04 - 59s/epoch - 20ms/step
Epoch 195/300
2985/2985 - 59s - loss: 1.9007e-04 - val_loss: 1.9252e-04 - 59s/epoch - 20ms/step
Epoch 196/300
2985/2985 - 59s - loss: 1.8729e-04 - val_loss: 2.0337e-04 - 59s/epoch - 20ms/step
Epoch 197/300
2985/2985 - 59s - loss: 1.9666e-04 - val_loss: 0.0022 - 59s/epoch - 20ms/step
Epoch 198/300
2985/2985 - 58s - loss: 2.0406e-04 - val_loss: 1.8812e-04 - 58s/epoch - 20ms/step
Epoch 199/300
2985/2985 - 59s - loss: 1.8690e-04 - val_loss: 1.6565e-04 - 59s/epoch - 20ms/step
Epoch 200/300
2985/2985 - 59s - loss: 1.8811e-04 - val_loss: 1.8141e-04 - 59s/epoch - 20ms/step
Epoch 201/300
2985/2985 - 59s - loss: 1.8786e-04 - val_loss: 1.6980e-04 - 59s/epoch - 20ms/step
Epoch 202/300
2985/2985 - 59s - loss: 1.9015e-04 - val_loss: 6.0502e-04 - 59s/epoch - 20ms/step
Epoch 203/300
2985/2985 - 58s - loss: 1.8831e-04 - val_loss: 2.3019e-04 - 58s/epoch - 20ms/step
Epoch 204/300
2985/2985 - 59s - loss: 1.9138e-04 - val_loss: 1.7046e-04 - 59s/epoch - 20ms/step
Epoch 205/300
2985/2985 - 59s - loss: 1.9001e-04 - val_loss: 1.7533e-04 - 59s/epoch - 20ms/step
Epoch 206/300
2985/2985 - 59s - loss: 1.8468e-04 - val_loss: 2.0183e-04 - 59s/epoch - 20ms/step
Epoch 207/300
2985/2985 - 59s - loss: 1.8731e-04 - val_loss: 2.4552e-04 - 59s/epoch - 20ms/step
Epoch 208/300
2985/2985 - 58s - loss: 1.9253e-04 - val_loss: 2.0437e-04 - 58s/epoch - 20ms/step
Epoch 209/300
2985/2985 - 59s - loss: 1.8639e-04 - val_loss: 1.7562e-04 - 59s/epoch - 20ms/step
Epoch 210/300
2985/2985 - 59s - loss: 1.8665e-04 - val_loss: 1.6136e-04 - 59s/epoch - 20ms/step
Epoch 211/300
2985/2985 - 59s - loss: 1.8595e-04 - val_loss: 1.8936e-04 - 59s/epoch - 20ms/step
Epoch 212/300
2985/2985 - 59s - loss: 1.8377e-04 - val_loss: 1.6122e-04 - 59s/epoch - 20ms/step
Epoch 213/300
2985/2985 - 59s - loss: 1.9098e-04 - val_loss: 1.6471e-04 - 59s/epoch - 20ms/step
Epoch 214/300
2985/2985 - 58s - loss: 1.8771e-04 - val_loss: 2.4096e-04 - 58s/epoch - 20ms/step
Epoch 215/300
2985/2985 - 59s - loss: 1.8517e-04 - val_loss: 1.6883e-04 - 59s/epoch - 20ms/step
Epoch 216/300
2985/2985 - 59s - loss: 1.8740e-04 - val_loss: 1.7342e-04 - 59s/epoch - 20ms/step
Epoch 217/300
2985/2985 - 59s - loss: 1.8441e-04 - val_loss: 1.5574e-04 - 59s/epoch - 20ms/step
Epoch 218/300
2985/2985 - 59s - loss: 1.9429e-04 - val_loss: 2.4316e-04 - 59s/epoch - 20ms/step
Epoch 219/300
2985/2985 - 58s - loss: 1.9197e-04 - val_loss: 1.6593e-04 - 58s/epoch - 20ms/step
Epoch 220/300
2985/2985 - 59s - loss: 1.8463e-04 - val_loss: 1.6942e-04 - 59s/epoch - 20ms/step
Epoch 221/300
2985/2985 - 59s - loss: 1.8377e-04 - val_loss: 1.8488e-04 - 59s/epoch - 20ms/step
Epoch 222/300
2985/2985 - 59s - loss: 1.8419e-04 - val_loss: 1.7256e-04 - 59s/epoch - 20ms/step
Epoch 223/300
2985/2985 - 59s - loss: 1.8920e-04 - val_loss: 6.7539e-04 - 59s/epoch - 20ms/step
Epoch 224/300
2985/2985 - 58s - loss: 1.8370e-04 - val_loss: 1.7925e-04 - 58s/epoch - 20ms/step
Epoch 225/300
2985/2985 - 59s - loss: 1.8229e-04 - val_loss: 2.1974e-04 - 59s/epoch - 20ms/step
Epoch 226/300
2985/2985 - 59s - loss: 1.8788e-04 - val_loss: 2.6265e-04 - 59s/epoch - 20ms/step
Epoch 227/300
2985/2985 - 59s - loss: 1.9986e-04 - val_loss: 1.6808e-04 - 59s/epoch - 20ms/step
Epoch 228/300
2985/2985 - 59s - loss: 1.8211e-04 - val_loss: 2.1542e-04 - 59s/epoch - 20ms/step
Epoch 229/300
2985/2985 - 59s - loss: 1.8289e-04 - val_loss: 2.0693e-04 - 59s/epoch - 20ms/step
Epoch 230/300
2985/2985 - 58s - loss: 1.8462e-04 - val_loss: 1.7562e-04 - 58s/epoch - 20ms/step
Epoch 231/300
2985/2985 - 59s - loss: 1.8589e-04 - val_loss: 1.7453e-04 - 59s/epoch - 20ms/step
Epoch 232/300
2985/2985 - 59s - loss: 1.8108e-04 - val_loss: 1.5870e-04 - 59s/epoch - 20ms/step
Epoch 233/300
2985/2985 - 59s - loss: 1.8191e-04 - val_loss: 2.7863e-04 - 59s/epoch - 20ms/step
Epoch 234/300
2985/2985 - 59s - loss: 2.0245e-04 - val_loss: 1.7317e-04 - 59s/epoch - 20ms/step
Epoch 235/300
2985/2985 - 59s - loss: 1.8356e-04 - val_loss: 1.4683e-04 - 59s/epoch - 20ms/step
Epoch 236/300
2985/2985 - 59s - loss: 1.8124e-04 - val_loss: 1.6828e-04 - 59s/epoch - 20ms/step
Epoch 237/300
2985/2985 - 59s - loss: 1.8179e-04 - val_loss: 1.9351e-04 - 59s/epoch - 20ms/step
Epoch 238/300
2985/2985 - 59s - loss: 1.9114e-04 - val_loss: 1.7276e-04 - 59s/epoch - 20ms/step
Epoch 239/300
2985/2985 - 59s - loss: 1.8684e-04 - val_loss: 1.7308e-04 - 59s/epoch - 20ms/step
Epoch 240/300
2985/2985 - 58s - loss: 1.7941e-04 - val_loss: 1.4869e-04 - 58s/epoch - 20ms/step
Epoch 241/300
2985/2985 - 59s - loss: 1.7780e-04 - val_loss: 1.5764e-04 - 59s/epoch - 20ms/step
Epoch 242/300
2985/2985 - 59s - loss: 1.9108e-04 - val_loss: 1.7275e-04 - 59s/epoch - 20ms/step
Epoch 243/300
2985/2985 - 59s - loss: 1.7955e-04 - val_loss: 1.5548e-04 - 59s/epoch - 20ms/step
Epoch 244/300
2985/2985 - 59s - loss: 1.8012e-04 - val_loss: 2.3250e-04 - 59s/epoch - 20ms/step
Epoch 245/300
2985/2985 - 58s - loss: 1.8231e-04 - val_loss: 1.7097e-04 - 58s/epoch - 20ms/step
Epoch 246/300
2985/2985 - 59s - loss: 1.8965e-04 - val_loss: 2.1354e-04 - 59s/epoch - 20ms/step
Epoch 247/300
2985/2985 - 59s - loss: 1.8966e-04 - val_loss: 1.6596e-04 - 59s/epoch - 20ms/step
Epoch 248/300
2985/2985 - 59s - loss: 1.8062e-04 - val_loss: 1.8536e-04 - 59s/epoch - 20ms/step
Epoch 249/300
2985/2985 - 59s - loss: 1.8127e-04 - val_loss: 1.8716e-04 - 59s/epoch - 20ms/step
Epoch 250/300
2985/2985 - 59s - loss: 1.8889e-04 - val_loss: 1.6466e-04 - 59s/epoch - 20ms/step
Epoch 251/300
2985/2985 - 58s - loss: 1.7730e-04 - val_loss: 1.8737e-04 - 58s/epoch - 20ms/step
Epoch 252/300
2985/2985 - 59s - loss: 1.7785e-04 - val_loss: 1.6499e-04 - 59s/epoch - 20ms/step
Epoch 253/300
2985/2985 - 59s - loss: 1.8066e-04 - val_loss: 1.3760e-04 - 59s/epoch - 20ms/step
Epoch 254/300
2985/2985 - 59s - loss: 1.7803e-04 - val_loss: 1.7222e-04 - 59s/epoch - 20ms/step
Epoch 255/300
2985/2985 - 59s - loss: 1.8218e-04 - val_loss: 1.8067e-04 - 59s/epoch - 20ms/step
Epoch 256/300
2985/2985 - 58s - loss: 1.7774e-04 - val_loss: 1.8319e-04 - 58s/epoch - 20ms/step
Epoch 257/300
2985/2985 - 59s - loss: 1.8054e-04 - val_loss: 1.9204e-04 - 59s/epoch - 20ms/step
Epoch 258/300
2985/2985 - 59s - loss: 1.7870e-04 - val_loss: 1.6155e-04 - 59s/epoch - 20ms/step
Epoch 259/300
2985/2985 - 59s - loss: 1.7961e-04 - val_loss: 1.7938e-04 - 59s/epoch - 20ms/step
Epoch 260/300
2985/2985 - 59s - loss: 1.7626e-04 - val_loss: 1.7890e-04 - 59s/epoch - 20ms/step
Epoch 261/300
2985/2985 - 58s - loss: 1.7842e-04 - val_loss: 2.1653e-04 - 58s/epoch - 20ms/step
Epoch 262/300
2985/2985 - 59s - loss: 1.7997e-04 - val_loss: 1.5555e-04 - 59s/epoch - 20ms/step
Epoch 263/300
2985/2985 - 59s - loss: 1.7780e-04 - val_loss: 1.6231e-04 - 59s/epoch - 20ms/step
Epoch 264/300
2985/2985 - 59s - loss: 1.7678e-04 - val_loss: 1.9048e-04 - 59s/epoch - 20ms/step
Epoch 265/300
2985/2985 - 59s - loss: 1.7705e-04 - val_loss: 1.6963e-04 - 59s/epoch - 20ms/step
Epoch 266/300
2985/2985 - 59s - loss: 1.7499e-04 - val_loss: 1.6271e-04 - 59s/epoch - 20ms/step
Epoch 267/300
2985/2985 - 58s - loss: 1.7635e-04 - val_loss: 2.0267e-04 - 58s/epoch - 20ms/step
Epoch 268/300
2985/2985 - 59s - loss: 1.7403e-04 - val_loss: 1.8023e-04 - 59s/epoch - 20ms/step
Epoch 269/300
2985/2985 - 59s - loss: 1.9987e-04 - val_loss: 0.0014 - 59s/epoch - 20ms/step
Epoch 270/300
2985/2985 - 59s - loss: 1.8402e-04 - val_loss: 1.6001e-04 - 59s/epoch - 20ms/step
Epoch 271/300
2985/2985 - 59s - loss: 1.7696e-04 - val_loss: 1.8980e-04 - 59s/epoch - 20ms/step
Epoch 272/300
2985/2985 - 58s - loss: 1.8284e-04 - val_loss: 1.6506e-04 - 58s/epoch - 20ms/step
Epoch 273/300
2985/2985 - 59s - loss: 1.7440e-04 - val_loss: 1.9013e-04 - 59s/epoch - 20ms/step
Epoch 274/300
2985/2985 - 59s - loss: 1.7610e-04 - val_loss: 1.7943e-04 - 59s/epoch - 20ms/step
Epoch 275/300
2985/2985 - 59s - loss: 1.8007e-04 - val_loss: 1.5445e-04 - 59s/epoch - 20ms/step
Epoch 276/300
2985/2985 - 59s - loss: 1.8255e-04 - val_loss: 1.6203e-04 - 59s/epoch - 20ms/step
Epoch 277/300
2985/2985 - 58s - loss: 1.8056e-04 - val_loss: 1.5711e-04 - 58s/epoch - 20ms/step
Epoch 278/300
2985/2985 - 59s - loss: 1.7561e-04 - val_loss: 1.6774e-04 - 59s/epoch - 20ms/step
Epoch 279/300
2985/2985 - 59s - loss: 1.7390e-04 - val_loss: 1.6166e-04 - 59s/epoch - 20ms/step
Epoch 280/300
2985/2985 - 59s - loss: 1.7500e-04 - val_loss: 1.6888e-04 - 59s/epoch - 20ms/step
Epoch 281/300
2985/2985 - 59s - loss: 1.7528e-04 - val_loss: 1.7841e-04 - 59s/epoch - 20ms/step
Epoch 282/300
2985/2985 - 59s - loss: 1.7409e-04 - val_loss: 1.8984e-04 - 59s/epoch - 20ms/step
Epoch 283/300
2985/2985 - 58s - loss: 1.7516e-04 - val_loss: 1.6639e-04 - 58s/epoch - 20ms/step
Epoch 284/300
2985/2985 - 59s - loss: 1.7442e-04 - val_loss: 1.5356e-04 - 59s/epoch - 20ms/step
Epoch 285/300
2985/2985 - 59s - loss: 1.7893e-04 - val_loss: 1.9133e-04 - 59s/epoch - 20ms/step
Epoch 286/300
2985/2985 - 59s - loss: 1.7148e-04 - val_loss: 1.6185e-04 - 59s/epoch - 20ms/step
Epoch 287/300
2985/2985 - 59s - loss: 1.7360e-04 - val_loss: 1.8041e-04 - 59s/epoch - 20ms/step
Epoch 288/300
2985/2985 - 58s - loss: 1.7449e-04 - val_loss: 1.8783e-04 - 58s/epoch - 20ms/step
Epoch 289/300
2985/2985 - 59s - loss: 1.8031e-04 - val_loss: 3.3136e-04 - 59s/epoch - 20ms/step
Epoch 290/300
2985/2985 - 59s - loss: 1.8932e-04 - val_loss: 2.9485e-04 - 59s/epoch - 20ms/step
Epoch 291/300
2985/2985 - 59s - loss: 1.9007e-04 - val_loss: 1.7136e-04 - 59s/epoch - 20ms/step
Epoch 292/300
2985/2985 - 59s - loss: 1.7809e-04 - val_loss: 1.8871e-04 - 59s/epoch - 20ms/step
Epoch 293/300
2985/2985 - 58s - loss: 1.7306e-04 - val_loss: 1.6385e-04 - 58s/epoch - 20ms/step
Epoch 294/300
2985/2985 - 59s - loss: 1.7844e-04 - val_loss: 1.5518e-04 - 59s/epoch - 20ms/step
Epoch 295/300
2985/2985 - 59s - loss: 1.7695e-04 - val_loss: 1.4781e-04 - 59s/epoch - 20ms/step
Epoch 296/300
2985/2985 - 59s - loss: 1.7381e-04 - val_loss: 1.5324e-04 - 59s/epoch - 20ms/step
Epoch 297/300
2985/2985 - 59s - loss: 1.7084e-04 - val_loss: 1.7600e-04 - 59s/epoch - 20ms/step
Epoch 298/300
2985/2985 - 59s - loss: 1.7135e-04 - val_loss: 1.7573e-04 - 59s/epoch - 20ms/step
Epoch 299/300
2985/2985 - 58s - loss: 1.7692e-04 - val_loss: 1.7870e-04 - 58s/epoch - 20ms/step
Epoch 300/300
2985/2985 - 59s - loss: 1.7388e-04 - val_loss: 2.1940e-04 - 59s/epoch - 20ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00021939950238447636
  1/332 [..............................] - ETA: 36s 16/332 [>.............................] - ETA: 1s  31/332 [=>............................] - ETA: 1s 47/332 [===>..........................] - ETA: 0s 63/332 [====>.........................] - ETA: 0s 79/332 [======>.......................] - ETA: 0s 95/332 [=======>......................] - ETA: 0s111/332 [=========>....................] - ETA: 0s127/332 [==========>...................] - ETA: 0s143/332 [===========>..................] - ETA: 0s159/332 [=============>................] - ETA: 0s175/332 [==============>...............] - ETA: 0s191/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s223/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s255/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s287/332 [========================>.....] - ETA: 0s303/332 [==========================>...] - ETA: 0s319/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.002402845049776134
cosine 0.001918440039455329
MAE: 0.008907639
RMSE: 0.014812136
r2: 0.9857674980929735
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 1264)              1598960   
                                                                 
 batch_normalization (BatchN  (None, 1264)             5056      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_1 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 632)               0         
                                                                 
 dense_1 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_2 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1264)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 1264)              1598960   
                                                                 
 batch_normalization (BatchN  (None, 1264)             5056      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 632)]             0         
                                                                 
 batch_normalization_1 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 632)               0         
                                                                 
 dense_1 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_2 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1264)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 32, 300, 0.0005, 0.5, 632, 0.0001738768332870677, 0.00021939950238447636, 0.002402845049776134, 0.001918440039455329, 0.008907639421522617, 0.014812136068940163, 0.9857674980929735, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_3 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_3 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_4 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 632)               0         
                                                                 
 dense_4 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_5 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 1264)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
2985/2985 - 60s - loss: 0.0066 - val_loss: 0.0026 - 60s/epoch - 20ms/step
Epoch 2/300
2985/2985 - 59s - loss: 0.0026 - val_loss: 0.0018 - 59s/epoch - 20ms/step
Epoch 3/300
2985/2985 - 59s - loss: 0.0021 - val_loss: 0.0014 - 59s/epoch - 20ms/step
Epoch 4/300
2985/2985 - 59s - loss: 0.0015 - val_loss: 0.0011 - 59s/epoch - 20ms/step
Epoch 5/300
2985/2985 - 59s - loss: 0.0012 - val_loss: 8.7895e-04 - 59s/epoch - 20ms/step
Epoch 6/300
2985/2985 - 59s - loss: 9.9455e-04 - val_loss: 7.8471e-04 - 59s/epoch - 20ms/step
Epoch 7/300
2985/2985 - 59s - loss: 8.6290e-04 - val_loss: 6.8987e-04 - 59s/epoch - 20ms/step
Epoch 8/300
2985/2985 - 59s - loss: 7.7397e-04 - val_loss: 6.6592e-04 - 59s/epoch - 20ms/step
Epoch 9/300
2985/2985 - 59s - loss: 7.1524e-04 - val_loss: 5.7678e-04 - 59s/epoch - 20ms/step
Epoch 10/300
2985/2985 - 59s - loss: 6.5976e-04 - val_loss: 5.4814e-04 - 59s/epoch - 20ms/step
Epoch 11/300
2985/2985 - 59s - loss: 6.6384e-04 - val_loss: 6.6833e-04 - 59s/epoch - 20ms/step
Epoch 12/300
2985/2985 - 59s - loss: 6.0085e-04 - val_loss: 5.5352e-04 - 59s/epoch - 20ms/step
Epoch 13/300
2985/2985 - 59s - loss: 5.6675e-04 - val_loss: 5.2542e-04 - 59s/epoch - 20ms/step
Epoch 14/300
2985/2985 - 59s - loss: 5.4280e-04 - val_loss: 4.4950e-04 - 59s/epoch - 20ms/step
Epoch 15/300
2985/2985 - 59s - loss: 5.3533e-04 - val_loss: 4.3551e-04 - 59s/epoch - 20ms/step
Epoch 16/300
2985/2985 - 59s - loss: 5.0631e-04 - val_loss: 4.2588e-04 - 59s/epoch - 20ms/step
Epoch 17/300
2985/2985 - 59s - loss: 4.9139e-04 - val_loss: 3.9606e-04 - 59s/epoch - 20ms/step
Epoch 18/300
2985/2985 - 59s - loss: 4.8555e-04 - val_loss: 4.8754e-04 - 59s/epoch - 20ms/step
Epoch 19/300
2985/2985 - 59s - loss: 4.7264e-04 - val_loss: 3.9392e-04 - 59s/epoch - 20ms/step
Epoch 20/300
2985/2985 - 59s - loss: 4.5318e-04 - val_loss: 3.5743e-04 - 59s/epoch - 20ms/step
Epoch 21/300
2985/2985 - 59s - loss: 4.4015e-04 - val_loss: 3.6762e-04 - 59s/epoch - 20ms/step
Epoch 22/300
2985/2985 - 59s - loss: 4.2892e-04 - val_loss: 3.7501e-04 - 59s/epoch - 20ms/step
Epoch 23/300
2985/2985 - 59s - loss: 4.2278e-04 - val_loss: 3.8574e-04 - 59s/epoch - 20ms/step
Epoch 24/300
2985/2985 - 59s - loss: 4.2939e-04 - val_loss: 3.6694e-04 - 59s/epoch - 20ms/step
Epoch 25/300
2985/2985 - 59s - loss: 4.0764e-04 - val_loss: 3.1586e-04 - 59s/epoch - 20ms/step
Epoch 26/300
2985/2985 - 59s - loss: 4.0197e-04 - val_loss: 3.1784e-04 - 59s/epoch - 20ms/step
Epoch 27/300
2985/2985 - 59s - loss: 4.0345e-04 - val_loss: 3.2072e-04 - 59s/epoch - 20ms/step
Epoch 28/300
2985/2985 - 59s - loss: 3.9152e-04 - val_loss: 3.0829e-04 - 59s/epoch - 20ms/step
Epoch 29/300
2985/2985 - 59s - loss: 3.8189e-04 - val_loss: 2.8596e-04 - 59s/epoch - 20ms/step
Epoch 30/300
2985/2985 - 59s - loss: 3.7207e-04 - val_loss: 2.9943e-04 - 59s/epoch - 20ms/step
Epoch 31/300
2985/2985 - 59s - loss: 3.6838e-04 - val_loss: 3.0193e-04 - 59s/epoch - 20ms/step
Epoch 32/300
2985/2985 - 59s - loss: 3.6562e-04 - val_loss: 2.7414e-04 - 59s/epoch - 20ms/step
Epoch 33/300
2985/2985 - 59s - loss: 3.5929e-04 - val_loss: 2.8182e-04 - 59s/epoch - 20ms/step
Epoch 34/300
2985/2985 - 59s - loss: 3.6503e-04 - val_loss: 2.6737e-04 - 59s/epoch - 20ms/step
Epoch 35/300
2985/2985 - 59s - loss: 3.6502e-04 - val_loss: 2.7140e-04 - 59s/epoch - 20ms/step
Epoch 36/300
2985/2985 - 59s - loss: 3.5019e-04 - val_loss: 2.6659e-04 - 59s/epoch - 20ms/step
Epoch 37/300
2985/2985 - 59s - loss: 3.4791e-04 - val_loss: 2.8196e-04 - 59s/epoch - 20ms/step
Epoch 38/300
2985/2985 - 59s - loss: 3.4410e-04 - val_loss: 2.5963e-04 - 59s/epoch - 20ms/step
Epoch 39/300
2985/2985 - 59s - loss: 3.4236e-04 - val_loss: 2.6494e-04 - 59s/epoch - 20ms/step
Epoch 40/300
2985/2985 - 59s - loss: 3.3842e-04 - val_loss: 2.8396e-04 - 59s/epoch - 20ms/step
Epoch 41/300
2985/2985 - 59s - loss: 3.3306e-04 - val_loss: 2.4419e-04 - 59s/epoch - 20ms/step
Epoch 42/300
2985/2985 - 59s - loss: 3.3649e-04 - val_loss: 2.5145e-04 - 59s/epoch - 20ms/step
Epoch 43/300
2985/2985 - 59s - loss: 3.2626e-04 - val_loss: 2.5098e-04 - 59s/epoch - 20ms/step
Epoch 44/300
2985/2985 - 59s - loss: 3.3129e-04 - val_loss: 2.8976e-04 - 59s/epoch - 20ms/step
Epoch 45/300
2985/2985 - 59s - loss: 3.2375e-04 - val_loss: 2.4514e-04 - 59s/epoch - 20ms/step
Epoch 46/300
2985/2985 - 59s - loss: 3.1977e-04 - val_loss: 2.5808e-04 - 59s/epoch - 20ms/step
Epoch 47/300
2985/2985 - 59s - loss: 3.3460e-04 - val_loss: 2.4042e-04 - 59s/epoch - 20ms/step
Epoch 48/300
2985/2985 - 59s - loss: 3.1741e-04 - val_loss: 2.2925e-04 - 59s/epoch - 20ms/step
Epoch 49/300
2985/2985 - 59s - loss: 3.2803e-04 - val_loss: 4.7914e-04 - 59s/epoch - 20ms/step
Epoch 50/300
2985/2985 - 59s - loss: 3.5062e-04 - val_loss: 4.1841e-04 - 59s/epoch - 20ms/step
Epoch 51/300
2985/2985 - 59s - loss: 3.3771e-04 - val_loss: 2.3544e-04 - 59s/epoch - 20ms/step
Epoch 52/300
2985/2985 - 59s - loss: 3.2310e-04 - val_loss: 2.5823e-04 - 59s/epoch - 20ms/step
Epoch 53/300
2985/2985 - 59s - loss: 3.1312e-04 - val_loss: 2.3331e-04 - 59s/epoch - 20ms/step
Epoch 54/300
2985/2985 - 59s - loss: 3.0260e-04 - val_loss: 2.6052e-04 - 59s/epoch - 20ms/step
Epoch 55/300
2985/2985 - 59s - loss: 3.0291e-04 - val_loss: 2.3063e-04 - 59s/epoch - 20ms/step
Epoch 56/300
2985/2985 - 59s - loss: 2.9907e-04 - val_loss: 2.3030e-04 - 59s/epoch - 20ms/step
Epoch 57/300
2985/2985 - 59s - loss: 3.0805e-04 - val_loss: 2.8777e-04 - 59s/epoch - 20ms/step
Epoch 58/300
2985/2985 - 59s - loss: 2.9640e-04 - val_loss: 2.2618e-04 - 59s/epoch - 20ms/step
Epoch 59/300
2985/2985 - 59s - loss: 2.9194e-04 - val_loss: 2.3454e-04 - 59s/epoch - 20ms/step
Epoch 60/300
2985/2985 - 59s - loss: 3.4117e-04 - val_loss: 2.2143e-04 - 59s/epoch - 20ms/step
Epoch 61/300
2985/2985 - 59s - loss: 2.9323e-04 - val_loss: 2.2574e-04 - 59s/epoch - 20ms/step
Epoch 62/300
2985/2985 - 59s - loss: 2.9231e-04 - val_loss: 2.4102e-04 - 59s/epoch - 20ms/step
Epoch 63/300
2985/2985 - 59s - loss: 2.8993e-04 - val_loss: 2.4531e-04 - 59s/epoch - 20ms/step
Epoch 64/300
2985/2985 - 59s - loss: 2.9229e-04 - val_loss: 2.2330e-04 - 59s/epoch - 20ms/step
Epoch 65/300
2985/2985 - 59s - loss: 2.8613e-04 - val_loss: 2.4108e-04 - 59s/epoch - 20ms/step
Epoch 66/300
2985/2985 - 59s - loss: 2.9023e-04 - val_loss: 2.2194e-04 - 59s/epoch - 20ms/step
Epoch 67/300
2985/2985 - 59s - loss: 2.8534e-04 - val_loss: 2.0965e-04 - 59s/epoch - 20ms/step
Epoch 68/300
2985/2985 - 59s - loss: 2.8948e-04 - val_loss: 2.4465e-04 - 59s/epoch - 20ms/step
Epoch 69/300
2985/2985 - 59s - loss: 2.8592e-04 - val_loss: 2.2562e-04 - 59s/epoch - 20ms/step
Epoch 70/300
2985/2985 - 59s - loss: 2.7904e-04 - val_loss: 2.3703e-04 - 59s/epoch - 20ms/step
Epoch 71/300
2985/2985 - 59s - loss: 2.8258e-04 - val_loss: 2.1063e-04 - 59s/epoch - 20ms/step
Epoch 72/300
2985/2985 - 59s - loss: 2.7993e-04 - val_loss: 2.1712e-04 - 59s/epoch - 20ms/step
Epoch 73/300
2985/2985 - 59s - loss: 2.7854e-04 - val_loss: 3.1638e-04 - 59s/epoch - 20ms/step
Epoch 74/300
2985/2985 - 59s - loss: 2.9611e-04 - val_loss: 2.1047e-04 - 59s/epoch - 20ms/step
Epoch 75/300
2985/2985 - 59s - loss: 2.7713e-04 - val_loss: 2.1353e-04 - 59s/epoch - 20ms/step
Epoch 76/300
2985/2985 - 59s - loss: 2.7180e-04 - val_loss: 2.1132e-04 - 59s/epoch - 20ms/step
Epoch 77/300
2985/2985 - 59s - loss: 2.7634e-04 - val_loss: 3.9059e-04 - 59s/epoch - 20ms/step
Epoch 78/300
2985/2985 - 59s - loss: 3.1379e-04 - val_loss: 2.1008e-04 - 59s/epoch - 20ms/step
Epoch 79/300
2985/2985 - 59s - loss: 2.7739e-04 - val_loss: 2.1267e-04 - 59s/epoch - 20ms/step
Epoch 80/300
2985/2985 - 59s - loss: 2.7235e-04 - val_loss: 2.2123e-04 - 59s/epoch - 20ms/step
Epoch 81/300
2985/2985 - 59s - loss: 2.6984e-04 - val_loss: 2.2479e-04 - 59s/epoch - 20ms/step
Epoch 82/300
2985/2985 - 59s - loss: 2.8092e-04 - val_loss: 2.1927e-04 - 59s/epoch - 20ms/step
Epoch 83/300
2985/2985 - 59s - loss: 2.7217e-04 - val_loss: 2.1484e-04 - 59s/epoch - 20ms/step
Epoch 84/300
2985/2985 - 59s - loss: 2.6480e-04 - val_loss: 2.0594e-04 - 59s/epoch - 20ms/step
Epoch 85/300
2985/2985 - 59s - loss: 2.6433e-04 - val_loss: 1.9094e-04 - 59s/epoch - 20ms/step
Epoch 86/300
2985/2985 - 59s - loss: 2.6725e-04 - val_loss: 2.0340e-04 - 59s/epoch - 20ms/step
Epoch 87/300
2985/2985 - 59s - loss: 2.6501e-04 - val_loss: 2.3514e-04 - 59s/epoch - 20ms/step
Epoch 88/300
2985/2985 - 59s - loss: 2.6702e-04 - val_loss: 2.2422e-04 - 59s/epoch - 20ms/step
Epoch 89/300
2985/2985 - 59s - loss: 2.6657e-04 - val_loss: 2.1497e-04 - 59s/epoch - 20ms/step
Epoch 90/300
2985/2985 - 59s - loss: 2.6704e-04 - val_loss: 2.2753e-04 - 59s/epoch - 20ms/step
Epoch 91/300
2985/2985 - 59s - loss: 2.5985e-04 - val_loss: 2.3888e-04 - 59s/epoch - 20ms/step
Epoch 92/300
2985/2985 - 59s - loss: 2.6201e-04 - val_loss: 2.4152e-04 - 59s/epoch - 20ms/step
Epoch 93/300
2985/2985 - 59s - loss: 2.6368e-04 - val_loss: 2.1801e-04 - 59s/epoch - 20ms/step
Epoch 94/300
2985/2985 - 59s - loss: 2.5455e-04 - val_loss: 1.9004e-04 - 59s/epoch - 20ms/step
Epoch 95/300
2985/2985 - 59s - loss: 2.5739e-04 - val_loss: 2.0105e-04 - 59s/epoch - 20ms/step
Epoch 96/300
2985/2985 - 59s - loss: 2.5477e-04 - val_loss: 2.1141e-04 - 59s/epoch - 20ms/step
Epoch 97/300
2985/2985 - 59s - loss: 2.5452e-04 - val_loss: 1.9273e-04 - 59s/epoch - 20ms/step
Epoch 98/300
2985/2985 - 59s - loss: 2.5355e-04 - val_loss: 1.9390e-04 - 59s/epoch - 20ms/step
Epoch 99/300
2985/2985 - 59s - loss: 2.5233e-04 - val_loss: 2.0607e-04 - 59s/epoch - 20ms/step
Epoch 100/300
2985/2985 - 59s - loss: 2.5067e-04 - val_loss: 2.2469e-04 - 59s/epoch - 20ms/step
Epoch 101/300
2985/2985 - 59s - loss: 2.5402e-04 - val_loss: 1.8649e-04 - 59s/epoch - 20ms/step
Epoch 102/300
2985/2985 - 59s - loss: 2.5164e-04 - val_loss: 1.9533e-04 - 59s/epoch - 20ms/step
Epoch 103/300
2985/2985 - 59s - loss: 2.7833e-04 - val_loss: 1.9360e-04 - 59s/epoch - 20ms/step
Epoch 104/300
2985/2985 - 59s - loss: 2.5519e-04 - val_loss: 4.8540e-04 - 59s/epoch - 20ms/step
Epoch 105/300
2985/2985 - 59s - loss: 2.8833e-04 - val_loss: 2.1079e-04 - 59s/epoch - 20ms/step
Epoch 106/300
2985/2985 - 59s - loss: 2.5137e-04 - val_loss: 1.9630e-04 - 59s/epoch - 20ms/step
Epoch 107/300
2985/2985 - 59s - loss: 2.5822e-04 - val_loss: 1.9688e-04 - 59s/epoch - 20ms/step
Epoch 108/300
2985/2985 - 59s - loss: 2.4693e-04 - val_loss: 2.0208e-04 - 59s/epoch - 20ms/step
Epoch 109/300
2985/2985 - 59s - loss: 2.4798e-04 - val_loss: 1.9807e-04 - 59s/epoch - 20ms/step
Epoch 110/300
2985/2985 - 59s - loss: 2.4808e-04 - val_loss: 2.2660e-04 - 59s/epoch - 20ms/step
Epoch 111/300
2985/2985 - 59s - loss: 2.4712e-04 - val_loss: 1.9479e-04 - 59s/epoch - 20ms/step
Epoch 112/300
2985/2985 - 59s - loss: 2.4606e-04 - val_loss: 2.0247e-04 - 59s/epoch - 20ms/step
Epoch 113/300
2985/2985 - 59s - loss: 2.4553e-04 - val_loss: 2.4042e-04 - 59s/epoch - 20ms/step
Epoch 114/300
2985/2985 - 59s - loss: 2.5607e-04 - val_loss: 2.0139e-04 - 59s/epoch - 20ms/step
Epoch 115/300
2985/2985 - 59s - loss: 2.4471e-04 - val_loss: 2.0086e-04 - 59s/epoch - 20ms/step
Epoch 116/300
2985/2985 - 59s - loss: 2.4518e-04 - val_loss: 1.9135e-04 - 59s/epoch - 20ms/step
Epoch 117/300
2985/2985 - 59s - loss: 2.4113e-04 - val_loss: 1.8775e-04 - 59s/epoch - 20ms/step
Epoch 118/300
2985/2985 - 59s - loss: 2.4159e-04 - val_loss: 1.9077e-04 - 59s/epoch - 20ms/step
Epoch 119/300
2985/2985 - 59s - loss: 2.4428e-04 - val_loss: 1.9500e-04 - 59s/epoch - 20ms/step
Epoch 120/300
2985/2985 - 59s - loss: 2.5547e-04 - val_loss: 1.8686e-04 - 59s/epoch - 20ms/step
Epoch 121/300
2985/2985 - 59s - loss: 2.4104e-04 - val_loss: 1.9567e-04 - 59s/epoch - 20ms/step
Epoch 122/300
2985/2985 - 59s - loss: 2.5113e-04 - val_loss: 1.9373e-04 - 59s/epoch - 20ms/step
Epoch 123/300
2985/2985 - 59s - loss: 2.3997e-04 - val_loss: 1.9001e-04 - 59s/epoch - 20ms/step
Epoch 124/300
2985/2985 - 59s - loss: 2.4010e-04 - val_loss: 2.1202e-04 - 59s/epoch - 20ms/step
Epoch 125/300
2985/2985 - 59s - loss: 2.4046e-04 - val_loss: 1.9621e-04 - 59s/epoch - 20ms/step
Epoch 126/300
2985/2985 - 59s - loss: 2.4238e-04 - val_loss: 1.8037e-04 - 59s/epoch - 20ms/step
Epoch 127/300
2985/2985 - 59s - loss: 2.3910e-04 - val_loss: 1.9443e-04 - 59s/epoch - 20ms/step
Epoch 128/300
2985/2985 - 59s - loss: 2.3724e-04 - val_loss: 1.8706e-04 - 59s/epoch - 20ms/step
Epoch 129/300
2985/2985 - 59s - loss: 2.3947e-04 - val_loss: 1.8219e-04 - 59s/epoch - 20ms/step
Epoch 130/300
2985/2985 - 59s - loss: 2.3485e-04 - val_loss: 1.8011e-04 - 59s/epoch - 20ms/step
Epoch 131/300
2985/2985 - 59s - loss: 2.4197e-04 - val_loss: 1.7552e-04 - 59s/epoch - 20ms/step
Epoch 132/300
2985/2985 - 59s - loss: 2.3540e-04 - val_loss: 1.8998e-04 - 59s/epoch - 20ms/step
Epoch 133/300
2985/2985 - 59s - loss: 2.3673e-04 - val_loss: 2.9119e-04 - 59s/epoch - 20ms/step
Epoch 134/300
2985/2985 - 59s - loss: 2.4572e-04 - val_loss: 1.9203e-04 - 59s/epoch - 20ms/step
Epoch 135/300
2985/2985 - 59s - loss: 2.3783e-04 - val_loss: 1.8263e-04 - 59s/epoch - 20ms/step
Epoch 136/300
2985/2985 - 59s - loss: 2.3418e-04 - val_loss: 1.7460e-04 - 59s/epoch - 20ms/step
Epoch 137/300
2985/2985 - 59s - loss: 2.3292e-04 - val_loss: 2.0976e-04 - 59s/epoch - 20ms/step
Epoch 138/300
2985/2985 - 59s - loss: 2.3135e-04 - val_loss: 1.9586e-04 - 59s/epoch - 20ms/step
Epoch 139/300
2985/2985 - 59s - loss: 2.3485e-04 - val_loss: 2.7357e-04 - 59s/epoch - 20ms/step
Epoch 140/300
2985/2985 - 59s - loss: 2.5824e-04 - val_loss: 1.8777e-04 - 59s/epoch - 20ms/step
Epoch 141/300
2985/2985 - 59s - loss: 2.3443e-04 - val_loss: 2.1906e-04 - 59s/epoch - 20ms/step
Epoch 142/300
2985/2985 - 59s - loss: 2.4728e-04 - val_loss: 1.9564e-04 - 59s/epoch - 20ms/step
Epoch 143/300
2985/2985 - 59s - loss: 2.3224e-04 - val_loss: 1.8079e-04 - 59s/epoch - 20ms/step
Epoch 144/300
2985/2985 - 59s - loss: 2.4244e-04 - val_loss: 1.8643e-04 - 59s/epoch - 20ms/step
Epoch 145/300
2985/2985 - 59s - loss: 2.5502e-04 - val_loss: 1.8532e-04 - 59s/epoch - 20ms/step
Epoch 146/300
2985/2985 - 59s - loss: 2.3517e-04 - val_loss: 1.9616e-04 - 59s/epoch - 20ms/step
Epoch 147/300
2985/2985 - 59s - loss: 2.3235e-04 - val_loss: 2.0554e-04 - 59s/epoch - 20ms/step
Epoch 148/300
2985/2985 - 59s - loss: 2.3146e-04 - val_loss: 2.0026e-04 - 59s/epoch - 20ms/step
Epoch 149/300
2985/2985 - 59s - loss: 2.2672e-04 - val_loss: 1.7324e-04 - 59s/epoch - 20ms/step
Epoch 150/300
2985/2985 - 59s - loss: 2.3039e-04 - val_loss: 1.9050e-04 - 59s/epoch - 20ms/step
Epoch 151/300
2985/2985 - 59s - loss: 2.2711e-04 - val_loss: 1.9031e-04 - 59s/epoch - 20ms/step
Epoch 152/300
2985/2985 - 59s - loss: 2.3309e-04 - val_loss: 1.7091e-04 - 59s/epoch - 20ms/step
Epoch 153/300
2985/2985 - 59s - loss: 2.2730e-04 - val_loss: 1.8428e-04 - 59s/epoch - 20ms/step
Epoch 154/300
2985/2985 - 59s - loss: 2.2846e-04 - val_loss: 1.8045e-04 - 59s/epoch - 20ms/step
Epoch 155/300
2985/2985 - 59s - loss: 2.2292e-04 - val_loss: 1.8246e-04 - 59s/epoch - 20ms/step
Epoch 156/300
2985/2985 - 59s - loss: 2.3008e-04 - val_loss: 1.8650e-04 - 59s/epoch - 20ms/step
Epoch 157/300
2985/2985 - 59s - loss: 2.2417e-04 - val_loss: 2.2337e-04 - 59s/epoch - 20ms/step
Epoch 158/300
2985/2985 - 59s - loss: 2.2460e-04 - val_loss: 1.7650e-04 - 59s/epoch - 20ms/step
Epoch 159/300
2985/2985 - 59s - loss: 2.2488e-04 - val_loss: 1.7655e-04 - 59s/epoch - 20ms/step
Epoch 160/300
2985/2985 - 59s - loss: 2.2818e-04 - val_loss: 1.8842e-04 - 59s/epoch - 20ms/step
Epoch 161/300
2985/2985 - 59s - loss: 2.2732e-04 - val_loss: 2.3909e-04 - 59s/epoch - 20ms/step
Epoch 162/300
2985/2985 - 59s - loss: 2.2610e-04 - val_loss: 1.9037e-04 - 59s/epoch - 20ms/step
Epoch 163/300
2985/2985 - 59s - loss: 2.2295e-04 - val_loss: 1.8026e-04 - 59s/epoch - 20ms/step
Epoch 164/300
2985/2985 - 59s - loss: 2.2775e-04 - val_loss: 1.9877e-04 - 59s/epoch - 20ms/step
Epoch 165/300
2985/2985 - 59s - loss: 2.3027e-04 - val_loss: 1.8635e-04 - 59s/epoch - 20ms/step
Epoch 166/300
2985/2985 - 59s - loss: 2.2835e-04 - val_loss: 1.8583e-04 - 59s/epoch - 20ms/step
Epoch 167/300
2985/2985 - 59s - loss: 2.2609e-04 - val_loss: 1.7380e-04 - 59s/epoch - 20ms/step
Epoch 168/300
2985/2985 - 59s - loss: 2.2155e-04 - val_loss: 1.8812e-04 - 59s/epoch - 20ms/step
Epoch 169/300
2985/2985 - 59s - loss: 2.2025e-04 - val_loss: 2.2252e-04 - 59s/epoch - 20ms/step
Epoch 170/300
2985/2985 - 59s - loss: 2.3084e-04 - val_loss: 1.9736e-04 - 59s/epoch - 20ms/step
Epoch 171/300
2985/2985 - 59s - loss: 2.2688e-04 - val_loss: 1.7089e-04 - 59s/epoch - 20ms/step
Epoch 172/300
2985/2985 - 59s - loss: 2.2070e-04 - val_loss: 1.9012e-04 - 59s/epoch - 20ms/step
Epoch 173/300
2985/2985 - 59s - loss: 2.2532e-04 - val_loss: 1.7439e-04 - 59s/epoch - 20ms/step
Epoch 174/300
2985/2985 - 59s - loss: 2.2032e-04 - val_loss: 1.6482e-04 - 59s/epoch - 20ms/step
Epoch 175/300
2985/2985 - 59s - loss: 2.1945e-04 - val_loss: 1.7237e-04 - 59s/epoch - 20ms/step
Epoch 176/300
2985/2985 - 59s - loss: 2.2088e-04 - val_loss: 1.7919e-04 - 59s/epoch - 20ms/step
Epoch 177/300
2985/2985 - 59s - loss: 2.3830e-04 - val_loss: 1.6882e-04 - 59s/epoch - 20ms/step
Epoch 178/300
2985/2985 - 59s - loss: 2.1823e-04 - val_loss: 1.8730e-04 - 59s/epoch - 20ms/step
Epoch 179/300
2985/2985 - 59s - loss: 2.3308e-04 - val_loss: 1.7610e-04 - 59s/epoch - 20ms/step
Epoch 180/300
2985/2985 - 59s - loss: 2.1888e-04 - val_loss: 1.9560e-04 - 59s/epoch - 20ms/step
Epoch 181/300
2985/2985 - 59s - loss: 2.1808e-04 - val_loss: 1.6937e-04 - 59s/epoch - 20ms/step
Epoch 182/300
2985/2985 - 59s - loss: 2.2377e-04 - val_loss: 1.9337e-04 - 59s/epoch - 20ms/step
Epoch 183/300
2985/2985 - 59s - loss: 2.3981e-04 - val_loss: 1.8415e-04 - 59s/epoch - 20ms/step
Epoch 184/300
2985/2985 - 59s - loss: 2.3554e-04 - val_loss: 1.7640e-04 - 59s/epoch - 20ms/step
Epoch 185/300
2985/2985 - 59s - loss: 2.2348e-04 - val_loss: 2.1627e-04 - 59s/epoch - 20ms/step
Epoch 186/300
2985/2985 - 59s - loss: 2.1662e-04 - val_loss: 1.7323e-04 - 59s/epoch - 20ms/step
Epoch 187/300
2985/2985 - 59s - loss: 2.1743e-04 - val_loss: 1.8194e-04 - 59s/epoch - 20ms/step
Epoch 188/300
2985/2985 - 59s - loss: 2.2153e-04 - val_loss: 1.7809e-04 - 59s/epoch - 20ms/step
Epoch 189/300
2985/2985 - 59s - loss: 2.2062e-04 - val_loss: 1.8375e-04 - 59s/epoch - 20ms/step
Epoch 190/300
2985/2985 - 59s - loss: 2.2104e-04 - val_loss: 1.8202e-04 - 59s/epoch - 20ms/step
Epoch 191/300
2985/2985 - 59s - loss: 2.2224e-04 - val_loss: 3.5812e-04 - 59s/epoch - 20ms/step
Epoch 192/300
2985/2985 - 59s - loss: 2.4210e-04 - val_loss: 1.8634e-04 - 59s/epoch - 20ms/step
Epoch 193/300
2985/2985 - 59s - loss: 2.1769e-04 - val_loss: 1.9574e-04 - 59s/epoch - 20ms/step
Epoch 194/300
2985/2985 - 59s - loss: 2.1976e-04 - val_loss: 2.1195e-04 - 59s/epoch - 20ms/step
Epoch 195/300
2985/2985 - 59s - loss: 2.1850e-04 - val_loss: 1.8650e-04 - 59s/epoch - 20ms/step
Epoch 196/300
2985/2985 - 59s - loss: 2.1371e-04 - val_loss: 1.8934e-04 - 59s/epoch - 20ms/step
Epoch 197/300
2985/2985 - 59s - loss: 2.2040e-04 - val_loss: 0.0012 - 59s/epoch - 20ms/step
Epoch 198/300
2985/2985 - 59s - loss: 2.1957e-04 - val_loss: 1.8049e-04 - 59s/epoch - 20ms/step
Epoch 199/300
2985/2985 - 59s - loss: 2.1559e-04 - val_loss: 1.7181e-04 - 59s/epoch - 20ms/step
Epoch 200/300
2985/2985 - 59s - loss: 2.1401e-04 - val_loss: 1.9064e-04 - 59s/epoch - 20ms/step
Epoch 201/300
2985/2985 - 59s - loss: 2.1190e-04 - val_loss: 1.7262e-04 - 59s/epoch - 20ms/step
Epoch 202/300
2985/2985 - 59s - loss: 2.1466e-04 - val_loss: 1.8165e-04 - 59s/epoch - 20ms/step
Epoch 203/300
2985/2985 - 59s - loss: 2.1543e-04 - val_loss: 2.1427e-04 - 59s/epoch - 20ms/step
Epoch 204/300
2985/2985 - 59s - loss: 2.1318e-04 - val_loss: 1.6772e-04 - 59s/epoch - 20ms/step
Epoch 205/300
2985/2985 - 59s - loss: 2.3844e-04 - val_loss: 1.6673e-04 - 59s/epoch - 20ms/step
Epoch 206/300
2985/2985 - 59s - loss: 2.1113e-04 - val_loss: 1.9870e-04 - 59s/epoch - 20ms/step
Epoch 207/300
2985/2985 - 59s - loss: 2.1238e-04 - val_loss: 1.8044e-04 - 59s/epoch - 20ms/step
Epoch 208/300
2985/2985 - 59s - loss: 2.1186e-04 - val_loss: 1.9919e-04 - 59s/epoch - 20ms/step
Epoch 209/300
2985/2985 - 59s - loss: 2.1792e-04 - val_loss: 1.8266e-04 - 59s/epoch - 20ms/step
Epoch 210/300
2985/2985 - 59s - loss: 2.1168e-04 - val_loss: 1.8706e-04 - 59s/epoch - 20ms/step
Epoch 211/300
2985/2985 - 59s - loss: 2.1137e-04 - val_loss: 2.0222e-04 - 59s/epoch - 20ms/step
Epoch 212/300
2985/2985 - 59s - loss: 2.1640e-04 - val_loss: 1.6131e-04 - 59s/epoch - 20ms/step
Epoch 213/300
2985/2985 - 59s - loss: 2.0983e-04 - val_loss: 1.8246e-04 - 59s/epoch - 20ms/step
Epoch 214/300
2985/2985 - 59s - loss: 2.1895e-04 - val_loss: 1.8760e-04 - 59s/epoch - 20ms/step
Epoch 215/300
2985/2985 - 59s - loss: 2.1166e-04 - val_loss: 1.7856e-04 - 59s/epoch - 20ms/step
Epoch 216/300
2985/2985 - 59s - loss: 2.2334e-04 - val_loss: 1.6494e-04 - 59s/epoch - 20ms/step
Epoch 217/300
2985/2985 - 59s - loss: 2.1202e-04 - val_loss: 1.7088e-04 - 59s/epoch - 20ms/step
Epoch 218/300
2985/2985 - 59s - loss: 2.1096e-04 - val_loss: 2.1884e-04 - 59s/epoch - 20ms/step
Epoch 219/300
2985/2985 - 59s - loss: 2.1205e-04 - val_loss: 1.6145e-04 - 59s/epoch - 20ms/step
Epoch 220/300
2985/2985 - 59s - loss: 2.1211e-04 - val_loss: 1.6966e-04 - 59s/epoch - 20ms/step
Epoch 221/300
2985/2985 - 59s - loss: 2.1072e-04 - val_loss: 1.7084e-04 - 59s/epoch - 20ms/step
Epoch 222/300
2985/2985 - 59s - loss: 2.1007e-04 - val_loss: 1.6035e-04 - 59s/epoch - 20ms/step
Epoch 223/300
2985/2985 - 59s - loss: 2.1330e-04 - val_loss: 2.5623e-04 - 59s/epoch - 20ms/step
Epoch 224/300
2985/2985 - 59s - loss: 2.0735e-04 - val_loss: 1.8116e-04 - 59s/epoch - 20ms/step
Epoch 225/300
2985/2985 - 59s - loss: 2.0788e-04 - val_loss: 1.8163e-04 - 59s/epoch - 20ms/step
Epoch 226/300
2985/2985 - 59s - loss: 2.2350e-04 - val_loss: 1.7085e-04 - 59s/epoch - 20ms/step
Epoch 227/300
2985/2985 - 59s - loss: 2.0943e-04 - val_loss: 1.6699e-04 - 59s/epoch - 20ms/step
Epoch 228/300
2985/2985 - 59s - loss: 2.0644e-04 - val_loss: 1.7431e-04 - 59s/epoch - 20ms/step
Epoch 229/300
2985/2985 - 59s - loss: 2.0700e-04 - val_loss: 3.0931e-04 - 59s/epoch - 20ms/step
Epoch 230/300
2985/2985 - 59s - loss: 2.1168e-04 - val_loss: 1.6590e-04 - 59s/epoch - 20ms/step
Epoch 231/300
2985/2985 - 59s - loss: 2.0636e-04 - val_loss: 1.7312e-04 - 59s/epoch - 20ms/step
Epoch 232/300
2985/2985 - 59s - loss: 2.0587e-04 - val_loss: 1.6031e-04 - 59s/epoch - 20ms/step
Epoch 233/300
2985/2985 - 59s - loss: 2.1168e-04 - val_loss: 2.1596e-04 - 59s/epoch - 20ms/step
Epoch 234/300
2985/2985 - 59s - loss: 2.0877e-04 - val_loss: 1.7851e-04 - 59s/epoch - 20ms/step
Epoch 235/300
2985/2985 - 59s - loss: 2.0885e-04 - val_loss: 1.5502e-04 - 59s/epoch - 20ms/step
Epoch 236/300
2985/2985 - 59s - loss: 2.0396e-04 - val_loss: 1.7481e-04 - 59s/epoch - 20ms/step
Epoch 237/300
2985/2985 - 59s - loss: 2.1425e-04 - val_loss: 1.9335e-04 - 59s/epoch - 20ms/step
Epoch 238/300
2985/2985 - 59s - loss: 2.1073e-04 - val_loss: 1.7373e-04 - 59s/epoch - 20ms/step
Epoch 239/300
2985/2985 - 59s - loss: 2.0627e-04 - val_loss: 1.6787e-04 - 59s/epoch - 20ms/step
Epoch 240/300
2985/2985 - 59s - loss: 2.0370e-04 - val_loss: 1.7539e-04 - 59s/epoch - 20ms/step
Epoch 241/300
2985/2985 - 59s - loss: 2.0180e-04 - val_loss: 1.7010e-04 - 59s/epoch - 20ms/step
Epoch 242/300
2985/2985 - 59s - loss: 2.0628e-04 - val_loss: 1.6071e-04 - 59s/epoch - 20ms/step
Epoch 243/300
2985/2985 - 59s - loss: 2.0346e-04 - val_loss: 1.6444e-04 - 59s/epoch - 20ms/step
Epoch 244/300
2985/2985 - 59s - loss: 2.0564e-04 - val_loss: 1.8687e-04 - 59s/epoch - 20ms/step
Epoch 245/300
2985/2985 - 59s - loss: 2.0306e-04 - val_loss: 1.7825e-04 - 59s/epoch - 20ms/step
Epoch 246/300
2985/2985 - 59s - loss: 2.1910e-04 - val_loss: 1.7374e-04 - 59s/epoch - 20ms/step
Epoch 247/300
2985/2985 - 59s - loss: 2.0873e-04 - val_loss: 1.8010e-04 - 59s/epoch - 20ms/step
Epoch 248/300
2985/2985 - 59s - loss: 2.0508e-04 - val_loss: 1.8105e-04 - 59s/epoch - 20ms/step
Epoch 249/300
2985/2985 - 59s - loss: 2.0897e-04 - val_loss: 1.6976e-04 - 59s/epoch - 20ms/step
Epoch 250/300
2985/2985 - 59s - loss: 2.0041e-04 - val_loss: 1.6275e-04 - 59s/epoch - 20ms/step
Epoch 251/300
2985/2985 - 59s - loss: 2.0196e-04 - val_loss: 2.0156e-04 - 59s/epoch - 20ms/step
Epoch 252/300
2985/2985 - 59s - loss: 2.0898e-04 - val_loss: 1.9224e-04 - 59s/epoch - 20ms/step
Epoch 253/300
2985/2985 - 59s - loss: 2.0501e-04 - val_loss: 1.8517e-04 - 59s/epoch - 20ms/step
Epoch 254/300
2985/2985 - 59s - loss: 2.0147e-04 - val_loss: 1.5807e-04 - 59s/epoch - 20ms/step
Epoch 255/300
2985/2985 - 59s - loss: 2.1100e-04 - val_loss: 1.5931e-04 - 59s/epoch - 20ms/step
Epoch 256/300
2985/2985 - 59s - loss: 2.0284e-04 - val_loss: 1.7980e-04 - 59s/epoch - 20ms/step
Epoch 257/300
2985/2985 - 59s - loss: 2.0486e-04 - val_loss: 1.6368e-04 - 59s/epoch - 20ms/step
Epoch 258/300
2985/2985 - 59s - loss: 1.9987e-04 - val_loss: 1.7218e-04 - 59s/epoch - 20ms/step
Epoch 259/300
2985/2985 - 59s - loss: 2.0510e-04 - val_loss: 1.7630e-04 - 59s/epoch - 20ms/step
Epoch 260/300
2985/2985 - 59s - loss: 2.0219e-04 - val_loss: 1.9924e-04 - 59s/epoch - 20ms/step
Epoch 261/300
2985/2985 - 59s - loss: 2.0697e-04 - val_loss: 1.7845e-04 - 59s/epoch - 20ms/step
Epoch 262/300
2985/2985 - 59s - loss: 2.1171e-04 - val_loss: 1.5240e-04 - 59s/epoch - 20ms/step
Epoch 263/300
2985/2985 - 59s - loss: 2.0139e-04 - val_loss: 1.6539e-04 - 59s/epoch - 20ms/step
Epoch 264/300
2985/2985 - 59s - loss: 2.0003e-04 - val_loss: 1.7944e-04 - 59s/epoch - 20ms/step
Epoch 265/300
2985/2985 - 59s - loss: 2.0156e-04 - val_loss: 1.7951e-04 - 59s/epoch - 20ms/step
Epoch 266/300
2985/2985 - 59s - loss: 2.0157e-04 - val_loss: 1.6467e-04 - 59s/epoch - 20ms/step
Epoch 267/300
2985/2985 - 59s - loss: 1.9867e-04 - val_loss: 1.8036e-04 - 59s/epoch - 20ms/step
Epoch 268/300
2985/2985 - 59s - loss: 1.9770e-04 - val_loss: 1.6732e-04 - 59s/epoch - 20ms/step
Epoch 269/300
2985/2985 - 59s - loss: 2.0266e-04 - val_loss: 2.4987e-04 - 59s/epoch - 20ms/step
Epoch 270/300
2985/2985 - 59s - loss: 2.0864e-04 - val_loss: 1.9127e-04 - 59s/epoch - 20ms/step
Epoch 271/300
2985/2985 - 59s - loss: 2.0293e-04 - val_loss: 1.7611e-04 - 59s/epoch - 20ms/step
Epoch 272/300
2985/2985 - 59s - loss: 2.0241e-04 - val_loss: 1.7409e-04 - 59s/epoch - 20ms/step
Epoch 273/300
2985/2985 - 59s - loss: 1.9903e-04 - val_loss: 2.0079e-04 - 59s/epoch - 20ms/step
Epoch 274/300
2985/2985 - 59s - loss: 2.1410e-04 - val_loss: 2.7415e-04 - 59s/epoch - 20ms/step
Epoch 275/300
2985/2985 - 59s - loss: 2.2137e-04 - val_loss: 1.6892e-04 - 59s/epoch - 20ms/step
Epoch 276/300
2985/2985 - 59s - loss: 1.9873e-04 - val_loss: 1.6117e-04 - 59s/epoch - 20ms/step
Epoch 277/300
2985/2985 - 59s - loss: 2.0134e-04 - val_loss: 1.7540e-04 - 59s/epoch - 20ms/step
Epoch 278/300
2985/2985 - 59s - loss: 1.9712e-04 - val_loss: 1.6209e-04 - 59s/epoch - 20ms/step
Epoch 279/300
2985/2985 - 59s - loss: 1.9877e-04 - val_loss: 1.6261e-04 - 59s/epoch - 20ms/step
Epoch 280/300
2985/2985 - 59s - loss: 1.9970e-04 - val_loss: 1.7672e-04 - 59s/epoch - 20ms/step
Epoch 281/300
2985/2985 - 59s - loss: 1.9802e-04 - val_loss: 1.7573e-04 - 59s/epoch - 20ms/step
Epoch 282/300
2985/2985 - 59s - loss: 2.0071e-04 - val_loss: 1.6564e-04 - 59s/epoch - 20ms/step
Epoch 283/300
2985/2985 - 59s - loss: 2.0155e-04 - val_loss: 1.9170e-04 - 59s/epoch - 20ms/step
Epoch 284/300
2985/2985 - 59s - loss: 1.9667e-04 - val_loss: 1.6885e-04 - 59s/epoch - 20ms/step
Epoch 285/300
2985/2985 - 59s - loss: 2.0442e-04 - val_loss: 1.8167e-04 - 59s/epoch - 20ms/step
Epoch 286/300
2985/2985 - 59s - loss: 1.9852e-04 - val_loss: 1.6638e-04 - 59s/epoch - 20ms/step
Epoch 287/300
2985/2985 - 59s - loss: 2.0190e-04 - val_loss: 2.0945e-04 - 59s/epoch - 20ms/step
Epoch 288/300
2985/2985 - 59s - loss: 2.0856e-04 - val_loss: 1.7331e-04 - 59s/epoch - 20ms/step
Epoch 289/300
2985/2985 - 59s - loss: 2.0060e-04 - val_loss: 3.2818e-04 - 59s/epoch - 20ms/step
Epoch 290/300
2985/2985 - 59s - loss: 2.1815e-04 - val_loss: 2.8556e-04 - 59s/epoch - 20ms/step
Epoch 291/300
2985/2985 - 59s - loss: 2.1167e-04 - val_loss: 1.8241e-04 - 59s/epoch - 20ms/step
Epoch 292/300
2985/2985 - 59s - loss: 2.0238e-04 - val_loss: 2.0145e-04 - 59s/epoch - 20ms/step
Epoch 293/300
2985/2985 - 59s - loss: 1.9832e-04 - val_loss: 1.9037e-04 - 59s/epoch - 20ms/step
Epoch 294/300
2985/2985 - 59s - loss: 2.1234e-04 - val_loss: 1.6622e-04 - 59s/epoch - 20ms/step
Epoch 295/300
2985/2985 - 59s - loss: 2.0055e-04 - val_loss: 1.4860e-04 - 59s/epoch - 20ms/step
Epoch 296/300
2985/2985 - 59s - loss: 2.0827e-04 - val_loss: 1.7943e-04 - 59s/epoch - 20ms/step
Epoch 297/300
2985/2985 - 59s - loss: 1.9743e-04 - val_loss: 1.7367e-04 - 59s/epoch - 20ms/step
Epoch 298/300
2985/2985 - 59s - loss: 1.9485e-04 - val_loss: 1.8426e-04 - 59s/epoch - 20ms/step
Epoch 299/300
2985/2985 - 59s - loss: 2.0670e-04 - val_loss: 2.8561e-04 - 59s/epoch - 20ms/step
Epoch 300/300
2985/2985 - 59s - loss: 2.3346e-04 - val_loss: 1.8168e-04 - 59s/epoch - 20ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00018168380483984947
  1/332 [..............................] - ETA: 29s 16/332 [>.............................] - ETA: 1s  31/332 [=>............................] - ETA: 1s 46/332 [===>..........................] - ETA: 0s 62/332 [====>.........................] - ETA: 0s 78/332 [======>.......................] - ETA: 0s 94/332 [=======>......................] - ETA: 0s109/332 [========>.....................] - ETA: 0s125/332 [==========>...................] - ETA: 0s141/332 [===========>..................] - ETA: 0s157/332 [=============>................] - ETA: 0s173/332 [==============>...............] - ETA: 0s188/332 [===============>..............] - ETA: 0s204/332 [=================>............] - ETA: 0s220/332 [==================>...........] - ETA: 0s236/332 [====================>.........] - ETA: 0s252/332 [=====================>........] - ETA: 0s268/332 [=======================>......] - ETA: 0s284/332 [========================>.....] - ETA: 0s300/332 [==========================>...] - ETA: 0s316/332 [===========================>..] - ETA: 0s332/332 [==============================] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.002071838524042324
cosine 0.0016501896951138368
MAE: 0.0075311344
RMSE: 0.013479002
r2: 0.9882139908023904
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_3 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_4 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 632)               0         
                                                                 
 dense_4 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_5 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 1264)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_3 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 632)]             0         
                                                                 
 batch_normalization_4 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 632)               0         
                                                                 
 dense_4 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_5 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 1264)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 32, 300, 0.001, 0.5, 632, 0.0002334593009436503, 0.00018168380483984947, 0.002071838524042324, 0.0016501896951138368, 0.007531134411692619, 0.013479001820087433, 0.9882139908023904, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_6 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_6 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_7 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 632)               0         
                                                                 
 dense_7 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_8 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 1264)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
2985/2985 - 59s - loss: 0.0064 - val_loss: 0.0027 - 59s/epoch - 20ms/step
Epoch 2/300
2985/2985 - 59s - loss: 0.0024 - val_loss: 0.0017 - 59s/epoch - 20ms/step
Epoch 3/300
2985/2985 - 59s - loss: 0.0017 - val_loss: 0.0014 - 59s/epoch - 20ms/step
Epoch 4/300
2985/2985 - 59s - loss: 0.0013 - val_loss: 9.8623e-04 - 59s/epoch - 20ms/step
Epoch 5/300
2985/2985 - 58s - loss: 0.0011 - val_loss: 0.0010 - 58s/epoch - 20ms/step
Epoch 6/300
2985/2985 - 59s - loss: 9.2092e-04 - val_loss: 7.4052e-04 - 59s/epoch - 20ms/step
Epoch 7/300
2985/2985 - 59s - loss: 8.1785e-04 - val_loss: 6.8893e-04 - 59s/epoch - 20ms/step
Epoch 8/300
2985/2985 - 59s - loss: 7.5658e-04 - val_loss: 6.2962e-04 - 59s/epoch - 20ms/step
Epoch 9/300
2985/2985 - 59s - loss: 7.0919e-04 - val_loss: 5.6361e-04 - 59s/epoch - 20ms/step
Epoch 10/300
2985/2985 - 58s - loss: 6.7484e-04 - val_loss: 5.5000e-04 - 58s/epoch - 20ms/step
Epoch 11/300
2985/2985 - 59s - loss: 6.3433e-04 - val_loss: 5.3014e-04 - 59s/epoch - 20ms/step
Epoch 12/300
2985/2985 - 59s - loss: 6.4628e-04 - val_loss: 4.9961e-04 - 59s/epoch - 20ms/step
Epoch 13/300
2985/2985 - 59s - loss: 5.9308e-04 - val_loss: 6.1421e-04 - 59s/epoch - 20ms/step
Epoch 14/300
2985/2985 - 59s - loss: 5.9764e-04 - val_loss: 4.5824e-04 - 59s/epoch - 20ms/step
Epoch 15/300
2985/2985 - 59s - loss: 5.8606e-04 - val_loss: 4.8388e-04 - 59s/epoch - 20ms/step
Epoch 16/300
2985/2985 - 58s - loss: 5.5977e-04 - val_loss: 4.7396e-04 - 58s/epoch - 20ms/step
Epoch 17/300
2985/2985 - 59s - loss: 5.3663e-04 - val_loss: 4.3180e-04 - 59s/epoch - 20ms/step
Epoch 18/300
2985/2985 - 59s - loss: 5.2759e-04 - val_loss: 4.5270e-04 - 59s/epoch - 20ms/step
Epoch 19/300
2985/2985 - 59s - loss: 5.1024e-04 - val_loss: 4.4585e-04 - 59s/epoch - 20ms/step
Epoch 20/300
2985/2985 - 59s - loss: 5.1149e-04 - val_loss: 4.0816e-04 - 59s/epoch - 20ms/step
Epoch 21/300
2985/2985 - 58s - loss: 4.9433e-04 - val_loss: 3.9183e-04 - 58s/epoch - 20ms/step
Epoch 22/300
2985/2985 - 59s - loss: 4.8855e-04 - val_loss: 4.7640e-04 - 59s/epoch - 20ms/step
Epoch 23/300
2985/2985 - 59s - loss: 5.0657e-04 - val_loss: 3.7626e-04 - 59s/epoch - 20ms/step
Epoch 24/300
2985/2985 - 59s - loss: 4.8119e-04 - val_loss: 3.9615e-04 - 59s/epoch - 20ms/step
Epoch 25/300
2985/2985 - 59s - loss: 4.6693e-04 - val_loss: 3.8502e-04 - 59s/epoch - 20ms/step
Epoch 26/300
2985/2985 - 58s - loss: 4.7300e-04 - val_loss: 3.4153e-04 - 58s/epoch - 20ms/step
Epoch 27/300
2985/2985 - 59s - loss: 4.4619e-04 - val_loss: 3.5351e-04 - 59s/epoch - 20ms/step
Epoch 28/300
2985/2985 - 59s - loss: 4.4324e-04 - val_loss: 3.3033e-04 - 59s/epoch - 20ms/step
Epoch 29/300
2985/2985 - 59s - loss: 4.4029e-04 - val_loss: 3.4719e-04 - 59s/epoch - 20ms/step
Epoch 30/300
2985/2985 - 59s - loss: 4.3425e-04 - val_loss: 3.5198e-04 - 59s/epoch - 20ms/step
Epoch 31/300
2985/2985 - 59s - loss: 4.3344e-04 - val_loss: 3.2308e-04 - 59s/epoch - 20ms/step
Epoch 32/300
2985/2985 - 58s - loss: 4.3231e-04 - val_loss: 3.4298e-04 - 58s/epoch - 20ms/step
Epoch 33/300
2985/2985 - 59s - loss: 4.2034e-04 - val_loss: 3.2100e-04 - 59s/epoch - 20ms/step
Epoch 34/300
2985/2985 - 59s - loss: 4.2773e-04 - val_loss: 3.0829e-04 - 59s/epoch - 20ms/step
Epoch 35/300
2985/2985 - 59s - loss: 4.1053e-04 - val_loss: 3.1224e-04 - 59s/epoch - 20ms/step
Epoch 36/300
2985/2985 - 59s - loss: 4.1222e-04 - val_loss: 3.2795e-04 - 59s/epoch - 20ms/step
Epoch 37/300
2985/2985 - 58s - loss: 4.0928e-04 - val_loss: 3.2669e-04 - 58s/epoch - 20ms/step
Epoch 38/300
2985/2985 - 59s - loss: 4.5600e-04 - val_loss: 3.0959e-04 - 59s/epoch - 20ms/step
Epoch 39/300
2985/2985 - 59s - loss: 4.1591e-04 - val_loss: 3.1640e-04 - 59s/epoch - 20ms/step
Epoch 40/300
2985/2985 - 59s - loss: 3.9783e-04 - val_loss: 4.0331e-04 - 59s/epoch - 20ms/step
Epoch 41/300
2985/2985 - 59s - loss: 4.1410e-04 - val_loss: 2.9238e-04 - 59s/epoch - 20ms/step
Epoch 42/300
2985/2985 - 58s - loss: 3.9176e-04 - val_loss: 3.0088e-04 - 58s/epoch - 20ms/step
Epoch 43/300
2985/2985 - 59s - loss: 3.8969e-04 - val_loss: 3.0230e-04 - 59s/epoch - 20ms/step
Epoch 44/300
2985/2985 - 59s - loss: 3.8313e-04 - val_loss: 3.5672e-04 - 59s/epoch - 20ms/step
Epoch 45/300
2985/2985 - 59s - loss: 3.9287e-04 - val_loss: 2.8829e-04 - 59s/epoch - 20ms/step
Epoch 46/300
2985/2985 - 59s - loss: 3.8022e-04 - val_loss: 2.8298e-04 - 59s/epoch - 20ms/step
Epoch 47/300
2985/2985 - 59s - loss: 3.7678e-04 - val_loss: 2.7903e-04 - 59s/epoch - 20ms/step
Epoch 48/300
2985/2985 - 58s - loss: 3.7927e-04 - val_loss: 2.8307e-04 - 58s/epoch - 20ms/step
Epoch 49/300
2985/2985 - 59s - loss: 3.7745e-04 - val_loss: 4.6583e-04 - 59s/epoch - 20ms/step
Epoch 50/300
2985/2985 - 59s - loss: 3.9693e-04 - val_loss: 3.0882e-04 - 59s/epoch - 20ms/step
Epoch 51/300
2985/2985 - 59s - loss: 3.6924e-04 - val_loss: 2.7863e-04 - 59s/epoch - 20ms/step
Epoch 52/300
2985/2985 - 59s - loss: 3.7768e-04 - val_loss: 2.7369e-04 - 59s/epoch - 20ms/step
Epoch 53/300
2985/2985 - 58s - loss: 3.6585e-04 - val_loss: 2.6484e-04 - 58s/epoch - 20ms/step
Epoch 54/300
2985/2985 - 59s - loss: 3.6142e-04 - val_loss: 2.8277e-04 - 59s/epoch - 20ms/step
Epoch 55/300
2985/2985 - 59s - loss: 3.5977e-04 - val_loss: 2.6766e-04 - 59s/epoch - 20ms/step
Epoch 56/300
2985/2985 - 59s - loss: 3.6667e-04 - val_loss: 2.6797e-04 - 59s/epoch - 20ms/step
Epoch 57/300
2985/2985 - 59s - loss: 3.5786e-04 - val_loss: 2.6531e-04 - 59s/epoch - 20ms/step
Epoch 58/300
2985/2985 - 58s - loss: 3.5309e-04 - val_loss: 2.5405e-04 - 58s/epoch - 20ms/step
Epoch 59/300
2985/2985 - 59s - loss: 3.5715e-04 - val_loss: 2.7054e-04 - 59s/epoch - 20ms/step
Epoch 60/300
2985/2985 - 59s - loss: 4.7195e-04 - val_loss: 3.0395e-04 - 59s/epoch - 20ms/step
Epoch 61/300
2985/2985 - 59s - loss: 3.8020e-04 - val_loss: 2.8350e-04 - 59s/epoch - 20ms/step
Epoch 62/300
2985/2985 - 59s - loss: 3.6587e-04 - val_loss: 2.8547e-04 - 59s/epoch - 20ms/step
Epoch 63/300
2985/2985 - 59s - loss: 3.6107e-04 - val_loss: 2.6814e-04 - 59s/epoch - 20ms/step
Epoch 64/300
2985/2985 - 58s - loss: 3.6037e-04 - val_loss: 2.6469e-04 - 58s/epoch - 20ms/step
Epoch 65/300
2985/2985 - 59s - loss: 3.5504e-04 - val_loss: 2.7531e-04 - 59s/epoch - 20ms/step
Epoch 66/300
2985/2985 - 59s - loss: 3.5315e-04 - val_loss: 2.7039e-04 - 59s/epoch - 20ms/step
Epoch 67/300
2985/2985 - 59s - loss: 3.5897e-04 - val_loss: 2.5253e-04 - 59s/epoch - 20ms/step
Epoch 68/300
2985/2985 - 59s - loss: 3.5370e-04 - val_loss: 2.7049e-04 - 59s/epoch - 20ms/step
Epoch 69/300
2985/2985 - 58s - loss: 3.5603e-04 - val_loss: 2.6013e-04 - 58s/epoch - 20ms/step
Epoch 70/300
2985/2985 - 59s - loss: 3.4992e-04 - val_loss: 3.3670e-04 - 59s/epoch - 20ms/step
Epoch 71/300
2985/2985 - 59s - loss: 3.4416e-04 - val_loss: 2.5465e-04 - 59s/epoch - 20ms/step
Epoch 72/300
2985/2985 - 59s - loss: 3.4953e-04 - val_loss: 5.4181e-04 - 59s/epoch - 20ms/step
Epoch 73/300
2985/2985 - 59s - loss: 3.8499e-04 - val_loss: 2.4603e-04 - 59s/epoch - 20ms/step
Epoch 74/300
2985/2985 - 58s - loss: 3.4471e-04 - val_loss: 2.6516e-04 - 58s/epoch - 20ms/step
Epoch 75/300
2985/2985 - 59s - loss: 3.6746e-04 - val_loss: 2.5035e-04 - 59s/epoch - 20ms/step
Epoch 76/300
2985/2985 - 59s - loss: 3.4081e-04 - val_loss: 2.5207e-04 - 59s/epoch - 20ms/step
Epoch 77/300
2985/2985 - 59s - loss: 3.4602e-04 - val_loss: 5.4840e-04 - 59s/epoch - 20ms/step
Epoch 78/300
2985/2985 - 59s - loss: 3.9931e-04 - val_loss: 2.5188e-04 - 59s/epoch - 20ms/step
Epoch 79/300
2985/2985 - 58s - loss: 3.4049e-04 - val_loss: 2.5367e-04 - 58s/epoch - 20ms/step
Epoch 80/300
2985/2985 - 59s - loss: 3.4339e-04 - val_loss: 2.5089e-04 - 59s/epoch - 20ms/step
Epoch 81/300
2985/2985 - 59s - loss: 3.3240e-04 - val_loss: 3.4478e-04 - 59s/epoch - 20ms/step
Epoch 82/300
2985/2985 - 59s - loss: 3.5574e-04 - val_loss: 2.5419e-04 - 59s/epoch - 20ms/step
Epoch 83/300
2985/2985 - 59s - loss: 3.3549e-04 - val_loss: 2.5406e-04 - 59s/epoch - 20ms/step
Epoch 84/300
2985/2985 - 59s - loss: 3.2961e-04 - val_loss: 2.3900e-04 - 59s/epoch - 20ms/step
Epoch 85/300
2985/2985 - 58s - loss: 3.3007e-04 - val_loss: 2.3804e-04 - 58s/epoch - 20ms/step
Epoch 86/300
2985/2985 - 59s - loss: 3.2836e-04 - val_loss: 2.3334e-04 - 59s/epoch - 20ms/step
Epoch 87/300
2985/2985 - 59s - loss: 3.2500e-04 - val_loss: 2.6409e-04 - 59s/epoch - 20ms/step
Epoch 88/300
2985/2985 - 59s - loss: 3.3592e-04 - val_loss: 5.0650e-04 - 59s/epoch - 20ms/step
Epoch 89/300
2985/2985 - 59s - loss: 3.7657e-04 - val_loss: 2.5093e-04 - 59s/epoch - 20ms/step
Epoch 90/300
2985/2985 - 58s - loss: 3.3629e-04 - val_loss: 2.3863e-04 - 58s/epoch - 20ms/step
Epoch 91/300
2985/2985 - 59s - loss: 3.2332e-04 - val_loss: 2.3458e-04 - 59s/epoch - 20ms/step
Epoch 92/300
2985/2985 - 59s - loss: 3.2355e-04 - val_loss: 2.5505e-04 - 59s/epoch - 20ms/step
Epoch 93/300
2985/2985 - 59s - loss: 3.2073e-04 - val_loss: 2.4685e-04 - 59s/epoch - 20ms/step
Epoch 94/300
2985/2985 - 59s - loss: 3.5409e-04 - val_loss: 2.3668e-04 - 59s/epoch - 20ms/step
Epoch 95/300
2985/2985 - 58s - loss: 3.3000e-04 - val_loss: 2.4641e-04 - 58s/epoch - 20ms/step
Epoch 96/300
2985/2985 - 59s - loss: 3.1949e-04 - val_loss: 2.4802e-04 - 59s/epoch - 20ms/step
Epoch 97/300
2985/2985 - 59s - loss: 3.2475e-04 - val_loss: 2.3125e-04 - 59s/epoch - 20ms/step
Epoch 98/300
2985/2985 - 59s - loss: 3.2274e-04 - val_loss: 2.5753e-04 - 59s/epoch - 20ms/step
Epoch 99/300
2985/2985 - 59s - loss: 3.1984e-04 - val_loss: 2.3672e-04 - 59s/epoch - 20ms/step
Epoch 100/300
2985/2985 - 59s - loss: 3.1743e-04 - val_loss: 2.4368e-04 - 59s/epoch - 20ms/step
Epoch 101/300
2985/2985 - 58s - loss: 3.1622e-04 - val_loss: 2.2958e-04 - 58s/epoch - 20ms/step
Epoch 102/300
2985/2985 - 59s - loss: 3.1408e-04 - val_loss: 2.3833e-04 - 59s/epoch - 20ms/step
Epoch 103/300
2985/2985 - 59s - loss: 3.4477e-04 - val_loss: 2.2940e-04 - 59s/epoch - 20ms/step
Epoch 104/300
2985/2985 - 59s - loss: 3.1417e-04 - val_loss: 2.3610e-04 - 59s/epoch - 20ms/step
Epoch 105/300
2985/2985 - 59s - loss: 3.1125e-04 - val_loss: 2.3737e-04 - 59s/epoch - 20ms/step
Epoch 106/300
2985/2985 - 58s - loss: 3.1387e-04 - val_loss: 2.3377e-04 - 58s/epoch - 20ms/step
Epoch 107/300
2985/2985 - 59s - loss: 3.1638e-04 - val_loss: 2.4011e-04 - 59s/epoch - 20ms/step
Epoch 108/300
2985/2985 - 59s - loss: 3.0655e-04 - val_loss: 2.1588e-04 - 59s/epoch - 20ms/step
Epoch 109/300
2985/2985 - 59s - loss: 3.1851e-04 - val_loss: 2.2556e-04 - 59s/epoch - 20ms/step
Epoch 110/300
2985/2985 - 59s - loss: 3.0843e-04 - val_loss: 2.3291e-04 - 59s/epoch - 20ms/step
Epoch 111/300
2985/2985 - 58s - loss: 3.1458e-04 - val_loss: 2.2241e-04 - 58s/epoch - 20ms/step
Epoch 112/300
2985/2985 - 59s - loss: 3.0415e-04 - val_loss: 2.3479e-04 - 59s/epoch - 20ms/step
Epoch 113/300
2985/2985 - 59s - loss: 3.0651e-04 - val_loss: 2.6146e-04 - 59s/epoch - 20ms/step
Epoch 114/300
2985/2985 - 59s - loss: 3.2439e-04 - val_loss: 2.2665e-04 - 59s/epoch - 20ms/step
Epoch 115/300
2985/2985 - 59s - loss: 3.0322e-04 - val_loss: 2.2591e-04 - 59s/epoch - 20ms/step
Epoch 116/300
2985/2985 - 59s - loss: 3.0365e-04 - val_loss: 2.1228e-04 - 59s/epoch - 20ms/step
Epoch 117/300
2985/2985 - 58s - loss: 3.0136e-04 - val_loss: 2.2164e-04 - 58s/epoch - 20ms/step
Epoch 118/300
2985/2985 - 59s - loss: 3.0108e-04 - val_loss: 2.2333e-04 - 59s/epoch - 20ms/step
Epoch 119/300
2985/2985 - 59s - loss: 3.0386e-04 - val_loss: 2.2928e-04 - 59s/epoch - 20ms/step
Epoch 120/300
2985/2985 - 59s - loss: 3.0026e-04 - val_loss: 2.2067e-04 - 59s/epoch - 20ms/step
Epoch 121/300
2985/2985 - 59s - loss: 3.0568e-04 - val_loss: 2.7325e-04 - 59s/epoch - 20ms/step
Epoch 122/300
2985/2985 - 58s - loss: 3.2369e-04 - val_loss: 2.1614e-04 - 58s/epoch - 20ms/step
Epoch 123/300
2985/2985 - 59s - loss: 3.0170e-04 - val_loss: 2.3171e-04 - 59s/epoch - 20ms/step
Epoch 124/300
2985/2985 - 59s - loss: 2.9691e-04 - val_loss: 2.4488e-04 - 59s/epoch - 20ms/step
Epoch 125/300
2985/2985 - 59s - loss: 3.6080e-04 - val_loss: 2.5966e-04 - 59s/epoch - 20ms/step
Epoch 126/300
2985/2985 - 59s - loss: 3.1256e-04 - val_loss: 2.1273e-04 - 59s/epoch - 20ms/step
Epoch 127/300
2985/2985 - 58s - loss: 3.1352e-04 - val_loss: 2.2818e-04 - 58s/epoch - 20ms/step
Epoch 128/300
2985/2985 - 59s - loss: 3.0267e-04 - val_loss: 2.2411e-04 - 59s/epoch - 20ms/step
Epoch 129/300
2985/2985 - 59s - loss: 3.1885e-04 - val_loss: 2.1098e-04 - 59s/epoch - 20ms/step
Epoch 130/300
2985/2985 - 59s - loss: 3.0307e-04 - val_loss: 2.1483e-04 - 59s/epoch - 20ms/step
Epoch 131/300
2985/2985 - 59s - loss: 3.1224e-04 - val_loss: 2.1829e-04 - 59s/epoch - 20ms/step
Epoch 132/300
2985/2985 - 59s - loss: 2.9924e-04 - val_loss: 2.2331e-04 - 59s/epoch - 20ms/step
Epoch 133/300
2985/2985 - 58s - loss: 3.0291e-04 - val_loss: 3.0587e-04 - 58s/epoch - 20ms/step
Epoch 134/300
2985/2985 - 59s - loss: 3.0293e-04 - val_loss: 2.1573e-04 - 59s/epoch - 20ms/step
Epoch 135/300
2985/2985 - 59s - loss: 2.9550e-04 - val_loss: 2.2051e-04 - 59s/epoch - 20ms/step
Epoch 136/300
2985/2985 - 59s - loss: 3.3625e-04 - val_loss: 2.1465e-04 - 59s/epoch - 20ms/step
Epoch 137/300
2985/2985 - 59s - loss: 2.9778e-04 - val_loss: 3.0264e-04 - 59s/epoch - 20ms/step
Epoch 138/300
2985/2985 - 58s - loss: 3.1059e-04 - val_loss: 2.4206e-04 - 58s/epoch - 20ms/step
Epoch 139/300
2985/2985 - 59s - loss: 2.9988e-04 - val_loss: 4.0784e-04 - 59s/epoch - 20ms/step
Epoch 140/300
2985/2985 - 59s - loss: 3.3908e-04 - val_loss: 2.2503e-04 - 59s/epoch - 20ms/step
Epoch 141/300
2985/2985 - 59s - loss: 3.0002e-04 - val_loss: 2.1589e-04 - 59s/epoch - 20ms/step
Epoch 142/300
2985/2985 - 59s - loss: 2.9611e-04 - val_loss: 2.1919e-04 - 59s/epoch - 20ms/step
Epoch 143/300
2985/2985 - 58s - loss: 2.9732e-04 - val_loss: 2.1950e-04 - 58s/epoch - 20ms/step
Epoch 144/300
2985/2985 - 59s - loss: 2.9470e-04 - val_loss: 2.0622e-04 - 59s/epoch - 20ms/step
Epoch 145/300
2985/2985 - 59s - loss: 2.9364e-04 - val_loss: 2.1233e-04 - 59s/epoch - 20ms/step
Epoch 146/300
2985/2985 - 59s - loss: 2.8831e-04 - val_loss: 2.1825e-04 - 59s/epoch - 20ms/step
Epoch 147/300
2985/2985 - 59s - loss: 2.9132e-04 - val_loss: 2.2961e-04 - 59s/epoch - 20ms/step
Epoch 148/300
2985/2985 - 58s - loss: 2.8938e-04 - val_loss: 2.3591e-04 - 58s/epoch - 20ms/step
Epoch 149/300
2985/2985 - 59s - loss: 2.8973e-04 - val_loss: 2.0778e-04 - 59s/epoch - 20ms/step
Epoch 150/300
2985/2985 - 59s - loss: 2.9785e-04 - val_loss: 2.2776e-04 - 59s/epoch - 20ms/step
Epoch 151/300
2985/2985 - 59s - loss: 2.8940e-04 - val_loss: 2.0726e-04 - 59s/epoch - 20ms/step
Epoch 152/300
2985/2985 - 59s - loss: 2.9927e-04 - val_loss: 2.1734e-04 - 59s/epoch - 20ms/step
Epoch 153/300
2985/2985 - 59s - loss: 2.8717e-04 - val_loss: 2.2209e-04 - 59s/epoch - 20ms/step
Epoch 154/300
2985/2985 - 58s - loss: 2.8696e-04 - val_loss: 2.2523e-04 - 58s/epoch - 20ms/step
Epoch 155/300
2985/2985 - 59s - loss: 2.8933e-04 - val_loss: 2.1854e-04 - 59s/epoch - 20ms/step
Epoch 156/300
2985/2985 - 59s - loss: 2.9265e-04 - val_loss: 2.1735e-04 - 59s/epoch - 20ms/step
Epoch 157/300
2985/2985 - 59s - loss: 2.8273e-04 - val_loss: 2.3283e-04 - 59s/epoch - 20ms/step
Epoch 158/300
2985/2985 - 59s - loss: 2.9016e-04 - val_loss: 2.1037e-04 - 59s/epoch - 20ms/step
Epoch 159/300
2985/2985 - 59s - loss: 2.8692e-04 - val_loss: 1.9654e-04 - 59s/epoch - 20ms/step
Epoch 160/300
2985/2985 - 59s - loss: 2.9972e-04 - val_loss: 4.4965e-04 - 59s/epoch - 20ms/step
Epoch 161/300
2985/2985 - 59s - loss: 3.0174e-04 - val_loss: 2.1171e-04 - 59s/epoch - 20ms/step
Epoch 162/300
2985/2985 - 59s - loss: 2.8291e-04 - val_loss: 2.2301e-04 - 59s/epoch - 20ms/step
Epoch 163/300
2985/2985 - 59s - loss: 2.8227e-04 - val_loss: 2.3294e-04 - 59s/epoch - 20ms/step
Epoch 164/300
2985/2985 - 58s - loss: 3.0315e-04 - val_loss: 4.4380e-04 - 58s/epoch - 20ms/step
Epoch 165/300
2985/2985 - 59s - loss: 3.3195e-04 - val_loss: 2.2434e-04 - 59s/epoch - 20ms/step
Epoch 166/300
2985/2985 - 59s - loss: 2.8556e-04 - val_loss: 2.1289e-04 - 59s/epoch - 20ms/step
Epoch 167/300
2985/2985 - 58s - loss: 2.8871e-04 - val_loss: 2.1945e-04 - 58s/epoch - 20ms/step
Epoch 168/300
2985/2985 - 59s - loss: 2.8569e-04 - val_loss: 2.1179e-04 - 59s/epoch - 20ms/step
Epoch 169/300
2985/2985 - 58s - loss: 2.8383e-04 - val_loss: 2.2463e-04 - 58s/epoch - 20ms/step
Epoch 170/300
2985/2985 - 58s - loss: 2.8158e-04 - val_loss: 2.8178e-04 - 58s/epoch - 20ms/step
Epoch 171/300
2985/2985 - 59s - loss: 3.0172e-04 - val_loss: 2.0832e-04 - 59s/epoch - 20ms/step
Epoch 172/300
2985/2985 - 58s - loss: 2.8044e-04 - val_loss: 2.2175e-04 - 58s/epoch - 20ms/step
Epoch 173/300
2985/2985 - 59s - loss: 2.8413e-04 - val_loss: 2.2527e-04 - 59s/epoch - 20ms/step
Epoch 174/300
2985/2985 - 58s - loss: 2.8133e-04 - val_loss: 2.1694e-04 - 58s/epoch - 20ms/step
Epoch 175/300
2985/2985 - 58s - loss: 2.7933e-04 - val_loss: 2.0536e-04 - 58s/epoch - 20ms/step
Epoch 176/300
2985/2985 - 59s - loss: 2.8162e-04 - val_loss: 2.0407e-04 - 59s/epoch - 20ms/step
Epoch 177/300
2985/2985 - 58s - loss: 2.8302e-04 - val_loss: 1.9162e-04 - 58s/epoch - 20ms/step
Epoch 178/300
2985/2985 - 58s - loss: 2.8326e-04 - val_loss: 1.9672e-04 - 58s/epoch - 20ms/step
Epoch 179/300
2985/2985 - 58s - loss: 2.9811e-04 - val_loss: 1.9965e-04 - 58s/epoch - 20ms/step
Epoch 180/300
2985/2985 - 58s - loss: 2.8923e-04 - val_loss: 1.9784e-04 - 58s/epoch - 20ms/step
Epoch 181/300
2985/2985 - 59s - loss: 2.7953e-04 - val_loss: 2.0899e-04 - 59s/epoch - 20ms/step
Epoch 182/300
2985/2985 - 59s - loss: 2.7709e-04 - val_loss: 2.3341e-04 - 59s/epoch - 20ms/step
Epoch 183/300
2985/2985 - 59s - loss: 2.9090e-04 - val_loss: 2.1027e-04 - 59s/epoch - 20ms/step
Epoch 184/300
2985/2985 - 59s - loss: 2.7867e-04 - val_loss: 2.1106e-04 - 59s/epoch - 20ms/step
Epoch 185/300
2985/2985 - 59s - loss: 2.8437e-04 - val_loss: 2.2985e-04 - 59s/epoch - 20ms/step
Epoch 186/300
2985/2985 - 58s - loss: 2.7430e-04 - val_loss: 1.9136e-04 - 58s/epoch - 20ms/step
Epoch 187/300
2985/2985 - 59s - loss: 2.7630e-04 - val_loss: 2.0774e-04 - 59s/epoch - 20ms/step
Epoch 188/300
2985/2985 - 59s - loss: 2.7589e-04 - val_loss: 2.1281e-04 - 59s/epoch - 20ms/step
Epoch 189/300
2985/2985 - 59s - loss: 2.7785e-04 - val_loss: 1.9551e-04 - 59s/epoch - 20ms/step
Epoch 190/300
2985/2985 - 58s - loss: 2.7153e-04 - val_loss: 2.1085e-04 - 58s/epoch - 20ms/step
Epoch 191/300
2985/2985 - 58s - loss: 2.9377e-04 - val_loss: 3.5131e-04 - 58s/epoch - 20ms/step
Epoch 192/300
2985/2985 - 59s - loss: 2.9257e-04 - val_loss: 2.0410e-04 - 59s/epoch - 20ms/step
Epoch 193/300
2985/2985 - 58s - loss: 2.8398e-04 - val_loss: 2.0681e-04 - 58s/epoch - 20ms/step
Epoch 194/300
2985/2985 - 59s - loss: 2.7278e-04 - val_loss: 2.0688e-04 - 59s/epoch - 20ms/step
Epoch 195/300
2985/2985 - 58s - loss: 2.7187e-04 - val_loss: 1.9313e-04 - 58s/epoch - 20ms/step
Epoch 196/300
2985/2985 - 58s - loss: 2.7321e-04 - val_loss: 2.3798e-04 - 58s/epoch - 20ms/step
Epoch 197/300
2985/2985 - 59s - loss: 2.7229e-04 - val_loss: 2.1286e-04 - 59s/epoch - 20ms/step
Epoch 198/300
2985/2985 - 59s - loss: 2.7919e-04 - val_loss: 2.2172e-04 - 59s/epoch - 20ms/step
Epoch 199/300
2985/2985 - 59s - loss: 2.6971e-04 - val_loss: 2.1081e-04 - 59s/epoch - 20ms/step
Epoch 200/300
2985/2985 - 59s - loss: 2.7819e-04 - val_loss: 2.1211e-04 - 59s/epoch - 20ms/step
Epoch 201/300
2985/2985 - 58s - loss: 2.6926e-04 - val_loss: 2.0213e-04 - 58s/epoch - 20ms/step
Epoch 202/300
2985/2985 - 58s - loss: 2.7804e-04 - val_loss: 2.1467e-04 - 58s/epoch - 20ms/step
Epoch 203/300
2985/2985 - 59s - loss: 2.7101e-04 - val_loss: 3.5573e-04 - 59s/epoch - 20ms/step
Epoch 204/300
2985/2985 - 59s - loss: 2.8127e-04 - val_loss: 1.9918e-04 - 59s/epoch - 20ms/step
Epoch 205/300
2985/2985 - 59s - loss: 2.9678e-04 - val_loss: 2.1595e-04 - 59s/epoch - 20ms/step
Epoch 206/300
2985/2985 - 59s - loss: 2.7288e-04 - val_loss: 2.0027e-04 - 59s/epoch - 20ms/step
Epoch 207/300
2985/2985 - 58s - loss: 2.7546e-04 - val_loss: 4.8474e-04 - 58s/epoch - 20ms/step
Epoch 208/300
2985/2985 - 59s - loss: 3.0669e-04 - val_loss: 2.0387e-04 - 59s/epoch - 20ms/step
Epoch 209/300
2985/2985 - 58s - loss: 2.7200e-04 - val_loss: 1.9991e-04 - 58s/epoch - 20ms/step
Epoch 210/300
2985/2985 - 59s - loss: 2.7379e-04 - val_loss: 2.1167e-04 - 59s/epoch - 20ms/step
Epoch 211/300
2985/2985 - 59s - loss: 2.7152e-04 - val_loss: 2.0664e-04 - 59s/epoch - 20ms/step
Epoch 212/300
2985/2985 - 58s - loss: 2.7703e-04 - val_loss: 2.0127e-04 - 58s/epoch - 20ms/step
Epoch 213/300
2985/2985 - 59s - loss: 2.6971e-04 - val_loss: 2.0156e-04 - 59s/epoch - 20ms/step
Epoch 214/300
2985/2985 - 59s - loss: 2.8131e-04 - val_loss: 2.2566e-04 - 59s/epoch - 20ms/step
Epoch 215/300
2985/2985 - 59s - loss: 2.8589e-04 - val_loss: 2.3075e-04 - 59s/epoch - 20ms/step
Epoch 216/300
2985/2985 - 59s - loss: 2.7267e-04 - val_loss: 1.9340e-04 - 59s/epoch - 20ms/step
Epoch 217/300
2985/2985 - 59s - loss: 2.6775e-04 - val_loss: 2.1092e-04 - 59s/epoch - 20ms/step
Epoch 218/300
2985/2985 - 58s - loss: 2.8013e-04 - val_loss: 4.7265e-04 - 58s/epoch - 20ms/step
Epoch 219/300
2985/2985 - 59s - loss: 2.7642e-04 - val_loss: 2.1199e-04 - 59s/epoch - 20ms/step
Epoch 220/300
2985/2985 - 59s - loss: 2.6677e-04 - val_loss: 2.0038e-04 - 59s/epoch - 20ms/step
Epoch 221/300
2985/2985 - 58s - loss: 2.9780e-04 - val_loss: 2.4586e-04 - 58s/epoch - 20ms/step
Epoch 222/300
2985/2985 - 59s - loss: 2.7125e-04 - val_loss: 2.5426e-04 - 59s/epoch - 20ms/step
Epoch 223/300
2985/2985 - 58s - loss: 2.7361e-04 - val_loss: 2.7271e-04 - 58s/epoch - 20ms/step
Epoch 224/300
2985/2985 - 59s - loss: 3.0673e-04 - val_loss: 2.1047e-04 - 59s/epoch - 20ms/step
Epoch 225/300
2985/2985 - 59s - loss: 2.7017e-04 - val_loss: 3.1153e-04 - 59s/epoch - 20ms/step
Epoch 226/300
2985/2985 - 59s - loss: 2.8342e-04 - val_loss: 2.9724e-04 - 59s/epoch - 20ms/step
Epoch 227/300
2985/2985 - 59s - loss: 2.8794e-04 - val_loss: 2.0638e-04 - 59s/epoch - 20ms/step
Epoch 228/300
2985/2985 - 58s - loss: 2.6605e-04 - val_loss: 2.1739e-04 - 58s/epoch - 20ms/step
Epoch 229/300
2985/2985 - 59s - loss: 2.6835e-04 - val_loss: 2.0624e-04 - 59s/epoch - 20ms/step
Epoch 230/300
2985/2985 - 58s - loss: 2.7067e-04 - val_loss: 1.9552e-04 - 58s/epoch - 20ms/step
Epoch 231/300
2985/2985 - 58s - loss: 2.7079e-04 - val_loss: 2.1132e-04 - 58s/epoch - 20ms/step
Epoch 232/300
2985/2985 - 59s - loss: 2.6273e-04 - val_loss: 1.9798e-04 - 59s/epoch - 20ms/step
Epoch 233/300
2985/2985 - 59s - loss: 2.6156e-04 - val_loss: 2.2250e-04 - 59s/epoch - 20ms/step
Epoch 234/300
2985/2985 - 58s - loss: 2.7552e-04 - val_loss: 2.1164e-04 - 58s/epoch - 20ms/step
Epoch 235/300
2985/2985 - 58s - loss: 2.6615e-04 - val_loss: 1.9805e-04 - 58s/epoch - 20ms/step
Epoch 236/300
2985/2985 - 59s - loss: 2.6127e-04 - val_loss: 2.1554e-04 - 59s/epoch - 20ms/step
Epoch 237/300
2985/2985 - 59s - loss: 2.6364e-04 - val_loss: 2.0996e-04 - 59s/epoch - 20ms/step
Epoch 238/300
2985/2985 - 59s - loss: 2.6795e-04 - val_loss: 2.0833e-04 - 59s/epoch - 20ms/step
Epoch 239/300
2985/2985 - 58s - loss: 2.6312e-04 - val_loss: 2.3332e-04 - 58s/epoch - 20ms/step
Epoch 240/300
2985/2985 - 59s - loss: 2.6201e-04 - val_loss: 2.0644e-04 - 59s/epoch - 20ms/step
Epoch 241/300
2985/2985 - 58s - loss: 2.5925e-04 - val_loss: 2.0195e-04 - 58s/epoch - 20ms/step
Epoch 242/300
2985/2985 - 58s - loss: 2.8007e-04 - val_loss: 1.9454e-04 - 58s/epoch - 20ms/step
Epoch 243/300
2985/2985 - 59s - loss: 2.8424e-04 - val_loss: 2.0421e-04 - 59s/epoch - 20ms/step
Epoch 244/300
2985/2985 - 58s - loss: 2.6856e-04 - val_loss: 2.8050e-04 - 58s/epoch - 20ms/step
Epoch 245/300
2985/2985 - 59s - loss: 2.6704e-04 - val_loss: 1.9335e-04 - 59s/epoch - 20ms/step
Epoch 246/300
2985/2985 - 59s - loss: 2.9511e-04 - val_loss: 3.0368e-04 - 59s/epoch - 20ms/step
Epoch 247/300
2985/2985 - 59s - loss: 2.8615e-04 - val_loss: 2.6549e-04 - 59s/epoch - 20ms/step
Epoch 248/300
2985/2985 - 59s - loss: 2.7047e-04 - val_loss: 3.4645e-04 - 59s/epoch - 20ms/step
Epoch 249/300
2985/2985 - 59s - loss: 2.8366e-04 - val_loss: 2.0505e-04 - 59s/epoch - 20ms/step
Epoch 250/300
2985/2985 - 58s - loss: 2.6004e-04 - val_loss: 2.0225e-04 - 58s/epoch - 20ms/step
Epoch 251/300
2985/2985 - 58s - loss: 2.6412e-04 - val_loss: 2.0291e-04 - 58s/epoch - 20ms/step
Epoch 252/300
2985/2985 - 59s - loss: 2.6357e-04 - val_loss: 2.1521e-04 - 59s/epoch - 20ms/step
Epoch 253/300
2985/2985 - 58s - loss: 2.7228e-04 - val_loss: 1.8964e-04 - 58s/epoch - 20ms/step
Epoch 254/300
2985/2985 - 59s - loss: 2.6605e-04 - val_loss: 2.1516e-04 - 59s/epoch - 20ms/step
Epoch 255/300
2985/2985 - 58s - loss: 2.6724e-04 - val_loss: 2.0540e-04 - 58s/epoch - 20ms/step
Epoch 256/300
2985/2985 - 59s - loss: 2.6075e-04 - val_loss: 1.9878e-04 - 59s/epoch - 20ms/step
Epoch 257/300
2985/2985 - 59s - loss: 2.6251e-04 - val_loss: 1.9867e-04 - 59s/epoch - 20ms/step
Epoch 258/300
2985/2985 - 58s - loss: 2.5788e-04 - val_loss: 1.9691e-04 - 58s/epoch - 20ms/step
Epoch 259/300
2985/2985 - 59s - loss: 2.5969e-04 - val_loss: 2.1305e-04 - 59s/epoch - 20ms/step
Epoch 260/300
2985/2985 - 58s - loss: 2.5918e-04 - val_loss: 1.9028e-04 - 58s/epoch - 20ms/step
Epoch 261/300
2985/2985 - 59s - loss: 2.6180e-04 - val_loss: 3.9530e-04 - 59s/epoch - 20ms/step
Epoch 262/300
2985/2985 - 58s - loss: 2.8039e-04 - val_loss: 1.8638e-04 - 58s/epoch - 20ms/step
Epoch 263/300
2985/2985 - 59s - loss: 2.6010e-04 - val_loss: 2.0229e-04 - 59s/epoch - 20ms/step
Epoch 264/300
2985/2985 - 59s - loss: 2.7857e-04 - val_loss: 2.1005e-04 - 59s/epoch - 20ms/step
Epoch 265/300
2985/2985 - 59s - loss: 2.5939e-04 - val_loss: 2.1961e-04 - 59s/epoch - 20ms/step
Epoch 266/300
2985/2985 - 58s - loss: 2.5964e-04 - val_loss: 1.9976e-04 - 58s/epoch - 20ms/step
Epoch 267/300
2985/2985 - 58s - loss: 2.5636e-04 - val_loss: 1.8953e-04 - 58s/epoch - 20ms/step
Epoch 268/300
2985/2985 - 59s - loss: 2.5664e-04 - val_loss: 2.0593e-04 - 59s/epoch - 20ms/step
Epoch 269/300
2985/2985 - 59s - loss: 2.7072e-04 - val_loss: 2.3168e-04 - 59s/epoch - 20ms/step
Epoch 270/300
2985/2985 - 59s - loss: 2.7077e-04 - val_loss: 2.2252e-04 - 59s/epoch - 20ms/step
Epoch 271/300
2985/2985 - 58s - loss: 2.5830e-04 - val_loss: 2.3301e-04 - 58s/epoch - 20ms/step
Epoch 272/300
2985/2985 - 59s - loss: 2.6066e-04 - val_loss: 2.0857e-04 - 59s/epoch - 20ms/step
Epoch 273/300
2985/2985 - 58s - loss: 2.6099e-04 - val_loss: 2.3818e-04 - 58s/epoch - 20ms/step
Epoch 274/300
2985/2985 - 58s - loss: 2.6298e-04 - val_loss: 3.4476e-04 - 58s/epoch - 20ms/step
Epoch 275/300
2985/2985 - 58s - loss: 2.7321e-04 - val_loss: 2.1280e-04 - 58s/epoch - 20ms/step
Epoch 276/300
2985/2985 - 58s - loss: 2.5552e-04 - val_loss: 2.0173e-04 - 58s/epoch - 20ms/step
Epoch 277/300
2985/2985 - 59s - loss: 2.7201e-04 - val_loss: 1.9393e-04 - 59s/epoch - 20ms/step
Epoch 278/300
2985/2985 - 59s - loss: 2.6008e-04 - val_loss: 1.8586e-04 - 59s/epoch - 20ms/step
Epoch 279/300
2985/2985 - 58s - loss: 2.5873e-04 - val_loss: 1.8791e-04 - 58s/epoch - 20ms/step
Epoch 280/300
2985/2985 - 59s - loss: 2.5991e-04 - val_loss: 1.9615e-04 - 59s/epoch - 20ms/step
Epoch 281/300
2985/2985 - 58s - loss: 2.6155e-04 - val_loss: 2.1201e-04 - 58s/epoch - 20ms/step
Epoch 282/300
2985/2985 - 58s - loss: 2.5617e-04 - val_loss: 2.1369e-04 - 58s/epoch - 20ms/step
Epoch 283/300
2985/2985 - 59s - loss: 2.5688e-04 - val_loss: 2.2586e-04 - 59s/epoch - 20ms/step
Epoch 284/300
2985/2985 - 59s - loss: 2.5175e-04 - val_loss: 1.9239e-04 - 59s/epoch - 20ms/step
Epoch 285/300
2985/2985 - 59s - loss: 2.7142e-04 - val_loss: 1.9929e-04 - 59s/epoch - 20ms/step
Epoch 286/300
2985/2985 - 58s - loss: 2.5547e-04 - val_loss: 1.9538e-04 - 58s/epoch - 20ms/step
Epoch 287/300
2985/2985 - 58s - loss: 2.5219e-04 - val_loss: 2.0322e-04 - 58s/epoch - 20ms/step
Epoch 288/300
2985/2985 - 59s - loss: 2.5567e-04 - val_loss: 1.9981e-04 - 59s/epoch - 20ms/step
Epoch 289/300
2985/2985 - 59s - loss: 2.5646e-04 - val_loss: 2.7990e-04 - 59s/epoch - 20ms/step
Epoch 290/300
2985/2985 - 59s - loss: 2.8318e-04 - val_loss: 4.9860e-04 - 59s/epoch - 20ms/step
Epoch 291/300
2985/2985 - 59s - loss: 2.8440e-04 - val_loss: 2.0488e-04 - 59s/epoch - 20ms/step
Epoch 292/300
2985/2985 - 58s - loss: 2.5863e-04 - val_loss: 2.0476e-04 - 58s/epoch - 20ms/step
Epoch 293/300
2985/2985 - 59s - loss: 2.5770e-04 - val_loss: 2.0451e-04 - 59s/epoch - 20ms/step
Epoch 294/300
2985/2985 - 59s - loss: 2.6774e-04 - val_loss: 1.8893e-04 - 59s/epoch - 20ms/step
Epoch 295/300
2985/2985 - 59s - loss: 2.8159e-04 - val_loss: 1.8313e-04 - 59s/epoch - 20ms/step
Epoch 296/300
2985/2985 - 59s - loss: 2.5697e-04 - val_loss: 2.0034e-04 - 59s/epoch - 20ms/step
Epoch 297/300
2985/2985 - 58s - loss: 2.5217e-04 - val_loss: 1.9792e-04 - 58s/epoch - 20ms/step
Epoch 298/300
2985/2985 - 59s - loss: 2.5528e-04 - val_loss: 2.0314e-04 - 59s/epoch - 20ms/step
Epoch 299/300
2985/2985 - 58s - loss: 2.5771e-04 - val_loss: 2.1763e-04 - 58s/epoch - 20ms/step
Epoch 300/300
2985/2985 - 59s - loss: 2.5453e-04 - val_loss: 1.9627e-04 - 59s/epoch - 20ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00019626629364211112
  1/332 [..............................] - ETA: 26s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s111/332 [=========>....................] - ETA: 0s127/332 [==========>...................] - ETA: 0s143/332 [===========>..................] - ETA: 0s159/332 [=============>................] - ETA: 0s175/332 [==============>...............] - ETA: 0s191/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s223/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s255/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s287/332 [========================>.....] - ETA: 0s303/332 [==========================>...] - ETA: 0s319/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0022460961348597978
cosine 0.0017829628438712334
MAE: 0.008006743
RMSE: 0.014009502
r2: 0.98726802512953
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_6 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_7 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 632)               0         
                                                                 
 dense_7 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_8 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 1264)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_6 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 632)]             0         
                                                                 
 batch_normalization_7 (Batc  (None, 632)              2528      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 632)               0         
                                                                 
 dense_7 (Dense)             (None, 1264)              800112    
                                                                 
 batch_normalization_8 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 1264)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 32, 300, 0.002, 0.5, 632, 0.00025452865520492196, 0.00019626629364211112, 0.0022460961348597978, 0.0017829628438712334, 0.008006743155419827, 0.014009501785039902, 0.98726802512953, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_9 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_9 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_10 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 632)               0         
                                                                 
 dense_10 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_11 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 1264)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/100
1493/1493 - 39s - loss: 0.0093 - val_loss: 0.0045 - 39s/epoch - 26ms/step
Epoch 2/100
1493/1493 - 38s - loss: 0.0032 - val_loss: 0.0027 - 38s/epoch - 26ms/step
Epoch 3/100
1493/1493 - 38s - loss: 0.0021 - val_loss: 0.0018 - 38s/epoch - 25ms/step
Epoch 4/100
1493/1493 - 38s - loss: 0.0017 - val_loss: 0.0018 - 38s/epoch - 25ms/step
Epoch 5/100
1493/1493 - 38s - loss: 0.0015 - val_loss: 0.0012 - 38s/epoch - 26ms/step
Epoch 6/100
1493/1493 - 38s - loss: 0.0013 - val_loss: 0.0014 - 38s/epoch - 26ms/step
Epoch 7/100
1493/1493 - 38s - loss: 0.0012 - val_loss: 0.0010 - 38s/epoch - 26ms/step
Epoch 8/100
1493/1493 - 38s - loss: 0.0011 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 9/100
1493/1493 - 38s - loss: 0.0010 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 10/100
1493/1493 - 38s - loss: 9.5230e-04 - val_loss: 8.8899e-04 - 38s/epoch - 26ms/step
Epoch 11/100
1493/1493 - 38s - loss: 9.1670e-04 - val_loss: 9.4077e-04 - 38s/epoch - 26ms/step
Epoch 12/100
1493/1493 - 38s - loss: 8.1029e-04 - val_loss: 9.3506e-04 - 38s/epoch - 25ms/step
Epoch 13/100
1493/1493 - 38s - loss: 8.0020e-04 - val_loss: 0.0020 - 38s/epoch - 26ms/step
Epoch 14/100
1493/1493 - 38s - loss: 8.3794e-04 - val_loss: 7.3365e-04 - 38s/epoch - 26ms/step
Epoch 15/100
1493/1493 - 38s - loss: 7.4827e-04 - val_loss: 6.9733e-04 - 38s/epoch - 26ms/step
Epoch 16/100
1493/1493 - 38s - loss: 6.8862e-04 - val_loss: 8.0924e-04 - 38s/epoch - 26ms/step
Epoch 17/100
1493/1493 - 38s - loss: 6.6886e-04 - val_loss: 9.4007e-04 - 38s/epoch - 26ms/step
Epoch 18/100
1493/1493 - 38s - loss: 6.6019e-04 - val_loss: 0.0012 - 38s/epoch - 26ms/step
Epoch 19/100
1493/1493 - 38s - loss: 6.5236e-04 - val_loss: 7.2561e-04 - 38s/epoch - 26ms/step
Epoch 20/100
1493/1493 - 38s - loss: 6.2252e-04 - val_loss: 7.3490e-04 - 38s/epoch - 25ms/step
Epoch 21/100
1493/1493 - 38s - loss: 5.8570e-04 - val_loss: 8.3473e-04 - 38s/epoch - 26ms/step
Epoch 22/100
1493/1493 - 38s - loss: 5.7371e-04 - val_loss: 8.2510e-04 - 38s/epoch - 26ms/step
Epoch 23/100
1493/1493 - 38s - loss: 5.5565e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 24/100
1493/1493 - 38s - loss: 5.6164e-04 - val_loss: 5.5251e-04 - 38s/epoch - 26ms/step
Epoch 25/100
1493/1493 - 38s - loss: 5.4753e-04 - val_loss: 5.8050e-04 - 38s/epoch - 26ms/step
Epoch 26/100
1493/1493 - 38s - loss: 5.1941e-04 - val_loss: 6.2401e-04 - 38s/epoch - 26ms/step
Epoch 27/100
1493/1493 - 38s - loss: 4.9006e-04 - val_loss: 5.3902e-04 - 38s/epoch - 26ms/step
Epoch 28/100
1493/1493 - 38s - loss: 4.7693e-04 - val_loss: 8.2052e-04 - 38s/epoch - 25ms/step
Epoch 29/100
1493/1493 - 38s - loss: 4.7745e-04 - val_loss: 5.0458e-04 - 38s/epoch - 25ms/step
Epoch 30/100
1493/1493 - 38s - loss: 4.6627e-04 - val_loss: 6.7328e-04 - 38s/epoch - 26ms/step
Epoch 31/100
1493/1493 - 38s - loss: 4.5246e-04 - val_loss: 6.1564e-04 - 38s/epoch - 26ms/step
Epoch 32/100
1493/1493 - 38s - loss: 5.1114e-04 - val_loss: 5.0844e-04 - 38s/epoch - 26ms/step
Epoch 33/100
1493/1493 - 38s - loss: 4.4365e-04 - val_loss: 4.7366e-04 - 38s/epoch - 26ms/step
Epoch 34/100
1493/1493 - 38s - loss: 4.2939e-04 - val_loss: 4.2921e-04 - 38s/epoch - 26ms/step
Epoch 35/100
1493/1493 - 38s - loss: 4.1416e-04 - val_loss: 0.0015 - 38s/epoch - 26ms/step
Epoch 36/100
1493/1493 - 38s - loss: 4.3211e-04 - val_loss: 6.1513e-04 - 38s/epoch - 25ms/step
Epoch 37/100
1493/1493 - 38s - loss: 4.0598e-04 - val_loss: 0.0011 - 38s/epoch - 25ms/step
Epoch 38/100
1493/1493 - 38s - loss: 4.4460e-04 - val_loss: 4.5799e-04 - 38s/epoch - 26ms/step
Epoch 39/100
1493/1493 - 38s - loss: 3.9136e-04 - val_loss: 4.2342e-04 - 38s/epoch - 26ms/step
Epoch 40/100
1493/1493 - 38s - loss: 3.7769e-04 - val_loss: 7.6946e-04 - 38s/epoch - 26ms/step
Epoch 41/100
1493/1493 - 38s - loss: 3.8885e-04 - val_loss: 4.1541e-04 - 38s/epoch - 26ms/step
Epoch 42/100
1493/1493 - 38s - loss: 3.7210e-04 - val_loss: 3.9082e-04 - 38s/epoch - 26ms/step
Epoch 43/100
1493/1493 - 38s - loss: 3.6479e-04 - val_loss: 4.4595e-04 - 38s/epoch - 26ms/step
Epoch 44/100
1493/1493 - 38s - loss: 3.7091e-04 - val_loss: 7.4839e-04 - 38s/epoch - 25ms/step
Epoch 45/100
1493/1493 - 38s - loss: 3.7570e-04 - val_loss: 3.7505e-04 - 38s/epoch - 26ms/step
Epoch 46/100
1493/1493 - 38s - loss: 3.4927e-04 - val_loss: 3.6900e-04 - 38s/epoch - 25ms/step
Epoch 47/100
1493/1493 - 38s - loss: 3.4428e-04 - val_loss: 3.5129e-04 - 38s/epoch - 25ms/step
Epoch 48/100
1493/1493 - 38s - loss: 3.4434e-04 - val_loss: 4.4795e-04 - 38s/epoch - 25ms/step
Epoch 49/100
1493/1493 - 38s - loss: 3.3951e-04 - val_loss: 4.9419e-04 - 38s/epoch - 25ms/step
Epoch 50/100
1493/1493 - 38s - loss: 3.3368e-04 - val_loss: 8.4234e-04 - 38s/epoch - 25ms/step
Epoch 51/100
1493/1493 - 38s - loss: 3.4120e-04 - val_loss: 3.4706e-04 - 38s/epoch - 26ms/step
Epoch 52/100
1493/1493 - 38s - loss: 3.2356e-04 - val_loss: 3.4784e-04 - 38s/epoch - 25ms/step
Epoch 53/100
1493/1493 - 38s - loss: 3.2213e-04 - val_loss: 3.6331e-04 - 38s/epoch - 26ms/step
Epoch 54/100
1493/1493 - 38s - loss: 3.1371e-04 - val_loss: 3.8709e-04 - 38s/epoch - 26ms/step
Epoch 55/100
1493/1493 - 38s - loss: 3.0868e-04 - val_loss: 3.5273e-04 - 38s/epoch - 26ms/step
Epoch 56/100
1493/1493 - 38s - loss: 3.1156e-04 - val_loss: 4.0305e-04 - 38s/epoch - 26ms/step
Epoch 57/100
1493/1493 - 38s - loss: 3.0180e-04 - val_loss: 3.9413e-04 - 38s/epoch - 26ms/step
Epoch 58/100
1493/1493 - 38s - loss: 2.9980e-04 - val_loss: 2.9862e-04 - 38s/epoch - 26ms/step
Epoch 59/100
1493/1493 - 38s - loss: 3.0034e-04 - val_loss: 4.1475e-04 - 38s/epoch - 26ms/step
Epoch 60/100
1493/1493 - 38s - loss: 3.0501e-04 - val_loss: 7.0112e-04 - 38s/epoch - 25ms/step
Epoch 61/100
1493/1493 - 38s - loss: 3.1398e-04 - val_loss: 3.3366e-04 - 38s/epoch - 26ms/step
Epoch 62/100
1493/1493 - 38s - loss: 2.8809e-04 - val_loss: 3.3190e-04 - 38s/epoch - 26ms/step
Epoch 63/100
1493/1493 - 38s - loss: 2.8625e-04 - val_loss: 3.6583e-04 - 38s/epoch - 26ms/step
Epoch 64/100
1493/1493 - 38s - loss: 2.8794e-04 - val_loss: 0.0016 - 38s/epoch - 26ms/step
Epoch 65/100
1493/1493 - 38s - loss: 3.8311e-04 - val_loss: 3.8281e-04 - 38s/epoch - 26ms/step
Epoch 66/100
1493/1493 - 38s - loss: 3.0176e-04 - val_loss: 3.1129e-04 - 38s/epoch - 26ms/step
Epoch 67/100
1493/1493 - 38s - loss: 2.8187e-04 - val_loss: 2.8762e-04 - 38s/epoch - 26ms/step
Epoch 68/100
1493/1493 - 38s - loss: 2.7388e-04 - val_loss: 4.4612e-04 - 38s/epoch - 25ms/step
Epoch 69/100
1493/1493 - 38s - loss: 2.8658e-04 - val_loss: 3.1514e-04 - 38s/epoch - 26ms/step
Epoch 70/100
1493/1493 - 38s - loss: 2.7161e-04 - val_loss: 4.0472e-04 - 38s/epoch - 26ms/step
Epoch 71/100
1493/1493 - 38s - loss: 2.7922e-04 - val_loss: 3.3400e-04 - 38s/epoch - 26ms/step
Epoch 72/100
1493/1493 - 38s - loss: 2.6587e-04 - val_loss: 3.4640e-04 - 38s/epoch - 26ms/step
Epoch 73/100
1493/1493 - 38s - loss: 2.7029e-04 - val_loss: 3.3314e-04 - 38s/epoch - 26ms/step
Epoch 74/100
1493/1493 - 38s - loss: 2.6501e-04 - val_loss: 2.6946e-04 - 38s/epoch - 26ms/step
Epoch 75/100
1493/1493 - 38s - loss: 2.5486e-04 - val_loss: 3.0723e-04 - 38s/epoch - 25ms/step
Epoch 76/100
1493/1493 - 38s - loss: 2.5455e-04 - val_loss: 3.3946e-04 - 38s/epoch - 25ms/step
Epoch 77/100
1493/1493 - 38s - loss: 2.5838e-04 - val_loss: 5.8469e-04 - 38s/epoch - 26ms/step
Epoch 78/100
1493/1493 - 38s - loss: 2.6767e-04 - val_loss: 3.7693e-04 - 38s/epoch - 26ms/step
Epoch 79/100
1493/1493 - 38s - loss: 2.5756e-04 - val_loss: 2.9528e-04 - 38s/epoch - 26ms/step
Epoch 80/100
1493/1493 - 38s - loss: 2.4530e-04 - val_loss: 2.4774e-04 - 38s/epoch - 26ms/step
Epoch 81/100
1493/1493 - 38s - loss: 2.4086e-04 - val_loss: 6.8018e-04 - 38s/epoch - 26ms/step
Epoch 82/100
1493/1493 - 38s - loss: 2.4468e-04 - val_loss: 2.4626e-04 - 38s/epoch - 26ms/step
Epoch 83/100
1493/1493 - 38s - loss: 2.3685e-04 - val_loss: 2.8584e-04 - 38s/epoch - 26ms/step
Epoch 84/100
1493/1493 - 38s - loss: 2.4016e-04 - val_loss: 2.5520e-04 - 38s/epoch - 25ms/step
Epoch 85/100
1493/1493 - 38s - loss: 2.3962e-04 - val_loss: 3.5494e-04 - 38s/epoch - 26ms/step
Epoch 86/100
1493/1493 - 38s - loss: 2.3581e-04 - val_loss: 3.1579e-04 - 38s/epoch - 26ms/step
Epoch 87/100
1493/1493 - 38s - loss: 2.3160e-04 - val_loss: 2.6869e-04 - 38s/epoch - 26ms/step
Epoch 88/100
1493/1493 - 38s - loss: 2.3166e-04 - val_loss: 3.0107e-04 - 38s/epoch - 26ms/step
Epoch 89/100
1493/1493 - 38s - loss: 2.3902e-04 - val_loss: 2.6301e-04 - 38s/epoch - 26ms/step
Epoch 90/100
1493/1493 - 38s - loss: 2.3051e-04 - val_loss: 2.4845e-04 - 38s/epoch - 26ms/step
Epoch 91/100
1493/1493 - 38s - loss: 2.2589e-04 - val_loss: 3.2061e-04 - 38s/epoch - 26ms/step
Epoch 92/100
1493/1493 - 38s - loss: 2.2501e-04 - val_loss: 5.8207e-04 - 38s/epoch - 25ms/step
Epoch 93/100
1493/1493 - 38s - loss: 2.5522e-04 - val_loss: 3.1751e-04 - 38s/epoch - 26ms/step
Epoch 94/100
1493/1493 - 38s - loss: 2.2915e-04 - val_loss: 2.0968e-04 - 38s/epoch - 26ms/step
Epoch 95/100
1493/1493 - 38s - loss: 2.2296e-04 - val_loss: 4.2229e-04 - 38s/epoch - 25ms/step
Epoch 96/100
1493/1493 - 38s - loss: 2.3270e-04 - val_loss: 2.6081e-04 - 38s/epoch - 25ms/step
Epoch 97/100
1493/1493 - 38s - loss: 2.1969e-04 - val_loss: 2.3441e-04 - 38s/epoch - 25ms/step
Epoch 98/100
1493/1493 - 38s - loss: 2.1467e-04 - val_loss: 2.7839e-04 - 38s/epoch - 26ms/step
Epoch 99/100
1493/1493 - 38s - loss: 2.1690e-04 - val_loss: 2.6229e-04 - 38s/epoch - 26ms/step
Epoch 100/100
1493/1493 - 38s - loss: 2.1791e-04 - val_loss: 2.7597e-04 - 38s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.0002759714552666992
  1/332 [..............................] - ETA: 25s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s128/332 [==========>...................] - ETA: 0s144/332 [============>.................] - ETA: 0s160/332 [=============>................] - ETA: 0s176/332 [==============>...............] - ETA: 0s192/332 [================>.............] - ETA: 0s208/332 [=================>............] - ETA: 0s224/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s272/332 [=======================>......] - ETA: 0s288/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0030689160867857115
cosine 0.0024359715836388724
MAE: 0.00996063
RMSE: 0.016612383
r2: 0.98209724403068
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_9 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_10 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 632)               0         
                                                                 
 dense_10 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_11 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 1264)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 1264)              1598960   
                                                                 
 batch_normalization_9 (Batc  (None, 1264)             5056      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_10 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 632)               0         
                                                                 
 dense_10 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_11 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 1264)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 100, 0.0005, 0.5, 632, 0.0002179100993089378, 0.0002759714552666992, 0.0030689160867857115, 0.0024359715836388724, 0.009960629977285862, 0.016612382605671883, 0.98209724403068, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_12 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_12 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_13 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 632)               0         
                                                                 
 dense_13 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_14 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 1264)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/100
1493/1493 - 39s - loss: 0.0077 - val_loss: 0.0032 - 39s/epoch - 26ms/step
Epoch 2/100
1493/1493 - 39s - loss: 0.0024 - val_loss: 0.0021 - 39s/epoch - 26ms/step
Epoch 3/100
1493/1493 - 39s - loss: 0.0019 - val_loss: 0.0018 - 39s/epoch - 26ms/step
Epoch 4/100
1493/1493 - 39s - loss: 0.0016 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 5/100
1493/1493 - 39s - loss: 0.0014 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 6/100
1493/1493 - 39s - loss: 0.0013 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 7/100
1493/1493 - 39s - loss: 0.0012 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 8/100
1493/1493 - 38s - loss: 0.0010 - val_loss: 0.0010 - 38s/epoch - 26ms/step
Epoch 9/100
1493/1493 - 39s - loss: 8.9544e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 10/100
1493/1493 - 39s - loss: 8.2440e-04 - val_loss: 7.9746e-04 - 39s/epoch - 26ms/step
Epoch 11/100
1493/1493 - 39s - loss: 7.5684e-04 - val_loss: 9.0770e-04 - 39s/epoch - 26ms/step
Epoch 12/100
1493/1493 - 39s - loss: 6.7189e-04 - val_loss: 0.0017 - 39s/epoch - 26ms/step
Epoch 13/100
1493/1493 - 39s - loss: 7.2308e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 14/100
1493/1493 - 39s - loss: 6.1921e-04 - val_loss: 6.0527e-04 - 39s/epoch - 26ms/step
Epoch 15/100
1493/1493 - 39s - loss: 5.6717e-04 - val_loss: 6.0219e-04 - 39s/epoch - 26ms/step
Epoch 16/100
1493/1493 - 38s - loss: 5.3356e-04 - val_loss: 5.4491e-04 - 38s/epoch - 26ms/step
Epoch 17/100
1493/1493 - 39s - loss: 5.1265e-04 - val_loss: 6.1264e-04 - 39s/epoch - 26ms/step
Epoch 18/100
1493/1493 - 39s - loss: 4.9217e-04 - val_loss: 7.2771e-04 - 39s/epoch - 26ms/step
Epoch 19/100
1493/1493 - 39s - loss: 4.7505e-04 - val_loss: 4.9324e-04 - 39s/epoch - 26ms/step
Epoch 20/100
1493/1493 - 39s - loss: 4.3733e-04 - val_loss: 5.0818e-04 - 39s/epoch - 26ms/step
Epoch 21/100
1493/1493 - 39s - loss: 4.1461e-04 - val_loss: 8.5691e-04 - 39s/epoch - 26ms/step
Epoch 22/100
1493/1493 - 39s - loss: 4.2599e-04 - val_loss: 5.2992e-04 - 39s/epoch - 26ms/step
Epoch 23/100
1493/1493 - 39s - loss: 3.9349e-04 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 24/100
1493/1493 - 38s - loss: 4.9622e-04 - val_loss: 4.8123e-04 - 38s/epoch - 26ms/step
Epoch 25/100
1493/1493 - 39s - loss: 3.7760e-04 - val_loss: 4.0225e-04 - 39s/epoch - 26ms/step
Epoch 26/100
1493/1493 - 39s - loss: 3.5694e-04 - val_loss: 4.2866e-04 - 39s/epoch - 26ms/step
Epoch 27/100
1493/1493 - 39s - loss: 3.4511e-04 - val_loss: 3.4429e-04 - 39s/epoch - 26ms/step
Epoch 28/100
1493/1493 - 39s - loss: 3.3598e-04 - val_loss: 3.9298e-04 - 39s/epoch - 26ms/step
Epoch 29/100
1493/1493 - 39s - loss: 3.2866e-04 - val_loss: 3.3618e-04 - 39s/epoch - 26ms/step
Epoch 30/100
1493/1493 - 39s - loss: 3.1763e-04 - val_loss: 3.4231e-04 - 39s/epoch - 26ms/step
Epoch 31/100
1493/1493 - 39s - loss: 3.3557e-04 - val_loss: 8.4896e-04 - 39s/epoch - 26ms/step
Epoch 32/100
1493/1493 - 38s - loss: 3.5182e-04 - val_loss: 3.2834e-04 - 38s/epoch - 26ms/step
Epoch 33/100
1493/1493 - 39s - loss: 3.1572e-04 - val_loss: 2.9360e-04 - 39s/epoch - 26ms/step
Epoch 34/100
1493/1493 - 39s - loss: 2.9357e-04 - val_loss: 2.6788e-04 - 39s/epoch - 26ms/step
Epoch 35/100
1493/1493 - 39s - loss: 2.8663e-04 - val_loss: 3.9184e-04 - 39s/epoch - 26ms/step
Epoch 36/100
1493/1493 - 39s - loss: 3.0246e-04 - val_loss: 5.1305e-04 - 39s/epoch - 26ms/step
Epoch 37/100
1493/1493 - 39s - loss: 2.9408e-04 - val_loss: 4.5873e-04 - 39s/epoch - 26ms/step
Epoch 38/100
1493/1493 - 39s - loss: 3.1027e-04 - val_loss: 2.6486e-04 - 39s/epoch - 26ms/step
Epoch 39/100
1493/1493 - 39s - loss: 2.7092e-04 - val_loss: 2.6945e-04 - 39s/epoch - 26ms/step
Epoch 40/100
1493/1493 - 38s - loss: 2.6477e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 41/100
1493/1493 - 39s - loss: 3.5962e-04 - val_loss: 2.7105e-04 - 39s/epoch - 26ms/step
Epoch 42/100
1493/1493 - 39s - loss: 2.6823e-04 - val_loss: 2.7355e-04 - 39s/epoch - 26ms/step
Epoch 43/100
1493/1493 - 39s - loss: 2.5843e-04 - val_loss: 3.0746e-04 - 39s/epoch - 26ms/step
Epoch 44/100
1493/1493 - 39s - loss: 2.6590e-04 - val_loss: 7.0573e-04 - 39s/epoch - 26ms/step
Epoch 45/100
1493/1493 - 39s - loss: 3.2044e-04 - val_loss: 2.1277e-04 - 39s/epoch - 26ms/step
Epoch 46/100
1493/1493 - 39s - loss: 2.4949e-04 - val_loss: 2.3755e-04 - 39s/epoch - 26ms/step
Epoch 47/100
1493/1493 - 39s - loss: 2.4750e-04 - val_loss: 3.1256e-04 - 39s/epoch - 26ms/step
Epoch 48/100
1493/1493 - 38s - loss: 2.4331e-04 - val_loss: 2.4871e-04 - 38s/epoch - 26ms/step
Epoch 49/100
1493/1493 - 39s - loss: 2.4321e-04 - val_loss: 5.6893e-04 - 39s/epoch - 26ms/step
Epoch 50/100
1493/1493 - 39s - loss: 3.0130e-04 - val_loss: 5.9388e-04 - 39s/epoch - 26ms/step
Epoch 51/100
1493/1493 - 39s - loss: 2.8130e-04 - val_loss: 1.9770e-04 - 39s/epoch - 26ms/step
Epoch 52/100
1493/1493 - 39s - loss: 2.3664e-04 - val_loss: 2.4568e-04 - 39s/epoch - 26ms/step
Epoch 53/100
1493/1493 - 39s - loss: 2.3422e-04 - val_loss: 2.3449e-04 - 39s/epoch - 26ms/step
Epoch 54/100
1493/1493 - 39s - loss: 2.3050e-04 - val_loss: 3.1733e-04 - 39s/epoch - 26ms/step
Epoch 55/100
1493/1493 - 39s - loss: 2.3927e-04 - val_loss: 2.0943e-04 - 39s/epoch - 26ms/step
Epoch 56/100
1493/1493 - 38s - loss: 2.2511e-04 - val_loss: 2.4381e-04 - 38s/epoch - 26ms/step
Epoch 57/100
1493/1493 - 39s - loss: 2.2749e-04 - val_loss: 2.2587e-04 - 39s/epoch - 26ms/step
Epoch 58/100
1493/1493 - 39s - loss: 2.2021e-04 - val_loss: 2.0917e-04 - 39s/epoch - 26ms/step
Epoch 59/100
1493/1493 - 39s - loss: 2.1797e-04 - val_loss: 2.4390e-04 - 39s/epoch - 26ms/step
Epoch 60/100
1493/1493 - 39s - loss: 2.1468e-04 - val_loss: 3.1894e-04 - 39s/epoch - 26ms/step
Epoch 61/100
1493/1493 - 39s - loss: 2.2126e-04 - val_loss: 2.1934e-04 - 39s/epoch - 26ms/step
Epoch 62/100
1493/1493 - 39s - loss: 2.5039e-04 - val_loss: 2.2991e-04 - 39s/epoch - 26ms/step
Epoch 63/100
1493/1493 - 39s - loss: 2.2169e-04 - val_loss: 2.9187e-04 - 39s/epoch - 26ms/step
Epoch 64/100
1493/1493 - 38s - loss: 2.1850e-04 - val_loss: 2.1205e-04 - 38s/epoch - 26ms/step
Epoch 65/100
1493/1493 - 39s - loss: 2.0936e-04 - val_loss: 2.6326e-04 - 39s/epoch - 26ms/step
Epoch 66/100
1493/1493 - 39s - loss: 2.3036e-04 - val_loss: 2.1217e-04 - 39s/epoch - 26ms/step
Epoch 67/100
1493/1493 - 39s - loss: 2.0677e-04 - val_loss: 1.9020e-04 - 39s/epoch - 26ms/step
Epoch 68/100
1493/1493 - 39s - loss: 2.0655e-04 - val_loss: 5.0141e-04 - 39s/epoch - 26ms/step
Epoch 69/100
1493/1493 - 39s - loss: 2.5937e-04 - val_loss: 2.6868e-04 - 39s/epoch - 26ms/step
Epoch 70/100
1493/1493 - 39s - loss: 2.0924e-04 - val_loss: 3.3738e-04 - 39s/epoch - 26ms/step
Epoch 71/100
1493/1493 - 39s - loss: 2.1966e-04 - val_loss: 2.0422e-04 - 39s/epoch - 26ms/step
Epoch 72/100
1493/1493 - 38s - loss: 2.0421e-04 - val_loss: 2.4907e-04 - 38s/epoch - 26ms/step
Epoch 73/100
1493/1493 - 39s - loss: 2.1753e-04 - val_loss: 3.0498e-04 - 39s/epoch - 26ms/step
Epoch 74/100
1493/1493 - 39s - loss: 2.2025e-04 - val_loss: 2.1546e-04 - 39s/epoch - 26ms/step
Epoch 75/100
1493/1493 - 39s - loss: 1.9777e-04 - val_loss: 2.0467e-04 - 39s/epoch - 26ms/step
Epoch 76/100
1493/1493 - 39s - loss: 1.9835e-04 - val_loss: 2.2090e-04 - 39s/epoch - 26ms/step
Epoch 77/100
1493/1493 - 39s - loss: 2.0004e-04 - val_loss: 6.0213e-04 - 39s/epoch - 26ms/step
Epoch 78/100
1493/1493 - 39s - loss: 2.3642e-04 - val_loss: 1.8007e-04 - 39s/epoch - 26ms/step
Epoch 79/100
1493/1493 - 39s - loss: 1.9583e-04 - val_loss: 2.9629e-04 - 39s/epoch - 26ms/step
Epoch 80/100
1493/1493 - 38s - loss: 1.9969e-04 - val_loss: 2.3913e-04 - 38s/epoch - 26ms/step
Epoch 81/100
1493/1493 - 39s - loss: 1.9787e-04 - val_loss: 3.0754e-04 - 39s/epoch - 26ms/step
Epoch 82/100
1493/1493 - 39s - loss: 1.9285e-04 - val_loss: 1.8357e-04 - 39s/epoch - 26ms/step
Epoch 83/100
1493/1493 - 39s - loss: 1.9020e-04 - val_loss: 1.7899e-04 - 39s/epoch - 26ms/step
Epoch 84/100
1493/1493 - 39s - loss: 1.8788e-04 - val_loss: 3.7227e-04 - 39s/epoch - 26ms/step
Epoch 85/100
1493/1493 - 39s - loss: 2.1762e-04 - val_loss: 2.2032e-04 - 39s/epoch - 26ms/step
Epoch 86/100
1493/1493 - 39s - loss: 1.9183e-04 - val_loss: 2.0487e-04 - 39s/epoch - 26ms/step
Epoch 87/100
1493/1493 - 39s - loss: 1.8582e-04 - val_loss: 2.2063e-04 - 39s/epoch - 26ms/step
Epoch 88/100
1493/1493 - 39s - loss: 1.8649e-04 - val_loss: 5.9516e-04 - 39s/epoch - 26ms/step
Epoch 89/100
1493/1493 - 39s - loss: 2.1946e-04 - val_loss: 1.9287e-04 - 39s/epoch - 26ms/step
Epoch 90/100
1493/1493 - 39s - loss: 1.9535e-04 - val_loss: 1.9928e-04 - 39s/epoch - 26ms/step
Epoch 91/100
1493/1493 - 39s - loss: 1.8377e-04 - val_loss: 2.2107e-04 - 39s/epoch - 26ms/step
Epoch 92/100
1493/1493 - 39s - loss: 1.8258e-04 - val_loss: 3.1368e-04 - 39s/epoch - 26ms/step
Epoch 93/100
1493/1493 - 39s - loss: 1.9852e-04 - val_loss: 1.8774e-04 - 39s/epoch - 26ms/step
Epoch 94/100
1493/1493 - 39s - loss: 1.8543e-04 - val_loss: 1.8769e-04 - 39s/epoch - 26ms/step
Epoch 95/100
1493/1493 - 39s - loss: 1.8030e-04 - val_loss: 2.7228e-04 - 39s/epoch - 26ms/step
Epoch 96/100
1493/1493 - 38s - loss: 1.8350e-04 - val_loss: 2.4151e-04 - 38s/epoch - 26ms/step
Epoch 97/100
1493/1493 - 39s - loss: 1.7855e-04 - val_loss: 1.9831e-04 - 39s/epoch - 26ms/step
Epoch 98/100
1493/1493 - 39s - loss: 1.7915e-04 - val_loss: 4.9307e-04 - 39s/epoch - 26ms/step
Epoch 99/100
1493/1493 - 39s - loss: 2.3165e-04 - val_loss: 1.8199e-04 - 39s/epoch - 26ms/step
Epoch 100/100
1493/1493 - 39s - loss: 1.8340e-04 - val_loss: 1.7464e-04 - 39s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00017464077973272651
  1/332 [..............................] - ETA: 27s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s128/332 [==========>...................] - ETA: 0s144/332 [============>.................] - ETA: 0s160/332 [=============>................] - ETA: 0s176/332 [==============>...............] - ETA: 0s192/332 [================>.............] - ETA: 0s208/332 [=================>............] - ETA: 0s224/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s272/332 [=======================>......] - ETA: 0s288/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0019761443115655676
cosine 0.0015643008904236018
MAE: 0.007554101
RMSE: 0.013215167
r2: 0.9886708228720876
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_12 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_13 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 632)               0         
                                                                 
 dense_13 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_14 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 1264)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_14 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_12 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_15 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_13 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 632)               0         
                                                                 
 dense_13 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_14 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 1264)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 100, 0.001, 0.5, 632, 0.00018339604139328003, 0.00017464077973272651, 0.0019761443115655676, 0.0015643008904236018, 0.007554100826382637, 0.013215167447924614, 0.9886708228720876, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_15 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_15 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_16 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 632)               0         
                                                                 
 dense_16 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_17 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 1264)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/100
1493/1493 - 39s - loss: 0.0075 - val_loss: 0.0029 - 39s/epoch - 26ms/step
Epoch 2/100
1493/1493 - 38s - loss: 0.0025 - val_loss: 0.0027 - 38s/epoch - 26ms/step
Epoch 3/100
1493/1493 - 38s - loss: 0.0020 - val_loss: 0.0027 - 38s/epoch - 26ms/step
Epoch 4/100
1493/1493 - 38s - loss: 0.0017 - val_loss: 0.0014 - 38s/epoch - 26ms/step
Epoch 5/100
1493/1493 - 38s - loss: 0.0013 - val_loss: 0.0012 - 38s/epoch - 26ms/step
Epoch 6/100
1493/1493 - 38s - loss: 0.0011 - val_loss: 0.0012 - 38s/epoch - 26ms/step
Epoch 7/100
1493/1493 - 38s - loss: 9.4517e-04 - val_loss: 7.4904e-04 - 38s/epoch - 26ms/step
Epoch 8/100
1493/1493 - 38s - loss: 7.9310e-04 - val_loss: 8.1427e-04 - 38s/epoch - 26ms/step
Epoch 9/100
1493/1493 - 38s - loss: 7.0035e-04 - val_loss: 7.2254e-04 - 38s/epoch - 26ms/step
Epoch 10/100
1493/1493 - 38s - loss: 6.3999e-04 - val_loss: 5.9417e-04 - 38s/epoch - 26ms/step
Epoch 11/100
1493/1493 - 38s - loss: 5.8724e-04 - val_loss: 5.6894e-04 - 38s/epoch - 26ms/step
Epoch 12/100
1493/1493 - 38s - loss: 5.3925e-04 - val_loss: 7.4970e-04 - 38s/epoch - 25ms/step
Epoch 13/100
1493/1493 - 38s - loss: 5.4303e-04 - val_loss: 0.0021 - 38s/epoch - 26ms/step
Epoch 14/100
1493/1493 - 38s - loss: 6.9896e-04 - val_loss: 5.8564e-04 - 38s/epoch - 26ms/step
Epoch 15/100
1493/1493 - 38s - loss: 5.2083e-04 - val_loss: 4.3910e-04 - 38s/epoch - 26ms/step
Epoch 16/100
1493/1493 - 38s - loss: 4.5866e-04 - val_loss: 4.3974e-04 - 38s/epoch - 26ms/step
Epoch 17/100
1493/1493 - 38s - loss: 4.4019e-04 - val_loss: 5.4863e-04 - 38s/epoch - 26ms/step
Epoch 18/100
1493/1493 - 38s - loss: 4.5073e-04 - val_loss: 5.6014e-04 - 38s/epoch - 26ms/step
Epoch 19/100
1493/1493 - 38s - loss: 4.5177e-04 - val_loss: 4.4521e-04 - 38s/epoch - 26ms/step
Epoch 20/100
1493/1493 - 38s - loss: 4.1175e-04 - val_loss: 4.4523e-04 - 38s/epoch - 25ms/step
Epoch 21/100
1493/1493 - 38s - loss: 4.0083e-04 - val_loss: 7.2817e-04 - 38s/epoch - 26ms/step
Epoch 22/100
1493/1493 - 38s - loss: 4.7244e-04 - val_loss: 4.8144e-04 - 38s/epoch - 26ms/step
Epoch 23/100
1493/1493 - 38s - loss: 4.0856e-04 - val_loss: 3.7271e-04 - 38s/epoch - 26ms/step
Epoch 24/100
1493/1493 - 38s - loss: 3.7819e-04 - val_loss: 5.6012e-04 - 38s/epoch - 26ms/step
Epoch 25/100
1493/1493 - 38s - loss: 4.2101e-04 - val_loss: 3.3526e-04 - 38s/epoch - 26ms/step
Epoch 26/100
1493/1493 - 38s - loss: 3.5960e-04 - val_loss: 3.3020e-04 - 38s/epoch - 26ms/step
Epoch 27/100
1493/1493 - 38s - loss: 3.4944e-04 - val_loss: 3.5086e-04 - 38s/epoch - 26ms/step
Epoch 28/100
1493/1493 - 38s - loss: 3.5203e-04 - val_loss: 3.5568e-04 - 38s/epoch - 25ms/step
Epoch 29/100
1493/1493 - 38s - loss: 3.4094e-04 - val_loss: 7.3998e-04 - 38s/epoch - 26ms/step
Epoch 30/100
1493/1493 - 38s - loss: 4.2002e-04 - val_loss: 3.1660e-04 - 38s/epoch - 26ms/step
Epoch 31/100
1493/1493 - 38s - loss: 3.3878e-04 - val_loss: 3.2800e-04 - 38s/epoch - 26ms/step
Epoch 32/100
1493/1493 - 38s - loss: 3.2798e-04 - val_loss: 2.8978e-04 - 38s/epoch - 26ms/step
Epoch 33/100
1493/1493 - 38s - loss: 3.2227e-04 - val_loss: 2.9803e-04 - 38s/epoch - 26ms/step
Epoch 34/100
1493/1493 - 38s - loss: 3.3684e-04 - val_loss: 2.7829e-04 - 38s/epoch - 26ms/step
Epoch 35/100
1493/1493 - 38s - loss: 3.2501e-04 - val_loss: 3.3898e-04 - 38s/epoch - 26ms/step
Epoch 36/100
1493/1493 - 38s - loss: 3.1551e-04 - val_loss: 2.8517e-04 - 38s/epoch - 25ms/step
Epoch 37/100
1493/1493 - 38s - loss: 3.0751e-04 - val_loss: 2.9586e-04 - 38s/epoch - 26ms/step
Epoch 38/100
1493/1493 - 38s - loss: 3.1026e-04 - val_loss: 5.4880e-04 - 38s/epoch - 26ms/step
Epoch 39/100
1493/1493 - 38s - loss: 3.7985e-04 - val_loss: 2.7551e-04 - 38s/epoch - 26ms/step
Epoch 40/100
1493/1493 - 38s - loss: 3.0748e-04 - val_loss: 4.0794e-04 - 38s/epoch - 26ms/step
Epoch 41/100
1493/1493 - 38s - loss: 3.1218e-04 - val_loss: 2.5837e-04 - 38s/epoch - 26ms/step
Epoch 42/100
1493/1493 - 38s - loss: 2.9311e-04 - val_loss: 2.8567e-04 - 38s/epoch - 26ms/step
Epoch 43/100
1493/1493 - 38s - loss: 2.9156e-04 - val_loss: 5.2631e-04 - 38s/epoch - 26ms/step
Epoch 44/100
1493/1493 - 37s - loss: 3.6631e-04 - val_loss: 3.9876e-04 - 37s/epoch - 25ms/step
Epoch 45/100
1493/1493 - 38s - loss: 3.2024e-04 - val_loss: 2.3815e-04 - 38s/epoch - 26ms/step
Epoch 46/100
1493/1493 - 38s - loss: 2.8947e-04 - val_loss: 2.5355e-04 - 38s/epoch - 26ms/step
Epoch 47/100
1493/1493 - 38s - loss: 2.8639e-04 - val_loss: 2.6996e-04 - 38s/epoch - 26ms/step
Epoch 48/100
1493/1493 - 38s - loss: 2.7996e-04 - val_loss: 3.7425e-04 - 38s/epoch - 26ms/step
Epoch 49/100
1493/1493 - 38s - loss: 3.0206e-04 - val_loss: 7.4826e-04 - 38s/epoch - 26ms/step
Epoch 50/100
1493/1493 - 38s - loss: 3.7742e-04 - val_loss: 7.5489e-04 - 38s/epoch - 26ms/step
Epoch 51/100
1493/1493 - 38s - loss: 3.4495e-04 - val_loss: 2.4633e-04 - 38s/epoch - 26ms/step
Epoch 52/100
1493/1493 - 38s - loss: 2.8547e-04 - val_loss: 2.4443e-04 - 38s/epoch - 25ms/step
Epoch 53/100
1493/1493 - 38s - loss: 2.7814e-04 - val_loss: 2.5244e-04 - 38s/epoch - 26ms/step
Epoch 54/100
1493/1493 - 38s - loss: 2.8467e-04 - val_loss: 3.0520e-04 - 38s/epoch - 26ms/step
Epoch 55/100
1493/1493 - 38s - loss: 2.7402e-04 - val_loss: 2.3535e-04 - 38s/epoch - 26ms/step
Epoch 56/100
1493/1493 - 38s - loss: 2.6665e-04 - val_loss: 2.7709e-04 - 38s/epoch - 26ms/step
Epoch 57/100
1493/1493 - 38s - loss: 2.7997e-04 - val_loss: 2.5083e-04 - 38s/epoch - 26ms/step
Epoch 58/100
1493/1493 - 38s - loss: 2.6440e-04 - val_loss: 2.3152e-04 - 38s/epoch - 26ms/step
Epoch 59/100
1493/1493 - 38s - loss: 2.9737e-04 - val_loss: 4.2605e-04 - 38s/epoch - 26ms/step
Epoch 60/100
1493/1493 - 38s - loss: 2.8018e-04 - val_loss: 2.7376e-04 - 38s/epoch - 26ms/step
Epoch 61/100
1493/1493 - 38s - loss: 2.6360e-04 - val_loss: 2.2839e-04 - 38s/epoch - 26ms/step
Epoch 62/100
1493/1493 - 38s - loss: 2.6290e-04 - val_loss: 3.1302e-04 - 38s/epoch - 26ms/step
Epoch 63/100
1493/1493 - 38s - loss: 2.5725e-04 - val_loss: 4.1245e-04 - 38s/epoch - 26ms/step
Epoch 64/100
1493/1493 - 38s - loss: 2.7487e-04 - val_loss: 2.9155e-04 - 38s/epoch - 26ms/step
Epoch 65/100
1493/1493 - 38s - loss: 2.5926e-04 - val_loss: 4.4992e-04 - 38s/epoch - 26ms/step
Epoch 66/100
1493/1493 - 38s - loss: 2.8601e-04 - val_loss: 2.6938e-04 - 38s/epoch - 26ms/step
Epoch 67/100
1493/1493 - 38s - loss: 2.5651e-04 - val_loss: 2.1681e-04 - 38s/epoch - 26ms/step
Epoch 68/100
1493/1493 - 38s - loss: 2.4926e-04 - val_loss: 2.6678e-04 - 38s/epoch - 26ms/step
Epoch 69/100
1493/1493 - 38s - loss: 2.6258e-04 - val_loss: 2.2141e-04 - 38s/epoch - 26ms/step
Epoch 70/100
1493/1493 - 38s - loss: 2.5065e-04 - val_loss: 5.6957e-04 - 38s/epoch - 26ms/step
Epoch 71/100
1493/1493 - 38s - loss: 3.0247e-04 - val_loss: 2.1269e-04 - 38s/epoch - 26ms/step
Epoch 72/100
1493/1493 - 38s - loss: 2.5185e-04 - val_loss: 3.1202e-04 - 38s/epoch - 26ms/step
Epoch 73/100
1493/1493 - 38s - loss: 2.8594e-04 - val_loss: 2.7264e-04 - 38s/epoch - 26ms/step
Epoch 74/100
1493/1493 - 38s - loss: 2.6923e-04 - val_loss: 2.5340e-04 - 38s/epoch - 26ms/step
Epoch 75/100
1493/1493 - 38s - loss: 2.5047e-04 - val_loss: 2.2119e-04 - 38s/epoch - 26ms/step
Epoch 76/100
1493/1493 - 38s - loss: 2.4547e-04 - val_loss: 2.4002e-04 - 38s/epoch - 26ms/step
Epoch 77/100
1493/1493 - 38s - loss: 2.4326e-04 - val_loss: 5.4689e-04 - 38s/epoch - 25ms/step
Epoch 78/100
1493/1493 - 38s - loss: 3.0598e-04 - val_loss: 2.3750e-04 - 38s/epoch - 26ms/step
Epoch 79/100
1493/1493 - 38s - loss: 2.5262e-04 - val_loss: 4.9737e-04 - 38s/epoch - 26ms/step
Epoch 80/100
1493/1493 - 38s - loss: 2.9442e-04 - val_loss: 2.1729e-04 - 38s/epoch - 26ms/step
Epoch 81/100
1493/1493 - 38s - loss: 2.4337e-04 - val_loss: 3.7214e-04 - 38s/epoch - 26ms/step
Epoch 82/100
1493/1493 - 38s - loss: 2.5403e-04 - val_loss: 2.1351e-04 - 38s/epoch - 26ms/step
Epoch 83/100
1493/1493 - 38s - loss: 2.4496e-04 - val_loss: 2.1153e-04 - 38s/epoch - 26ms/step
Epoch 84/100
1493/1493 - 38s - loss: 2.3737e-04 - val_loss: 3.0053e-04 - 38s/epoch - 26ms/step
Epoch 85/100
1493/1493 - 38s - loss: 2.4562e-04 - val_loss: 3.4685e-04 - 38s/epoch - 25ms/step
Epoch 86/100
1493/1493 - 38s - loss: 2.5480e-04 - val_loss: 2.0699e-04 - 38s/epoch - 26ms/step
Epoch 87/100
1493/1493 - 38s - loss: 2.3395e-04 - val_loss: 2.5652e-04 - 38s/epoch - 26ms/step
Epoch 88/100
1493/1493 - 38s - loss: 2.3519e-04 - val_loss: 5.0316e-04 - 38s/epoch - 26ms/step
Epoch 89/100
1493/1493 - 38s - loss: 2.9056e-04 - val_loss: 2.1817e-04 - 38s/epoch - 26ms/step
Epoch 90/100
1493/1493 - 38s - loss: 2.3814e-04 - val_loss: 2.1334e-04 - 38s/epoch - 26ms/step
Epoch 91/100
1493/1493 - 38s - loss: 2.3212e-04 - val_loss: 2.2280e-04 - 38s/epoch - 26ms/step
Epoch 92/100
1493/1493 - 38s - loss: 2.3479e-04 - val_loss: 2.7591e-04 - 38s/epoch - 26ms/step
Epoch 93/100
1493/1493 - 38s - loss: 2.4731e-04 - val_loss: 2.4347e-04 - 38s/epoch - 25ms/step
Epoch 94/100
1493/1493 - 38s - loss: 2.3102e-04 - val_loss: 2.0787e-04 - 38s/epoch - 26ms/step
Epoch 95/100
1493/1493 - 38s - loss: 2.2871e-04 - val_loss: 2.6245e-04 - 38s/epoch - 26ms/step
Epoch 96/100
1493/1493 - 38s - loss: 2.3298e-04 - val_loss: 2.5816e-04 - 38s/epoch - 26ms/step
Epoch 97/100
1493/1493 - 38s - loss: 2.2639e-04 - val_loss: 2.2136e-04 - 38s/epoch - 26ms/step
Epoch 98/100
1493/1493 - 38s - loss: 2.2651e-04 - val_loss: 4.0684e-04 - 38s/epoch - 26ms/step
Epoch 99/100
1493/1493 - 38s - loss: 2.6583e-04 - val_loss: 2.2406e-04 - 38s/epoch - 26ms/step
Epoch 100/100
1493/1493 - 38s - loss: 2.2930e-04 - val_loss: 2.0427e-04 - 38s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00020427304843906313
  1/332 [..............................] - ETA: 27s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s128/332 [==========>...................] - ETA: 0s144/332 [============>.................] - ETA: 0s160/332 [=============>................] - ETA: 0s176/332 [==============>...............] - ETA: 0s192/332 [================>.............] - ETA: 0s208/332 [=================>............] - ETA: 0s224/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s272/332 [=======================>......] - ETA: 0s288/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0023459401606524886
cosine 0.0018535031997793537
MAE: 0.008002099
RMSE: 0.014292409
r2: 0.9867489455550509
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_15 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_16 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 632)               0         
                                                                 
 dense_16 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_17 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 1264)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_17 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_15 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_18 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_16 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 632)               0         
                                                                 
 dense_16 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_17 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 1264)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 100, 0.002, 0.5, 632, 0.0002292989956913516, 0.00020427304843906313, 0.0023459401606524886, 0.0018535031997793537, 0.008002098649740219, 0.014292408712208271, 0.9867489455550509, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_18 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_18 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_19 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 632)               0         
                                                                 
 dense_19 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_20 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 1264)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/200
1493/1493 - 39s - loss: 0.0093 - val_loss: 0.0044 - 39s/epoch - 26ms/step
Epoch 2/200
1493/1493 - 38s - loss: 0.0032 - val_loss: 0.0026 - 38s/epoch - 26ms/step
Epoch 3/200
1493/1493 - 39s - loss: 0.0021 - val_loss: 0.0018 - 39s/epoch - 26ms/step
Epoch 4/200
1493/1493 - 39s - loss: 0.0017 - val_loss: 0.0019 - 39s/epoch - 26ms/step
Epoch 5/200
1493/1493 - 39s - loss: 0.0015 - val_loss: 0.0012 - 39s/epoch - 26ms/step
Epoch 6/200
1493/1493 - 39s - loss: 0.0013 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 7/200
1493/1493 - 39s - loss: 0.0012 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 8/200
1493/1493 - 39s - loss: 0.0011 - val_loss: 0.0012 - 39s/epoch - 26ms/step
Epoch 9/200
1493/1493 - 39s - loss: 0.0010 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 10/200
1493/1493 - 39s - loss: 9.4552e-04 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 11/200
1493/1493 - 39s - loss: 9.0609e-04 - val_loss: 8.8838e-04 - 39s/epoch - 26ms/step
Epoch 12/200
1493/1493 - 39s - loss: 8.1729e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 13/200
1493/1493 - 39s - loss: 7.9885e-04 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 14/200
1493/1493 - 39s - loss: 7.9229e-04 - val_loss: 7.5055e-04 - 39s/epoch - 26ms/step
Epoch 15/200
1493/1493 - 39s - loss: 7.4201e-04 - val_loss: 8.3055e-04 - 39s/epoch - 26ms/step
Epoch 16/200
1493/1493 - 39s - loss: 6.9406e-04 - val_loss: 8.1344e-04 - 39s/epoch - 26ms/step
Epoch 17/200
1493/1493 - 39s - loss: 6.6107e-04 - val_loss: 9.2451e-04 - 39s/epoch - 26ms/step
Epoch 18/200
1493/1493 - 39s - loss: 6.5169e-04 - val_loss: 9.8442e-04 - 39s/epoch - 26ms/step
Epoch 19/200
1493/1493 - 39s - loss: 6.3034e-04 - val_loss: 7.8106e-04 - 39s/epoch - 26ms/step
Epoch 20/200
1493/1493 - 39s - loss: 6.2008e-04 - val_loss: 6.5786e-04 - 39s/epoch - 26ms/step
Epoch 21/200
1493/1493 - 39s - loss: 5.8551e-04 - val_loss: 8.6341e-04 - 39s/epoch - 26ms/step
Epoch 22/200
1493/1493 - 39s - loss: 5.6505e-04 - val_loss: 7.1141e-04 - 39s/epoch - 26ms/step
Epoch 23/200
1493/1493 - 39s - loss: 5.5098e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 24/200
1493/1493 - 39s - loss: 5.5791e-04 - val_loss: 6.0727e-04 - 39s/epoch - 26ms/step
Epoch 25/200
1493/1493 - 39s - loss: 5.3818e-04 - val_loss: 5.8429e-04 - 39s/epoch - 26ms/step
Epoch 26/200
1493/1493 - 39s - loss: 5.1234e-04 - val_loss: 7.0000e-04 - 39s/epoch - 26ms/step
Epoch 27/200
1493/1493 - 39s - loss: 4.9030e-04 - val_loss: 5.1528e-04 - 39s/epoch - 26ms/step
Epoch 28/200
1493/1493 - 39s - loss: 4.7265e-04 - val_loss: 8.3833e-04 - 39s/epoch - 26ms/step
Epoch 29/200
1493/1493 - 39s - loss: 4.7062e-04 - val_loss: 5.6321e-04 - 39s/epoch - 26ms/step
Epoch 30/200
1493/1493 - 39s - loss: 4.6724e-04 - val_loss: 6.6992e-04 - 39s/epoch - 26ms/step
Epoch 31/200
1493/1493 - 39s - loss: 4.5077e-04 - val_loss: 5.5931e-04 - 39s/epoch - 26ms/step
Epoch 32/200
1493/1493 - 39s - loss: 5.0785e-04 - val_loss: 4.3633e-04 - 39s/epoch - 26ms/step
Epoch 33/200
1493/1493 - 39s - loss: 4.4144e-04 - val_loss: 4.4354e-04 - 39s/epoch - 26ms/step
Epoch 34/200
1493/1493 - 39s - loss: 4.2752e-04 - val_loss: 4.5118e-04 - 39s/epoch - 26ms/step
Epoch 35/200
1493/1493 - 39s - loss: 4.1395e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 36/200
1493/1493 - 39s - loss: 4.3590e-04 - val_loss: 4.8189e-04 - 39s/epoch - 26ms/step
Epoch 37/200
1493/1493 - 39s - loss: 4.0712e-04 - val_loss: 8.8080e-04 - 39s/epoch - 26ms/step
Epoch 38/200
1493/1493 - 39s - loss: 4.4110e-04 - val_loss: 4.1216e-04 - 39s/epoch - 26ms/step
Epoch 39/200
1493/1493 - 39s - loss: 3.9115e-04 - val_loss: 3.9249e-04 - 39s/epoch - 26ms/step
Epoch 40/200
1493/1493 - 39s - loss: 3.7940e-04 - val_loss: 9.1011e-04 - 39s/epoch - 26ms/step
Epoch 41/200
1493/1493 - 39s - loss: 3.9521e-04 - val_loss: 3.9457e-04 - 39s/epoch - 26ms/step
Epoch 42/200
1493/1493 - 39s - loss: 3.7020e-04 - val_loss: 3.6815e-04 - 39s/epoch - 26ms/step
Epoch 43/200
1493/1493 - 39s - loss: 3.6972e-04 - val_loss: 4.3810e-04 - 39s/epoch - 26ms/step
Epoch 44/200
1493/1493 - 39s - loss: 3.7110e-04 - val_loss: 6.4420e-04 - 39s/epoch - 26ms/step
Epoch 45/200
1493/1493 - 39s - loss: 3.6758e-04 - val_loss: 3.7241e-04 - 39s/epoch - 26ms/step
Epoch 46/200
1493/1493 - 39s - loss: 3.4905e-04 - val_loss: 8.4294e-04 - 39s/epoch - 26ms/step
Epoch 47/200
1493/1493 - 39s - loss: 3.4278e-04 - val_loss: 3.7283e-04 - 39s/epoch - 26ms/step
Epoch 48/200
1493/1493 - 39s - loss: 3.4508e-04 - val_loss: 4.3904e-04 - 39s/epoch - 26ms/step
Epoch 49/200
1493/1493 - 39s - loss: 3.3677e-04 - val_loss: 6.0105e-04 - 39s/epoch - 26ms/step
Epoch 50/200
1493/1493 - 39s - loss: 3.3622e-04 - val_loss: 4.9091e-04 - 39s/epoch - 26ms/step
Epoch 51/200
1493/1493 - 39s - loss: 3.3293e-04 - val_loss: 4.1459e-04 - 39s/epoch - 26ms/step
Epoch 52/200
1493/1493 - 39s - loss: 3.2225e-04 - val_loss: 3.5942e-04 - 39s/epoch - 26ms/step
Epoch 53/200
1493/1493 - 39s - loss: 3.2281e-04 - val_loss: 4.1173e-04 - 39s/epoch - 26ms/step
Epoch 54/200
1493/1493 - 39s - loss: 3.1555e-04 - val_loss: 4.0258e-04 - 39s/epoch - 26ms/step
Epoch 55/200
1493/1493 - 39s - loss: 3.0517e-04 - val_loss: 3.3984e-04 - 39s/epoch - 26ms/step
Epoch 56/200
1493/1493 - 39s - loss: 3.0775e-04 - val_loss: 3.8703e-04 - 39s/epoch - 26ms/step
Epoch 57/200
1493/1493 - 39s - loss: 2.9819e-04 - val_loss: 4.1550e-04 - 39s/epoch - 26ms/step
Epoch 58/200
1493/1493 - 39s - loss: 2.9897e-04 - val_loss: 3.0543e-04 - 39s/epoch - 26ms/step
Epoch 59/200
1493/1493 - 39s - loss: 2.9543e-04 - val_loss: 3.2778e-04 - 39s/epoch - 26ms/step
Epoch 60/200
1493/1493 - 39s - loss: 2.9571e-04 - val_loss: 6.3106e-04 - 39s/epoch - 26ms/step
Epoch 61/200
1493/1493 - 39s - loss: 3.0420e-04 - val_loss: 3.1179e-04 - 39s/epoch - 26ms/step
Epoch 62/200
1493/1493 - 39s - loss: 2.8590e-04 - val_loss: 3.0284e-04 - 39s/epoch - 26ms/step
Epoch 63/200
1493/1493 - 39s - loss: 2.8324e-04 - val_loss: 3.7517e-04 - 39s/epoch - 26ms/step
Epoch 64/200
1493/1493 - 39s - loss: 2.8743e-04 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 65/200
1493/1493 - 39s - loss: 4.2141e-04 - val_loss: 2.9553e-04 - 39s/epoch - 26ms/step
Epoch 66/200
1493/1493 - 39s - loss: 2.8757e-04 - val_loss: 3.7094e-04 - 39s/epoch - 26ms/step
Epoch 67/200
1493/1493 - 39s - loss: 2.7957e-04 - val_loss: 3.1980e-04 - 39s/epoch - 26ms/step
Epoch 68/200
1493/1493 - 39s - loss: 2.7118e-04 - val_loss: 6.3147e-04 - 39s/epoch - 26ms/step
Epoch 69/200
1493/1493 - 39s - loss: 2.9831e-04 - val_loss: 3.1407e-04 - 39s/epoch - 26ms/step
Epoch 70/200
1493/1493 - 39s - loss: 2.7128e-04 - val_loss: 3.6776e-04 - 39s/epoch - 26ms/step
Epoch 71/200
1493/1493 - 39s - loss: 2.7406e-04 - val_loss: 2.8107e-04 - 39s/epoch - 26ms/step
Epoch 72/200
1493/1493 - 39s - loss: 2.6530e-04 - val_loss: 3.4141e-04 - 39s/epoch - 26ms/step
Epoch 73/200
1493/1493 - 39s - loss: 2.7071e-04 - val_loss: 3.1593e-04 - 39s/epoch - 26ms/step
Epoch 74/200
1493/1493 - 39s - loss: 2.6368e-04 - val_loss: 2.8780e-04 - 39s/epoch - 26ms/step
Epoch 75/200
1493/1493 - 39s - loss: 2.5421e-04 - val_loss: 2.6673e-04 - 39s/epoch - 26ms/step
Epoch 76/200
1493/1493 - 39s - loss: 2.5383e-04 - val_loss: 3.1959e-04 - 39s/epoch - 26ms/step
Epoch 77/200
1493/1493 - 39s - loss: 2.5842e-04 - val_loss: 4.6402e-04 - 39s/epoch - 26ms/step
Epoch 78/200
1493/1493 - 39s - loss: 2.5798e-04 - val_loss: 0.0013 - 39s/epoch - 26ms/step
Epoch 79/200
1493/1493 - 39s - loss: 3.1122e-04 - val_loss: 2.3015e-04 - 39s/epoch - 26ms/step
Epoch 80/200
1493/1493 - 39s - loss: 2.4872e-04 - val_loss: 2.2419e-04 - 39s/epoch - 26ms/step
Epoch 81/200
1493/1493 - 39s - loss: 2.4387e-04 - val_loss: 4.7477e-04 - 39s/epoch - 26ms/step
Epoch 82/200
1493/1493 - 39s - loss: 2.4225e-04 - val_loss: 2.5532e-04 - 39s/epoch - 26ms/step
Epoch 83/200
1493/1493 - 39s - loss: 2.3931e-04 - val_loss: 4.7818e-04 - 39s/epoch - 26ms/step
Epoch 84/200
1493/1493 - 39s - loss: 2.4127e-04 - val_loss: 2.5659e-04 - 39s/epoch - 26ms/step
Epoch 85/200
1493/1493 - 39s - loss: 2.4021e-04 - val_loss: 3.1740e-04 - 39s/epoch - 26ms/step
Epoch 86/200
1493/1493 - 39s - loss: 2.3731e-04 - val_loss: 2.8657e-04 - 39s/epoch - 26ms/step
Epoch 87/200
1493/1493 - 38s - loss: 2.3313e-04 - val_loss: 2.7236e-04 - 38s/epoch - 26ms/step
Epoch 88/200
1493/1493 - 38s - loss: 2.3452e-04 - val_loss: 3.5971e-04 - 38s/epoch - 26ms/step
Epoch 89/200
1493/1493 - 39s - loss: 2.4165e-04 - val_loss: 2.3901e-04 - 39s/epoch - 26ms/step
Epoch 90/200
1493/1493 - 39s - loss: 2.2991e-04 - val_loss: 2.7228e-04 - 39s/epoch - 26ms/step
Epoch 91/200
1493/1493 - 39s - loss: 2.2583e-04 - val_loss: 3.2017e-04 - 39s/epoch - 26ms/step
Epoch 92/200
1493/1493 - 39s - loss: 2.2636e-04 - val_loss: 5.6579e-04 - 39s/epoch - 26ms/step
Epoch 93/200
1493/1493 - 39s - loss: 2.5319e-04 - val_loss: 2.7277e-04 - 39s/epoch - 26ms/step
Epoch 94/200
1493/1493 - 39s - loss: 2.2499e-04 - val_loss: 2.0138e-04 - 39s/epoch - 26ms/step
Epoch 95/200
1493/1493 - 39s - loss: 2.2184e-04 - val_loss: 2.9014e-04 - 39s/epoch - 26ms/step
Epoch 96/200
1493/1493 - 39s - loss: 2.2442e-04 - val_loss: 3.0981e-04 - 39s/epoch - 26ms/step
Epoch 97/200
1493/1493 - 39s - loss: 2.2364e-04 - val_loss: 2.2034e-04 - 39s/epoch - 26ms/step
Epoch 98/200
1493/1493 - 39s - loss: 2.1372e-04 - val_loss: 2.9771e-04 - 39s/epoch - 26ms/step
Epoch 99/200
1493/1493 - 39s - loss: 2.1509e-04 - val_loss: 2.7283e-04 - 39s/epoch - 26ms/step
Epoch 100/200
1493/1493 - 39s - loss: 2.2062e-04 - val_loss: 2.7014e-04 - 39s/epoch - 26ms/step
Epoch 101/200
1493/1493 - 39s - loss: 2.1538e-04 - val_loss: 3.5150e-04 - 39s/epoch - 26ms/step
Epoch 102/200
1493/1493 - 39s - loss: 2.2169e-04 - val_loss: 3.1956e-04 - 39s/epoch - 26ms/step
Epoch 103/200
1493/1493 - 39s - loss: 2.1323e-04 - val_loss: 2.5789e-04 - 39s/epoch - 26ms/step
Epoch 104/200
1493/1493 - 39s - loss: 2.0831e-04 - val_loss: 3.9615e-04 - 39s/epoch - 26ms/step
Epoch 105/200
1493/1493 - 39s - loss: 2.1464e-04 - val_loss: 2.4222e-04 - 39s/epoch - 26ms/step
Epoch 106/200
1493/1493 - 39s - loss: 2.0618e-04 - val_loss: 2.4344e-04 - 39s/epoch - 26ms/step
Epoch 107/200
1493/1493 - 39s - loss: 2.0494e-04 - val_loss: 2.6452e-04 - 39s/epoch - 26ms/step
Epoch 108/200
1493/1493 - 39s - loss: 2.0649e-04 - val_loss: 2.5873e-04 - 39s/epoch - 26ms/step
Epoch 109/200
1493/1493 - 39s - loss: 2.0328e-04 - val_loss: 2.6412e-04 - 39s/epoch - 26ms/step
Epoch 110/200
1493/1493 - 39s - loss: 2.0209e-04 - val_loss: 2.4553e-04 - 39s/epoch - 26ms/step
Epoch 111/200
1493/1493 - 39s - loss: 2.0323e-04 - val_loss: 7.9729e-04 - 39s/epoch - 26ms/step
Epoch 112/200
1493/1493 - 39s - loss: 2.4051e-04 - val_loss: 2.0054e-04 - 39s/epoch - 26ms/step
Epoch 113/200
1493/1493 - 38s - loss: 2.0406e-04 - val_loss: 6.6986e-04 - 38s/epoch - 26ms/step
Epoch 114/200
1493/1493 - 39s - loss: 2.5121e-04 - val_loss: 1.7556e-04 - 39s/epoch - 26ms/step
Epoch 115/200
1493/1493 - 39s - loss: 2.0041e-04 - val_loss: 2.9305e-04 - 39s/epoch - 26ms/step
Epoch 116/200
1493/1493 - 38s - loss: 1.9823e-04 - val_loss: 2.6925e-04 - 38s/epoch - 26ms/step
Epoch 117/200
1493/1493 - 38s - loss: 1.9621e-04 - val_loss: 2.5876e-04 - 38s/epoch - 26ms/step
Epoch 118/200
1493/1493 - 39s - loss: 2.0281e-04 - val_loss: 2.2703e-04 - 39s/epoch - 26ms/step
Epoch 119/200
1493/1493 - 39s - loss: 1.9481e-04 - val_loss: 1.8687e-04 - 39s/epoch - 26ms/step
Epoch 120/200
1493/1493 - 39s - loss: 1.9281e-04 - val_loss: 2.1185e-04 - 39s/epoch - 26ms/step
Epoch 121/200
1493/1493 - 39s - loss: 1.9260e-04 - val_loss: 2.6449e-04 - 39s/epoch - 26ms/step
Epoch 122/200
1493/1493 - 39s - loss: 1.9750e-04 - val_loss: 2.3267e-04 - 39s/epoch - 26ms/step
Epoch 123/200
1493/1493 - 39s - loss: 1.9749e-04 - val_loss: 2.3258e-04 - 39s/epoch - 26ms/step
Epoch 124/200
1493/1493 - 39s - loss: 1.8918e-04 - val_loss: 2.4610e-04 - 39s/epoch - 26ms/step
Epoch 125/200
1493/1493 - 39s - loss: 1.9181e-04 - val_loss: 1.8646e-04 - 39s/epoch - 26ms/step
Epoch 126/200
1493/1493 - 39s - loss: 1.8822e-04 - val_loss: 2.6066e-04 - 39s/epoch - 26ms/step
Epoch 127/200
1493/1493 - 39s - loss: 1.8665e-04 - val_loss: 3.2581e-04 - 39s/epoch - 26ms/step
Epoch 128/200
1493/1493 - 39s - loss: 1.9195e-04 - val_loss: 1.7927e-04 - 39s/epoch - 26ms/step
Epoch 129/200
1493/1493 - 39s - loss: 1.8422e-04 - val_loss: 1.9391e-04 - 39s/epoch - 26ms/step
Epoch 130/200
1493/1493 - 39s - loss: 1.8360e-04 - val_loss: 1.8097e-04 - 39s/epoch - 26ms/step
Epoch 131/200
1493/1493 - 38s - loss: 1.8714e-04 - val_loss: 7.7130e-04 - 38s/epoch - 26ms/step
Epoch 132/200
1493/1493 - 38s - loss: 2.3074e-04 - val_loss: 1.6821e-04 - 38s/epoch - 26ms/step
Epoch 133/200
1493/1493 - 39s - loss: 1.8324e-04 - val_loss: 1.8730e-04 - 39s/epoch - 26ms/step
Epoch 134/200
1493/1493 - 39s - loss: 1.8161e-04 - val_loss: 1.7920e-04 - 39s/epoch - 26ms/step
Epoch 135/200
1493/1493 - 39s - loss: 1.7942e-04 - val_loss: 1.9230e-04 - 39s/epoch - 26ms/step
Epoch 136/200
1493/1493 - 39s - loss: 1.8309e-04 - val_loss: 3.7012e-04 - 39s/epoch - 26ms/step
Epoch 137/200
1493/1493 - 39s - loss: 2.2289e-04 - val_loss: 4.7269e-04 - 39s/epoch - 26ms/step
Epoch 138/200
1493/1493 - 39s - loss: 2.2331e-04 - val_loss: 1.7904e-04 - 39s/epoch - 26ms/step
Epoch 139/200
1493/1493 - 39s - loss: 1.8602e-04 - val_loss: 2.7929e-04 - 39s/epoch - 26ms/step
Epoch 140/200
1493/1493 - 39s - loss: 1.9255e-04 - val_loss: 3.9990e-04 - 39s/epoch - 26ms/step
Epoch 141/200
1493/1493 - 39s - loss: 1.9167e-04 - val_loss: 2.7343e-04 - 39s/epoch - 26ms/step
Epoch 142/200
1493/1493 - 39s - loss: 1.8413e-04 - val_loss: 2.0249e-04 - 39s/epoch - 26ms/step
Epoch 143/200
1493/1493 - 39s - loss: 1.7685e-04 - val_loss: 2.4542e-04 - 39s/epoch - 26ms/step
Epoch 144/200
1493/1493 - 39s - loss: 1.8113e-04 - val_loss: 1.8374e-04 - 39s/epoch - 26ms/step
Epoch 145/200
1493/1493 - 39s - loss: 1.7719e-04 - val_loss: 2.2261e-04 - 39s/epoch - 26ms/step
Epoch 146/200
1493/1493 - 39s - loss: 1.7885e-04 - val_loss: 1.6290e-04 - 39s/epoch - 26ms/step
Epoch 147/200
1493/1493 - 39s - loss: 1.7209e-04 - val_loss: 2.2208e-04 - 39s/epoch - 26ms/step
Epoch 148/200
1493/1493 - 39s - loss: 1.7411e-04 - val_loss: 3.8547e-04 - 39s/epoch - 26ms/step
Epoch 149/200
1493/1493 - 39s - loss: 1.7227e-04 - val_loss: 1.7410e-04 - 39s/epoch - 26ms/step
Epoch 150/200
1493/1493 - 39s - loss: 1.7192e-04 - val_loss: 4.3647e-04 - 39s/epoch - 26ms/step
Epoch 151/200
1493/1493 - 39s - loss: 1.9021e-04 - val_loss: 1.7551e-04 - 39s/epoch - 26ms/step
Epoch 152/200
1493/1493 - 39s - loss: 1.7048e-04 - val_loss: 3.4823e-04 - 39s/epoch - 26ms/step
Epoch 153/200
1493/1493 - 39s - loss: 1.7666e-04 - val_loss: 2.0257e-04 - 39s/epoch - 26ms/step
Epoch 154/200
1493/1493 - 39s - loss: 1.6954e-04 - val_loss: 5.5877e-04 - 39s/epoch - 26ms/step
Epoch 155/200
1493/1493 - 39s - loss: 2.0190e-04 - val_loss: 1.7213e-04 - 39s/epoch - 26ms/step
Epoch 156/200
1493/1493 - 39s - loss: 1.7144e-04 - val_loss: 1.8208e-04 - 39s/epoch - 26ms/step
Epoch 157/200
1493/1493 - 39s - loss: 1.6652e-04 - val_loss: 2.0491e-04 - 39s/epoch - 26ms/step
Epoch 158/200
1493/1493 - 39s - loss: 1.7127e-04 - val_loss: 1.9490e-04 - 39s/epoch - 26ms/step
Epoch 159/200
1493/1493 - 39s - loss: 1.6653e-04 - val_loss: 1.6577e-04 - 39s/epoch - 26ms/step
Epoch 160/200
1493/1493 - 39s - loss: 1.6589e-04 - val_loss: 2.2292e-04 - 39s/epoch - 26ms/step
Epoch 161/200
1493/1493 - 39s - loss: 1.7247e-04 - val_loss: 1.8781e-04 - 39s/epoch - 26ms/step
Epoch 162/200
1493/1493 - 39s - loss: 1.6496e-04 - val_loss: 1.6518e-04 - 39s/epoch - 26ms/step
Epoch 163/200
1493/1493 - 39s - loss: 1.6592e-04 - val_loss: 3.3846e-04 - 39s/epoch - 26ms/step
Epoch 164/200
1493/1493 - 39s - loss: 1.7531e-04 - val_loss: 1.6593e-04 - 39s/epoch - 26ms/step
Epoch 165/200
1493/1493 - 38s - loss: 1.7220e-04 - val_loss: 2.0790e-04 - 38s/epoch - 26ms/step
Epoch 166/200
1493/1493 - 39s - loss: 1.6488e-04 - val_loss: 1.7031e-04 - 39s/epoch - 26ms/step
Epoch 167/200
1493/1493 - 39s - loss: 1.6222e-04 - val_loss: 1.6082e-04 - 39s/epoch - 26ms/step
Epoch 168/200
1493/1493 - 39s - loss: 1.6143e-04 - val_loss: 1.6244e-04 - 39s/epoch - 26ms/step
Epoch 169/200
1493/1493 - 39s - loss: 1.6123e-04 - val_loss: 2.6479e-04 - 39s/epoch - 26ms/step
Epoch 170/200
1493/1493 - 39s - loss: 1.6445e-04 - val_loss: 4.6120e-04 - 39s/epoch - 26ms/step
Epoch 171/200
1493/1493 - 39s - loss: 2.0215e-04 - val_loss: 2.5495e-04 - 39s/epoch - 26ms/step
Epoch 172/200
1493/1493 - 39s - loss: 1.7453e-04 - val_loss: 2.3573e-04 - 39s/epoch - 26ms/step
Epoch 173/200
1493/1493 - 39s - loss: 1.6593e-04 - val_loss: 1.4248e-04 - 39s/epoch - 26ms/step
Epoch 174/200
1493/1493 - 39s - loss: 1.6034e-04 - val_loss: 1.7583e-04 - 39s/epoch - 26ms/step
Epoch 175/200
1493/1493 - 39s - loss: 1.6115e-04 - val_loss: 2.0020e-04 - 39s/epoch - 26ms/step
Epoch 176/200
1493/1493 - 39s - loss: 1.6039e-04 - val_loss: 1.8675e-04 - 39s/epoch - 26ms/step
Epoch 177/200
1493/1493 - 39s - loss: 1.6002e-04 - val_loss: 1.4037e-04 - 39s/epoch - 26ms/step
Epoch 178/200
1493/1493 - 39s - loss: 1.5715e-04 - val_loss: 1.7141e-04 - 39s/epoch - 26ms/step
Epoch 179/200
1493/1493 - 39s - loss: 1.5791e-04 - val_loss: 1.7410e-04 - 39s/epoch - 26ms/step
Epoch 180/200
1493/1493 - 39s - loss: 1.5718e-04 - val_loss: 3.3625e-04 - 39s/epoch - 26ms/step
Epoch 181/200
1493/1493 - 39s - loss: 1.6876e-04 - val_loss: 2.0915e-04 - 39s/epoch - 26ms/step
Epoch 182/200
1493/1493 - 39s - loss: 1.5890e-04 - val_loss: 2.0829e-04 - 39s/epoch - 26ms/step
Epoch 183/200
1493/1493 - 39s - loss: 1.5504e-04 - val_loss: 2.4463e-04 - 39s/epoch - 26ms/step
Epoch 184/200
1493/1493 - 39s - loss: 1.5594e-04 - val_loss: 1.3789e-04 - 39s/epoch - 26ms/step
Epoch 185/200
1493/1493 - 39s - loss: 1.5321e-04 - val_loss: 2.5787e-04 - 39s/epoch - 26ms/step
Epoch 186/200
1493/1493 - 39s - loss: 1.6114e-04 - val_loss: 1.6714e-04 - 39s/epoch - 26ms/step
Epoch 187/200
1493/1493 - 39s - loss: 1.5443e-04 - val_loss: 2.8271e-04 - 39s/epoch - 26ms/step
Epoch 188/200
1493/1493 - 39s - loss: 1.7828e-04 - val_loss: 1.7386e-04 - 39s/epoch - 26ms/step
Epoch 189/200
1493/1493 - 39s - loss: 1.5665e-04 - val_loss: 2.1729e-04 - 39s/epoch - 26ms/step
Epoch 190/200
1493/1493 - 39s - loss: 1.5700e-04 - val_loss: 1.9574e-04 - 39s/epoch - 26ms/step
Epoch 191/200
1493/1493 - 39s - loss: 1.5432e-04 - val_loss: 2.5598e-04 - 39s/epoch - 26ms/step
Epoch 192/200
1493/1493 - 38s - loss: 1.5450e-04 - val_loss: 2.0838e-04 - 38s/epoch - 26ms/step
Epoch 193/200
1493/1493 - 39s - loss: 1.5759e-04 - val_loss: 3.1199e-04 - 39s/epoch - 26ms/step
Epoch 194/200
1493/1493 - 38s - loss: 1.6768e-04 - val_loss: 4.8438e-04 - 38s/epoch - 26ms/step
Epoch 195/200
1493/1493 - 39s - loss: 1.7647e-04 - val_loss: 1.4885e-04 - 39s/epoch - 26ms/step
Epoch 196/200
1493/1493 - 39s - loss: 1.5288e-04 - val_loss: 1.6488e-04 - 39s/epoch - 26ms/step
Epoch 197/200
1493/1493 - 39s - loss: 1.5225e-04 - val_loss: 2.2872e-04 - 39s/epoch - 26ms/step
Epoch 198/200
1493/1493 - 39s - loss: 1.5752e-04 - val_loss: 2.2569e-04 - 39s/epoch - 26ms/step
Epoch 199/200
1493/1493 - 39s - loss: 1.5625e-04 - val_loss: 1.3757e-04 - 39s/epoch - 26ms/step
Epoch 200/200
1493/1493 - 39s - loss: 1.4904e-04 - val_loss: 1.6709e-04 - 39s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00016709297779016197
  1/332 [..............................] - ETA: 24s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s127/332 [==========>...................] - ETA: 0s143/332 [===========>..................] - ETA: 0s159/332 [=============>................] - ETA: 0s175/332 [==============>...............] - ETA: 0s191/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s223/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s255/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s287/332 [========================>.....] - ETA: 0s303/332 [==========================>...] - ETA: 0s319/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0019041431082719414
cosine 0.0015011419732751281
MAE: 0.0076962737
RMSE: 0.012926443
r2: 0.9891605491355117
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_18 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_19 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 632)               0         
                                                                 
 dense_19 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_20 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 1264)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_20 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_18 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_21 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_19 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 632)               0         
                                                                 
 dense_19 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_20 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 1264)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 200, 0.0005, 0.5, 632, 0.0001490377471782267, 0.00016709297779016197, 0.0019041431082719414, 0.0015011419732751281, 0.007696273736655712, 0.012926442548632622, 0.9891605491355117, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_21 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_21 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_22 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 632)               0         
                                                                 
 dense_22 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_23 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 1264)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/200
1493/1493 - 39s - loss: 0.0078 - val_loss: 0.0032 - 39s/epoch - 26ms/step
Epoch 2/200
1493/1493 - 38s - loss: 0.0025 - val_loss: 0.0025 - 38s/epoch - 26ms/step
Epoch 3/200
1493/1493 - 39s - loss: 0.0019 - val_loss: 0.0021 - 39s/epoch - 26ms/step
Epoch 4/200
1493/1493 - 39s - loss: 0.0016 - val_loss: 0.0017 - 39s/epoch - 26ms/step
Epoch 5/200
1493/1493 - 39s - loss: 0.0014 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 6/200
1493/1493 - 39s - loss: 0.0012 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 7/200
1493/1493 - 39s - loss: 0.0011 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 8/200
1493/1493 - 39s - loss: 0.0010 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 9/200
1493/1493 - 38s - loss: 9.0629e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 10/200
1493/1493 - 38s - loss: 8.3460e-04 - val_loss: 8.2850e-04 - 38s/epoch - 26ms/step
Epoch 11/200
1493/1493 - 39s - loss: 7.5588e-04 - val_loss: 7.7040e-04 - 39s/epoch - 26ms/step
Epoch 12/200
1493/1493 - 39s - loss: 6.8325e-04 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 13/200
1493/1493 - 39s - loss: 6.9822e-04 - val_loss: 9.9238e-04 - 39s/epoch - 26ms/step
Epoch 14/200
1493/1493 - 39s - loss: 6.1694e-04 - val_loss: 6.1989e-04 - 39s/epoch - 26ms/step
Epoch 15/200
1493/1493 - 39s - loss: 5.7313e-04 - val_loss: 5.8657e-04 - 39s/epoch - 26ms/step
Epoch 16/200
1493/1493 - 39s - loss: 5.3561e-04 - val_loss: 5.8845e-04 - 39s/epoch - 26ms/step
Epoch 17/200
1493/1493 - 39s - loss: 5.0796e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 18/200
1493/1493 - 39s - loss: 5.1867e-04 - val_loss: 7.9938e-04 - 39s/epoch - 26ms/step
Epoch 19/200
1493/1493 - 39s - loss: 4.8191e-04 - val_loss: 5.6184e-04 - 39s/epoch - 26ms/step
Epoch 20/200
1493/1493 - 39s - loss: 4.4876e-04 - val_loss: 4.5329e-04 - 39s/epoch - 26ms/step
Epoch 21/200
1493/1493 - 39s - loss: 4.2111e-04 - val_loss: 6.0277e-04 - 39s/epoch - 26ms/step
Epoch 22/200
1493/1493 - 39s - loss: 4.1705e-04 - val_loss: 8.4127e-04 - 39s/epoch - 26ms/step
Epoch 23/200
1493/1493 - 39s - loss: 4.1346e-04 - val_loss: 5.0257e-04 - 39s/epoch - 26ms/step
Epoch 24/200
1493/1493 - 39s - loss: 4.1525e-04 - val_loss: 4.7522e-04 - 39s/epoch - 26ms/step
Epoch 25/200
1493/1493 - 39s - loss: 3.8213e-04 - val_loss: 4.2505e-04 - 39s/epoch - 26ms/step
Epoch 26/200
1493/1493 - 39s - loss: 3.6141e-04 - val_loss: 4.7449e-04 - 39s/epoch - 26ms/step
Epoch 27/200
1493/1493 - 39s - loss: 3.4521e-04 - val_loss: 3.4569e-04 - 39s/epoch - 26ms/step
Epoch 28/200
1493/1493 - 39s - loss: 3.3441e-04 - val_loss: 6.8948e-04 - 39s/epoch - 26ms/step
Epoch 29/200
1493/1493 - 39s - loss: 3.5180e-04 - val_loss: 3.6280e-04 - 39s/epoch - 26ms/step
Epoch 30/200
1493/1493 - 39s - loss: 3.2182e-04 - val_loss: 3.8794e-04 - 39s/epoch - 26ms/step
Epoch 31/200
1493/1493 - 39s - loss: 3.4166e-04 - val_loss: 8.2516e-04 - 39s/epoch - 26ms/step
Epoch 32/200
1493/1493 - 39s - loss: 3.8150e-04 - val_loss: 2.8188e-04 - 39s/epoch - 26ms/step
Epoch 33/200
1493/1493 - 39s - loss: 3.0669e-04 - val_loss: 3.0824e-04 - 39s/epoch - 26ms/step
Epoch 34/200
1493/1493 - 39s - loss: 3.0367e-04 - val_loss: 2.6849e-04 - 39s/epoch - 26ms/step
Epoch 35/200
1493/1493 - 39s - loss: 2.9011e-04 - val_loss: 9.2053e-04 - 39s/epoch - 26ms/step
Epoch 36/200
1493/1493 - 39s - loss: 3.7775e-04 - val_loss: 3.4547e-04 - 39s/epoch - 26ms/step
Epoch 37/200
1493/1493 - 39s - loss: 2.8953e-04 - val_loss: 4.0509e-04 - 39s/epoch - 26ms/step
Epoch 38/200
1493/1493 - 39s - loss: 2.8686e-04 - val_loss: 2.8601e-04 - 39s/epoch - 26ms/step
Epoch 39/200
1493/1493 - 39s - loss: 2.8013e-04 - val_loss: 2.7469e-04 - 39s/epoch - 26ms/step
Epoch 40/200
1493/1493 - 39s - loss: 2.6782e-04 - val_loss: 9.3789e-04 - 39s/epoch - 26ms/step
Epoch 41/200
1493/1493 - 39s - loss: 3.5908e-04 - val_loss: 2.5729e-04 - 39s/epoch - 26ms/step
Epoch 42/200
1493/1493 - 39s - loss: 2.7071e-04 - val_loss: 2.5783e-04 - 39s/epoch - 26ms/step
Epoch 43/200
1493/1493 - 39s - loss: 2.6012e-04 - val_loss: 2.9863e-04 - 39s/epoch - 26ms/step
Epoch 44/200
1493/1493 - 39s - loss: 2.6196e-04 - val_loss: 3.4414e-04 - 39s/epoch - 26ms/step
Epoch 45/200
1493/1493 - 39s - loss: 2.6730e-04 - val_loss: 2.2399e-04 - 39s/epoch - 26ms/step
Epoch 46/200
1493/1493 - 39s - loss: 2.4575e-04 - val_loss: 2.5875e-04 - 39s/epoch - 26ms/step
Epoch 47/200
1493/1493 - 39s - loss: 2.4724e-04 - val_loss: 2.3694e-04 - 39s/epoch - 26ms/step
Epoch 48/200
1493/1493 - 39s - loss: 2.4066e-04 - val_loss: 2.6588e-04 - 39s/epoch - 26ms/step
Epoch 49/200
1493/1493 - 39s - loss: 2.4700e-04 - val_loss: 9.3760e-04 - 39s/epoch - 26ms/step
Epoch 50/200
1493/1493 - 39s - loss: 3.6172e-04 - val_loss: 4.3506e-04 - 39s/epoch - 26ms/step
Epoch 51/200
1493/1493 - 39s - loss: 2.6715e-04 - val_loss: 1.9888e-04 - 39s/epoch - 26ms/step
Epoch 52/200
1493/1493 - 39s - loss: 2.3676e-04 - val_loss: 2.3852e-04 - 39s/epoch - 26ms/step
Epoch 53/200
1493/1493 - 39s - loss: 2.3416e-04 - val_loss: 2.3709e-04 - 39s/epoch - 26ms/step
Epoch 54/200
1493/1493 - 39s - loss: 2.3258e-04 - val_loss: 2.2798e-04 - 39s/epoch - 26ms/step
Epoch 55/200
1493/1493 - 39s - loss: 2.2541e-04 - val_loss: 2.2579e-04 - 39s/epoch - 26ms/step
Epoch 56/200
1493/1493 - 39s - loss: 2.2345e-04 - val_loss: 2.5342e-04 - 39s/epoch - 26ms/step
Epoch 57/200
1493/1493 - 39s - loss: 2.2228e-04 - val_loss: 2.1481e-04 - 39s/epoch - 26ms/step
Epoch 58/200
1493/1493 - 38s - loss: 2.1792e-04 - val_loss: 2.1125e-04 - 38s/epoch - 26ms/step
Epoch 59/200
1493/1493 - 38s - loss: 2.2094e-04 - val_loss: 2.0674e-04 - 38s/epoch - 26ms/step
Epoch 60/200
1493/1493 - 38s - loss: 2.1318e-04 - val_loss: 2.9793e-04 - 38s/epoch - 26ms/step
Epoch 61/200
1493/1493 - 39s - loss: 2.1635e-04 - val_loss: 2.1762e-04 - 39s/epoch - 26ms/step
Epoch 62/200
1493/1493 - 39s - loss: 2.2694e-04 - val_loss: 2.3353e-04 - 39s/epoch - 26ms/step
Epoch 63/200
1493/1493 - 39s - loss: 2.0890e-04 - val_loss: 2.4270e-04 - 39s/epoch - 26ms/step
Epoch 64/200
1493/1493 - 39s - loss: 2.1083e-04 - val_loss: 7.4163e-04 - 39s/epoch - 26ms/step
Epoch 65/200
1493/1493 - 39s - loss: 2.5124e-04 - val_loss: 2.1031e-04 - 39s/epoch - 26ms/step
Epoch 66/200
1493/1493 - 38s - loss: 2.1688e-04 - val_loss: 2.1849e-04 - 38s/epoch - 26ms/step
Epoch 67/200
1493/1493 - 38s - loss: 2.0595e-04 - val_loss: 1.9530e-04 - 38s/epoch - 26ms/step
Epoch 68/200
1493/1493 - 39s - loss: 2.0317e-04 - val_loss: 4.4316e-04 - 39s/epoch - 26ms/step
Epoch 69/200
1493/1493 - 39s - loss: 2.3434e-04 - val_loss: 3.0226e-04 - 39s/epoch - 26ms/step
Epoch 70/200
1493/1493 - 39s - loss: 2.1113e-04 - val_loss: 2.7481e-04 - 39s/epoch - 26ms/step
Epoch 71/200
1493/1493 - 39s - loss: 2.3014e-04 - val_loss: 1.8635e-04 - 39s/epoch - 26ms/step
Epoch 72/200
1493/1493 - 39s - loss: 2.0284e-04 - val_loss: 2.6642e-04 - 39s/epoch - 26ms/step
Epoch 73/200
1493/1493 - 39s - loss: 2.1348e-04 - val_loss: 3.5071e-04 - 39s/epoch - 26ms/step
Epoch 74/200
1493/1493 - 39s - loss: 2.2679e-04 - val_loss: 1.9330e-04 - 39s/epoch - 26ms/step
Epoch 75/200
1493/1493 - 39s - loss: 1.9692e-04 - val_loss: 2.1536e-04 - 39s/epoch - 26ms/step
Epoch 76/200
1493/1493 - 39s - loss: 2.0288e-04 - val_loss: 2.2592e-04 - 39s/epoch - 26ms/step
Epoch 77/200
1493/1493 - 39s - loss: 1.9295e-04 - val_loss: 2.3901e-04 - 39s/epoch - 26ms/step
Epoch 78/200
1493/1493 - 39s - loss: 1.9788e-04 - val_loss: 2.2855e-04 - 39s/epoch - 26ms/step
Epoch 79/200
1493/1493 - 39s - loss: 1.9289e-04 - val_loss: 2.5759e-04 - 39s/epoch - 26ms/step
Epoch 80/200
1493/1493 - 39s - loss: 2.0026e-04 - val_loss: 2.0090e-04 - 39s/epoch - 26ms/step
Epoch 81/200
1493/1493 - 39s - loss: 1.8894e-04 - val_loss: 2.8928e-04 - 39s/epoch - 26ms/step
Epoch 82/200
1493/1493 - 38s - loss: 1.8791e-04 - val_loss: 2.3091e-04 - 38s/epoch - 26ms/step
Epoch 83/200
1493/1493 - 39s - loss: 1.9048e-04 - val_loss: 1.7336e-04 - 39s/epoch - 26ms/step
Epoch 84/200
1493/1493 - 39s - loss: 1.8585e-04 - val_loss: 3.8750e-04 - 39s/epoch - 26ms/step
Epoch 85/200
1493/1493 - 39s - loss: 2.1936e-04 - val_loss: 2.1061e-04 - 39s/epoch - 26ms/step
Epoch 86/200
1493/1493 - 39s - loss: 1.9221e-04 - val_loss: 1.8496e-04 - 39s/epoch - 26ms/step
Epoch 87/200
1493/1493 - 39s - loss: 1.8340e-04 - val_loss: 2.2856e-04 - 39s/epoch - 26ms/step
Epoch 88/200
1493/1493 - 39s - loss: 1.8443e-04 - val_loss: 4.7600e-04 - 39s/epoch - 26ms/step
Epoch 89/200
1493/1493 - 39s - loss: 2.4606e-04 - val_loss: 1.7504e-04 - 39s/epoch - 26ms/step
Epoch 90/200
1493/1493 - 39s - loss: 1.9096e-04 - val_loss: 1.8926e-04 - 39s/epoch - 26ms/step
Epoch 91/200
1493/1493 - 39s - loss: 1.8327e-04 - val_loss: 2.2604e-04 - 39s/epoch - 26ms/step
Epoch 92/200
1493/1493 - 39s - loss: 1.8264e-04 - val_loss: 3.2692e-04 - 39s/epoch - 26ms/step
Epoch 93/200
1493/1493 - 39s - loss: 2.1115e-04 - val_loss: 1.7738e-04 - 39s/epoch - 26ms/step
Epoch 94/200
1493/1493 - 38s - loss: 1.8211e-04 - val_loss: 1.8354e-04 - 38s/epoch - 26ms/step
Epoch 95/200
1493/1493 - 39s - loss: 1.8020e-04 - val_loss: 2.0865e-04 - 39s/epoch - 26ms/step
Epoch 96/200
1493/1493 - 39s - loss: 1.8132e-04 - val_loss: 2.4825e-04 - 39s/epoch - 26ms/step
Epoch 97/200
1493/1493 - 39s - loss: 1.7887e-04 - val_loss: 1.7810e-04 - 39s/epoch - 26ms/step
Epoch 98/200
1493/1493 - 38s - loss: 1.8180e-04 - val_loss: 6.3658e-04 - 38s/epoch - 26ms/step
Epoch 99/200
1493/1493 - 39s - loss: 2.3955e-04 - val_loss: 1.6989e-04 - 39s/epoch - 26ms/step
Epoch 100/200
1493/1493 - 39s - loss: 1.8495e-04 - val_loss: 1.6250e-04 - 39s/epoch - 26ms/step
Epoch 101/200
1493/1493 - 39s - loss: 1.7954e-04 - val_loss: 2.7512e-04 - 39s/epoch - 26ms/step
Epoch 102/200
1493/1493 - 39s - loss: 1.9363e-04 - val_loss: 3.7544e-04 - 39s/epoch - 26ms/step
Epoch 103/200
1493/1493 - 39s - loss: 2.1183e-04 - val_loss: 1.8969e-04 - 39s/epoch - 26ms/step
Epoch 104/200
1493/1493 - 39s - loss: 1.7848e-04 - val_loss: 3.5178e-04 - 39s/epoch - 26ms/step
Epoch 105/200
1493/1493 - 39s - loss: 1.9276e-04 - val_loss: 1.6881e-04 - 39s/epoch - 26ms/step
Epoch 106/200
1493/1493 - 39s - loss: 1.7429e-04 - val_loss: 1.9578e-04 - 39s/epoch - 26ms/step
Epoch 107/200
1493/1493 - 39s - loss: 1.7756e-04 - val_loss: 1.8558e-04 - 39s/epoch - 26ms/step
Epoch 108/200
1493/1493 - 39s - loss: 1.7144e-04 - val_loss: 1.9975e-04 - 39s/epoch - 26ms/step
Epoch 109/200
1493/1493 - 39s - loss: 1.7088e-04 - val_loss: 2.2137e-04 - 39s/epoch - 26ms/step
Epoch 110/200
1493/1493 - 39s - loss: 1.7121e-04 - val_loss: 1.9764e-04 - 39s/epoch - 26ms/step
Epoch 111/200
1493/1493 - 39s - loss: 1.7034e-04 - val_loss: 1.8193e-04 - 39s/epoch - 26ms/step
Epoch 112/200
1493/1493 - 38s - loss: 1.6783e-04 - val_loss: 2.0343e-04 - 38s/epoch - 26ms/step
Epoch 113/200
1493/1493 - 39s - loss: 1.6804e-04 - val_loss: 4.2000e-04 - 39s/epoch - 26ms/step
Epoch 114/200
1493/1493 - 38s - loss: 2.1582e-04 - val_loss: 1.7358e-04 - 38s/epoch - 26ms/step
Epoch 115/200
1493/1493 - 39s - loss: 1.7301e-04 - val_loss: 2.8541e-04 - 39s/epoch - 26ms/step
Epoch 116/200
1493/1493 - 39s - loss: 1.7346e-04 - val_loss: 3.3598e-04 - 39s/epoch - 26ms/step
Epoch 117/200
1493/1493 - 39s - loss: 1.7973e-04 - val_loss: 1.8837e-04 - 39s/epoch - 26ms/step
Epoch 118/200
1493/1493 - 39s - loss: 1.6851e-04 - val_loss: 1.6826e-04 - 39s/epoch - 26ms/step
Epoch 119/200
1493/1493 - 39s - loss: 1.6579e-04 - val_loss: 1.6558e-04 - 39s/epoch - 26ms/step
Epoch 120/200
1493/1493 - 39s - loss: 1.6359e-04 - val_loss: 1.5307e-04 - 39s/epoch - 26ms/step
Epoch 121/200
1493/1493 - 39s - loss: 1.6544e-04 - val_loss: 3.7211e-04 - 39s/epoch - 26ms/step
Epoch 122/200
1493/1493 - 39s - loss: 1.7187e-04 - val_loss: 1.4328e-04 - 39s/epoch - 26ms/step
Epoch 123/200
1493/1493 - 39s - loss: 1.6096e-04 - val_loss: 2.1146e-04 - 39s/epoch - 26ms/step
Epoch 124/200
1493/1493 - 39s - loss: 1.6294e-04 - val_loss: 2.0046e-04 - 39s/epoch - 26ms/step
Epoch 125/200
1493/1493 - 39s - loss: 1.6182e-04 - val_loss: 1.6207e-04 - 39s/epoch - 26ms/step
Epoch 126/200
1493/1493 - 39s - loss: 1.6022e-04 - val_loss: 3.4749e-04 - 39s/epoch - 26ms/step
Epoch 127/200
1493/1493 - 39s - loss: 1.7543e-04 - val_loss: 5.1231e-04 - 39s/epoch - 26ms/step
Epoch 128/200
1493/1493 - 39s - loss: 1.8296e-04 - val_loss: 3.3923e-04 - 39s/epoch - 26ms/step
Epoch 129/200
1493/1493 - 39s - loss: 1.7944e-04 - val_loss: 1.5048e-04 - 39s/epoch - 26ms/step
Epoch 130/200
1493/1493 - 39s - loss: 1.6142e-04 - val_loss: 1.6853e-04 - 39s/epoch - 26ms/step
Epoch 131/200
1493/1493 - 39s - loss: 1.6254e-04 - val_loss: 3.2568e-04 - 39s/epoch - 26ms/step
Epoch 132/200
1493/1493 - 39s - loss: 1.8494e-04 - val_loss: 1.6679e-04 - 39s/epoch - 26ms/step
Epoch 133/200
1493/1493 - 39s - loss: 1.6147e-04 - val_loss: 1.5652e-04 - 39s/epoch - 26ms/step
Epoch 134/200
1493/1493 - 39s - loss: 1.5768e-04 - val_loss: 1.6820e-04 - 39s/epoch - 26ms/step
Epoch 135/200
1493/1493 - 39s - loss: 1.5722e-04 - val_loss: 1.5792e-04 - 39s/epoch - 26ms/step
Epoch 136/200
1493/1493 - 39s - loss: 1.5578e-04 - val_loss: 1.6749e-04 - 39s/epoch - 26ms/step
Epoch 137/200
1493/1493 - 39s - loss: 1.6180e-04 - val_loss: 3.7501e-04 - 39s/epoch - 26ms/step
Epoch 138/200
1493/1493 - 39s - loss: 1.7984e-04 - val_loss: 1.9750e-04 - 39s/epoch - 26ms/step
Epoch 139/200
1493/1493 - 39s - loss: 1.6120e-04 - val_loss: 1.8586e-04 - 39s/epoch - 26ms/step
Epoch 140/200
1493/1493 - 39s - loss: 1.6095e-04 - val_loss: 1.6348e-04 - 39s/epoch - 26ms/step
Epoch 141/200
1493/1493 - 39s - loss: 1.5816e-04 - val_loss: 4.9190e-04 - 39s/epoch - 26ms/step
Epoch 142/200
1493/1493 - 39s - loss: 1.9622e-04 - val_loss: 1.5816e-04 - 39s/epoch - 26ms/step
Epoch 143/200
1493/1493 - 39s - loss: 1.5776e-04 - val_loss: 2.4143e-04 - 39s/epoch - 26ms/step
Epoch 144/200
1493/1493 - 39s - loss: 1.7381e-04 - val_loss: 1.6594e-04 - 39s/epoch - 26ms/step
Epoch 145/200
1493/1493 - 39s - loss: 1.5559e-04 - val_loss: 1.6082e-04 - 39s/epoch - 26ms/step
Epoch 146/200
1493/1493 - 39s - loss: 1.5437e-04 - val_loss: 1.8585e-04 - 39s/epoch - 26ms/step
Epoch 147/200
1493/1493 - 39s - loss: 1.5266e-04 - val_loss: 2.0469e-04 - 39s/epoch - 26ms/step
Epoch 148/200
1493/1493 - 39s - loss: 1.5745e-04 - val_loss: 2.5556e-04 - 39s/epoch - 26ms/step
Epoch 149/200
1493/1493 - 39s - loss: 1.5179e-04 - val_loss: 1.6611e-04 - 39s/epoch - 26ms/step
Epoch 150/200
1493/1493 - 39s - loss: 1.5105e-04 - val_loss: 1.5083e-04 - 39s/epoch - 26ms/step
Epoch 151/200
1493/1493 - 39s - loss: 1.5110e-04 - val_loss: 1.9725e-04 - 39s/epoch - 26ms/step
Epoch 152/200
1493/1493 - 39s - loss: 1.5532e-04 - val_loss: 3.3286e-04 - 39s/epoch - 26ms/step
Epoch 153/200
1493/1493 - 39s - loss: 1.7621e-04 - val_loss: 2.0316e-04 - 39s/epoch - 26ms/step
Epoch 154/200
1493/1493 - 39s - loss: 1.5096e-04 - val_loss: 2.1595e-04 - 39s/epoch - 26ms/step
Epoch 155/200
1493/1493 - 39s - loss: 1.5524e-04 - val_loss: 1.7929e-04 - 39s/epoch - 26ms/step
Epoch 156/200
1493/1493 - 39s - loss: 1.5381e-04 - val_loss: 1.6514e-04 - 39s/epoch - 26ms/step
Epoch 157/200
1493/1493 - 39s - loss: 1.5087e-04 - val_loss: 4.0375e-04 - 39s/epoch - 26ms/step
Epoch 158/200
1493/1493 - 39s - loss: 1.9006e-04 - val_loss: 1.6741e-04 - 39s/epoch - 26ms/step
Epoch 159/200
1493/1493 - 39s - loss: 1.5605e-04 - val_loss: 1.3769e-04 - 39s/epoch - 26ms/step
Epoch 160/200
1493/1493 - 39s - loss: 1.5045e-04 - val_loss: 2.1443e-04 - 39s/epoch - 26ms/step
Epoch 161/200
1493/1493 - 39s - loss: 1.6679e-04 - val_loss: 1.4452e-04 - 39s/epoch - 26ms/step
Epoch 162/200
1493/1493 - 38s - loss: 1.5082e-04 - val_loss: 1.6416e-04 - 38s/epoch - 26ms/step
Epoch 163/200
1493/1493 - 39s - loss: 1.5090e-04 - val_loss: 1.8755e-04 - 39s/epoch - 26ms/step
Epoch 164/200
1493/1493 - 38s - loss: 1.5335e-04 - val_loss: 1.7705e-04 - 38s/epoch - 26ms/step
Epoch 165/200
1493/1493 - 39s - loss: 1.6035e-04 - val_loss: 1.7986e-04 - 39s/epoch - 26ms/step
Epoch 166/200
1493/1493 - 39s - loss: 1.4787e-04 - val_loss: 1.5708e-04 - 39s/epoch - 26ms/step
Epoch 167/200
1493/1493 - 39s - loss: 1.4873e-04 - val_loss: 1.4864e-04 - 39s/epoch - 26ms/step
Epoch 168/200
1493/1493 - 39s - loss: 1.4844e-04 - val_loss: 1.5224e-04 - 39s/epoch - 26ms/step
Epoch 169/200
1493/1493 - 39s - loss: 1.4730e-04 - val_loss: 3.0555e-04 - 39s/epoch - 26ms/step
Epoch 170/200
1493/1493 - 39s - loss: 1.6094e-04 - val_loss: 3.2928e-04 - 39s/epoch - 26ms/step
Epoch 171/200
1493/1493 - 39s - loss: 1.8165e-04 - val_loss: 2.0369e-04 - 39s/epoch - 26ms/step
Epoch 172/200
1493/1493 - 39s - loss: 1.5143e-04 - val_loss: 2.0323e-04 - 39s/epoch - 26ms/step
Epoch 173/200
1493/1493 - 39s - loss: 1.4991e-04 - val_loss: 1.5242e-04 - 39s/epoch - 26ms/step
Epoch 174/200
1493/1493 - 39s - loss: 1.4476e-04 - val_loss: 2.2897e-04 - 39s/epoch - 26ms/step
Epoch 175/200
1493/1493 - 39s - loss: 1.4794e-04 - val_loss: 1.6879e-04 - 39s/epoch - 26ms/step
Epoch 176/200
1493/1493 - 39s - loss: 1.4879e-04 - val_loss: 2.9866e-04 - 39s/epoch - 26ms/step
Epoch 177/200
1493/1493 - 39s - loss: 1.5985e-04 - val_loss: 1.8462e-04 - 39s/epoch - 26ms/step
Epoch 178/200
1493/1493 - 39s - loss: 1.4748e-04 - val_loss: 1.5940e-04 - 39s/epoch - 26ms/step
Epoch 179/200
1493/1493 - 39s - loss: 1.4352e-04 - val_loss: 1.6550e-04 - 39s/epoch - 26ms/step
Epoch 180/200
1493/1493 - 39s - loss: 1.4372e-04 - val_loss: 2.9500e-04 - 39s/epoch - 26ms/step
Epoch 181/200
1493/1493 - 39s - loss: 1.5861e-04 - val_loss: 1.8783e-04 - 39s/epoch - 26ms/step
Epoch 182/200
1493/1493 - 39s - loss: 1.4653e-04 - val_loss: 1.6634e-04 - 39s/epoch - 26ms/step
Epoch 183/200
1493/1493 - 39s - loss: 1.4279e-04 - val_loss: 1.6647e-04 - 39s/epoch - 26ms/step
Epoch 184/200
1493/1493 - 39s - loss: 1.4463e-04 - val_loss: 1.5356e-04 - 39s/epoch - 26ms/step
Epoch 185/200
1493/1493 - 39s - loss: 1.4124e-04 - val_loss: 2.0577e-04 - 39s/epoch - 26ms/step
Epoch 186/200
1493/1493 - 39s - loss: 1.4259e-04 - val_loss: 1.4452e-04 - 39s/epoch - 26ms/step
Epoch 187/200
1493/1493 - 38s - loss: 1.4129e-04 - val_loss: 1.6866e-04 - 38s/epoch - 26ms/step
Epoch 188/200
1493/1493 - 39s - loss: 1.4146e-04 - val_loss: 2.0576e-04 - 39s/epoch - 26ms/step
Epoch 189/200
1493/1493 - 39s - loss: 1.4519e-04 - val_loss: 1.8402e-04 - 39s/epoch - 26ms/step
Epoch 190/200
1493/1493 - 39s - loss: 1.4585e-04 - val_loss: 2.1513e-04 - 39s/epoch - 26ms/step
Epoch 191/200
1493/1493 - 39s - loss: 1.4789e-04 - val_loss: 2.2316e-04 - 39s/epoch - 26ms/step
Epoch 192/200
1493/1493 - 39s - loss: 1.5080e-04 - val_loss: 2.9765e-04 - 39s/epoch - 26ms/step
Epoch 193/200
1493/1493 - 39s - loss: 1.7151e-04 - val_loss: 2.4422e-04 - 39s/epoch - 26ms/step
Epoch 194/200
1493/1493 - 39s - loss: 1.5966e-04 - val_loss: 2.0578e-04 - 39s/epoch - 26ms/step
Epoch 195/200
1493/1493 - 39s - loss: 1.5229e-04 - val_loss: 1.7750e-04 - 39s/epoch - 26ms/step
Epoch 196/200
1493/1493 - 39s - loss: 1.4408e-04 - val_loss: 1.6018e-04 - 39s/epoch - 26ms/step
Epoch 197/200
1493/1493 - 39s - loss: 1.4172e-04 - val_loss: 2.2131e-04 - 39s/epoch - 26ms/step
Epoch 198/200
1493/1493 - 39s - loss: 1.4497e-04 - val_loss: 1.9573e-04 - 39s/epoch - 26ms/step
Epoch 199/200
1493/1493 - 39s - loss: 1.4999e-04 - val_loss: 1.5029e-04 - 39s/epoch - 26ms/step
Epoch 200/200
1493/1493 - 39s - loss: 1.4031e-04 - val_loss: 1.6007e-04 - 39s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00016007396334316581
  1/332 [..............................] - ETA: 27s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 95/332 [=======>......................] - ETA: 0s111/332 [=========>....................] - ETA: 0s127/332 [==========>...................] - ETA: 0s142/332 [===========>..................] - ETA: 0s158/332 [=============>................] - ETA: 0s174/332 [==============>...............] - ETA: 0s190/332 [================>.............] - ETA: 0s206/332 [=================>............] - ETA: 0s222/332 [===================>..........] - ETA: 0s238/332 [====================>.........] - ETA: 0s254/332 [=====================>........] - ETA: 0s270/332 [=======================>......] - ETA: 0s286/332 [========================>.....] - ETA: 0s302/332 [==========================>...] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0018340671484846913
cosine 0.0014448136349601473
MAE: 0.007123843
RMSE: 0.012652029
r2: 0.9896159108670951
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       multiple                  0         
                                                                 
 dense_21 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_21 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_22 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 632)               0         
                                                                 
 dense_22 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_23 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 1264)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_23 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_22 (InputLayer)       multiple                  0         
                                                                 
 dense_21 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_21 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_24 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_22 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 632)               0         
                                                                 
 dense_22 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_23 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 1264)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 200, 0.001, 0.5, 632, 0.00014030789316166192, 0.00016007396334316581, 0.0018340671484846913, 0.0014448136349601473, 0.007123842835426331, 0.012652029283344746, 0.9896159108670951, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_24 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_24 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_25 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 632)               0         
                                                                 
 dense_25 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_26 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 1264)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/200
1493/1493 - 40s - loss: 0.0074 - val_loss: 0.0028 - 40s/epoch - 27ms/step
Epoch 2/200
1493/1493 - 39s - loss: 0.0024 - val_loss: 0.0024 - 39s/epoch - 26ms/step
Epoch 3/200
1493/1493 - 39s - loss: 0.0019 - val_loss: 0.0020 - 39s/epoch - 26ms/step
Epoch 4/200
1493/1493 - 39s - loss: 0.0016 - val_loss: 0.0019 - 39s/epoch - 26ms/step
Epoch 5/200
1493/1493 - 39s - loss: 0.0013 - val_loss: 0.0012 - 39s/epoch - 26ms/step
Epoch 6/200
1493/1493 - 39s - loss: 0.0011 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 7/200
1493/1493 - 39s - loss: 9.9683e-04 - val_loss: 8.0820e-04 - 39s/epoch - 26ms/step
Epoch 8/200
1493/1493 - 39s - loss: 8.2103e-04 - val_loss: 8.1233e-04 - 39s/epoch - 26ms/step
Epoch 9/200
1493/1493 - 39s - loss: 7.0571e-04 - val_loss: 6.9548e-04 - 39s/epoch - 26ms/step
Epoch 10/200
1493/1493 - 39s - loss: 6.4022e-04 - val_loss: 5.8912e-04 - 39s/epoch - 26ms/step
Epoch 11/200
1493/1493 - 39s - loss: 5.8519e-04 - val_loss: 6.0417e-04 - 39s/epoch - 26ms/step
Epoch 12/200
1493/1493 - 39s - loss: 5.4164e-04 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 13/200
1493/1493 - 39s - loss: 6.4115e-04 - val_loss: 0.0034 - 39s/epoch - 26ms/step
Epoch 14/200
1493/1493 - 39s - loss: 9.6010e-04 - val_loss: 5.4131e-04 - 39s/epoch - 26ms/step
Epoch 15/200
1493/1493 - 39s - loss: 5.5818e-04 - val_loss: 5.3841e-04 - 39s/epoch - 26ms/step
Epoch 16/200
1493/1493 - 39s - loss: 5.0083e-04 - val_loss: 8.6692e-04 - 39s/epoch - 26ms/step
Epoch 17/200
1493/1493 - 39s - loss: 5.5007e-04 - val_loss: 4.6889e-04 - 39s/epoch - 26ms/step
Epoch 18/200
1493/1493 - 39s - loss: 4.6426e-04 - val_loss: 0.0013 - 39s/epoch - 26ms/step
Epoch 19/200
1493/1493 - 39s - loss: 5.9829e-04 - val_loss: 4.5676e-04 - 39s/epoch - 26ms/step
Epoch 20/200
1493/1493 - 39s - loss: 4.5263e-04 - val_loss: 4.2092e-04 - 39s/epoch - 26ms/step
Epoch 21/200
1493/1493 - 39s - loss: 4.2736e-04 - val_loss: 4.1076e-04 - 39s/epoch - 26ms/step
Epoch 22/200
1493/1493 - 39s - loss: 4.1802e-04 - val_loss: 8.8562e-04 - 39s/epoch - 26ms/step
Epoch 23/200
1493/1493 - 39s - loss: 4.8762e-04 - val_loss: 7.1713e-04 - 39s/epoch - 26ms/step
Epoch 24/200
1493/1493 - 39s - loss: 4.4263e-04 - val_loss: 4.3954e-04 - 39s/epoch - 26ms/step
Epoch 25/200
1493/1493 - 39s - loss: 4.0713e-04 - val_loss: 3.8157e-04 - 39s/epoch - 26ms/step
Epoch 26/200
1493/1493 - 39s - loss: 3.7915e-04 - val_loss: 4.4176e-04 - 39s/epoch - 26ms/step
Epoch 27/200
1493/1493 - 39s - loss: 3.7020e-04 - val_loss: 3.3872e-04 - 39s/epoch - 26ms/step
Epoch 28/200
1493/1493 - 39s - loss: 3.6276e-04 - val_loss: 3.4669e-04 - 39s/epoch - 26ms/step
Epoch 29/200
1493/1493 - 39s - loss: 3.5673e-04 - val_loss: 3.8144e-04 - 39s/epoch - 26ms/step
Epoch 30/200
1493/1493 - 39s - loss: 3.5301e-04 - val_loss: 3.3619e-04 - 39s/epoch - 26ms/step
Epoch 31/200
1493/1493 - 39s - loss: 3.4443e-04 - val_loss: 4.6835e-04 - 39s/epoch - 26ms/step
Epoch 32/200
1493/1493 - 39s - loss: 3.6992e-04 - val_loss: 2.7652e-04 - 39s/epoch - 26ms/step
Epoch 33/200
1493/1493 - 39s - loss: 3.3506e-04 - val_loss: 2.9013e-04 - 39s/epoch - 26ms/step
Epoch 34/200
1493/1493 - 39s - loss: 3.2693e-04 - val_loss: 3.0992e-04 - 39s/epoch - 26ms/step
Epoch 35/200
1493/1493 - 39s - loss: 3.2847e-04 - val_loss: 4.3115e-04 - 39s/epoch - 26ms/step
Epoch 36/200
1493/1493 - 39s - loss: 3.4037e-04 - val_loss: 3.4106e-04 - 39s/epoch - 26ms/step
Epoch 37/200
1493/1493 - 39s - loss: 3.2971e-04 - val_loss: 6.4224e-04 - 39s/epoch - 26ms/step
Epoch 38/200
1493/1493 - 39s - loss: 3.9038e-04 - val_loss: 4.2121e-04 - 39s/epoch - 26ms/step
Epoch 39/200
1493/1493 - 39s - loss: 3.4398e-04 - val_loss: 2.7753e-04 - 39s/epoch - 26ms/step
Epoch 40/200
1493/1493 - 39s - loss: 3.1361e-04 - val_loss: 3.6197e-04 - 39s/epoch - 26ms/step
Epoch 41/200
1493/1493 - 39s - loss: 3.1625e-04 - val_loss: 2.6705e-04 - 39s/epoch - 26ms/step
Epoch 42/200
1493/1493 - 39s - loss: 3.0643e-04 - val_loss: 2.7737e-04 - 39s/epoch - 26ms/step
Epoch 43/200
1493/1493 - 39s - loss: 3.0138e-04 - val_loss: 3.2099e-04 - 39s/epoch - 26ms/step
Epoch 44/200
1493/1493 - 39s - loss: 3.0755e-04 - val_loss: 6.1013e-04 - 39s/epoch - 26ms/step
Epoch 45/200
1493/1493 - 39s - loss: 3.7973e-04 - val_loss: 2.4630e-04 - 39s/epoch - 26ms/step
Epoch 46/200
1493/1493 - 39s - loss: 3.0183e-04 - val_loss: 2.5177e-04 - 39s/epoch - 26ms/step
Epoch 47/200
1493/1493 - 39s - loss: 2.9474e-04 - val_loss: 4.5069e-04 - 39s/epoch - 26ms/step
Epoch 48/200
1493/1493 - 39s - loss: 3.1897e-04 - val_loss: 3.1749e-04 - 39s/epoch - 26ms/step
Epoch 49/200
1493/1493 - 39s - loss: 2.9765e-04 - val_loss: 5.5977e-04 - 39s/epoch - 26ms/step
Epoch 50/200
1493/1493 - 39s - loss: 3.4911e-04 - val_loss: 3.9604e-04 - 39s/epoch - 26ms/step
Epoch 51/200
1493/1493 - 39s - loss: 2.9569e-04 - val_loss: 2.3608e-04 - 39s/epoch - 26ms/step
Epoch 52/200
1493/1493 - 39s - loss: 2.8279e-04 - val_loss: 2.3977e-04 - 39s/epoch - 26ms/step
Epoch 53/200
1493/1493 - 39s - loss: 2.8537e-04 - val_loss: 2.5194e-04 - 39s/epoch - 26ms/step
Epoch 54/200
1493/1493 - 39s - loss: 2.8002e-04 - val_loss: 2.6417e-04 - 39s/epoch - 26ms/step
Epoch 55/200
1493/1493 - 39s - loss: 2.7459e-04 - val_loss: 2.3385e-04 - 39s/epoch - 26ms/step
Epoch 56/200
1493/1493 - 39s - loss: 2.7368e-04 - val_loss: 2.6729e-04 - 39s/epoch - 26ms/step
Epoch 57/200
1493/1493 - 39s - loss: 2.8929e-04 - val_loss: 2.4445e-04 - 39s/epoch - 26ms/step
Epoch 58/200
1493/1493 - 39s - loss: 2.7088e-04 - val_loss: 2.4274e-04 - 39s/epoch - 26ms/step
Epoch 59/200
1493/1493 - 39s - loss: 2.6929e-04 - val_loss: 6.0312e-04 - 39s/epoch - 26ms/step
Epoch 60/200
1493/1493 - 39s - loss: 3.2224e-04 - val_loss: 2.5301e-04 - 39s/epoch - 26ms/step
Epoch 61/200
1493/1493 - 39s - loss: 2.7034e-04 - val_loss: 2.3379e-04 - 39s/epoch - 26ms/step
Epoch 62/200
1493/1493 - 39s - loss: 3.1228e-04 - val_loss: 2.9759e-04 - 39s/epoch - 26ms/step
Epoch 63/200
1493/1493 - 39s - loss: 2.7665e-04 - val_loss: 2.8054e-04 - 39s/epoch - 26ms/step
Epoch 64/200
1493/1493 - 39s - loss: 2.6921e-04 - val_loss: 4.0281e-04 - 39s/epoch - 26ms/step
Epoch 65/200
1493/1493 - 39s - loss: 2.8307e-04 - val_loss: 3.0301e-04 - 39s/epoch - 26ms/step
Epoch 66/200
1493/1493 - 39s - loss: 2.7644e-04 - val_loss: 2.4300e-04 - 39s/epoch - 26ms/step
Epoch 67/200
1493/1493 - 39s - loss: 2.6098e-04 - val_loss: 2.1805e-04 - 39s/epoch - 26ms/step
Epoch 68/200
1493/1493 - 39s - loss: 2.6158e-04 - val_loss: 6.2996e-04 - 39s/epoch - 26ms/step
Epoch 69/200
1493/1493 - 39s - loss: 3.6993e-04 - val_loss: 2.7240e-04 - 39s/epoch - 26ms/step
Epoch 70/200
1493/1493 - 39s - loss: 2.7715e-04 - val_loss: 3.8201e-04 - 39s/epoch - 26ms/step
Epoch 71/200
1493/1493 - 39s - loss: 2.7589e-04 - val_loss: 2.2940e-04 - 39s/epoch - 26ms/step
Epoch 72/200
1493/1493 - 39s - loss: 2.6968e-04 - val_loss: 6.4899e-04 - 39s/epoch - 26ms/step
Epoch 73/200
1493/1493 - 39s - loss: 3.4192e-04 - val_loss: 9.8173e-04 - 39s/epoch - 26ms/step
Epoch 74/200
1493/1493 - 39s - loss: 3.4306e-04 - val_loss: 2.5646e-04 - 39s/epoch - 26ms/step
Epoch 75/200
1493/1493 - 39s - loss: 2.8229e-04 - val_loss: 3.3645e-04 - 39s/epoch - 26ms/step
Epoch 76/200
1493/1493 - 39s - loss: 2.9872e-04 - val_loss: 2.3507e-04 - 39s/epoch - 26ms/step
Epoch 77/200
1493/1493 - 39s - loss: 2.7070e-04 - val_loss: 6.2126e-04 - 39s/epoch - 26ms/step
Epoch 78/200
1493/1493 - 39s - loss: 3.5084e-04 - val_loss: 3.4951e-04 - 39s/epoch - 26ms/step
Epoch 79/200
1493/1493 - 39s - loss: 2.8446e-04 - val_loss: 2.7249e-04 - 39s/epoch - 26ms/step
Epoch 80/200
1493/1493 - 39s - loss: 2.6905e-04 - val_loss: 2.4273e-04 - 39s/epoch - 26ms/step
Epoch 81/200
1493/1493 - 39s - loss: 2.6363e-04 - val_loss: 3.7542e-04 - 39s/epoch - 26ms/step
Epoch 82/200
1493/1493 - 39s - loss: 2.6323e-04 - val_loss: 2.2868e-04 - 39s/epoch - 26ms/step
Epoch 83/200
1493/1493 - 39s - loss: 2.5596e-04 - val_loss: 2.1693e-04 - 39s/epoch - 26ms/step
Epoch 84/200
1493/1493 - 39s - loss: 2.5347e-04 - val_loss: 3.2816e-04 - 39s/epoch - 26ms/step
Epoch 85/200
1493/1493 - 39s - loss: 2.6825e-04 - val_loss: 4.5257e-04 - 39s/epoch - 26ms/step
Epoch 86/200
1493/1493 - 39s - loss: 2.9013e-04 - val_loss: 2.1421e-04 - 39s/epoch - 26ms/step
Epoch 87/200
1493/1493 - 39s - loss: 2.5041e-04 - val_loss: 2.3832e-04 - 39s/epoch - 26ms/step
Epoch 88/200
1493/1493 - 39s - loss: 2.4791e-04 - val_loss: 3.4446e-04 - 39s/epoch - 26ms/step
Epoch 89/200
1493/1493 - 39s - loss: 2.7029e-04 - val_loss: 2.1518e-04 - 39s/epoch - 26ms/step
Epoch 90/200
1493/1493 - 39s - loss: 2.4479e-04 - val_loss: 2.3022e-04 - 39s/epoch - 26ms/step
Epoch 91/200
1493/1493 - 39s - loss: 2.4277e-04 - val_loss: 2.4435e-04 - 39s/epoch - 26ms/step
Epoch 92/200
1493/1493 - 39s - loss: 2.4398e-04 - val_loss: 3.6731e-04 - 39s/epoch - 26ms/step
Epoch 93/200
1493/1493 - 39s - loss: 2.9031e-04 - val_loss: 2.4839e-04 - 39s/epoch - 26ms/step
Epoch 94/200
1493/1493 - 39s - loss: 2.4660e-04 - val_loss: 1.9987e-04 - 39s/epoch - 26ms/step
Epoch 95/200
1493/1493 - 39s - loss: 2.4370e-04 - val_loss: 2.3098e-04 - 39s/epoch - 26ms/step
Epoch 96/200
1493/1493 - 39s - loss: 2.4082e-04 - val_loss: 3.1157e-04 - 39s/epoch - 26ms/step
Epoch 97/200
1493/1493 - 39s - loss: 2.5107e-04 - val_loss: 3.3992e-04 - 39s/epoch - 26ms/step
Epoch 98/200
1493/1493 - 39s - loss: 2.3987e-04 - val_loss: 3.4597e-04 - 39s/epoch - 26ms/step
Epoch 99/200
1493/1493 - 39s - loss: 2.6373e-04 - val_loss: 2.1811e-04 - 39s/epoch - 26ms/step
Epoch 100/200
1493/1493 - 39s - loss: 2.4375e-04 - val_loss: 2.3537e-04 - 39s/epoch - 26ms/step
Epoch 101/200
1493/1493 - 39s - loss: 2.3946e-04 - val_loss: 5.0871e-04 - 39s/epoch - 26ms/step
Epoch 102/200
1493/1493 - 39s - loss: 2.9454e-04 - val_loss: 5.3844e-04 - 39s/epoch - 26ms/step
Epoch 103/200
1493/1493 - 39s - loss: 3.2320e-04 - val_loss: 2.0498e-04 - 39s/epoch - 26ms/step
Epoch 104/200
1493/1493 - 39s - loss: 2.5170e-04 - val_loss: 7.5177e-04 - 39s/epoch - 26ms/step
Epoch 105/200
1493/1493 - 39s - loss: 2.8432e-04 - val_loss: 2.1837e-04 - 39s/epoch - 26ms/step
Epoch 106/200
1493/1493 - 39s - loss: 2.4251e-04 - val_loss: 3.2121e-04 - 39s/epoch - 26ms/step
Epoch 107/200
1493/1493 - 39s - loss: 2.5724e-04 - val_loss: 2.5253e-04 - 39s/epoch - 26ms/step
Epoch 108/200
1493/1493 - 39s - loss: 2.4184e-04 - val_loss: 2.1702e-04 - 39s/epoch - 26ms/step
Epoch 109/200
1493/1493 - 39s - loss: 2.3663e-04 - val_loss: 2.2653e-04 - 39s/epoch - 26ms/step
Epoch 110/200
1493/1493 - 39s - loss: 2.3469e-04 - val_loss: 2.1599e-04 - 39s/epoch - 26ms/step
Epoch 111/200
1493/1493 - 39s - loss: 2.3422e-04 - val_loss: 2.2156e-04 - 39s/epoch - 26ms/step
Epoch 112/200
1493/1493 - 39s - loss: 2.3151e-04 - val_loss: 2.0027e-04 - 39s/epoch - 26ms/step
Epoch 113/200
1493/1493 - 39s - loss: 2.2808e-04 - val_loss: 3.1585e-04 - 39s/epoch - 26ms/step
Epoch 114/200
1493/1493 - 39s - loss: 2.6137e-04 - val_loss: 2.5098e-04 - 39s/epoch - 26ms/step
Epoch 115/200
1493/1493 - 39s - loss: 2.4219e-04 - val_loss: 7.3085e-04 - 39s/epoch - 26ms/step
Epoch 116/200
1493/1493 - 39s - loss: 3.0579e-04 - val_loss: 4.0435e-04 - 39s/epoch - 26ms/step
Epoch 117/200
1493/1493 - 39s - loss: 2.4494e-04 - val_loss: 2.2408e-04 - 39s/epoch - 26ms/step
Epoch 118/200
1493/1493 - 39s - loss: 2.3447e-04 - val_loss: 1.8860e-04 - 39s/epoch - 26ms/step
Epoch 119/200
1493/1493 - 39s - loss: 2.2910e-04 - val_loss: 2.0271e-04 - 39s/epoch - 26ms/step
Epoch 120/200
1493/1493 - 39s - loss: 2.2701e-04 - val_loss: 2.0412e-04 - 39s/epoch - 26ms/step
Epoch 121/200
1493/1493 - 39s - loss: 2.2811e-04 - val_loss: 2.8872e-04 - 39s/epoch - 26ms/step
Epoch 122/200
1493/1493 - 39s - loss: 2.3350e-04 - val_loss: 2.4427e-04 - 39s/epoch - 26ms/step
Epoch 123/200
1493/1493 - 39s - loss: 2.2914e-04 - val_loss: 2.1856e-04 - 39s/epoch - 26ms/step
Epoch 124/200
1493/1493 - 39s - loss: 2.2467e-04 - val_loss: 2.1978e-04 - 39s/epoch - 26ms/step
Epoch 125/200
1493/1493 - 39s - loss: 2.2431e-04 - val_loss: 2.1306e-04 - 39s/epoch - 26ms/step
Epoch 126/200
1493/1493 - 39s - loss: 2.2367e-04 - val_loss: 3.8269e-04 - 39s/epoch - 26ms/step
Epoch 127/200
1493/1493 - 39s - loss: 2.3618e-04 - val_loss: 4.1809e-04 - 39s/epoch - 26ms/step
Epoch 128/200
1493/1493 - 39s - loss: 2.5249e-04 - val_loss: 2.2437e-04 - 39s/epoch - 26ms/step
Epoch 129/200
1493/1493 - 39s - loss: 2.2821e-04 - val_loss: 1.7789e-04 - 39s/epoch - 26ms/step
Epoch 130/200
1493/1493 - 39s - loss: 2.2142e-04 - val_loss: 1.8978e-04 - 39s/epoch - 26ms/step
Epoch 131/200
1493/1493 - 39s - loss: 2.2260e-04 - val_loss: 2.3634e-04 - 39s/epoch - 26ms/step
Epoch 132/200
1493/1493 - 39s - loss: 2.2529e-04 - val_loss: 3.9753e-04 - 39s/epoch - 26ms/step
Epoch 133/200
1493/1493 - 39s - loss: 2.7187e-04 - val_loss: 2.3591e-04 - 39s/epoch - 26ms/step
Epoch 134/200
1493/1493 - 39s - loss: 2.3107e-04 - val_loss: 1.8293e-04 - 39s/epoch - 26ms/step
Epoch 135/200
1493/1493 - 39s - loss: 2.1985e-04 - val_loss: 1.9575e-04 - 39s/epoch - 26ms/step
Epoch 136/200
1493/1493 - 39s - loss: 2.1747e-04 - val_loss: 2.2428e-04 - 39s/epoch - 26ms/step
Epoch 137/200
1493/1493 - 39s - loss: 2.1970e-04 - val_loss: 2.0527e-04 - 39s/epoch - 26ms/step
Epoch 138/200
1493/1493 - 39s - loss: 2.1791e-04 - val_loss: 3.1643e-04 - 39s/epoch - 26ms/step
Epoch 139/200
1493/1493 - 39s - loss: 2.4405e-04 - val_loss: 2.6858e-04 - 39s/epoch - 26ms/step
Epoch 140/200
1493/1493 - 39s - loss: 2.3180e-04 - val_loss: 1.8290e-04 - 39s/epoch - 26ms/step
Epoch 141/200
1493/1493 - 39s - loss: 2.2074e-04 - val_loss: 5.1169e-04 - 39s/epoch - 26ms/step
Epoch 142/200
1493/1493 - 39s - loss: 2.9965e-04 - val_loss: 2.0406e-04 - 39s/epoch - 26ms/step
Epoch 143/200
1493/1493 - 39s - loss: 2.2675e-04 - val_loss: 2.1588e-04 - 39s/epoch - 26ms/step
Epoch 144/200
1493/1493 - 39s - loss: 2.3834e-04 - val_loss: 2.1050e-04 - 39s/epoch - 26ms/step
Epoch 145/200
1493/1493 - 39s - loss: 2.2418e-04 - val_loss: 1.8513e-04 - 39s/epoch - 26ms/step
Epoch 146/200
1493/1493 - 39s - loss: 2.1629e-04 - val_loss: 2.0899e-04 - 39s/epoch - 26ms/step
Epoch 147/200
1493/1493 - 39s - loss: 2.1593e-04 - val_loss: 3.1251e-04 - 39s/epoch - 26ms/step
Epoch 148/200
1493/1493 - 39s - loss: 2.3208e-04 - val_loss: 2.1113e-04 - 39s/epoch - 26ms/step
Epoch 149/200
1493/1493 - 39s - loss: 2.1177e-04 - val_loss: 1.9983e-04 - 39s/epoch - 26ms/step
Epoch 150/200
1493/1493 - 39s - loss: 2.1206e-04 - val_loss: 1.9255e-04 - 39s/epoch - 26ms/step
Epoch 151/200
1493/1493 - 39s - loss: 2.1303e-04 - val_loss: 2.1566e-04 - 39s/epoch - 26ms/step
Epoch 152/200
1493/1493 - 39s - loss: 2.2362e-04 - val_loss: 4.0395e-04 - 39s/epoch - 26ms/step
Epoch 153/200
1493/1493 - 39s - loss: 2.4390e-04 - val_loss: 1.9116e-04 - 39s/epoch - 26ms/step
Epoch 154/200
1493/1493 - 39s - loss: 2.1268e-04 - val_loss: 3.3933e-04 - 39s/epoch - 26ms/step
Epoch 155/200
1493/1493 - 39s - loss: 2.4070e-04 - val_loss: 2.0699e-04 - 39s/epoch - 26ms/step
Epoch 156/200
1493/1493 - 39s - loss: 2.1590e-04 - val_loss: 2.0223e-04 - 39s/epoch - 26ms/step
Epoch 157/200
1493/1493 - 39s - loss: 2.1103e-04 - val_loss: 1.9499e-04 - 39s/epoch - 26ms/step
Epoch 158/200
1493/1493 - 39s - loss: 2.1053e-04 - val_loss: 1.9658e-04 - 39s/epoch - 26ms/step
Epoch 159/200
1493/1493 - 39s - loss: 2.0980e-04 - val_loss: 1.7525e-04 - 39s/epoch - 26ms/step
Epoch 160/200
1493/1493 - 39s - loss: 2.1047e-04 - val_loss: 3.2476e-04 - 39s/epoch - 26ms/step
Epoch 161/200
1493/1493 - 39s - loss: 2.5261e-04 - val_loss: 1.9484e-04 - 39s/epoch - 26ms/step
Epoch 162/200
1493/1493 - 39s - loss: 2.1189e-04 - val_loss: 1.7825e-04 - 39s/epoch - 26ms/step
Epoch 163/200
1493/1493 - 39s - loss: 2.1023e-04 - val_loss: 2.7179e-04 - 39s/epoch - 26ms/step
Epoch 164/200
1493/1493 - 39s - loss: 2.1775e-04 - val_loss: 2.9516e-04 - 39s/epoch - 26ms/step
Epoch 165/200
1493/1493 - 39s - loss: 2.1794e-04 - val_loss: 1.8664e-04 - 39s/epoch - 26ms/step
Epoch 166/200
1493/1493 - 39s - loss: 2.0799e-04 - val_loss: 1.9103e-04 - 39s/epoch - 26ms/step
Epoch 167/200
1493/1493 - 39s - loss: 2.0980e-04 - val_loss: 1.8820e-04 - 39s/epoch - 26ms/step
Epoch 168/200
1493/1493 - 39s - loss: 2.1155e-04 - val_loss: 1.8990e-04 - 39s/epoch - 26ms/step
Epoch 169/200
1493/1493 - 39s - loss: 2.0662e-04 - val_loss: 3.9879e-04 - 39s/epoch - 26ms/step
Epoch 170/200
1493/1493 - 39s - loss: 2.2655e-04 - val_loss: 2.9992e-04 - 39s/epoch - 26ms/step
Epoch 171/200
1493/1493 - 39s - loss: 2.3136e-04 - val_loss: 2.4213e-04 - 39s/epoch - 26ms/step
Epoch 172/200
1493/1493 - 39s - loss: 2.1013e-04 - val_loss: 2.4630e-04 - 39s/epoch - 26ms/step
Epoch 173/200
1493/1493 - 39s - loss: 2.1815e-04 - val_loss: 2.3396e-04 - 39s/epoch - 26ms/step
Epoch 174/200
1493/1493 - 39s - loss: 2.1362e-04 - val_loss: 2.0844e-04 - 39s/epoch - 26ms/step
Epoch 175/200
1493/1493 - 39s - loss: 2.0569e-04 - val_loss: 2.1053e-04 - 39s/epoch - 26ms/step
Epoch 176/200
1493/1493 - 39s - loss: 2.0903e-04 - val_loss: 3.7973e-04 - 39s/epoch - 26ms/step
Epoch 177/200
1493/1493 - 39s - loss: 2.4454e-04 - val_loss: 1.9595e-04 - 39s/epoch - 26ms/step
Epoch 178/200
1493/1493 - 39s - loss: 2.1041e-04 - val_loss: 1.7406e-04 - 39s/epoch - 26ms/step
Epoch 179/200
1493/1493 - 39s - loss: 2.0370e-04 - val_loss: 1.9602e-04 - 39s/epoch - 26ms/step
Epoch 180/200
1493/1493 - 39s - loss: 2.0405e-04 - val_loss: 3.8601e-04 - 39s/epoch - 26ms/step
Epoch 181/200
1493/1493 - 39s - loss: 2.3728e-04 - val_loss: 1.9493e-04 - 39s/epoch - 26ms/step
Epoch 182/200
1493/1493 - 39s - loss: 2.1038e-04 - val_loss: 2.2397e-04 - 39s/epoch - 26ms/step
Epoch 183/200
1493/1493 - 39s - loss: 2.0350e-04 - val_loss: 2.0063e-04 - 39s/epoch - 26ms/step
Epoch 184/200
1493/1493 - 39s - loss: 2.1121e-04 - val_loss: 1.6662e-04 - 39s/epoch - 26ms/step
Epoch 185/200
1493/1493 - 39s - loss: 2.0141e-04 - val_loss: 2.3245e-04 - 39s/epoch - 26ms/step
Epoch 186/200
1493/1493 - 39s - loss: 2.0324e-04 - val_loss: 1.7515e-04 - 39s/epoch - 26ms/step
Epoch 187/200
1493/1493 - 39s - loss: 2.0010e-04 - val_loss: 1.7353e-04 - 39s/epoch - 26ms/step
Epoch 188/200
1493/1493 - 39s - loss: 2.0017e-04 - val_loss: 2.3101e-04 - 39s/epoch - 26ms/step
Epoch 189/200
1493/1493 - 39s - loss: 2.1512e-04 - val_loss: 1.8928e-04 - 39s/epoch - 26ms/step
Epoch 190/200
1493/1493 - 39s - loss: 2.0244e-04 - val_loss: 1.9151e-04 - 39s/epoch - 26ms/step
Epoch 191/200
1493/1493 - 39s - loss: 2.0614e-04 - val_loss: 6.6297e-04 - 39s/epoch - 26ms/step
Epoch 192/200
1493/1493 - 39s - loss: 2.8126e-04 - val_loss: 3.8165e-04 - 39s/epoch - 26ms/step
Epoch 193/200
1493/1493 - 39s - loss: 2.5634e-04 - val_loss: 2.5512e-04 - 39s/epoch - 26ms/step
Epoch 194/200
1493/1493 - 39s - loss: 2.1540e-04 - val_loss: 5.3077e-04 - 39s/epoch - 26ms/step
Epoch 195/200
1493/1493 - 39s - loss: 2.3989e-04 - val_loss: 3.5175e-04 - 39s/epoch - 26ms/step
Epoch 196/200
1493/1493 - 39s - loss: 2.1717e-04 - val_loss: 2.0044e-04 - 39s/epoch - 26ms/step
Epoch 197/200
1493/1493 - 39s - loss: 2.0480e-04 - val_loss: 3.1160e-04 - 39s/epoch - 26ms/step
Epoch 198/200
1493/1493 - 39s - loss: 2.1276e-04 - val_loss: 2.6392e-04 - 39s/epoch - 26ms/step
Epoch 199/200
1493/1493 - 39s - loss: 2.0572e-04 - val_loss: 1.9081e-04 - 39s/epoch - 26ms/step
Epoch 200/200
1493/1493 - 39s - loss: 2.0215e-04 - val_loss: 1.8672e-04 - 39s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.0001867224636953324
  1/332 [..............................] - ETA: 26s 16/332 [>.............................] - ETA: 1s  31/332 [=>............................] - ETA: 1s 46/332 [===>..........................] - ETA: 0s 61/332 [====>.........................] - ETA: 0s 76/332 [=====>........................] - ETA: 0s 91/332 [=======>......................] - ETA: 0s106/332 [========>.....................] - ETA: 0s121/332 [=========>....................] - ETA: 0s136/332 [===========>..................] - ETA: 0s151/332 [============>.................] - ETA: 0s166/332 [==============>...............] - ETA: 0s181/332 [===============>..............] - ETA: 0s196/332 [================>.............] - ETA: 0s211/332 [==================>...........] - ETA: 0s226/332 [===================>..........] - ETA: 0s241/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s286/332 [========================>.....] - ETA: 0s301/332 [==========================>...] - ETA: 0s316/332 [===========================>..] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.002135980462875179
cosine 0.0016832155043163077
MAE: 0.0076820473
RMSE: 0.01366464
r2: 0.9878871568632407
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       multiple                  0         
                                                                 
 dense_24 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_24 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_25 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 632)               0         
                                                                 
 dense_25 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_26 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 1264)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_26 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_25 (InputLayer)       multiple                  0         
                                                                 
 dense_24 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_24 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_27 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_25 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 632)               0         
                                                                 
 dense_25 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_26 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 1264)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 200, 0.002, 0.5, 632, 0.00020214635878801346, 0.0001867224636953324, 0.002135980462875179, 0.0016832155043163077, 0.007682047318667173, 0.013664639554917812, 0.9878871568632407, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_27 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_27 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_28 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 632)               0         
                                                                 
 dense_28 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_29 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 1264)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
1493/1493 - 39s - loss: 0.0093 - val_loss: 0.0044 - 39s/epoch - 26ms/step
Epoch 2/300
1493/1493 - 38s - loss: 0.0032 - val_loss: 0.0029 - 38s/epoch - 26ms/step
Epoch 3/300
1493/1493 - 38s - loss: 0.0022 - val_loss: 0.0019 - 38s/epoch - 26ms/step
Epoch 4/300
1493/1493 - 39s - loss: 0.0017 - val_loss: 0.0021 - 39s/epoch - 26ms/step
Epoch 5/300
1493/1493 - 38s - loss: 0.0015 - val_loss: 0.0012 - 38s/epoch - 26ms/step
Epoch 6/300
1493/1493 - 38s - loss: 0.0013 - val_loss: 0.0014 - 38s/epoch - 26ms/step
Epoch 7/300
1493/1493 - 39s - loss: 0.0012 - val_loss: 9.8929e-04 - 39s/epoch - 26ms/step
Epoch 8/300
1493/1493 - 38s - loss: 0.0011 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 9/300
1493/1493 - 38s - loss: 0.0010 - val_loss: 0.0015 - 38s/epoch - 26ms/step
Epoch 10/300
1493/1493 - 39s - loss: 9.9424e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 11/300
1493/1493 - 38s - loss: 9.1341e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 12/300
1493/1493 - 39s - loss: 8.2142e-04 - val_loss: 8.6675e-04 - 39s/epoch - 26ms/step
Epoch 13/300
1493/1493 - 39s - loss: 8.0730e-04 - val_loss: 0.0017 - 39s/epoch - 26ms/step
Epoch 14/300
1493/1493 - 38s - loss: 8.1315e-04 - val_loss: 7.1266e-04 - 38s/epoch - 26ms/step
Epoch 15/300
1493/1493 - 39s - loss: 7.6038e-04 - val_loss: 6.8245e-04 - 39s/epoch - 26ms/step
Epoch 16/300
1493/1493 - 39s - loss: 6.9313e-04 - val_loss: 8.6951e-04 - 39s/epoch - 26ms/step
Epoch 17/300
1493/1493 - 39s - loss: 6.7331e-04 - val_loss: 9.3802e-04 - 39s/epoch - 26ms/step
Epoch 18/300
1493/1493 - 38s - loss: 6.6801e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 19/300
1493/1493 - 38s - loss: 6.7218e-04 - val_loss: 8.1788e-04 - 38s/epoch - 26ms/step
Epoch 20/300
1493/1493 - 39s - loss: 6.2862e-04 - val_loss: 7.2695e-04 - 39s/epoch - 26ms/step
Epoch 21/300
1493/1493 - 38s - loss: 6.0220e-04 - val_loss: 8.0528e-04 - 38s/epoch - 26ms/step
Epoch 22/300
1493/1493 - 39s - loss: 5.8329e-04 - val_loss: 7.1735e-04 - 39s/epoch - 26ms/step
Epoch 23/300
1493/1493 - 39s - loss: 5.6999e-04 - val_loss: 9.8317e-04 - 39s/epoch - 26ms/step
Epoch 24/300
1493/1493 - 38s - loss: 5.6438e-04 - val_loss: 5.5503e-04 - 38s/epoch - 26ms/step
Epoch 25/300
1493/1493 - 38s - loss: 5.3013e-04 - val_loss: 5.7679e-04 - 38s/epoch - 26ms/step
Epoch 26/300
1493/1493 - 38s - loss: 5.3135e-04 - val_loss: 6.7838e-04 - 38s/epoch - 26ms/step
Epoch 27/300
1493/1493 - 38s - loss: 4.9514e-04 - val_loss: 4.9888e-04 - 38s/epoch - 26ms/step
Epoch 28/300
1493/1493 - 38s - loss: 4.8303e-04 - val_loss: 8.8881e-04 - 38s/epoch - 26ms/step
Epoch 29/300
1493/1493 - 38s - loss: 4.8282e-04 - val_loss: 6.2190e-04 - 38s/epoch - 26ms/step
Epoch 30/300
1493/1493 - 39s - loss: 4.7953e-04 - val_loss: 6.4261e-04 - 39s/epoch - 26ms/step
Epoch 31/300
1493/1493 - 39s - loss: 4.5762e-04 - val_loss: 5.4963e-04 - 39s/epoch - 26ms/step
Epoch 32/300
1493/1493 - 39s - loss: 5.2442e-04 - val_loss: 6.6799e-04 - 39s/epoch - 26ms/step
Epoch 33/300
1493/1493 - 38s - loss: 4.6490e-04 - val_loss: 4.5980e-04 - 38s/epoch - 26ms/step
Epoch 34/300
1493/1493 - 39s - loss: 4.3587e-04 - val_loss: 3.9715e-04 - 39s/epoch - 26ms/step
Epoch 35/300
1493/1493 - 39s - loss: 4.2016e-04 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 36/300
1493/1493 - 38s - loss: 4.4050e-04 - val_loss: 5.2572e-04 - 38s/epoch - 26ms/step
Epoch 37/300
1493/1493 - 39s - loss: 4.1217e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 38/300
1493/1493 - 38s - loss: 4.4100e-04 - val_loss: 4.1506e-04 - 38s/epoch - 26ms/step
Epoch 39/300
1493/1493 - 38s - loss: 3.9735e-04 - val_loss: 4.1623e-04 - 38s/epoch - 26ms/step
Epoch 40/300
1493/1493 - 38s - loss: 3.8043e-04 - val_loss: 6.7410e-04 - 38s/epoch - 26ms/step
Epoch 41/300
1493/1493 - 39s - loss: 3.9678e-04 - val_loss: 4.0340e-04 - 39s/epoch - 26ms/step
Epoch 42/300
1493/1493 - 39s - loss: 3.7640e-04 - val_loss: 4.0755e-04 - 39s/epoch - 26ms/step
Epoch 43/300
1493/1493 - 39s - loss: 3.7031e-04 - val_loss: 4.5830e-04 - 39s/epoch - 26ms/step
Epoch 44/300
1493/1493 - 38s - loss: 3.7773e-04 - val_loss: 0.0011 - 38s/epoch - 26ms/step
Epoch 45/300
1493/1493 - 39s - loss: 4.0390e-04 - val_loss: 4.0332e-04 - 39s/epoch - 26ms/step
Epoch 46/300
1493/1493 - 39s - loss: 3.5911e-04 - val_loss: 3.3067e-04 - 39s/epoch - 26ms/step
Epoch 47/300
1493/1493 - 38s - loss: 3.4875e-04 - val_loss: 3.5985e-04 - 38s/epoch - 26ms/step
Epoch 48/300
1493/1493 - 39s - loss: 3.4757e-04 - val_loss: 4.4547e-04 - 39s/epoch - 26ms/step
Epoch 49/300
1493/1493 - 39s - loss: 3.4593e-04 - val_loss: 0.0018 - 39s/epoch - 26ms/step
Epoch 50/300
1493/1493 - 39s - loss: 4.4116e-04 - val_loss: 6.6209e-04 - 39s/epoch - 26ms/step
Epoch 51/300
1493/1493 - 39s - loss: 3.4512e-04 - val_loss: 3.4303e-04 - 39s/epoch - 26ms/step
Epoch 52/300
1493/1493 - 38s - loss: 3.2934e-04 - val_loss: 3.3965e-04 - 38s/epoch - 26ms/step
Epoch 53/300
1493/1493 - 38s - loss: 3.2750e-04 - val_loss: 4.1881e-04 - 38s/epoch - 26ms/step
Epoch 54/300
1493/1493 - 39s - loss: 3.2977e-04 - val_loss: 4.0604e-04 - 39s/epoch - 26ms/step
Epoch 55/300
1493/1493 - 39s - loss: 3.1106e-04 - val_loss: 3.7150e-04 - 39s/epoch - 26ms/step
Epoch 56/300
1493/1493 - 39s - loss: 3.1548e-04 - val_loss: 4.6130e-04 - 39s/epoch - 26ms/step
Epoch 57/300
1493/1493 - 39s - loss: 3.0634e-04 - val_loss: 4.0085e-04 - 39s/epoch - 26ms/step
Epoch 58/300
1493/1493 - 38s - loss: 3.0362e-04 - val_loss: 3.1428e-04 - 38s/epoch - 26ms/step
Epoch 59/300
1493/1493 - 39s - loss: 3.0173e-04 - val_loss: 3.0675e-04 - 39s/epoch - 26ms/step
Epoch 60/300
1493/1493 - 38s - loss: 2.9880e-04 - val_loss: 4.6108e-04 - 38s/epoch - 26ms/step
Epoch 61/300
1493/1493 - 38s - loss: 2.9854e-04 - val_loss: 3.4136e-04 - 38s/epoch - 26ms/step
Epoch 62/300
1493/1493 - 39s - loss: 2.9362e-04 - val_loss: 3.9658e-04 - 39s/epoch - 26ms/step
Epoch 63/300
1493/1493 - 38s - loss: 2.8929e-04 - val_loss: 4.0574e-04 - 38s/epoch - 26ms/step
Epoch 64/300
1493/1493 - 38s - loss: 2.9036e-04 - val_loss: 0.0021 - 38s/epoch - 26ms/step
Epoch 65/300
1493/1493 - 38s - loss: 4.1115e-04 - val_loss: 4.5492e-04 - 38s/epoch - 26ms/step
Epoch 66/300
1493/1493 - 39s - loss: 3.0571e-04 - val_loss: 3.0424e-04 - 39s/epoch - 26ms/step
Epoch 67/300
1493/1493 - 39s - loss: 2.8204e-04 - val_loss: 3.0100e-04 - 39s/epoch - 26ms/step
Epoch 68/300
1493/1493 - 38s - loss: 2.7709e-04 - val_loss: 0.0010 - 38s/epoch - 26ms/step
Epoch 69/300
1493/1493 - 39s - loss: 3.2801e-04 - val_loss: 2.9491e-04 - 39s/epoch - 26ms/step
Epoch 70/300
1493/1493 - 39s - loss: 2.7387e-04 - val_loss: 5.0833e-04 - 39s/epoch - 26ms/step
Epoch 71/300
1493/1493 - 39s - loss: 2.7943e-04 - val_loss: 2.6597e-04 - 39s/epoch - 26ms/step
Epoch 72/300
1493/1493 - 39s - loss: 2.6893e-04 - val_loss: 3.6534e-04 - 39s/epoch - 26ms/step
Epoch 73/300
1493/1493 - 39s - loss: 2.7382e-04 - val_loss: 3.3610e-04 - 39s/epoch - 26ms/step
Epoch 74/300
1493/1493 - 39s - loss: 2.6853e-04 - val_loss: 2.7617e-04 - 39s/epoch - 26ms/step
Epoch 75/300
1493/1493 - 39s - loss: 2.5682e-04 - val_loss: 2.7185e-04 - 39s/epoch - 26ms/step
Epoch 76/300
1493/1493 - 38s - loss: 2.5576e-04 - val_loss: 3.1043e-04 - 38s/epoch - 26ms/step
Epoch 77/300
1493/1493 - 39s - loss: 2.5739e-04 - val_loss: 4.3789e-04 - 39s/epoch - 26ms/step
Epoch 78/300
1493/1493 - 39s - loss: 2.5921e-04 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 79/300
1493/1493 - 38s - loss: 3.2348e-04 - val_loss: 2.2256e-04 - 38s/epoch - 26ms/step
Epoch 80/300
1493/1493 - 38s - loss: 2.4821e-04 - val_loss: 2.2754e-04 - 38s/epoch - 26ms/step
Epoch 81/300
1493/1493 - 38s - loss: 2.5321e-04 - val_loss: 4.3453e-04 - 38s/epoch - 26ms/step
Epoch 82/300
1493/1493 - 38s - loss: 2.4726e-04 - val_loss: 2.3285e-04 - 38s/epoch - 26ms/step
Epoch 83/300
1493/1493 - 39s - loss: 2.4011e-04 - val_loss: 2.7536e-04 - 39s/epoch - 26ms/step
Epoch 84/300
1493/1493 - 38s - loss: 2.4314e-04 - val_loss: 2.6737e-04 - 38s/epoch - 26ms/step
Epoch 85/300
1493/1493 - 38s - loss: 2.4377e-04 - val_loss: 3.4408e-04 - 38s/epoch - 26ms/step
Epoch 86/300
1493/1493 - 38s - loss: 2.3946e-04 - val_loss: 2.8324e-04 - 38s/epoch - 26ms/step
Epoch 87/300
1493/1493 - 39s - loss: 2.3524e-04 - val_loss: 2.6952e-04 - 39s/epoch - 26ms/step
Epoch 88/300
1493/1493 - 39s - loss: 2.3630e-04 - val_loss: 4.1712e-04 - 39s/epoch - 26ms/step
Epoch 89/300
1493/1493 - 38s - loss: 2.4553e-04 - val_loss: 2.6705e-04 - 38s/epoch - 26ms/step
Epoch 90/300
1493/1493 - 39s - loss: 2.3083e-04 - val_loss: 2.5236e-04 - 39s/epoch - 26ms/step
Epoch 91/300
1493/1493 - 39s - loss: 2.2738e-04 - val_loss: 2.9162e-04 - 39s/epoch - 26ms/step
Epoch 92/300
1493/1493 - 38s - loss: 2.3012e-04 - val_loss: 8.9965e-04 - 38s/epoch - 26ms/step
Epoch 93/300
1493/1493 - 39s - loss: 2.7975e-04 - val_loss: 2.7325e-04 - 39s/epoch - 26ms/step
Epoch 94/300
1493/1493 - 38s - loss: 2.3345e-04 - val_loss: 1.9309e-04 - 38s/epoch - 26ms/step
Epoch 95/300
1493/1493 - 39s - loss: 2.2483e-04 - val_loss: 2.5751e-04 - 39s/epoch - 26ms/step
Epoch 96/300
1493/1493 - 39s - loss: 2.2684e-04 - val_loss: 2.5668e-04 - 39s/epoch - 26ms/step
Epoch 97/300
1493/1493 - 39s - loss: 2.2280e-04 - val_loss: 2.2254e-04 - 39s/epoch - 26ms/step
Epoch 98/300
1493/1493 - 39s - loss: 2.1689e-04 - val_loss: 2.5059e-04 - 39s/epoch - 26ms/step
Epoch 99/300
1493/1493 - 39s - loss: 2.1665e-04 - val_loss: 2.3160e-04 - 39s/epoch - 26ms/step
Epoch 100/300
1493/1493 - 38s - loss: 2.1728e-04 - val_loss: 2.5583e-04 - 38s/epoch - 26ms/step
Epoch 101/300
1493/1493 - 39s - loss: 2.1614e-04 - val_loss: 9.8578e-04 - 39s/epoch - 26ms/step
Epoch 102/300
1493/1493 - 39s - loss: 2.5440e-04 - val_loss: 3.0845e-04 - 39s/epoch - 26ms/step
Epoch 103/300
1493/1493 - 39s - loss: 2.2049e-04 - val_loss: 2.3195e-04 - 39s/epoch - 26ms/step
Epoch 104/300
1493/1493 - 39s - loss: 2.1157e-04 - val_loss: 4.6313e-04 - 39s/epoch - 26ms/step
Epoch 105/300
1493/1493 - 39s - loss: 2.2105e-04 - val_loss: 2.1570e-04 - 39s/epoch - 26ms/step
Epoch 106/300
1493/1493 - 38s - loss: 2.0783e-04 - val_loss: 2.2264e-04 - 38s/epoch - 26ms/step
Epoch 107/300
1493/1493 - 39s - loss: 2.0642e-04 - val_loss: 2.6091e-04 - 39s/epoch - 26ms/step
Epoch 108/300
1493/1493 - 38s - loss: 2.1831e-04 - val_loss: 2.3336e-04 - 38s/epoch - 26ms/step
Epoch 109/300
1493/1493 - 38s - loss: 2.0621e-04 - val_loss: 2.7219e-04 - 38s/epoch - 26ms/step
Epoch 110/300
1493/1493 - 39s - loss: 2.0417e-04 - val_loss: 2.4753e-04 - 39s/epoch - 26ms/step
Epoch 111/300
1493/1493 - 38s - loss: 2.0415e-04 - val_loss: 4.6645e-04 - 38s/epoch - 26ms/step
Epoch 112/300
1493/1493 - 38s - loss: 2.2081e-04 - val_loss: 2.2135e-04 - 38s/epoch - 26ms/step
Epoch 113/300
1493/1493 - 38s - loss: 2.0428e-04 - val_loss: 9.0889e-04 - 38s/epoch - 26ms/step
Epoch 114/300
1493/1493 - 38s - loss: 2.3747e-04 - val_loss: 1.6914e-04 - 38s/epoch - 26ms/step
Epoch 115/300
1493/1493 - 38s - loss: 1.9965e-04 - val_loss: 4.2996e-04 - 38s/epoch - 26ms/step
Epoch 116/300
1493/1493 - 39s - loss: 1.9875e-04 - val_loss: 2.4818e-04 - 39s/epoch - 26ms/step
Epoch 117/300
1493/1493 - 38s - loss: 1.9739e-04 - val_loss: 2.5806e-04 - 38s/epoch - 26ms/step
Epoch 118/300
1493/1493 - 38s - loss: 1.9848e-04 - val_loss: 2.3372e-04 - 38s/epoch - 26ms/step
Epoch 119/300
1493/1493 - 39s - loss: 1.9681e-04 - val_loss: 1.9507e-04 - 39s/epoch - 26ms/step
Epoch 120/300
1493/1493 - 39s - loss: 1.9415e-04 - val_loss: 2.2914e-04 - 39s/epoch - 26ms/step
Epoch 121/300
1493/1493 - 39s - loss: 1.9456e-04 - val_loss: 3.4874e-04 - 39s/epoch - 26ms/step
Epoch 122/300
1493/1493 - 39s - loss: 1.9459e-04 - val_loss: 2.4161e-04 - 39s/epoch - 26ms/step
Epoch 123/300
1493/1493 - 39s - loss: 1.9549e-04 - val_loss: 2.2688e-04 - 39s/epoch - 26ms/step
Epoch 124/300
1493/1493 - 39s - loss: 1.8988e-04 - val_loss: 4.2094e-04 - 39s/epoch - 26ms/step
Epoch 125/300
1493/1493 - 38s - loss: 2.0012e-04 - val_loss: 1.8397e-04 - 38s/epoch - 26ms/step
Epoch 126/300
1493/1493 - 39s - loss: 1.9109e-04 - val_loss: 3.0993e-04 - 39s/epoch - 26ms/step
Epoch 127/300
1493/1493 - 39s - loss: 1.9113e-04 - val_loss: 3.0232e-04 - 39s/epoch - 26ms/step
Epoch 128/300
1493/1493 - 39s - loss: 1.8928e-04 - val_loss: 1.8986e-04 - 39s/epoch - 26ms/step
Epoch 129/300
1493/1493 - 39s - loss: 1.8517e-04 - val_loss: 2.2496e-04 - 39s/epoch - 26ms/step
Epoch 130/300
1493/1493 - 38s - loss: 1.8386e-04 - val_loss: 1.8470e-04 - 38s/epoch - 26ms/step
Epoch 131/300
1493/1493 - 38s - loss: 1.8718e-04 - val_loss: 6.5725e-04 - 38s/epoch - 26ms/step
Epoch 132/300
1493/1493 - 38s - loss: 2.1500e-04 - val_loss: 1.6796e-04 - 38s/epoch - 26ms/step
Epoch 133/300
1493/1493 - 38s - loss: 1.8254e-04 - val_loss: 3.8147e-04 - 38s/epoch - 26ms/step
Epoch 134/300
1493/1493 - 39s - loss: 2.0293e-04 - val_loss: 1.9671e-04 - 39s/epoch - 26ms/step
Epoch 135/300
1493/1493 - 39s - loss: 1.8047e-04 - val_loss: 1.7897e-04 - 39s/epoch - 26ms/step
Epoch 136/300
1493/1493 - 38s - loss: 1.8119e-04 - val_loss: 3.3216e-04 - 38s/epoch - 26ms/step
Epoch 137/300
1493/1493 - 38s - loss: 1.9764e-04 - val_loss: 3.9903e-04 - 38s/epoch - 26ms/step
Epoch 138/300
1493/1493 - 39s - loss: 2.0085e-04 - val_loss: 2.0184e-04 - 39s/epoch - 26ms/step
Epoch 139/300
1493/1493 - 39s - loss: 1.8133e-04 - val_loss: 2.2064e-04 - 39s/epoch - 26ms/step
Epoch 140/300
1493/1493 - 39s - loss: 1.8405e-04 - val_loss: 8.1193e-04 - 39s/epoch - 26ms/step
Epoch 141/300
1493/1493 - 38s - loss: 2.1253e-04 - val_loss: 4.1948e-04 - 38s/epoch - 26ms/step
Epoch 142/300
1493/1493 - 39s - loss: 2.0699e-04 - val_loss: 1.7792e-04 - 39s/epoch - 26ms/step
Epoch 143/300
1493/1493 - 39s - loss: 1.7737e-04 - val_loss: 2.3312e-04 - 39s/epoch - 26ms/step
Epoch 144/300
1493/1493 - 39s - loss: 1.8667e-04 - val_loss: 1.6631e-04 - 39s/epoch - 26ms/step
Epoch 145/300
1493/1493 - 38s - loss: 1.7519e-04 - val_loss: 2.6132e-04 - 38s/epoch - 26ms/step
Epoch 146/300
1493/1493 - 39s - loss: 1.7943e-04 - val_loss: 1.8414e-04 - 39s/epoch - 26ms/step
Epoch 147/300
1493/1493 - 38s - loss: 1.7173e-04 - val_loss: 2.1084e-04 - 38s/epoch - 26ms/step
Epoch 148/300
1493/1493 - 38s - loss: 1.7334e-04 - val_loss: 3.8231e-04 - 38s/epoch - 26ms/step
Epoch 149/300
1493/1493 - 38s - loss: 1.7244e-04 - val_loss: 2.1128e-04 - 38s/epoch - 26ms/step
Epoch 150/300
1493/1493 - 38s - loss: 1.7153e-04 - val_loss: 2.0097e-04 - 38s/epoch - 26ms/step
Epoch 151/300
1493/1493 - 39s - loss: 1.7515e-04 - val_loss: 1.7768e-04 - 39s/epoch - 26ms/step
Epoch 152/300
1493/1493 - 39s - loss: 1.6987e-04 - val_loss: 3.5947e-04 - 39s/epoch - 26ms/step
Epoch 153/300
1493/1493 - 39s - loss: 1.7706e-04 - val_loss: 1.9966e-04 - 39s/epoch - 26ms/step
Epoch 154/300
1493/1493 - 39s - loss: 1.7024e-04 - val_loss: 5.6058e-04 - 39s/epoch - 26ms/step
Epoch 155/300
1493/1493 - 39s - loss: 2.0844e-04 - val_loss: 1.6196e-04 - 39s/epoch - 26ms/step
Epoch 156/300
1493/1493 - 38s - loss: 1.7094e-04 - val_loss: 2.0322e-04 - 38s/epoch - 26ms/step
Epoch 157/300
1493/1493 - 38s - loss: 1.6636e-04 - val_loss: 2.3492e-04 - 38s/epoch - 26ms/step
Epoch 158/300
1493/1493 - 39s - loss: 1.7074e-04 - val_loss: 2.2329e-04 - 39s/epoch - 26ms/step
Epoch 159/300
1493/1493 - 39s - loss: 1.6837e-04 - val_loss: 1.6365e-04 - 39s/epoch - 26ms/step
Epoch 160/300
1493/1493 - 39s - loss: 1.6664e-04 - val_loss: 2.7951e-04 - 39s/epoch - 26ms/step
Epoch 161/300
1493/1493 - 38s - loss: 1.8386e-04 - val_loss: 1.8330e-04 - 38s/epoch - 26ms/step
Epoch 162/300
1493/1493 - 38s - loss: 1.6635e-04 - val_loss: 1.6307e-04 - 38s/epoch - 26ms/step
Epoch 163/300
1493/1493 - 38s - loss: 1.6659e-04 - val_loss: 2.4331e-04 - 38s/epoch - 26ms/step
Epoch 164/300
1493/1493 - 39s - loss: 1.6728e-04 - val_loss: 1.7636e-04 - 39s/epoch - 26ms/step
Epoch 165/300
1493/1493 - 38s - loss: 1.8690e-04 - val_loss: 1.9860e-04 - 38s/epoch - 26ms/step
Epoch 166/300
1493/1493 - 39s - loss: 1.6464e-04 - val_loss: 1.7995e-04 - 39s/epoch - 26ms/step
Epoch 167/300
1493/1493 - 39s - loss: 1.6405e-04 - val_loss: 1.6329e-04 - 39s/epoch - 26ms/step
Epoch 168/300
1493/1493 - 38s - loss: 1.6172e-04 - val_loss: 1.6644e-04 - 38s/epoch - 26ms/step
Epoch 169/300
1493/1493 - 38s - loss: 1.6218e-04 - val_loss: 2.7289e-04 - 38s/epoch - 26ms/step
Epoch 170/300
1493/1493 - 39s - loss: 1.6309e-04 - val_loss: 4.5563e-04 - 39s/epoch - 26ms/step
Epoch 171/300
1493/1493 - 39s - loss: 1.9398e-04 - val_loss: 2.2367e-04 - 39s/epoch - 26ms/step
Epoch 172/300
1493/1493 - 39s - loss: 1.7443e-04 - val_loss: 4.2655e-04 - 39s/epoch - 26ms/step
Epoch 173/300
1493/1493 - 38s - loss: 1.8004e-04 - val_loss: 1.5033e-04 - 38s/epoch - 26ms/step
Epoch 174/300
1493/1493 - 39s - loss: 1.5979e-04 - val_loss: 1.9193e-04 - 39s/epoch - 26ms/step
Epoch 175/300
1493/1493 - 39s - loss: 1.6186e-04 - val_loss: 1.7988e-04 - 39s/epoch - 26ms/step
Epoch 176/300
1493/1493 - 39s - loss: 1.6077e-04 - val_loss: 1.7181e-04 - 39s/epoch - 26ms/step
Epoch 177/300
1493/1493 - 39s - loss: 1.5999e-04 - val_loss: 1.6454e-04 - 39s/epoch - 26ms/step
Epoch 178/300
1493/1493 - 38s - loss: 1.5786e-04 - val_loss: 1.8063e-04 - 38s/epoch - 26ms/step
Epoch 179/300
1493/1493 - 39s - loss: 1.5563e-04 - val_loss: 2.3517e-04 - 39s/epoch - 26ms/step
Epoch 180/300
1493/1493 - 39s - loss: 1.5972e-04 - val_loss: 1.8096e-04 - 39s/epoch - 26ms/step
Epoch 181/300
1493/1493 - 38s - loss: 1.5954e-04 - val_loss: 4.0702e-04 - 38s/epoch - 26ms/step
Epoch 182/300
1493/1493 - 38s - loss: 1.5942e-04 - val_loss: 2.1240e-04 - 38s/epoch - 26ms/step
Epoch 183/300
1493/1493 - 38s - loss: 1.5516e-04 - val_loss: 1.9480e-04 - 38s/epoch - 26ms/step
Epoch 184/300
1493/1493 - 39s - loss: 1.5520e-04 - val_loss: 1.4759e-04 - 39s/epoch - 26ms/step
Epoch 185/300
1493/1493 - 38s - loss: 1.5182e-04 - val_loss: 1.9672e-04 - 38s/epoch - 26ms/step
Epoch 186/300
1493/1493 - 38s - loss: 1.5268e-04 - val_loss: 1.5782e-04 - 38s/epoch - 26ms/step
Epoch 187/300
1493/1493 - 38s - loss: 1.5360e-04 - val_loss: 2.4941e-04 - 38s/epoch - 26ms/step
Epoch 188/300
1493/1493 - 39s - loss: 1.8350e-04 - val_loss: 2.5147e-04 - 39s/epoch - 26ms/step
Epoch 189/300
1493/1493 - 39s - loss: 1.5597e-04 - val_loss: 2.4218e-04 - 39s/epoch - 26ms/step
Epoch 190/300
1493/1493 - 38s - loss: 1.5804e-04 - val_loss: 3.0608e-04 - 38s/epoch - 26ms/step
Epoch 191/300
1493/1493 - 39s - loss: 1.5891e-04 - val_loss: 2.9485e-04 - 39s/epoch - 26ms/step
Epoch 192/300
1493/1493 - 39s - loss: 1.5714e-04 - val_loss: 2.0440e-04 - 39s/epoch - 26ms/step
Epoch 193/300
1493/1493 - 39s - loss: 1.6106e-04 - val_loss: 5.2259e-04 - 39s/epoch - 26ms/step
Epoch 194/300
1493/1493 - 39s - loss: 1.8642e-04 - val_loss: 3.2630e-04 - 39s/epoch - 26ms/step
Epoch 195/300
1493/1493 - 39s - loss: 1.6573e-04 - val_loss: 1.5042e-04 - 39s/epoch - 26ms/step
Epoch 196/300
1493/1493 - 39s - loss: 1.5184e-04 - val_loss: 1.4144e-04 - 39s/epoch - 26ms/step
Epoch 197/300
1493/1493 - 38s - loss: 1.5130e-04 - val_loss: 2.4185e-04 - 38s/epoch - 26ms/step
Epoch 198/300
1493/1493 - 38s - loss: 1.5624e-04 - val_loss: 1.8942e-04 - 38s/epoch - 26ms/step
Epoch 199/300
1493/1493 - 38s - loss: 1.5044e-04 - val_loss: 1.4409e-04 - 38s/epoch - 26ms/step
Epoch 200/300
1493/1493 - 39s - loss: 1.4818e-04 - val_loss: 1.6158e-04 - 39s/epoch - 26ms/step
Epoch 201/300
1493/1493 - 39s - loss: 1.4844e-04 - val_loss: 1.4176e-04 - 39s/epoch - 26ms/step
Epoch 202/300
1493/1493 - 39s - loss: 1.5023e-04 - val_loss: 3.7196e-04 - 39s/epoch - 26ms/step
Epoch 203/300
1493/1493 - 39s - loss: 1.7013e-04 - val_loss: 3.0294e-04 - 39s/epoch - 26ms/step
Epoch 204/300
1493/1493 - 38s - loss: 1.6058e-04 - val_loss: 1.3521e-04 - 38s/epoch - 26ms/step
Epoch 205/300
1493/1493 - 39s - loss: 1.4788e-04 - val_loss: 3.0593e-04 - 39s/epoch - 26ms/step
Epoch 206/300
1493/1493 - 38s - loss: 1.5231e-04 - val_loss: 2.4531e-04 - 38s/epoch - 26ms/step
Epoch 207/300
1493/1493 - 39s - loss: 1.4758e-04 - val_loss: 1.9353e-04 - 39s/epoch - 26ms/step
Epoch 208/300
1493/1493 - 39s - loss: 1.4766e-04 - val_loss: 2.0605e-04 - 39s/epoch - 26ms/step
Epoch 209/300
1493/1493 - 38s - loss: 1.5033e-04 - val_loss: 3.4802e-04 - 38s/epoch - 26ms/step
Epoch 210/300
1493/1493 - 39s - loss: 1.7336e-04 - val_loss: 1.6139e-04 - 39s/epoch - 26ms/step
Epoch 211/300
1493/1493 - 39s - loss: 1.4831e-04 - val_loss: 1.4480e-04 - 39s/epoch - 26ms/step
Epoch 212/300
1493/1493 - 39s - loss: 1.4786e-04 - val_loss: 1.5478e-04 - 39s/epoch - 26ms/step
Epoch 213/300
1493/1493 - 38s - loss: 1.4676e-04 - val_loss: 1.6799e-04 - 38s/epoch - 26ms/step
Epoch 214/300
1493/1493 - 38s - loss: 1.4571e-04 - val_loss: 1.7893e-04 - 38s/epoch - 26ms/step
Epoch 215/300
1493/1493 - 39s - loss: 1.4347e-04 - val_loss: 2.0517e-04 - 39s/epoch - 26ms/step
Epoch 216/300
1493/1493 - 39s - loss: 1.4736e-04 - val_loss: 1.5875e-04 - 39s/epoch - 26ms/step
Epoch 217/300
1493/1493 - 39s - loss: 1.4209e-04 - val_loss: 1.4182e-04 - 39s/epoch - 26ms/step
Epoch 218/300
1493/1493 - 39s - loss: 1.4216e-04 - val_loss: 3.2016e-04 - 39s/epoch - 26ms/step
Epoch 219/300
1493/1493 - 39s - loss: 1.5761e-04 - val_loss: 1.3360e-04 - 39s/epoch - 26ms/step
Epoch 220/300
1493/1493 - 39s - loss: 1.4565e-04 - val_loss: 1.6348e-04 - 39s/epoch - 26ms/step
Epoch 221/300
1493/1493 - 39s - loss: 1.4346e-04 - val_loss: 1.7510e-04 - 39s/epoch - 26ms/step
Epoch 222/300
1493/1493 - 38s - loss: 1.4280e-04 - val_loss: 2.6833e-04 - 38s/epoch - 26ms/step
Epoch 223/300
1493/1493 - 38s - loss: 1.4981e-04 - val_loss: 1.5111e-04 - 38s/epoch - 26ms/step
Epoch 224/300
1493/1493 - 39s - loss: 1.4297e-04 - val_loss: 5.5380e-04 - 39s/epoch - 26ms/step
Epoch 225/300
1493/1493 - 38s - loss: 1.6654e-04 - val_loss: 1.9470e-04 - 38s/epoch - 26ms/step
Epoch 226/300
1493/1493 - 39s - loss: 1.4627e-04 - val_loss: 2.0441e-04 - 39s/epoch - 26ms/step
Epoch 227/300
1493/1493 - 38s - loss: 1.5026e-04 - val_loss: 1.6233e-04 - 38s/epoch - 26ms/step
Epoch 228/300
1493/1493 - 38s - loss: 1.4097e-04 - val_loss: 2.0350e-04 - 38s/epoch - 26ms/step
Epoch 229/300
1493/1493 - 38s - loss: 1.5160e-04 - val_loss: 7.1460e-04 - 38s/epoch - 26ms/step
Epoch 230/300
1493/1493 - 38s - loss: 1.6055e-04 - val_loss: 1.5623e-04 - 38s/epoch - 26ms/step
Epoch 231/300
1493/1493 - 39s - loss: 1.4505e-04 - val_loss: 4.9785e-04 - 39s/epoch - 26ms/step
Epoch 232/300
1493/1493 - 39s - loss: 1.6821e-04 - val_loss: 2.0831e-04 - 39s/epoch - 26ms/step
Epoch 233/300
1493/1493 - 39s - loss: 1.4576e-04 - val_loss: 1.4950e-04 - 39s/epoch - 26ms/step
Epoch 234/300
1493/1493 - 39s - loss: 1.4119e-04 - val_loss: 1.5216e-04 - 39s/epoch - 26ms/step
Epoch 235/300
1493/1493 - 38s - loss: 1.4490e-04 - val_loss: 1.5071e-04 - 38s/epoch - 26ms/step
Epoch 236/300
1493/1493 - 38s - loss: 1.3883e-04 - val_loss: 1.8989e-04 - 38s/epoch - 26ms/step
Epoch 237/300
1493/1493 - 38s - loss: 1.3964e-04 - val_loss: 1.7459e-04 - 38s/epoch - 26ms/step
Epoch 238/300
1493/1493 - 38s - loss: 1.3782e-04 - val_loss: 1.8332e-04 - 38s/epoch - 26ms/step
Epoch 239/300
1493/1493 - 39s - loss: 1.4001e-04 - val_loss: 2.2167e-04 - 39s/epoch - 26ms/step
Epoch 240/300
1493/1493 - 39s - loss: 1.4304e-04 - val_loss: 1.3385e-04 - 39s/epoch - 26ms/step
Epoch 241/300
1493/1493 - 38s - loss: 1.3634e-04 - val_loss: 1.7477e-04 - 38s/epoch - 26ms/step
Epoch 242/300
1493/1493 - 39s - loss: 1.3847e-04 - val_loss: 1.6672e-04 - 39s/epoch - 26ms/step
Epoch 243/300
1493/1493 - 39s - loss: 1.4054e-04 - val_loss: 1.6117e-04 - 39s/epoch - 26ms/step
Epoch 244/300
1493/1493 - 39s - loss: 1.3796e-04 - val_loss: 2.2887e-04 - 39s/epoch - 26ms/step
Epoch 245/300
1493/1493 - 38s - loss: 1.3865e-04 - val_loss: 1.6406e-04 - 38s/epoch - 26ms/step
Epoch 246/300
1493/1493 - 38s - loss: 1.3981e-04 - val_loss: 3.6940e-04 - 38s/epoch - 26ms/step
Epoch 247/300
1493/1493 - 39s - loss: 1.5806e-04 - val_loss: 1.6081e-04 - 39s/epoch - 26ms/step
Epoch 248/300
1493/1493 - 38s - loss: 1.3818e-04 - val_loss: 3.9859e-04 - 38s/epoch - 26ms/step
Epoch 249/300
1493/1493 - 39s - loss: 1.5886e-04 - val_loss: 1.2838e-04 - 39s/epoch - 26ms/step
Epoch 250/300
1493/1493 - 38s - loss: 1.3992e-04 - val_loss: 1.6782e-04 - 38s/epoch - 26ms/step
Epoch 251/300
1493/1493 - 39s - loss: 1.3718e-04 - val_loss: 1.7668e-04 - 39s/epoch - 26ms/step
Epoch 252/300
1493/1493 - 39s - loss: 1.3797e-04 - val_loss: 2.1799e-04 - 39s/epoch - 26ms/step
Epoch 253/300
1493/1493 - 39s - loss: 1.3928e-04 - val_loss: 2.7994e-04 - 39s/epoch - 26ms/step
Epoch 254/300
1493/1493 - 38s - loss: 1.4264e-04 - val_loss: 2.9744e-04 - 38s/epoch - 26ms/step
Epoch 255/300
1493/1493 - 38s - loss: 1.4790e-04 - val_loss: 1.6015e-04 - 38s/epoch - 26ms/step
Epoch 256/300
1493/1493 - 39s - loss: 1.3870e-04 - val_loss: 1.4069e-04 - 39s/epoch - 26ms/step
Epoch 257/300
1493/1493 - 38s - loss: 1.3602e-04 - val_loss: 2.5206e-04 - 38s/epoch - 26ms/step
Epoch 258/300
1493/1493 - 39s - loss: 1.4642e-04 - val_loss: 2.2139e-04 - 39s/epoch - 26ms/step
Epoch 259/300
1493/1493 - 39s - loss: 1.4351e-04 - val_loss: 3.4897e-04 - 39s/epoch - 26ms/step
Epoch 260/300
1493/1493 - 39s - loss: 1.5724e-04 - val_loss: 1.5586e-04 - 39s/epoch - 26ms/step
Epoch 261/300
1493/1493 - 39s - loss: 1.3815e-04 - val_loss: 1.6668e-04 - 39s/epoch - 26ms/step
Epoch 262/300
1493/1493 - 38s - loss: 1.3915e-04 - val_loss: 1.5808e-04 - 38s/epoch - 26ms/step
Epoch 263/300
1493/1493 - 38s - loss: 1.3538e-04 - val_loss: 1.5027e-04 - 38s/epoch - 26ms/step
Epoch 264/300
1493/1493 - 39s - loss: 1.3905e-04 - val_loss: 1.4431e-04 - 39s/epoch - 26ms/step
Epoch 265/300
1493/1493 - 39s - loss: 1.3301e-04 - val_loss: 2.1404e-04 - 39s/epoch - 26ms/step
Epoch 266/300
1493/1493 - 39s - loss: 1.3527e-04 - val_loss: 1.5516e-04 - 39s/epoch - 26ms/step
Epoch 267/300
1493/1493 - 39s - loss: 1.3431e-04 - val_loss: 3.8824e-04 - 39s/epoch - 26ms/step
Epoch 268/300
1493/1493 - 38s - loss: 1.4005e-04 - val_loss: 1.4440e-04 - 38s/epoch - 26ms/step
Epoch 269/300
1493/1493 - 38s - loss: 1.3297e-04 - val_loss: 1.7807e-04 - 38s/epoch - 26ms/step
Epoch 270/300
1493/1493 - 39s - loss: 1.3364e-04 - val_loss: 1.8500e-04 - 39s/epoch - 26ms/step
Epoch 271/300
1493/1493 - 38s - loss: 1.3235e-04 - val_loss: 1.5303e-04 - 38s/epoch - 26ms/step
Epoch 272/300
1493/1493 - 39s - loss: 1.3633e-04 - val_loss: 4.0013e-04 - 39s/epoch - 26ms/step
Epoch 273/300
1493/1493 - 38s - loss: 1.4496e-04 - val_loss: 2.3799e-04 - 38s/epoch - 26ms/step
Epoch 274/300
1493/1493 - 39s - loss: 1.4361e-04 - val_loss: 2.6643e-04 - 39s/epoch - 26ms/step
Epoch 275/300
1493/1493 - 39s - loss: 1.4996e-04 - val_loss: 1.5277e-04 - 39s/epoch - 26ms/step
Epoch 276/300
1493/1493 - 39s - loss: 1.3166e-04 - val_loss: 1.8897e-04 - 39s/epoch - 26ms/step
Epoch 277/300
1493/1493 - 38s - loss: 1.3452e-04 - val_loss: 4.3437e-04 - 38s/epoch - 26ms/step
Epoch 278/300
1493/1493 - 38s - loss: 1.4790e-04 - val_loss: 1.3300e-04 - 38s/epoch - 26ms/step
Epoch 279/300
1493/1493 - 38s - loss: 1.3211e-04 - val_loss: 1.9051e-04 - 38s/epoch - 26ms/step
Epoch 280/300
1493/1493 - 38s - loss: 1.3580e-04 - val_loss: 1.5369e-04 - 38s/epoch - 26ms/step
Epoch 281/300
1493/1493 - 39s - loss: 1.3157e-04 - val_loss: 1.5476e-04 - 39s/epoch - 26ms/step
Epoch 282/300
1493/1493 - 39s - loss: 1.3160e-04 - val_loss: 1.4073e-04 - 39s/epoch - 26ms/step
Epoch 283/300
1493/1493 - 38s - loss: 1.3008e-04 - val_loss: 1.7699e-04 - 38s/epoch - 26ms/step
Epoch 284/300
1493/1493 - 38s - loss: 1.3188e-04 - val_loss: 2.6802e-04 - 38s/epoch - 26ms/step
Epoch 285/300
1493/1493 - 39s - loss: 1.4377e-04 - val_loss: 2.1777e-04 - 39s/epoch - 26ms/step
Epoch 286/300
1493/1493 - 39s - loss: 1.3076e-04 - val_loss: 1.5082e-04 - 39s/epoch - 26ms/step
Epoch 287/300
1493/1493 - 38s - loss: 1.3183e-04 - val_loss: 3.9041e-04 - 38s/epoch - 26ms/step
Epoch 288/300
1493/1493 - 39s - loss: 1.5054e-04 - val_loss: 2.6359e-04 - 39s/epoch - 26ms/step
Epoch 289/300
1493/1493 - 39s - loss: 1.3280e-04 - val_loss: 5.2322e-04 - 39s/epoch - 26ms/step
Epoch 290/300
1493/1493 - 38s - loss: 1.5162e-04 - val_loss: 2.5220e-04 - 38s/epoch - 26ms/step
Epoch 291/300
1493/1493 - 39s - loss: 1.3736e-04 - val_loss: 1.6228e-04 - 39s/epoch - 26ms/step
Epoch 292/300
1493/1493 - 39s - loss: 1.2872e-04 - val_loss: 1.4865e-04 - 39s/epoch - 26ms/step
Epoch 293/300
1493/1493 - 38s - loss: 1.3107e-04 - val_loss: 1.4997e-04 - 38s/epoch - 26ms/step
Epoch 294/300
1493/1493 - 39s - loss: 1.3227e-04 - val_loss: 2.0683e-04 - 39s/epoch - 26ms/step
Epoch 295/300
1493/1493 - 38s - loss: 1.4497e-04 - val_loss: 1.3263e-04 - 38s/epoch - 26ms/step
Epoch 296/300
1493/1493 - 39s - loss: 1.3089e-04 - val_loss: 3.2966e-04 - 39s/epoch - 26ms/step
Epoch 297/300
1493/1493 - 39s - loss: 1.3750e-04 - val_loss: 1.4718e-04 - 39s/epoch - 26ms/step
Epoch 298/300
1493/1493 - 39s - loss: 1.3080e-04 - val_loss: 1.3221e-04 - 39s/epoch - 26ms/step
Epoch 299/300
1493/1493 - 39s - loss: 1.3132e-04 - val_loss: 1.7559e-04 - 39s/epoch - 26ms/step
Epoch 300/300
1493/1493 - 38s - loss: 1.3347e-04 - val_loss: 1.6671e-04 - 38s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00016670633340254426
  1/332 [..............................] - ETA: 28s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 47/332 [===>..........................] - ETA: 0s 63/332 [====>.........................] - ETA: 0s 79/332 [======>.......................] - ETA: 0s 95/332 [=======>......................] - ETA: 0s111/332 [=========>....................] - ETA: 0s127/332 [==========>...................] - ETA: 0s143/332 [===========>..................] - ETA: 0s159/332 [=============>................] - ETA: 0s175/332 [==============>...............] - ETA: 0s191/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s223/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s255/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s287/332 [========================>.....] - ETA: 0s302/332 [==========================>...] - ETA: 0s318/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0018719727706334028
cosine 0.001513563234132953
MAE: 0.007876581
RMSE: 0.012911476
r2: 0.989185587611652
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       multiple                  0         
                                                                 
 dense_27 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_27 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_28 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 632)               0         
                                                                 
 dense_28 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_29 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 1264)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_29 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_28 (InputLayer)       multiple                  0         
                                                                 
 dense_27 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_27 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_30 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_28 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 632)               0         
                                                                 
 dense_28 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_29 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 1264)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 300, 0.0005, 0.5, 632, 0.0001334656699327752, 0.00016670633340254426, 0.0018719727706334028, 0.001513563234132953, 0.007876580581068993, 0.012911476194858551, 0.989185587611652, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_31 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_30 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_30 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_31 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 632)               0         
                                                                 
 dense_31 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_32 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 1264)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
1493/1493 - 40s - loss: 0.0078 - val_loss: 0.0033 - 40s/epoch - 27ms/step
Epoch 2/300
1493/1493 - 39s - loss: 0.0025 - val_loss: 0.0024 - 39s/epoch - 26ms/step
Epoch 3/300
1493/1493 - 39s - loss: 0.0019 - val_loss: 0.0018 - 39s/epoch - 26ms/step
Epoch 4/300
1493/1493 - 39s - loss: 0.0016 - val_loss: 0.0018 - 39s/epoch - 26ms/step
Epoch 5/300
1493/1493 - 39s - loss: 0.0014 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 6/300
1493/1493 - 39s - loss: 0.0013 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 7/300
1493/1493 - 39s - loss: 0.0012 - val_loss: 0.0012 - 39s/epoch - 26ms/step
Epoch 8/300
1493/1493 - 39s - loss: 9.9993e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 9/300
1493/1493 - 39s - loss: 9.0488e-04 - val_loss: 0.0017 - 39s/epoch - 26ms/step
Epoch 10/300
1493/1493 - 39s - loss: 9.1399e-04 - val_loss: 8.0490e-04 - 39s/epoch - 26ms/step
Epoch 11/300
1493/1493 - 39s - loss: 7.6029e-04 - val_loss: 7.6065e-04 - 39s/epoch - 26ms/step
Epoch 12/300
1493/1493 - 39s - loss: 6.7927e-04 - val_loss: 0.0017 - 39s/epoch - 26ms/step
Epoch 13/300
1493/1493 - 39s - loss: 7.4275e-04 - val_loss: 0.0019 - 39s/epoch - 26ms/step
Epoch 14/300
1493/1493 - 39s - loss: 6.9526e-04 - val_loss: 5.8193e-04 - 39s/epoch - 26ms/step
Epoch 15/300
1493/1493 - 39s - loss: 5.8055e-04 - val_loss: 5.5697e-04 - 39s/epoch - 26ms/step
Epoch 16/300
1493/1493 - 39s - loss: 5.3360e-04 - val_loss: 5.4082e-04 - 39s/epoch - 26ms/step
Epoch 17/300
1493/1493 - 39s - loss: 5.0205e-04 - val_loss: 6.3644e-04 - 39s/epoch - 26ms/step
Epoch 18/300
1493/1493 - 39s - loss: 4.8494e-04 - val_loss: 0.0014 - 39s/epoch - 26ms/step
Epoch 19/300
1493/1493 - 39s - loss: 5.3881e-04 - val_loss: 6.2431e-04 - 39s/epoch - 26ms/step
Epoch 20/300
1493/1493 - 39s - loss: 4.5346e-04 - val_loss: 4.6496e-04 - 39s/epoch - 26ms/step
Epoch 21/300
1493/1493 - 39s - loss: 4.2167e-04 - val_loss: 7.1688e-04 - 39s/epoch - 26ms/step
Epoch 22/300
1493/1493 - 39s - loss: 4.3081e-04 - val_loss: 0.0015 - 39s/epoch - 26ms/step
Epoch 23/300
1493/1493 - 39s - loss: 4.8890e-04 - val_loss: 4.8472e-04 - 39s/epoch - 26ms/step
Epoch 24/300
1493/1493 - 39s - loss: 4.0914e-04 - val_loss: 3.9701e-04 - 39s/epoch - 26ms/step
Epoch 25/300
1493/1493 - 39s - loss: 3.7500e-04 - val_loss: 3.7146e-04 - 39s/epoch - 26ms/step
Epoch 26/300
1493/1493 - 39s - loss: 3.6046e-04 - val_loss: 5.3605e-04 - 39s/epoch - 26ms/step
Epoch 27/300
1493/1493 - 39s - loss: 3.5198e-04 - val_loss: 3.3807e-04 - 39s/epoch - 26ms/step
Epoch 28/300
1493/1493 - 39s - loss: 3.3572e-04 - val_loss: 4.0530e-04 - 39s/epoch - 26ms/step
Epoch 29/300
1493/1493 - 39s - loss: 3.2856e-04 - val_loss: 3.4740e-04 - 39s/epoch - 26ms/step
Epoch 30/300
1493/1493 - 39s - loss: 3.2030e-04 - val_loss: 3.2392e-04 - 39s/epoch - 26ms/step
Epoch 31/300
1493/1493 - 39s - loss: 3.3418e-04 - val_loss: 0.0010 - 39s/epoch - 26ms/step
Epoch 32/300
1493/1493 - 39s - loss: 4.1090e-04 - val_loss: 5.2571e-04 - 39s/epoch - 26ms/step
Epoch 33/300
1493/1493 - 39s - loss: 3.4251e-04 - val_loss: 2.8317e-04 - 39s/epoch - 26ms/step
Epoch 34/300
1493/1493 - 39s - loss: 2.9866e-04 - val_loss: 2.7926e-04 - 39s/epoch - 26ms/step
Epoch 35/300
1493/1493 - 39s - loss: 3.1370e-04 - val_loss: 7.8611e-04 - 39s/epoch - 26ms/step
Epoch 36/300
1493/1493 - 39s - loss: 3.8326e-04 - val_loss: 4.0648e-04 - 39s/epoch - 26ms/step
Epoch 37/300
1493/1493 - 39s - loss: 3.1080e-04 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 38/300
1493/1493 - 39s - loss: 3.8339e-04 - val_loss: 2.5677e-04 - 39s/epoch - 26ms/step
Epoch 39/300
1493/1493 - 39s - loss: 2.8905e-04 - val_loss: 2.5932e-04 - 39s/epoch - 26ms/step
Epoch 40/300
1493/1493 - 39s - loss: 2.7652e-04 - val_loss: 8.8940e-04 - 39s/epoch - 26ms/step
Epoch 41/300
1493/1493 - 39s - loss: 3.1699e-04 - val_loss: 2.5237e-04 - 39s/epoch - 26ms/step
Epoch 42/300
1493/1493 - 39s - loss: 2.7681e-04 - val_loss: 2.6146e-04 - 39s/epoch - 26ms/step
Epoch 43/300
1493/1493 - 39s - loss: 2.6306e-04 - val_loss: 3.6108e-04 - 39s/epoch - 26ms/step
Epoch 44/300
1493/1493 - 39s - loss: 2.7642e-04 - val_loss: 4.9275e-04 - 39s/epoch - 26ms/step
Epoch 45/300
1493/1493 - 39s - loss: 2.8456e-04 - val_loss: 2.3849e-04 - 39s/epoch - 26ms/step
Epoch 46/300
1493/1493 - 39s - loss: 2.4964e-04 - val_loss: 2.3900e-04 - 39s/epoch - 26ms/step
Epoch 47/300
1493/1493 - 39s - loss: 2.4821e-04 - val_loss: 3.2076e-04 - 39s/epoch - 26ms/step
Epoch 48/300
1493/1493 - 39s - loss: 2.4470e-04 - val_loss: 2.5856e-04 - 39s/epoch - 26ms/step
Epoch 49/300
1493/1493 - 39s - loss: 2.5021e-04 - val_loss: 0.0013 - 39s/epoch - 26ms/step
Epoch 50/300
1493/1493 - 39s - loss: 3.6491e-04 - val_loss: 6.8067e-04 - 39s/epoch - 26ms/step
Epoch 51/300
1493/1493 - 39s - loss: 2.8159e-04 - val_loss: 1.9254e-04 - 39s/epoch - 26ms/step
Epoch 52/300
1493/1493 - 39s - loss: 2.3961e-04 - val_loss: 2.4043e-04 - 39s/epoch - 26ms/step
Epoch 53/300
1493/1493 - 39s - loss: 2.3682e-04 - val_loss: 2.5556e-04 - 39s/epoch - 26ms/step
Epoch 54/300
1493/1493 - 39s - loss: 2.3643e-04 - val_loss: 2.4570e-04 - 39s/epoch - 26ms/step
Epoch 55/300
1493/1493 - 39s - loss: 2.2790e-04 - val_loss: 2.2832e-04 - 39s/epoch - 26ms/step
Epoch 56/300
1493/1493 - 39s - loss: 2.2600e-04 - val_loss: 2.6495e-04 - 39s/epoch - 26ms/step
Epoch 57/300
1493/1493 - 39s - loss: 2.2162e-04 - val_loss: 2.4292e-04 - 39s/epoch - 26ms/step
Epoch 58/300
1493/1493 - 39s - loss: 2.2001e-04 - val_loss: 2.2593e-04 - 39s/epoch - 26ms/step
Epoch 59/300
1493/1493 - 39s - loss: 2.1806e-04 - val_loss: 2.3024e-04 - 39s/epoch - 26ms/step
Epoch 60/300
1493/1493 - 39s - loss: 2.1611e-04 - val_loss: 3.4635e-04 - 39s/epoch - 26ms/step
Epoch 61/300
1493/1493 - 39s - loss: 2.2286e-04 - val_loss: 2.2477e-04 - 39s/epoch - 26ms/step
Epoch 62/300
1493/1493 - 39s - loss: 2.1324e-04 - val_loss: 2.3887e-04 - 39s/epoch - 26ms/step
Epoch 63/300
1493/1493 - 39s - loss: 2.0932e-04 - val_loss: 2.5852e-04 - 39s/epoch - 26ms/step
Epoch 64/300
1493/1493 - 39s - loss: 2.0776e-04 - val_loss: 3.7911e-04 - 39s/epoch - 26ms/step
Epoch 65/300
1493/1493 - 39s - loss: 2.2498e-04 - val_loss: 2.7897e-04 - 39s/epoch - 26ms/step
Epoch 66/300
1493/1493 - 39s - loss: 2.2607e-04 - val_loss: 2.1343e-04 - 39s/epoch - 26ms/step
Epoch 67/300
1493/1493 - 39s - loss: 2.0581e-04 - val_loss: 1.9660e-04 - 39s/epoch - 26ms/step
Epoch 68/300
1493/1493 - 39s - loss: 2.0385e-04 - val_loss: 4.5582e-04 - 39s/epoch - 26ms/step
Epoch 69/300
1493/1493 - 39s - loss: 2.4049e-04 - val_loss: 2.7761e-04 - 39s/epoch - 26ms/step
Epoch 70/300
1493/1493 - 39s - loss: 2.0889e-04 - val_loss: 3.4155e-04 - 39s/epoch - 26ms/step
Epoch 71/300
1493/1493 - 39s - loss: 2.2313e-04 - val_loss: 2.0043e-04 - 39s/epoch - 26ms/step
Epoch 72/300
1493/1493 - 39s - loss: 2.0428e-04 - val_loss: 2.2688e-04 - 39s/epoch - 26ms/step
Epoch 73/300
1493/1493 - 39s - loss: 2.0461e-04 - val_loss: 4.0735e-04 - 39s/epoch - 26ms/step
Epoch 74/300
1493/1493 - 39s - loss: 2.3379e-04 - val_loss: 2.7812e-04 - 39s/epoch - 26ms/step
Epoch 75/300
1493/1493 - 39s - loss: 2.0140e-04 - val_loss: 1.8387e-04 - 39s/epoch - 26ms/step
Epoch 76/300
1493/1493 - 39s - loss: 1.9690e-04 - val_loss: 2.1574e-04 - 39s/epoch - 26ms/step
Epoch 77/300
1493/1493 - 39s - loss: 1.9195e-04 - val_loss: 4.4820e-04 - 39s/epoch - 26ms/step
Epoch 78/300
1493/1493 - 39s - loss: 2.1572e-04 - val_loss: 2.2320e-04 - 39s/epoch - 26ms/step
Epoch 79/300
1493/1493 - 39s - loss: 1.9455e-04 - val_loss: 2.5364e-04 - 39s/epoch - 26ms/step
Epoch 80/300
1493/1493 - 39s - loss: 1.9648e-04 - val_loss: 2.0726e-04 - 39s/epoch - 26ms/step
Epoch 81/300
1493/1493 - 39s - loss: 1.9138e-04 - val_loss: 3.2320e-04 - 39s/epoch - 26ms/step
Epoch 82/300
1493/1493 - 39s - loss: 1.8892e-04 - val_loss: 2.1473e-04 - 39s/epoch - 26ms/step
Epoch 83/300
1493/1493 - 39s - loss: 1.8542e-04 - val_loss: 1.8408e-04 - 39s/epoch - 26ms/step
Epoch 84/300
1493/1493 - 39s - loss: 1.8529e-04 - val_loss: 3.6170e-04 - 39s/epoch - 26ms/step
Epoch 85/300
1493/1493 - 39s - loss: 2.1540e-04 - val_loss: 2.5387e-04 - 39s/epoch - 26ms/step
Epoch 86/300
1493/1493 - 39s - loss: 1.9693e-04 - val_loss: 2.0583e-04 - 39s/epoch - 26ms/step
Epoch 87/300
1493/1493 - 39s - loss: 1.8260e-04 - val_loss: 2.1587e-04 - 39s/epoch - 26ms/step
Epoch 88/300
1493/1493 - 39s - loss: 1.8190e-04 - val_loss: 3.6401e-04 - 39s/epoch - 26ms/step
Epoch 89/300
1493/1493 - 39s - loss: 2.0773e-04 - val_loss: 1.9852e-04 - 39s/epoch - 26ms/step
Epoch 90/300
1493/1493 - 39s - loss: 1.8272e-04 - val_loss: 1.9266e-04 - 39s/epoch - 26ms/step
Epoch 91/300
1493/1493 - 39s - loss: 1.7900e-04 - val_loss: 2.3075e-04 - 39s/epoch - 26ms/step
Epoch 92/300
1493/1493 - 39s - loss: 1.8131e-04 - val_loss: 3.7828e-04 - 39s/epoch - 26ms/step
Epoch 93/300
1493/1493 - 39s - loss: 2.3287e-04 - val_loss: 1.8065e-04 - 39s/epoch - 26ms/step
Epoch 94/300
1493/1493 - 39s - loss: 1.8170e-04 - val_loss: 1.8705e-04 - 39s/epoch - 26ms/step
Epoch 95/300
1493/1493 - 39s - loss: 1.7914e-04 - val_loss: 2.1112e-04 - 39s/epoch - 26ms/step
Epoch 96/300
1493/1493 - 39s - loss: 1.8237e-04 - val_loss: 2.3021e-04 - 39s/epoch - 26ms/step
Epoch 97/300
1493/1493 - 39s - loss: 1.7645e-04 - val_loss: 1.8468e-04 - 39s/epoch - 26ms/step
Epoch 98/300
1493/1493 - 39s - loss: 1.7750e-04 - val_loss: 4.1393e-04 - 39s/epoch - 26ms/step
Epoch 99/300
1493/1493 - 39s - loss: 2.1528e-04 - val_loss: 1.8104e-04 - 39s/epoch - 26ms/step
Epoch 100/300
1493/1493 - 39s - loss: 1.7873e-04 - val_loss: 1.7803e-04 - 39s/epoch - 26ms/step
Epoch 101/300
1493/1493 - 39s - loss: 1.7641e-04 - val_loss: 3.6711e-04 - 39s/epoch - 26ms/step
Epoch 102/300
1493/1493 - 39s - loss: 2.0047e-04 - val_loss: 4.9284e-04 - 39s/epoch - 26ms/step
Epoch 103/300
1493/1493 - 39s - loss: 2.3600e-04 - val_loss: 1.9546e-04 - 39s/epoch - 26ms/step
Epoch 104/300
1493/1493 - 39s - loss: 1.8346e-04 - val_loss: 5.2295e-04 - 39s/epoch - 26ms/step
Epoch 105/300
1493/1493 - 39s - loss: 2.0577e-04 - val_loss: 2.0433e-04 - 39s/epoch - 26ms/step
Epoch 106/300
1493/1493 - 39s - loss: 1.7807e-04 - val_loss: 3.3630e-04 - 39s/epoch - 26ms/step
Epoch 107/300
1493/1493 - 39s - loss: 1.9844e-04 - val_loss: 2.1446e-04 - 39s/epoch - 26ms/step
Epoch 108/300
1493/1493 - 39s - loss: 1.7538e-04 - val_loss: 1.7287e-04 - 39s/epoch - 26ms/step
Epoch 109/300
1493/1493 - 39s - loss: 1.7430e-04 - val_loss: 2.0011e-04 - 39s/epoch - 26ms/step
Epoch 110/300
1493/1493 - 39s - loss: 1.7089e-04 - val_loss: 2.1883e-04 - 39s/epoch - 26ms/step
Epoch 111/300
1493/1493 - 39s - loss: 1.7088e-04 - val_loss: 1.8434e-04 - 39s/epoch - 26ms/step
Epoch 112/300
1493/1493 - 39s - loss: 1.6676e-04 - val_loss: 1.9550e-04 - 39s/epoch - 26ms/step
Epoch 113/300
1493/1493 - 39s - loss: 1.6876e-04 - val_loss: 4.1289e-04 - 39s/epoch - 26ms/step
Epoch 114/300
1493/1493 - 39s - loss: 2.0820e-04 - val_loss: 1.6777e-04 - 39s/epoch - 26ms/step
Epoch 115/300
1493/1493 - 39s - loss: 1.6954e-04 - val_loss: 4.1165e-04 - 39s/epoch - 26ms/step
Epoch 116/300
1493/1493 - 39s - loss: 1.7430e-04 - val_loss: 2.2165e-04 - 39s/epoch - 26ms/step
Epoch 117/300
1493/1493 - 39s - loss: 1.6787e-04 - val_loss: 2.3852e-04 - 39s/epoch - 26ms/step
Epoch 118/300
1493/1493 - 39s - loss: 1.7439e-04 - val_loss: 1.8811e-04 - 39s/epoch - 26ms/step
Epoch 119/300
1493/1493 - 39s - loss: 1.6538e-04 - val_loss: 1.6426e-04 - 39s/epoch - 26ms/step
Epoch 120/300
1493/1493 - 39s - loss: 1.6377e-04 - val_loss: 1.7861e-04 - 39s/epoch - 26ms/step
Epoch 121/300
1493/1493 - 39s - loss: 1.6493e-04 - val_loss: 2.7621e-04 - 39s/epoch - 26ms/step
Epoch 122/300
1493/1493 - 39s - loss: 1.6670e-04 - val_loss: 1.7629e-04 - 39s/epoch - 26ms/step
Epoch 123/300
1493/1493 - 39s - loss: 1.6077e-04 - val_loss: 1.9461e-04 - 39s/epoch - 26ms/step
Epoch 124/300
1493/1493 - 39s - loss: 1.6021e-04 - val_loss: 2.1776e-04 - 39s/epoch - 26ms/step
Epoch 125/300
1493/1493 - 39s - loss: 1.6297e-04 - val_loss: 1.6551e-04 - 39s/epoch - 26ms/step
Epoch 126/300
1493/1493 - 39s - loss: 1.5914e-04 - val_loss: 2.0804e-04 - 39s/epoch - 26ms/step
Epoch 127/300
1493/1493 - 39s - loss: 1.6100e-04 - val_loss: 7.3701e-04 - 39s/epoch - 26ms/step
Epoch 128/300
1493/1493 - 39s - loss: 1.8589e-04 - val_loss: 2.4044e-04 - 39s/epoch - 26ms/step
Epoch 129/300
1493/1493 - 39s - loss: 1.7514e-04 - val_loss: 1.7457e-04 - 39s/epoch - 26ms/step
Epoch 130/300
1493/1493 - 39s - loss: 1.5951e-04 - val_loss: 1.8383e-04 - 39s/epoch - 26ms/step
Epoch 131/300
1493/1493 - 39s - loss: 1.6155e-04 - val_loss: 3.3754e-04 - 39s/epoch - 26ms/step
Epoch 132/300
1493/1493 - 39s - loss: 1.8636e-04 - val_loss: 1.7517e-04 - 39s/epoch - 26ms/step
Epoch 133/300
1493/1493 - 39s - loss: 1.6001e-04 - val_loss: 2.0166e-04 - 39s/epoch - 26ms/step
Epoch 134/300
1493/1493 - 39s - loss: 1.6169e-04 - val_loss: 2.9978e-04 - 39s/epoch - 26ms/step
Epoch 135/300
1493/1493 - 39s - loss: 1.7392e-04 - val_loss: 1.6236e-04 - 39s/epoch - 26ms/step
Epoch 136/300
1493/1493 - 39s - loss: 1.5689e-04 - val_loss: 2.0426e-04 - 39s/epoch - 26ms/step
Epoch 137/300
1493/1493 - 39s - loss: 1.6263e-04 - val_loss: 2.2764e-04 - 39s/epoch - 26ms/step
Epoch 138/300
1493/1493 - 39s - loss: 1.6390e-04 - val_loss: 1.9610e-04 - 39s/epoch - 26ms/step
Epoch 139/300
1493/1493 - 39s - loss: 1.5838e-04 - val_loss: 2.8380e-04 - 39s/epoch - 26ms/step
Epoch 140/300
1493/1493 - 39s - loss: 1.7423e-04 - val_loss: 2.7756e-04 - 39s/epoch - 26ms/step
Epoch 141/300
1493/1493 - 39s - loss: 1.6691e-04 - val_loss: 2.7890e-04 - 39s/epoch - 26ms/step
Epoch 142/300
1493/1493 - 39s - loss: 1.7243e-04 - val_loss: 1.7907e-04 - 39s/epoch - 26ms/step
Epoch 143/300
1493/1493 - 39s - loss: 1.5600e-04 - val_loss: 2.9716e-04 - 39s/epoch - 26ms/step
Epoch 144/300
1493/1493 - 39s - loss: 1.6792e-04 - val_loss: 1.5303e-04 - 39s/epoch - 26ms/step
Epoch 145/300
1493/1493 - 39s - loss: 1.5317e-04 - val_loss: 1.6214e-04 - 39s/epoch - 26ms/step
Epoch 146/300
1493/1493 - 39s - loss: 1.5313e-04 - val_loss: 1.7813e-04 - 39s/epoch - 26ms/step
Epoch 147/300
1493/1493 - 39s - loss: 1.5123e-04 - val_loss: 3.0614e-04 - 39s/epoch - 26ms/step
Epoch 148/300
1493/1493 - 39s - loss: 1.5745e-04 - val_loss: 3.2254e-04 - 39s/epoch - 26ms/step
Epoch 149/300
1493/1493 - 39s - loss: 1.5092e-04 - val_loss: 2.0284e-04 - 39s/epoch - 26ms/step
Epoch 150/300
1493/1493 - 39s - loss: 1.5101e-04 - val_loss: 1.9561e-04 - 39s/epoch - 26ms/step
Epoch 151/300
1493/1493 - 39s - loss: 1.5478e-04 - val_loss: 1.8649e-04 - 39s/epoch - 26ms/step
Epoch 152/300
1493/1493 - 39s - loss: 1.5173e-04 - val_loss: 4.9383e-04 - 39s/epoch - 26ms/step
Epoch 153/300
1493/1493 - 39s - loss: 1.7893e-04 - val_loss: 1.8134e-04 - 39s/epoch - 26ms/step
Epoch 154/300
1493/1493 - 39s - loss: 1.5179e-04 - val_loss: 2.2987e-04 - 39s/epoch - 26ms/step
Epoch 155/300
1493/1493 - 39s - loss: 1.5308e-04 - val_loss: 2.3081e-04 - 39s/epoch - 26ms/step
Epoch 156/300
1493/1493 - 39s - loss: 1.5265e-04 - val_loss: 1.8894e-04 - 39s/epoch - 26ms/step
Epoch 157/300
1493/1493 - 39s - loss: 1.4889e-04 - val_loss: 3.1522e-04 - 39s/epoch - 26ms/step
Epoch 158/300
1493/1493 - 39s - loss: 1.7515e-04 - val_loss: 1.7494e-04 - 39s/epoch - 26ms/step
Epoch 159/300
1493/1493 - 39s - loss: 1.5087e-04 - val_loss: 1.8619e-04 - 39s/epoch - 26ms/step
Epoch 160/300
1493/1493 - 39s - loss: 1.4892e-04 - val_loss: 2.7296e-04 - 39s/epoch - 26ms/step
Epoch 161/300
1493/1493 - 39s - loss: 1.6973e-04 - val_loss: 1.6257e-04 - 39s/epoch - 26ms/step
Epoch 162/300
1493/1493 - 39s - loss: 1.4937e-04 - val_loss: 1.8747e-04 - 39s/epoch - 26ms/step
Epoch 163/300
1493/1493 - 39s - loss: 1.5138e-04 - val_loss: 2.0416e-04 - 39s/epoch - 26ms/step
Epoch 164/300
1493/1493 - 39s - loss: 1.5423e-04 - val_loss: 5.1082e-04 - 39s/epoch - 26ms/step
Epoch 165/300
1493/1493 - 39s - loss: 1.9701e-04 - val_loss: 1.5676e-04 - 39s/epoch - 26ms/step
Epoch 166/300
1493/1493 - 39s - loss: 1.5116e-04 - val_loss: 1.6404e-04 - 39s/epoch - 26ms/step
Epoch 167/300
1493/1493 - 39s - loss: 1.4875e-04 - val_loss: 1.5890e-04 - 39s/epoch - 26ms/step
Epoch 168/300
1493/1493 - 39s - loss: 1.4791e-04 - val_loss: 1.9749e-04 - 39s/epoch - 26ms/step
Epoch 169/300
1493/1493 - 39s - loss: 1.4847e-04 - val_loss: 3.9536e-04 - 39s/epoch - 26ms/step
Epoch 170/300
1493/1493 - 39s - loss: 1.7072e-04 - val_loss: 3.8649e-04 - 39s/epoch - 26ms/step
Epoch 171/300
1493/1493 - 39s - loss: 1.8906e-04 - val_loss: 2.4229e-04 - 39s/epoch - 26ms/step
Epoch 172/300
1493/1493 - 39s - loss: 1.5378e-04 - val_loss: 1.5641e-04 - 39s/epoch - 26ms/step
Epoch 173/300
1493/1493 - 39s - loss: 1.4817e-04 - val_loss: 1.7426e-04 - 39s/epoch - 26ms/step
Epoch 174/300
1493/1493 - 39s - loss: 1.4567e-04 - val_loss: 1.8227e-04 - 39s/epoch - 26ms/step
Epoch 175/300
1493/1493 - 39s - loss: 1.4674e-04 - val_loss: 1.7844e-04 - 39s/epoch - 26ms/step
Epoch 176/300
1493/1493 - 39s - loss: 1.4761e-04 - val_loss: 2.2065e-04 - 39s/epoch - 26ms/step
Epoch 177/300
1493/1493 - 39s - loss: 1.5608e-04 - val_loss: 2.0536e-04 - 39s/epoch - 26ms/step
Epoch 178/300
1493/1493 - 39s - loss: 1.4808e-04 - val_loss: 1.6300e-04 - 39s/epoch - 26ms/step
Epoch 179/300
1493/1493 - 39s - loss: 1.4400e-04 - val_loss: 2.0273e-04 - 39s/epoch - 26ms/step
Epoch 180/300
1493/1493 - 39s - loss: 1.4688e-04 - val_loss: 4.0587e-04 - 39s/epoch - 26ms/step
Epoch 181/300
1493/1493 - 39s - loss: 1.9443e-04 - val_loss: 2.1444e-04 - 39s/epoch - 26ms/step
Epoch 182/300
1493/1493 - 39s - loss: 1.5637e-04 - val_loss: 2.1259e-04 - 39s/epoch - 26ms/step
Epoch 183/300
1493/1493 - 39s - loss: 1.4581e-04 - val_loss: 1.9830e-04 - 39s/epoch - 26ms/step
Epoch 184/300
1493/1493 - 39s - loss: 1.5001e-04 - val_loss: 1.7809e-04 - 39s/epoch - 26ms/step
Epoch 185/300
1493/1493 - 39s - loss: 1.4201e-04 - val_loss: 2.1380e-04 - 39s/epoch - 26ms/step
Epoch 186/300
1493/1493 - 39s - loss: 1.4406e-04 - val_loss: 1.4726e-04 - 39s/epoch - 26ms/step
Epoch 187/300
1493/1493 - 39s - loss: 1.4545e-04 - val_loss: 1.7071e-04 - 39s/epoch - 26ms/step
Epoch 188/300
1493/1493 - 39s - loss: 1.4117e-04 - val_loss: 1.8847e-04 - 39s/epoch - 26ms/step
Epoch 189/300
1493/1493 - 39s - loss: 1.4629e-04 - val_loss: 2.2680e-04 - 39s/epoch - 26ms/step
Epoch 190/300
1493/1493 - 39s - loss: 1.4370e-04 - val_loss: 4.2767e-04 - 39s/epoch - 26ms/step
Epoch 191/300
1493/1493 - 39s - loss: 1.6290e-04 - val_loss: 2.1831e-04 - 39s/epoch - 26ms/step
Epoch 192/300
1493/1493 - 39s - loss: 1.4462e-04 - val_loss: 1.9695e-04 - 39s/epoch - 26ms/step
Epoch 193/300
1493/1493 - 39s - loss: 1.4523e-04 - val_loss: 3.3799e-04 - 39s/epoch - 26ms/step
Epoch 194/300
1493/1493 - 39s - loss: 1.6540e-04 - val_loss: 3.1999e-04 - 39s/epoch - 26ms/step
Epoch 195/300
1493/1493 - 39s - loss: 1.4850e-04 - val_loss: 2.6545e-04 - 39s/epoch - 26ms/step
Epoch 196/300
1493/1493 - 39s - loss: 1.5209e-04 - val_loss: 1.4150e-04 - 39s/epoch - 26ms/step
Epoch 197/300
1493/1493 - 39s - loss: 1.4141e-04 - val_loss: 3.0438e-04 - 39s/epoch - 26ms/step
Epoch 198/300
1493/1493 - 39s - loss: 1.4646e-04 - val_loss: 1.7996e-04 - 39s/epoch - 26ms/step
Epoch 199/300
1493/1493 - 39s - loss: 1.4051e-04 - val_loss: 1.8401e-04 - 39s/epoch - 26ms/step
Epoch 200/300
1493/1493 - 39s - loss: 1.3986e-04 - val_loss: 1.7806e-04 - 39s/epoch - 26ms/step
Epoch 201/300
1493/1493 - 39s - loss: 1.3715e-04 - val_loss: 1.5433e-04 - 39s/epoch - 26ms/step
Epoch 202/300
1493/1493 - 39s - loss: 1.3869e-04 - val_loss: 2.1149e-04 - 39s/epoch - 26ms/step
Epoch 203/300
1493/1493 - 39s - loss: 1.4098e-04 - val_loss: 4.6337e-04 - 39s/epoch - 26ms/step
Epoch 204/300
1493/1493 - 39s - loss: 1.6725e-04 - val_loss: 2.1939e-04 - 39s/epoch - 26ms/step
Epoch 205/300
1493/1493 - 39s - loss: 1.4368e-04 - val_loss: 1.5085e-04 - 39s/epoch - 26ms/step
Epoch 206/300
1493/1493 - 39s - loss: 1.3721e-04 - val_loss: 2.2420e-04 - 39s/epoch - 26ms/step
Epoch 207/300
1493/1493 - 39s - loss: 1.3846e-04 - val_loss: 1.9480e-04 - 39s/epoch - 26ms/step
Epoch 208/300
1493/1493 - 39s - loss: 1.3888e-04 - val_loss: 1.8263e-04 - 39s/epoch - 26ms/step
Epoch 209/300
1493/1493 - 39s - loss: 1.3762e-04 - val_loss: 1.7201e-04 - 39s/epoch - 26ms/step
Epoch 210/300
1493/1493 - 39s - loss: 1.3878e-04 - val_loss: 2.2600e-04 - 39s/epoch - 26ms/step
Epoch 211/300
1493/1493 - 39s - loss: 1.4136e-04 - val_loss: 1.7366e-04 - 39s/epoch - 26ms/step
Epoch 212/300
1493/1493 - 39s - loss: 1.3579e-04 - val_loss: 1.6510e-04 - 39s/epoch - 26ms/step
Epoch 213/300
1493/1493 - 39s - loss: 1.3708e-04 - val_loss: 1.5298e-04 - 39s/epoch - 26ms/step
Epoch 214/300
1493/1493 - 39s - loss: 1.3624e-04 - val_loss: 3.5421e-04 - 39s/epoch - 26ms/step
Epoch 215/300
1493/1493 - 39s - loss: 1.6504e-04 - val_loss: 1.8364e-04 - 39s/epoch - 26ms/step
Epoch 216/300
1493/1493 - 39s - loss: 1.4215e-04 - val_loss: 1.5315e-04 - 39s/epoch - 26ms/step
Epoch 217/300
1493/1493 - 39s - loss: 1.3372e-04 - val_loss: 1.7439e-04 - 39s/epoch - 26ms/step
Epoch 218/300
1493/1493 - 39s - loss: 1.3421e-04 - val_loss: 1.4994e-04 - 39s/epoch - 26ms/step
Epoch 219/300
1493/1493 - 39s - loss: 1.3420e-04 - val_loss: 2.6704e-04 - 39s/epoch - 26ms/step
Epoch 220/300
1493/1493 - 39s - loss: 1.4620e-04 - val_loss: 1.5173e-04 - 39s/epoch - 26ms/step
Epoch 221/300
1493/1493 - 39s - loss: 1.3554e-04 - val_loss: 1.8732e-04 - 39s/epoch - 26ms/step
Epoch 222/300
1493/1493 - 39s - loss: 1.3531e-04 - val_loss: 2.8809e-04 - 39s/epoch - 26ms/step
Epoch 223/300
1493/1493 - 39s - loss: 1.4755e-04 - val_loss: 1.6853e-04 - 39s/epoch - 26ms/step
Epoch 224/300
1493/1493 - 39s - loss: 1.3461e-04 - val_loss: 2.8326e-04 - 39s/epoch - 26ms/step
Epoch 225/300
1493/1493 - 39s - loss: 1.4001e-04 - val_loss: 1.8521e-04 - 39s/epoch - 26ms/step
Epoch 226/300
1493/1493 - 39s - loss: 1.3684e-04 - val_loss: 1.8958e-04 - 39s/epoch - 26ms/step
Epoch 227/300
1493/1493 - 39s - loss: 1.4672e-04 - val_loss: 1.7246e-04 - 39s/epoch - 26ms/step
Epoch 228/300
1493/1493 - 39s - loss: 1.3411e-04 - val_loss: 1.6284e-04 - 39s/epoch - 26ms/step
Epoch 229/300
1493/1493 - 39s - loss: 1.3493e-04 - val_loss: 1.8997e-04 - 39s/epoch - 26ms/step
Epoch 230/300
1493/1493 - 39s - loss: 1.3263e-04 - val_loss: 1.6711e-04 - 39s/epoch - 26ms/step
Epoch 231/300
1493/1493 - 39s - loss: 1.3360e-04 - val_loss: 2.3828e-04 - 39s/epoch - 26ms/step
Epoch 232/300
1493/1493 - 39s - loss: 1.4124e-04 - val_loss: 4.7915e-04 - 39s/epoch - 26ms/step
Epoch 233/300
1493/1493 - 39s - loss: 1.5832e-04 - val_loss: 1.5523e-04 - 39s/epoch - 26ms/step
Epoch 234/300
1493/1493 - 39s - loss: 1.3269e-04 - val_loss: 1.6676e-04 - 39s/epoch - 26ms/step
Epoch 235/300
1493/1493 - 39s - loss: 1.3657e-04 - val_loss: 1.9458e-04 - 39s/epoch - 26ms/step
Epoch 236/300
1493/1493 - 39s - loss: 1.3208e-04 - val_loss: 1.6539e-04 - 39s/epoch - 26ms/step
Epoch 237/300
1493/1493 - 39s - loss: 1.3179e-04 - val_loss: 2.3393e-04 - 39s/epoch - 26ms/step
Epoch 238/300
1493/1493 - 39s - loss: 1.3711e-04 - val_loss: 1.5402e-04 - 39s/epoch - 26ms/step
Epoch 239/300
1493/1493 - 39s - loss: 1.3173e-04 - val_loss: 2.1421e-04 - 39s/epoch - 26ms/step
Epoch 240/300
1493/1493 - 39s - loss: 1.3062e-04 - val_loss: 1.3836e-04 - 39s/epoch - 26ms/step
Epoch 241/300
1493/1493 - 39s - loss: 1.2906e-04 - val_loss: 1.5366e-04 - 39s/epoch - 26ms/step
Epoch 242/300
1493/1493 - 39s - loss: 1.3121e-04 - val_loss: 5.9308e-04 - 39s/epoch - 26ms/step
Epoch 243/300
1493/1493 - 39s - loss: 1.6084e-04 - val_loss: 3.5844e-04 - 39s/epoch - 26ms/step
Epoch 244/300
1493/1493 - 39s - loss: 1.6083e-04 - val_loss: 6.2119e-04 - 39s/epoch - 26ms/step
Epoch 245/300
1493/1493 - 39s - loss: 1.5402e-04 - val_loss: 1.5834e-04 - 39s/epoch - 26ms/step
Epoch 246/300
1493/1493 - 39s - loss: 1.3620e-04 - val_loss: 4.1972e-04 - 39s/epoch - 26ms/step
Epoch 247/300
1493/1493 - 39s - loss: 1.6135e-04 - val_loss: 1.7386e-04 - 39s/epoch - 26ms/step
Epoch 248/300
1493/1493 - 39s - loss: 1.3672e-04 - val_loss: 2.8878e-04 - 39s/epoch - 26ms/step
Epoch 249/300
1493/1493 - 39s - loss: 1.4502e-04 - val_loss: 1.5671e-04 - 39s/epoch - 26ms/step
Epoch 250/300
1493/1493 - 39s - loss: 1.3333e-04 - val_loss: 1.8230e-04 - 39s/epoch - 26ms/step
Epoch 251/300
1493/1493 - 39s - loss: 1.3326e-04 - val_loss: 3.0297e-04 - 39s/epoch - 26ms/step
Epoch 252/300
1493/1493 - 39s - loss: 1.4768e-04 - val_loss: 1.9993e-04 - 39s/epoch - 26ms/step
Epoch 253/300
1493/1493 - 39s - loss: 1.3353e-04 - val_loss: 1.4681e-04 - 39s/epoch - 26ms/step
Epoch 254/300
1493/1493 - 39s - loss: 1.3078e-04 - val_loss: 2.9353e-04 - 39s/epoch - 26ms/step
Epoch 255/300
1493/1493 - 39s - loss: 1.4408e-04 - val_loss: 1.8991e-04 - 39s/epoch - 26ms/step
Epoch 256/300
1493/1493 - 39s - loss: 1.3624e-04 - val_loss: 1.4762e-04 - 39s/epoch - 26ms/step
Epoch 257/300
1493/1493 - 39s - loss: 1.3411e-04 - val_loss: 5.5986e-04 - 39s/epoch - 26ms/step
Epoch 258/300
1493/1493 - 39s - loss: 1.8117e-04 - val_loss: 2.8896e-04 - 39s/epoch - 26ms/step
Epoch 259/300
1493/1493 - 39s - loss: 1.4226e-04 - val_loss: 3.2902e-04 - 39s/epoch - 26ms/step
Epoch 260/300
1493/1493 - 39s - loss: 1.4887e-04 - val_loss: 1.9894e-04 - 39s/epoch - 26ms/step
Epoch 261/300
1493/1493 - 39s - loss: 1.3365e-04 - val_loss: 1.7279e-04 - 39s/epoch - 26ms/step
Epoch 262/300
1493/1493 - 39s - loss: 1.3206e-04 - val_loss: 1.6969e-04 - 39s/epoch - 26ms/step
Epoch 263/300
1493/1493 - 39s - loss: 1.2934e-04 - val_loss: 2.0015e-04 - 39s/epoch - 26ms/step
Epoch 264/300
1493/1493 - 39s - loss: 1.3518e-04 - val_loss: 1.5265e-04 - 39s/epoch - 26ms/step
Epoch 265/300
1493/1493 - 39s - loss: 1.3112e-04 - val_loss: 3.2407e-04 - 39s/epoch - 26ms/step
Epoch 266/300
1493/1493 - 39s - loss: 1.5480e-04 - val_loss: 1.7136e-04 - 39s/epoch - 26ms/step
Epoch 267/300
1493/1493 - 39s - loss: 1.3241e-04 - val_loss: 1.8080e-04 - 39s/epoch - 26ms/step
Epoch 268/300
1493/1493 - 39s - loss: 1.2760e-04 - val_loss: 1.6767e-04 - 39s/epoch - 26ms/step
Epoch 269/300
1493/1493 - 39s - loss: 1.3255e-04 - val_loss: 4.9823e-04 - 39s/epoch - 26ms/step
Epoch 270/300
1493/1493 - 39s - loss: 1.6265e-04 - val_loss: 4.5203e-04 - 39s/epoch - 26ms/step
Epoch 271/300
1493/1493 - 39s - loss: 1.4719e-04 - val_loss: 1.6245e-04 - 39s/epoch - 26ms/step
Epoch 272/300
1493/1493 - 39s - loss: 1.3480e-04 - val_loss: 7.4081e-04 - 39s/epoch - 26ms/step
Epoch 273/300
1493/1493 - 39s - loss: 1.6450e-04 - val_loss: 6.0734e-04 - 39s/epoch - 26ms/step
Epoch 274/300
1493/1493 - 39s - loss: 1.5693e-04 - val_loss: 2.3840e-04 - 39s/epoch - 26ms/step
Epoch 275/300
1493/1493 - 39s - loss: 1.4383e-04 - val_loss: 1.7021e-04 - 39s/epoch - 26ms/step
Epoch 276/300
1493/1493 - 39s - loss: 1.3088e-04 - val_loss: 3.1984e-04 - 39s/epoch - 26ms/step
Epoch 277/300
1493/1493 - 39s - loss: 1.4346e-04 - val_loss: 2.5134e-04 - 39s/epoch - 26ms/step
Epoch 278/300
1493/1493 - 39s - loss: 1.3914e-04 - val_loss: 1.7447e-04 - 39s/epoch - 26ms/step
Epoch 279/300
1493/1493 - 39s - loss: 1.2931e-04 - val_loss: 1.5886e-04 - 39s/epoch - 26ms/step
Epoch 280/300
1493/1493 - 39s - loss: 1.3116e-04 - val_loss: 2.1959e-04 - 39s/epoch - 26ms/step
Epoch 281/300
1493/1493 - 39s - loss: 1.3011e-04 - val_loss: 1.8285e-04 - 39s/epoch - 26ms/step
Epoch 282/300
1493/1493 - 39s - loss: 1.2902e-04 - val_loss: 1.7316e-04 - 39s/epoch - 26ms/step
Epoch 283/300
1493/1493 - 39s - loss: 1.2768e-04 - val_loss: 1.7222e-04 - 39s/epoch - 26ms/step
Epoch 284/300
1493/1493 - 39s - loss: 1.2797e-04 - val_loss: 1.6670e-04 - 39s/epoch - 26ms/step
Epoch 285/300
1493/1493 - 39s - loss: 1.3160e-04 - val_loss: 5.3146e-04 - 39s/epoch - 26ms/step
Epoch 286/300
1493/1493 - 39s - loss: 1.2819e-04 - val_loss: 1.7282e-04 - 39s/epoch - 26ms/step
Epoch 287/300
1493/1493 - 39s - loss: 1.2635e-04 - val_loss: 2.8092e-04 - 39s/epoch - 26ms/step
Epoch 288/300
1493/1493 - 39s - loss: 1.3838e-04 - val_loss: 1.8538e-04 - 39s/epoch - 26ms/step
Epoch 289/300
1493/1493 - 39s - loss: 1.3037e-04 - val_loss: 2.6270e-04 - 39s/epoch - 26ms/step
Epoch 290/300
1493/1493 - 39s - loss: 1.3468e-04 - val_loss: 2.3097e-04 - 39s/epoch - 26ms/step
Epoch 291/300
1493/1493 - 39s - loss: 1.3022e-04 - val_loss: 1.8993e-04 - 39s/epoch - 26ms/step
Epoch 292/300
1493/1493 - 39s - loss: 1.2534e-04 - val_loss: 1.5496e-04 - 39s/epoch - 26ms/step
Epoch 293/300
1493/1493 - 39s - loss: 1.2596e-04 - val_loss: 1.6449e-04 - 39s/epoch - 26ms/step
Epoch 294/300
1493/1493 - 39s - loss: 1.2664e-04 - val_loss: 1.5848e-04 - 39s/epoch - 26ms/step
Epoch 295/300
1493/1493 - 39s - loss: 1.2538e-04 - val_loss: 1.4607e-04 - 39s/epoch - 26ms/step
Epoch 296/300
1493/1493 - 39s - loss: 1.2462e-04 - val_loss: 2.0804e-04 - 39s/epoch - 26ms/step
Epoch 297/300
1493/1493 - 39s - loss: 1.2484e-04 - val_loss: 1.6818e-04 - 39s/epoch - 26ms/step
Epoch 298/300
1493/1493 - 39s - loss: 1.2598e-04 - val_loss: 2.8505e-04 - 39s/epoch - 26ms/step
Epoch 299/300
1493/1493 - 39s - loss: 1.5194e-04 - val_loss: 1.7073e-04 - 39s/epoch - 26ms/step
Epoch 300/300
1493/1493 - 39s - loss: 1.2755e-04 - val_loss: 1.6169e-04 - 39s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.0001616922381799668
  1/332 [..............................] - ETA: 26s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s128/332 [==========>...................] - ETA: 0s144/332 [============>.................] - ETA: 0s160/332 [=============>................] - ETA: 0s176/332 [==============>...............] - ETA: 0s192/332 [================>.............] - ETA: 0s208/332 [=================>............] - ETA: 0s224/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s272/332 [=======================>......] - ETA: 0s288/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0018568031020852875
cosine 0.0014634648842763056
MAE: 0.0076364083
RMSE: 0.012715822
r2: 0.9895109379380005
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_31 (InputLayer)       multiple                  0         
                                                                 
 dense_30 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_30 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_31 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 632)               0         
                                                                 
 dense_31 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_32 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 1264)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_32 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_31 (InputLayer)       multiple                  0         
                                                                 
 dense_30 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_30 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_33 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_31 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 632)               0         
                                                                 
 dense_31 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_32 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 1264)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 300, 0.001, 0.5, 632, 0.00012754782801494002, 0.0001616922381799668, 0.0018568031020852875, 0.0014634648842763056, 0.007636408321559429, 0.012715822085738182, 0.9895109379380005, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_34 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_33 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_33 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_33 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_34 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_34 (ReLU)             (None, 632)               0         
                                                                 
 dense_34 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_35 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_35 (ReLU)             (None, 1264)              0         
                                                                 
 dense_35 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Epoch 1/300
1493/1493 - 39s - loss: 0.0074 - val_loss: 0.0029 - 39s/epoch - 26ms/step
Epoch 2/300
1493/1493 - 38s - loss: 0.0024 - val_loss: 0.0021 - 38s/epoch - 26ms/step
Epoch 3/300
1493/1493 - 38s - loss: 0.0019 - val_loss: 0.0023 - 38s/epoch - 26ms/step
Epoch 4/300
1493/1493 - 39s - loss: 0.0016 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 5/300
1493/1493 - 38s - loss: 0.0013 - val_loss: 0.0014 - 38s/epoch - 26ms/step
Epoch 6/300
1493/1493 - 39s - loss: 0.0011 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 7/300
1493/1493 - 39s - loss: 9.3953e-04 - val_loss: 9.0185e-04 - 39s/epoch - 26ms/step
Epoch 8/300
1493/1493 - 38s - loss: 7.9980e-04 - val_loss: 8.0803e-04 - 38s/epoch - 26ms/step
Epoch 9/300
1493/1493 - 39s - loss: 6.9560e-04 - val_loss: 7.0382e-04 - 39s/epoch - 26ms/step
Epoch 10/300
1493/1493 - 39s - loss: 6.2141e-04 - val_loss: 6.6848e-04 - 39s/epoch - 26ms/step
Epoch 11/300
1493/1493 - 39s - loss: 5.6722e-04 - val_loss: 6.1151e-04 - 39s/epoch - 26ms/step
Epoch 12/300
1493/1493 - 39s - loss: 5.2789e-04 - val_loss: 0.0016 - 39s/epoch - 26ms/step
Epoch 13/300
1493/1493 - 38s - loss: 6.5375e-04 - val_loss: 0.0038 - 38s/epoch - 26ms/step
Epoch 14/300
1493/1493 - 39s - loss: 0.0010 - val_loss: 0.0011 - 39s/epoch - 26ms/step
Epoch 15/300
1493/1493 - 38s - loss: 6.3478e-04 - val_loss: 7.1444e-04 - 38s/epoch - 26ms/step
Epoch 16/300
1493/1493 - 38s - loss: 5.3126e-04 - val_loss: 4.7042e-04 - 38s/epoch - 26ms/step
Epoch 17/300
1493/1493 - 39s - loss: 4.7892e-04 - val_loss: 5.4956e-04 - 39s/epoch - 26ms/step
Epoch 18/300
1493/1493 - 39s - loss: 4.6369e-04 - val_loss: 5.3467e-04 - 39s/epoch - 26ms/step
Epoch 19/300
1493/1493 - 39s - loss: 4.5099e-04 - val_loss: 4.3340e-04 - 39s/epoch - 26ms/step
Epoch 20/300
1493/1493 - 38s - loss: 4.2522e-04 - val_loss: 6.2644e-04 - 38s/epoch - 26ms/step
Epoch 21/300
1493/1493 - 38s - loss: 4.5783e-04 - val_loss: 0.0016 - 38s/epoch - 26ms/step
Epoch 22/300
1493/1493 - 39s - loss: 6.0740e-04 - val_loss: 6.0442e-04 - 39s/epoch - 26ms/step
Epoch 23/300
1493/1493 - 39s - loss: 4.5032e-04 - val_loss: 3.8816e-04 - 39s/epoch - 26ms/step
Epoch 24/300
1493/1493 - 38s - loss: 4.1593e-04 - val_loss: 5.5229e-04 - 38s/epoch - 26ms/step
Epoch 25/300
1493/1493 - 38s - loss: 4.1520e-04 - val_loss: 3.4268e-04 - 38s/epoch - 26ms/step
Epoch 26/300
1493/1493 - 39s - loss: 3.8486e-04 - val_loss: 3.6369e-04 - 39s/epoch - 26ms/step
Epoch 27/300
1493/1493 - 39s - loss: 3.8437e-04 - val_loss: 3.3963e-04 - 39s/epoch - 26ms/step
Epoch 28/300
1493/1493 - 39s - loss: 3.6594e-04 - val_loss: 4.4216e-04 - 39s/epoch - 26ms/step
Epoch 29/300
1493/1493 - 39s - loss: 3.7174e-04 - val_loss: 3.5537e-04 - 39s/epoch - 26ms/step
Epoch 30/300
1493/1493 - 39s - loss: 3.5420e-04 - val_loss: 3.5476e-04 - 39s/epoch - 26ms/step
Epoch 31/300
1493/1493 - 39s - loss: 3.4447e-04 - val_loss: 3.5989e-04 - 39s/epoch - 26ms/step
Epoch 32/300
1493/1493 - 38s - loss: 3.4975e-04 - val_loss: 3.3977e-04 - 38s/epoch - 26ms/step
Epoch 33/300
1493/1493 - 39s - loss: 3.5277e-04 - val_loss: 2.8566e-04 - 39s/epoch - 26ms/step
Epoch 34/300
1493/1493 - 38s - loss: 3.3138e-04 - val_loss: 2.8384e-04 - 38s/epoch - 26ms/step
Epoch 35/300
1493/1493 - 39s - loss: 3.3915e-04 - val_loss: 6.8498e-04 - 39s/epoch - 26ms/step
Epoch 36/300
1493/1493 - 39s - loss: 3.8055e-04 - val_loss: 8.0471e-04 - 39s/epoch - 26ms/step
Epoch 37/300
1493/1493 - 38s - loss: 4.6558e-04 - val_loss: 3.6303e-04 - 38s/epoch - 26ms/step
Epoch 38/300
1493/1493 - 39s - loss: 3.5785e-04 - val_loss: 3.3389e-04 - 39s/epoch - 26ms/step
Epoch 39/300
1493/1493 - 39s - loss: 3.3946e-04 - val_loss: 2.6690e-04 - 39s/epoch - 26ms/step
Epoch 40/300
1493/1493 - 38s - loss: 3.2387e-04 - val_loss: 4.7712e-04 - 38s/epoch - 26ms/step
Epoch 41/300
1493/1493 - 38s - loss: 3.2864e-04 - val_loss: 2.6341e-04 - 38s/epoch - 26ms/step
Epoch 42/300
1493/1493 - 38s - loss: 3.1461e-04 - val_loss: 2.7058e-04 - 38s/epoch - 26ms/step
Epoch 43/300
1493/1493 - 38s - loss: 3.0998e-04 - val_loss: 2.8608e-04 - 38s/epoch - 26ms/step
Epoch 44/300
1493/1493 - 39s - loss: 3.0661e-04 - val_loss: 3.9616e-04 - 39s/epoch - 26ms/step
Epoch 45/300
1493/1493 - 39s - loss: 3.3926e-04 - val_loss: 2.6153e-04 - 39s/epoch - 26ms/step
Epoch 46/300
1493/1493 - 39s - loss: 3.0260e-04 - val_loss: 2.5889e-04 - 39s/epoch - 26ms/step
Epoch 47/300
1493/1493 - 39s - loss: 3.0111e-04 - val_loss: 3.9149e-04 - 39s/epoch - 26ms/step
Epoch 48/300
1493/1493 - 38s - loss: 3.1421e-04 - val_loss: 3.1108e-04 - 38s/epoch - 26ms/step
Epoch 49/300
1493/1493 - 39s - loss: 2.9989e-04 - val_loss: 7.3894e-04 - 39s/epoch - 26ms/step
Epoch 50/300
1493/1493 - 38s - loss: 3.8968e-04 - val_loss: 5.4045e-04 - 38s/epoch - 26ms/step
Epoch 51/300
1493/1493 - 38s - loss: 3.3285e-04 - val_loss: 2.4727e-04 - 38s/epoch - 26ms/step
Epoch 52/300
1493/1493 - 38s - loss: 2.9794e-04 - val_loss: 2.6469e-04 - 38s/epoch - 26ms/step
Epoch 53/300
1493/1493 - 39s - loss: 2.9021e-04 - val_loss: 2.9006e-04 - 39s/epoch - 26ms/step
Epoch 54/300
1493/1493 - 38s - loss: 3.0182e-04 - val_loss: 2.9052e-04 - 38s/epoch - 26ms/step
Epoch 55/300
1493/1493 - 39s - loss: 2.8413e-04 - val_loss: 2.4793e-04 - 39s/epoch - 26ms/step
Epoch 56/300
1493/1493 - 38s - loss: 2.8026e-04 - val_loss: 2.8110e-04 - 38s/epoch - 26ms/step
Epoch 57/300
1493/1493 - 38s - loss: 2.7880e-04 - val_loss: 2.7354e-04 - 38s/epoch - 26ms/step
Epoch 58/300
1493/1493 - 39s - loss: 2.7691e-04 - val_loss: 2.3338e-04 - 39s/epoch - 26ms/step
Epoch 59/300
1493/1493 - 39s - loss: 2.8160e-04 - val_loss: 3.8886e-04 - 39s/epoch - 26ms/step
Epoch 60/300
1493/1493 - 39s - loss: 3.0242e-04 - val_loss: 2.9517e-04 - 39s/epoch - 26ms/step
Epoch 61/300
1493/1493 - 39s - loss: 2.7887e-04 - val_loss: 2.3350e-04 - 39s/epoch - 26ms/step
Epoch 62/300
1493/1493 - 38s - loss: 2.7012e-04 - val_loss: 2.6558e-04 - 38s/epoch - 26ms/step
Epoch 63/300
1493/1493 - 39s - loss: 2.6752e-04 - val_loss: 2.6650e-04 - 39s/epoch - 26ms/step
Epoch 64/300
1493/1493 - 38s - loss: 2.7137e-04 - val_loss: 9.7057e-04 - 38s/epoch - 26ms/step
Epoch 65/300
1493/1493 - 39s - loss: 3.6515e-04 - val_loss: 9.9644e-04 - 39s/epoch - 26ms/step
Epoch 66/300
1493/1493 - 39s - loss: 3.3533e-04 - val_loss: 3.5843e-04 - 39s/epoch - 26ms/step
Epoch 67/300
1493/1493 - 38s - loss: 2.8226e-04 - val_loss: 2.2166e-04 - 38s/epoch - 26ms/step
Epoch 68/300
1493/1493 - 39s - loss: 2.7061e-04 - val_loss: 7.5549e-04 - 39s/epoch - 26ms/step
Epoch 69/300
1493/1493 - 39s - loss: 3.0283e-04 - val_loss: 2.4367e-04 - 39s/epoch - 26ms/step
Epoch 70/300
1493/1493 - 38s - loss: 2.6982e-04 - val_loss: 3.7690e-04 - 38s/epoch - 26ms/step
Epoch 71/300
1493/1493 - 39s - loss: 3.0215e-04 - val_loss: 2.4563e-04 - 39s/epoch - 26ms/step
Epoch 72/300
1493/1493 - 38s - loss: 2.7115e-04 - val_loss: 3.3776e-04 - 38s/epoch - 26ms/step
Epoch 73/300
1493/1493 - 38s - loss: 2.8945e-04 - val_loss: 2.5260e-04 - 38s/epoch - 26ms/step
Epoch 74/300
1493/1493 - 39s - loss: 2.6906e-04 - val_loss: 2.3472e-04 - 39s/epoch - 26ms/step
Epoch 75/300
1493/1493 - 39s - loss: 2.6069e-04 - val_loss: 3.8949e-04 - 39s/epoch - 26ms/step
Epoch 76/300
1493/1493 - 38s - loss: 2.8085e-04 - val_loss: 2.4424e-04 - 38s/epoch - 26ms/step
Epoch 77/300
1493/1493 - 39s - loss: 2.5920e-04 - val_loss: 4.1734e-04 - 39s/epoch - 26ms/step
Epoch 78/300
1493/1493 - 39s - loss: 3.0501e-04 - val_loss: 2.6749e-04 - 39s/epoch - 26ms/step
Epoch 79/300
1493/1493 - 39s - loss: 2.6696e-04 - val_loss: 3.0984e-04 - 39s/epoch - 26ms/step
Epoch 80/300
1493/1493 - 39s - loss: 2.6719e-04 - val_loss: 5.2372e-04 - 39s/epoch - 26ms/step
Epoch 81/300
1493/1493 - 38s - loss: 3.0829e-04 - val_loss: 2.8827e-04 - 38s/epoch - 26ms/step
Epoch 82/300
1493/1493 - 39s - loss: 2.5716e-04 - val_loss: 2.3432e-04 - 39s/epoch - 26ms/step
Epoch 83/300
1493/1493 - 38s - loss: 2.5274e-04 - val_loss: 2.2011e-04 - 38s/epoch - 26ms/step
Epoch 84/300
1493/1493 - 39s - loss: 2.5238e-04 - val_loss: 2.7370e-04 - 39s/epoch - 26ms/step
Epoch 85/300
1493/1493 - 39s - loss: 2.5731e-04 - val_loss: 2.4702e-04 - 39s/epoch - 26ms/step
Epoch 86/300
1493/1493 - 38s - loss: 2.5981e-04 - val_loss: 2.0566e-04 - 38s/epoch - 26ms/step
Epoch 87/300
1493/1493 - 38s - loss: 2.4538e-04 - val_loss: 2.2520e-04 - 38s/epoch - 26ms/step
Epoch 88/300
1493/1493 - 39s - loss: 2.4445e-04 - val_loss: 4.5705e-04 - 39s/epoch - 26ms/step
Epoch 89/300
1493/1493 - 38s - loss: 2.8088e-04 - val_loss: 2.1762e-04 - 38s/epoch - 26ms/step
Epoch 90/300
1493/1493 - 39s - loss: 2.4819e-04 - val_loss: 2.3331e-04 - 39s/epoch - 26ms/step
Epoch 91/300
1493/1493 - 39s - loss: 2.4185e-04 - val_loss: 2.3622e-04 - 39s/epoch - 26ms/step
Epoch 92/300
1493/1493 - 39s - loss: 2.4349e-04 - val_loss: 3.6204e-04 - 39s/epoch - 26ms/step
Epoch 93/300
1493/1493 - 39s - loss: 2.9140e-04 - val_loss: 2.4307e-04 - 39s/epoch - 26ms/step
Epoch 94/300
1493/1493 - 39s - loss: 2.4721e-04 - val_loss: 2.0095e-04 - 39s/epoch - 26ms/step
Epoch 95/300
1493/1493 - 38s - loss: 2.4326e-04 - val_loss: 2.9159e-04 - 38s/epoch - 26ms/step
Epoch 96/300
1493/1493 - 39s - loss: 2.5586e-04 - val_loss: 3.4513e-04 - 39s/epoch - 26ms/step
Epoch 97/300
1493/1493 - 38s - loss: 2.5251e-04 - val_loss: 2.2221e-04 - 38s/epoch - 26ms/step
Epoch 98/300
1493/1493 - 38s - loss: 2.4086e-04 - val_loss: 3.5891e-04 - 38s/epoch - 26ms/step
Epoch 99/300
1493/1493 - 38s - loss: 2.7388e-04 - val_loss: 2.2860e-04 - 38s/epoch - 26ms/step
Epoch 100/300
1493/1493 - 39s - loss: 2.4332e-04 - val_loss: 2.1027e-04 - 39s/epoch - 26ms/step
Epoch 101/300
1493/1493 - 39s - loss: 2.4186e-04 - val_loss: 4.5789e-04 - 39s/epoch - 26ms/step
Epoch 102/300
1493/1493 - 39s - loss: 2.9592e-04 - val_loss: 6.0203e-04 - 39s/epoch - 26ms/step
Epoch 103/300
1493/1493 - 39s - loss: 3.4483e-04 - val_loss: 2.4546e-04 - 39s/epoch - 26ms/step
Epoch 104/300
1493/1493 - 39s - loss: 2.6247e-04 - val_loss: 0.0013 - 39s/epoch - 26ms/step
Epoch 105/300
1493/1493 - 38s - loss: 3.3886e-04 - val_loss: 2.3311e-04 - 38s/epoch - 26ms/step
Epoch 106/300
1493/1493 - 39s - loss: 2.5897e-04 - val_loss: 5.0762e-04 - 39s/epoch - 26ms/step
Epoch 107/300
1493/1493 - 39s - loss: 2.7178e-04 - val_loss: 2.1704e-04 - 39s/epoch - 26ms/step
Epoch 108/300
1493/1493 - 38s - loss: 2.4509e-04 - val_loss: 2.3803e-04 - 38s/epoch - 26ms/step
Epoch 109/300
1493/1493 - 39s - loss: 2.4547e-04 - val_loss: 2.3526e-04 - 39s/epoch - 26ms/step
Epoch 110/300
1493/1493 - 39s - loss: 2.4767e-04 - val_loss: 3.5611e-04 - 39s/epoch - 26ms/step
Epoch 111/300
1493/1493 - 39s - loss: 2.5486e-04 - val_loss: 2.1462e-04 - 39s/epoch - 26ms/step
Epoch 112/300
1493/1493 - 39s - loss: 2.3654e-04 - val_loss: 2.0043e-04 - 39s/epoch - 26ms/step
Epoch 113/300
1493/1493 - 38s - loss: 2.3680e-04 - val_loss: 4.4222e-04 - 38s/epoch - 26ms/step
Epoch 114/300
1493/1493 - 38s - loss: 2.8556e-04 - val_loss: 2.2805e-04 - 38s/epoch - 26ms/step
Epoch 115/300
1493/1493 - 38s - loss: 2.4401e-04 - val_loss: 6.2338e-04 - 38s/epoch - 26ms/step
Epoch 116/300
1493/1493 - 38s - loss: 2.8622e-04 - val_loss: 6.2839e-04 - 38s/epoch - 26ms/step
Epoch 117/300
1493/1493 - 39s - loss: 2.7570e-04 - val_loss: 2.9925e-04 - 39s/epoch - 26ms/step
Epoch 118/300
1493/1493 - 39s - loss: 2.5298e-04 - val_loss: 1.9848e-04 - 39s/epoch - 26ms/step
Epoch 119/300
1493/1493 - 38s - loss: 2.3694e-04 - val_loss: 1.9927e-04 - 38s/epoch - 26ms/step
Epoch 120/300
1493/1493 - 39s - loss: 2.3327e-04 - val_loss: 2.0985e-04 - 39s/epoch - 26ms/step
Epoch 121/300
1493/1493 - 38s - loss: 2.3480e-04 - val_loss: 2.7639e-04 - 38s/epoch - 26ms/step
Epoch 122/300
1493/1493 - 39s - loss: 2.3646e-04 - val_loss: 3.3530e-04 - 39s/epoch - 26ms/step
Epoch 123/300
1493/1493 - 39s - loss: 2.5226e-04 - val_loss: 2.2144e-04 - 39s/epoch - 26ms/step
Epoch 124/300
1493/1493 - 39s - loss: 2.3274e-04 - val_loss: 3.2080e-04 - 39s/epoch - 26ms/step
Epoch 125/300
1493/1493 - 38s - loss: 2.5080e-04 - val_loss: 2.0711e-04 - 38s/epoch - 26ms/step
Epoch 126/300
1493/1493 - 39s - loss: 2.2849e-04 - val_loss: 3.3140e-04 - 39s/epoch - 26ms/step
Epoch 127/300
1493/1493 - 38s - loss: 2.4212e-04 - val_loss: 2.6378e-04 - 38s/epoch - 26ms/step
Epoch 128/300
1493/1493 - 38s - loss: 2.3459e-04 - val_loss: 2.2483e-04 - 38s/epoch - 26ms/step
Epoch 129/300
1493/1493 - 38s - loss: 2.3022e-04 - val_loss: 1.8179e-04 - 38s/epoch - 26ms/step
Epoch 130/300
1493/1493 - 39s - loss: 2.2470e-04 - val_loss: 1.8590e-04 - 39s/epoch - 26ms/step
Epoch 131/300
1493/1493 - 39s - loss: 2.3045e-04 - val_loss: 2.3564e-04 - 39s/epoch - 26ms/step
Epoch 132/300
1493/1493 - 39s - loss: 2.2753e-04 - val_loss: 1.9728e-04 - 39s/epoch - 26ms/step
Epoch 133/300
1493/1493 - 39s - loss: 2.2726e-04 - val_loss: 1.9634e-04 - 39s/epoch - 26ms/step
Epoch 134/300
1493/1493 - 38s - loss: 2.2329e-04 - val_loss: 2.8908e-04 - 38s/epoch - 26ms/step
Epoch 135/300
1493/1493 - 39s - loss: 2.4326e-04 - val_loss: 1.9417e-04 - 39s/epoch - 26ms/step
Epoch 136/300
1493/1493 - 39s - loss: 2.2191e-04 - val_loss: 2.2313e-04 - 39s/epoch - 26ms/step
Epoch 137/300
1493/1493 - 38s - loss: 2.2415e-04 - val_loss: 3.4484e-04 - 38s/epoch - 26ms/step
Epoch 138/300
1493/1493 - 39s - loss: 2.5186e-04 - val_loss: 2.1888e-04 - 39s/epoch - 26ms/step
Epoch 139/300
1493/1493 - 39s - loss: 2.2803e-04 - val_loss: 3.2288e-04 - 39s/epoch - 26ms/step
Epoch 140/300
1493/1493 - 39s - loss: 2.4350e-04 - val_loss: 2.0003e-04 - 39s/epoch - 26ms/step
Epoch 141/300
1493/1493 - 38s - loss: 2.2587e-04 - val_loss: 4.8409e-04 - 38s/epoch - 26ms/step
Epoch 142/300
1493/1493 - 39s - loss: 2.8145e-04 - val_loss: 1.8881e-04 - 39s/epoch - 26ms/step
Epoch 143/300
1493/1493 - 38s - loss: 2.2845e-04 - val_loss: 2.0683e-04 - 38s/epoch - 26ms/step
Epoch 144/300
1493/1493 - 39s - loss: 2.3294e-04 - val_loss: 1.8551e-04 - 39s/epoch - 26ms/step
Epoch 145/300
1493/1493 - 38s - loss: 2.2166e-04 - val_loss: 1.9381e-04 - 38s/epoch - 26ms/step
Epoch 146/300
1493/1493 - 38s - loss: 2.1935e-04 - val_loss: 2.1684e-04 - 38s/epoch - 26ms/step
Epoch 147/300
1493/1493 - 39s - loss: 2.1988e-04 - val_loss: 4.3586e-04 - 39s/epoch - 26ms/step
Epoch 148/300
1493/1493 - 38s - loss: 2.4870e-04 - val_loss: 2.8570e-04 - 38s/epoch - 26ms/step
Epoch 149/300
1493/1493 - 38s - loss: 2.3801e-04 - val_loss: 1.9900e-04 - 38s/epoch - 26ms/step
Epoch 150/300
1493/1493 - 39s - loss: 2.1914e-04 - val_loss: 2.3879e-04 - 39s/epoch - 26ms/step
Epoch 151/300
1493/1493 - 39s - loss: 2.2124e-04 - val_loss: 2.0852e-04 - 39s/epoch - 26ms/step
Epoch 152/300
1493/1493 - 39s - loss: 2.1838e-04 - val_loss: 3.5380e-04 - 39s/epoch - 26ms/step
Epoch 153/300
1493/1493 - 38s - loss: 2.4335e-04 - val_loss: 2.0512e-04 - 38s/epoch - 26ms/step
Epoch 154/300
1493/1493 - 38s - loss: 2.2594e-04 - val_loss: 2.8849e-04 - 38s/epoch - 26ms/step
Epoch 155/300
1493/1493 - 39s - loss: 2.2727e-04 - val_loss: 2.1335e-04 - 39s/epoch - 26ms/step
Epoch 156/300
1493/1493 - 39s - loss: 2.1833e-04 - val_loss: 2.0593e-04 - 39s/epoch - 26ms/step
Epoch 157/300
1493/1493 - 38s - loss: 2.1414e-04 - val_loss: 2.5886e-04 - 38s/epoch - 26ms/step
Epoch 158/300
1493/1493 - 39s - loss: 2.2214e-04 - val_loss: 2.0385e-04 - 39s/epoch - 26ms/step
Epoch 159/300
1493/1493 - 39s - loss: 2.1381e-04 - val_loss: 1.7886e-04 - 39s/epoch - 26ms/step
Epoch 160/300
1493/1493 - 38s - loss: 2.1477e-04 - val_loss: 3.4837e-04 - 38s/epoch - 26ms/step
Epoch 161/300
1493/1493 - 39s - loss: 2.4122e-04 - val_loss: 1.8825e-04 - 39s/epoch - 26ms/step
Epoch 162/300
1493/1493 - 38s - loss: 2.1492e-04 - val_loss: 1.8888e-04 - 38s/epoch - 26ms/step
Epoch 163/300
1493/1493 - 38s - loss: 2.2497e-04 - val_loss: 2.6425e-04 - 38s/epoch - 26ms/step
Epoch 164/300
1493/1493 - 39s - loss: 2.2500e-04 - val_loss: 2.1369e-04 - 39s/epoch - 26ms/step
Epoch 165/300
1493/1493 - 39s - loss: 2.3202e-04 - val_loss: 1.8039e-04 - 39s/epoch - 26ms/step
Epoch 166/300
1493/1493 - 38s - loss: 2.1493e-04 - val_loss: 2.0158e-04 - 38s/epoch - 26ms/step
Epoch 167/300
1493/1493 - 38s - loss: 2.1350e-04 - val_loss: 1.9182e-04 - 38s/epoch - 26ms/step
Epoch 168/300
1493/1493 - 39s - loss: 2.2111e-04 - val_loss: 1.8674e-04 - 39s/epoch - 26ms/step
Epoch 169/300
1493/1493 - 39s - loss: 2.1033e-04 - val_loss: 2.3584e-04 - 39s/epoch - 26ms/step
Epoch 170/300
1493/1493 - 38s - loss: 2.1908e-04 - val_loss: 4.4185e-04 - 38s/epoch - 26ms/step
Epoch 171/300
1493/1493 - 38s - loss: 2.7817e-04 - val_loss: 2.6019e-04 - 38s/epoch - 26ms/step
Epoch 172/300
1493/1493 - 38s - loss: 2.2380e-04 - val_loss: 3.5894e-04 - 38s/epoch - 26ms/step
Epoch 173/300
1493/1493 - 39s - loss: 2.3123e-04 - val_loss: 1.9407e-04 - 39s/epoch - 26ms/step
Epoch 174/300
1493/1493 - 38s - loss: 2.1101e-04 - val_loss: 1.9444e-04 - 38s/epoch - 26ms/step
Epoch 175/300
1493/1493 - 38s - loss: 2.1146e-04 - val_loss: 2.3024e-04 - 38s/epoch - 26ms/step
Epoch 176/300
1493/1493 - 39s - loss: 2.1838e-04 - val_loss: 2.1421e-04 - 39s/epoch - 26ms/step
Epoch 177/300
1493/1493 - 39s - loss: 2.1251e-04 - val_loss: 1.8412e-04 - 39s/epoch - 26ms/step
Epoch 178/300
1493/1493 - 38s - loss: 2.0943e-04 - val_loss: 1.7028e-04 - 38s/epoch - 26ms/step
Epoch 179/300
1493/1493 - 39s - loss: 2.0707e-04 - val_loss: 1.9090e-04 - 39s/epoch - 26ms/step
Epoch 180/300
1493/1493 - 38s - loss: 2.0891e-04 - val_loss: 3.6365e-04 - 38s/epoch - 26ms/step
Epoch 181/300
1493/1493 - 39s - loss: 2.5794e-04 - val_loss: 3.5691e-04 - 39s/epoch - 26ms/step
Epoch 182/300
1493/1493 - 39s - loss: 2.3004e-04 - val_loss: 1.9536e-04 - 39s/epoch - 26ms/step
Epoch 183/300
1493/1493 - 39s - loss: 2.0957e-04 - val_loss: 2.1637e-04 - 39s/epoch - 26ms/step
Epoch 184/300
1493/1493 - 39s - loss: 2.3154e-04 - val_loss: 1.8679e-04 - 39s/epoch - 26ms/step
Epoch 185/300
1493/1493 - 39s - loss: 2.1225e-04 - val_loss: 2.2174e-04 - 39s/epoch - 26ms/step
Epoch 186/300
1493/1493 - 38s - loss: 2.1126e-04 - val_loss: 1.8291e-04 - 38s/epoch - 26ms/step
Epoch 187/300
1493/1493 - 39s - loss: 2.0780e-04 - val_loss: 1.7261e-04 - 39s/epoch - 26ms/step
Epoch 188/300
1493/1493 - 39s - loss: 2.0827e-04 - val_loss: 2.4705e-04 - 39s/epoch - 26ms/step
Epoch 189/300
1493/1493 - 38s - loss: 2.0820e-04 - val_loss: 2.3767e-04 - 38s/epoch - 26ms/step
Epoch 190/300
1493/1493 - 39s - loss: 2.1140e-04 - val_loss: 2.6751e-04 - 39s/epoch - 26ms/step
Epoch 191/300
1493/1493 - 38s - loss: 2.2994e-04 - val_loss: 7.3255e-04 - 38s/epoch - 26ms/step
Epoch 192/300
1493/1493 - 38s - loss: 2.7640e-04 - val_loss: 1.9984e-04 - 38s/epoch - 26ms/step
Epoch 193/300
1493/1493 - 39s - loss: 2.2004e-04 - val_loss: 4.0910e-04 - 39s/epoch - 26ms/step
Epoch 194/300
1493/1493 - 38s - loss: 2.4739e-04 - val_loss: 3.6508e-04 - 38s/epoch - 26ms/step
Epoch 195/300
1493/1493 - 38s - loss: 2.4006e-04 - val_loss: 3.0187e-04 - 38s/epoch - 26ms/step
Epoch 196/300
1493/1493 - 39s - loss: 2.2410e-04 - val_loss: 2.0417e-04 - 39s/epoch - 26ms/step
Epoch 197/300
1493/1493 - 39s - loss: 2.0897e-04 - val_loss: 2.2645e-04 - 39s/epoch - 26ms/step
Epoch 198/300
1493/1493 - 38s - loss: 2.1059e-04 - val_loss: 2.4026e-04 - 38s/epoch - 26ms/step
Epoch 199/300
1493/1493 - 38s - loss: 2.0964e-04 - val_loss: 1.9858e-04 - 38s/epoch - 26ms/step
Epoch 200/300
1493/1493 - 39s - loss: 2.0574e-04 - val_loss: 1.9391e-04 - 39s/epoch - 26ms/step
Epoch 201/300
1493/1493 - 39s - loss: 2.0418e-04 - val_loss: 1.7380e-04 - 39s/epoch - 26ms/step
Epoch 202/300
1493/1493 - 38s - loss: 2.0595e-04 - val_loss: 2.2790e-04 - 38s/epoch - 26ms/step
Epoch 203/300
1493/1493 - 39s - loss: 2.1186e-04 - val_loss: 7.3861e-04 - 39s/epoch - 26ms/step
Epoch 204/300
1493/1493 - 39s - loss: 3.1423e-04 - val_loss: 2.6154e-04 - 39s/epoch - 26ms/step
Epoch 205/300
1493/1493 - 38s - loss: 2.2258e-04 - val_loss: 1.8697e-04 - 38s/epoch - 26ms/step
Epoch 206/300
1493/1493 - 39s - loss: 2.1030e-04 - val_loss: 2.8764e-04 - 39s/epoch - 26ms/step
Epoch 207/300
1493/1493 - 39s - loss: 2.1432e-04 - val_loss: 2.6632e-04 - 39s/epoch - 26ms/step
Epoch 208/300
1493/1493 - 38s - loss: 2.1525e-04 - val_loss: 2.2378e-04 - 38s/epoch - 26ms/step
Epoch 209/300
1493/1493 - 38s - loss: 2.0862e-04 - val_loss: 2.7403e-04 - 38s/epoch - 26ms/step
Epoch 210/300
1493/1493 - 38s - loss: 2.1482e-04 - val_loss: 2.4094e-04 - 38s/epoch - 26ms/step
Epoch 211/300
1493/1493 - 39s - loss: 2.1241e-04 - val_loss: 1.9967e-04 - 39s/epoch - 26ms/step
Epoch 212/300
1493/1493 - 38s - loss: 2.1199e-04 - val_loss: 2.0087e-04 - 38s/epoch - 26ms/step
Epoch 213/300
1493/1493 - 39s - loss: 2.0441e-04 - val_loss: 1.8898e-04 - 39s/epoch - 26ms/step
Epoch 214/300
1493/1493 - 39s - loss: 2.0287e-04 - val_loss: 2.0750e-04 - 39s/epoch - 26ms/step
Epoch 215/300
1493/1493 - 39s - loss: 2.0461e-04 - val_loss: 2.7407e-04 - 39s/epoch - 26ms/step
Epoch 216/300
1493/1493 - 39s - loss: 2.0875e-04 - val_loss: 1.6930e-04 - 39s/epoch - 26ms/step
Epoch 217/300
1493/1493 - 39s - loss: 1.9845e-04 - val_loss: 1.7214e-04 - 39s/epoch - 26ms/step
Epoch 218/300
1493/1493 - 38s - loss: 1.9840e-04 - val_loss: 2.3437e-04 - 38s/epoch - 26ms/step
Epoch 219/300
1493/1493 - 39s - loss: 2.0401e-04 - val_loss: 5.5603e-04 - 39s/epoch - 26ms/step
Epoch 220/300
1493/1493 - 39s - loss: 2.5627e-04 - val_loss: 1.7664e-04 - 39s/epoch - 26ms/step
Epoch 221/300
1493/1493 - 39s - loss: 2.0356e-04 - val_loss: 2.4045e-04 - 39s/epoch - 26ms/step
Epoch 222/300
1493/1493 - 38s - loss: 2.0598e-04 - val_loss: 3.0892e-04 - 38s/epoch - 26ms/step
Epoch 223/300
1493/1493 - 39s - loss: 2.1688e-04 - val_loss: 2.3994e-04 - 39s/epoch - 26ms/step
Epoch 224/300
1493/1493 - 39s - loss: 2.0819e-04 - val_loss: 2.6179e-04 - 39s/epoch - 26ms/step
Epoch 225/300
1493/1493 - 39s - loss: 2.0451e-04 - val_loss: 2.8453e-04 - 39s/epoch - 26ms/step
Epoch 226/300
1493/1493 - 38s - loss: 2.1040e-04 - val_loss: 1.9567e-04 - 38s/epoch - 26ms/step
Epoch 227/300
1493/1493 - 38s - loss: 2.0540e-04 - val_loss: 2.4368e-04 - 38s/epoch - 26ms/step
Epoch 228/300
1493/1493 - 39s - loss: 2.0018e-04 - val_loss: 2.1674e-04 - 39s/epoch - 26ms/step
Epoch 229/300
1493/1493 - 39s - loss: 1.9935e-04 - val_loss: 2.0095e-04 - 39s/epoch - 26ms/step
Epoch 230/300
1493/1493 - 39s - loss: 1.9725e-04 - val_loss: 2.1012e-04 - 39s/epoch - 26ms/step
Epoch 231/300
1493/1493 - 39s - loss: 1.9789e-04 - val_loss: 2.2718e-04 - 39s/epoch - 26ms/step
Epoch 232/300
1493/1493 - 39s - loss: 2.0142e-04 - val_loss: 3.1133e-04 - 39s/epoch - 26ms/step
Epoch 233/300
1493/1493 - 38s - loss: 2.2972e-04 - val_loss: 1.9475e-04 - 38s/epoch - 26ms/step
Epoch 234/300
1493/1493 - 39s - loss: 1.9871e-04 - val_loss: 2.2040e-04 - 39s/epoch - 26ms/step
Epoch 235/300
1493/1493 - 38s - loss: 2.1755e-04 - val_loss: 1.9132e-04 - 38s/epoch - 26ms/step
Epoch 236/300
1493/1493 - 38s - loss: 1.9745e-04 - val_loss: 1.7548e-04 - 38s/epoch - 26ms/step
Epoch 237/300
1493/1493 - 39s - loss: 1.9847e-04 - val_loss: 3.2131e-04 - 39s/epoch - 26ms/step
Epoch 238/300
1493/1493 - 39s - loss: 2.2664e-04 - val_loss: 1.7814e-04 - 39s/epoch - 26ms/step
Epoch 239/300
1493/1493 - 39s - loss: 2.0135e-04 - val_loss: 2.9547e-04 - 39s/epoch - 26ms/step
Epoch 240/300
1493/1493 - 38s - loss: 2.1982e-04 - val_loss: 1.8880e-04 - 38s/epoch - 26ms/step
Epoch 241/300
1493/1493 - 38s - loss: 1.9706e-04 - val_loss: 1.7376e-04 - 38s/epoch - 26ms/step
Epoch 242/300
1493/1493 - 39s - loss: 1.9691e-04 - val_loss: 2.4188e-04 - 39s/epoch - 26ms/step
Epoch 243/300
1493/1493 - 38s - loss: 2.1408e-04 - val_loss: 3.1371e-04 - 38s/epoch - 26ms/step
Epoch 244/300
1493/1493 - 38s - loss: 2.1489e-04 - val_loss: 2.5556e-04 - 38s/epoch - 26ms/step
Epoch 245/300
1493/1493 - 39s - loss: 2.0600e-04 - val_loss: 1.9760e-04 - 39s/epoch - 26ms/step
Epoch 246/300
1493/1493 - 39s - loss: 2.0404e-04 - val_loss: 7.0333e-04 - 39s/epoch - 26ms/step
Epoch 247/300
1493/1493 - 39s - loss: 2.7994e-04 - val_loss: 3.0883e-04 - 39s/epoch - 26ms/step
Epoch 248/300
1493/1493 - 39s - loss: 2.0645e-04 - val_loss: 3.2958e-04 - 39s/epoch - 26ms/step
Epoch 249/300
1493/1493 - 38s - loss: 2.1217e-04 - val_loss: 1.8149e-04 - 38s/epoch - 26ms/step
Epoch 250/300
1493/1493 - 39s - loss: 1.9755e-04 - val_loss: 2.0170e-04 - 39s/epoch - 26ms/step
Epoch 251/300
1493/1493 - 38s - loss: 2.0047e-04 - val_loss: 2.2329e-04 - 38s/epoch - 26ms/step
Epoch 252/300
1493/1493 - 39s - loss: 1.9931e-04 - val_loss: 2.5836e-04 - 39s/epoch - 26ms/step
Epoch 253/300
1493/1493 - 38s - loss: 2.0322e-04 - val_loss: 1.9344e-04 - 38s/epoch - 26ms/step
Epoch 254/300
1493/1493 - 39s - loss: 1.9691e-04 - val_loss: 3.4847e-04 - 39s/epoch - 26ms/step
Epoch 255/300
1493/1493 - 38s - loss: 2.0295e-04 - val_loss: 1.8843e-04 - 38s/epoch - 26ms/step
Epoch 256/300
1493/1493 - 39s - loss: 1.9841e-04 - val_loss: 1.8595e-04 - 39s/epoch - 26ms/step
Epoch 257/300
1493/1493 - 38s - loss: 1.9545e-04 - val_loss: 4.4896e-04 - 38s/epoch - 26ms/step
Epoch 258/300
1493/1493 - 39s - loss: 2.3898e-04 - val_loss: 2.8541e-04 - 39s/epoch - 26ms/step
Epoch 259/300
1493/1493 - 38s - loss: 2.0502e-04 - val_loss: 3.0728e-04 - 38s/epoch - 26ms/step
Epoch 260/300
1493/1493 - 39s - loss: 2.3417e-04 - val_loss: 3.3495e-04 - 39s/epoch - 26ms/step
Epoch 261/300
1493/1493 - 39s - loss: 2.1853e-04 - val_loss: 2.7268e-04 - 39s/epoch - 26ms/step
Epoch 262/300
1493/1493 - 39s - loss: 2.0621e-04 - val_loss: 1.9025e-04 - 39s/epoch - 26ms/step
Epoch 263/300
1493/1493 - 39s - loss: 1.9626e-04 - val_loss: 2.1257e-04 - 39s/epoch - 26ms/step
Epoch 264/300
1493/1493 - 39s - loss: 2.0079e-04 - val_loss: 1.8503e-04 - 39s/epoch - 26ms/step
Epoch 265/300
1493/1493 - 39s - loss: 1.9659e-04 - val_loss: 3.4552e-04 - 39s/epoch - 26ms/step
Epoch 266/300
1493/1493 - 38s - loss: 2.3596e-04 - val_loss: 2.0946e-04 - 38s/epoch - 26ms/step
Epoch 267/300
1493/1493 - 38s - loss: 1.9824e-04 - val_loss: 2.0274e-04 - 38s/epoch - 26ms/step
Epoch 268/300
1493/1493 - 39s - loss: 1.9444e-04 - val_loss: 2.0591e-04 - 39s/epoch - 26ms/step
Epoch 269/300
1493/1493 - 38s - loss: 1.9735e-04 - val_loss: 4.4391e-04 - 38s/epoch - 26ms/step
Epoch 270/300
1493/1493 - 39s - loss: 2.3850e-04 - val_loss: 2.3968e-04 - 39s/epoch - 26ms/step
Epoch 271/300
1493/1493 - 39s - loss: 1.9875e-04 - val_loss: 2.0674e-04 - 39s/epoch - 26ms/step
Epoch 272/300
1493/1493 - 39s - loss: 1.9888e-04 - val_loss: 3.3915e-04 - 39s/epoch - 26ms/step
Epoch 273/300
1493/1493 - 38s - loss: 2.3501e-04 - val_loss: 2.6450e-04 - 38s/epoch - 26ms/step
Epoch 274/300
1493/1493 - 39s - loss: 2.1037e-04 - val_loss: 4.2591e-04 - 39s/epoch - 26ms/step
Epoch 275/300
1493/1493 - 38s - loss: 2.3049e-04 - val_loss: 1.6847e-04 - 38s/epoch - 26ms/step
Epoch 276/300
1493/1493 - 39s - loss: 1.9306e-04 - val_loss: 1.8811e-04 - 39s/epoch - 26ms/step
Epoch 277/300
1493/1493 - 39s - loss: 1.9653e-04 - val_loss: 4.8613e-04 - 39s/epoch - 26ms/step
Epoch 278/300
1493/1493 - 39s - loss: 2.3648e-04 - val_loss: 1.9433e-04 - 39s/epoch - 26ms/step
Epoch 279/300
1493/1493 - 39s - loss: 1.9674e-04 - val_loss: 2.4550e-04 - 39s/epoch - 26ms/step
Epoch 280/300
1493/1493 - 39s - loss: 2.0276e-04 - val_loss: 1.8146e-04 - 39s/epoch - 26ms/step
Epoch 281/300
1493/1493 - 38s - loss: 1.9338e-04 - val_loss: 2.0003e-04 - 38s/epoch - 26ms/step
Epoch 282/300
1493/1493 - 38s - loss: 1.9353e-04 - val_loss: 1.9571e-04 - 38s/epoch - 26ms/step
Epoch 283/300
1493/1493 - 38s - loss: 1.9112e-04 - val_loss: 2.9058e-04 - 38s/epoch - 26ms/step
Epoch 284/300
1493/1493 - 38s - loss: 2.1461e-04 - val_loss: 2.1208e-04 - 38s/epoch - 26ms/step
Epoch 285/300
1493/1493 - 38s - loss: 1.9333e-04 - val_loss: 2.5638e-04 - 38s/epoch - 26ms/step
Epoch 286/300
1493/1493 - 39s - loss: 1.9210e-04 - val_loss: 1.8765e-04 - 39s/epoch - 26ms/step
Epoch 287/300
1493/1493 - 39s - loss: 1.9343e-04 - val_loss: 5.2042e-04 - 39s/epoch - 26ms/step
Epoch 288/300
1493/1493 - 39s - loss: 2.4766e-04 - val_loss: 2.8238e-04 - 39s/epoch - 26ms/step
Epoch 289/300
1493/1493 - 39s - loss: 1.9595e-04 - val_loss: 3.9568e-04 - 39s/epoch - 26ms/step
Epoch 290/300
1493/1493 - 39s - loss: 2.0508e-04 - val_loss: 3.7057e-04 - 39s/epoch - 26ms/step
Epoch 291/300
1493/1493 - 38s - loss: 2.0814e-04 - val_loss: 2.2534e-04 - 38s/epoch - 26ms/step
Epoch 292/300
1493/1493 - 39s - loss: 1.9018e-04 - val_loss: 1.9566e-04 - 39s/epoch - 26ms/step
Epoch 293/300
1493/1493 - 38s - loss: 1.9020e-04 - val_loss: 1.7926e-04 - 38s/epoch - 26ms/step
Epoch 294/300
1493/1493 - 39s - loss: 1.9147e-04 - val_loss: 2.5337e-04 - 39s/epoch - 26ms/step
Epoch 295/300
1493/1493 - 39s - loss: 1.9492e-04 - val_loss: 1.8354e-04 - 39s/epoch - 26ms/step
Epoch 296/300
1493/1493 - 39s - loss: 1.8776e-04 - val_loss: 2.3282e-04 - 39s/epoch - 26ms/step
Epoch 297/300
1493/1493 - 39s - loss: 1.8978e-04 - val_loss: 1.8499e-04 - 39s/epoch - 26ms/step
Epoch 298/300
1493/1493 - 39s - loss: 1.9075e-04 - val_loss: 4.4246e-04 - 39s/epoch - 26ms/step
Epoch 299/300
1493/1493 - 38s - loss: 2.2846e-04 - val_loss: 2.0825e-04 - 38s/epoch - 26ms/step
Epoch 300/300
1493/1493 - 38s - loss: 1.9080e-04 - val_loss: 2.9627e-04 - 38s/epoch - 26ms/step
COMPRESSED VECTOR SIZE: 632
Loss in the autoencoder: 0.00029627486946992576
  1/332 [..............................] - ETA: 27s 16/332 [>.............................] - ETA: 1s  32/332 [=>............................] - ETA: 1s 48/332 [===>..........................] - ETA: 0s 64/332 [====>.........................] - ETA: 0s 80/332 [======>.......................] - ETA: 0s 96/332 [=======>......................] - ETA: 0s112/332 [=========>....................] - ETA: 0s128/332 [==========>...................] - ETA: 0s144/332 [============>.................] - ETA: 0s160/332 [=============>................] - ETA: 0s176/332 [==============>...............] - ETA: 0s192/332 [================>.............] - ETA: 0s208/332 [=================>............] - ETA: 0s224/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s256/332 [======================>.......] - ETA: 0s272/332 [=======================>......] - ETA: 0s288/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s320/332 [===========================>..] - ETA: 0s332/332 [==============================] - 1s 3ms/step
correlation 0.0033056313615001647
cosine 0.0026111130978627066
MAE: 0.0114620635
RMSE: 0.017212637
r2: 0.980781014427317
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_33"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_34 (InputLayer)       multiple                  0         
                                                                 
 dense_33 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_33 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_33 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
 batch_normalization_34 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_34 (ReLU)             (None, 632)               0         
                                                                 
 dense_34 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_35 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_35 (ReLU)             (None, 1264)              0         
                                                                 
 dense_35 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 4,810,152
Trainable params: 4,803,832
Non-trainable params: 6,320
_________________________________________________________________
Encoder
Model: "model_34"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_35 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_34 (InputLayer)       multiple                  0         
                                                                 
 dense_33 (Dense)            (None, 1264)              1598960   
                                                                 
 batch_normalization_33 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_33 (ReLU)             (None, 1264)              0         
                                                                 
 bottleneck (Dense)          (None, 632)               799480    
                                                                 
=================================================================
Total params: 2,403,496
Trainable params: 2,400,968
Non-trainable params: 2,528
_________________________________________________________________
Decoder
Model: "model_35"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_36 (InputLayer)       [(None, 632)]             0         
                                                                 
 batch_normalization_34 (Bat  (None, 632)              2528      
 chNormalization)                                                
                                                                 
 re_lu_34 (ReLU)             (None, 632)               0         
                                                                 
 dense_34 (Dense)            (None, 1264)              800112    
                                                                 
 batch_normalization_35 (Bat  (None, 1264)             5056      
 chNormalization)                                                
                                                                 
 re_lu_35 (ReLU)             (None, 1264)              0         
                                                                 
 dense_35 (Dense)            (None, 1264)              1598960   
                                                                 
=================================================================
Total params: 2,406,656
Trainable params: 2,402,864
Non-trainable params: 3,792
_________________________________________________________________
['n_b', 'mse', 64, 300, 0.002, 0.5, 632, 0.00019079732010141015, 0.00029627486946992576, 0.0033056313615001647, 0.0026111130978627066, 0.011462063528597355, 0.0172126367688179, 0.980781014427317, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Sat Dec 31 09:36:35 CET 2022
done
