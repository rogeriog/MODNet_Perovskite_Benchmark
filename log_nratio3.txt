start
Wed Dec 28 16:06:42 CET 2022
2022-12-28 16:06:43.191391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-28 16:06:43.267349: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2022-12-28 16:07:15,839 - modnet - INFO - Loaded <modnet.preprocessing.MODData object at 0x7fdc95a2c8b0> object, created with modnet version 0.1.12
        AtomicOrbitals|HOMO_character  ...  BondFractions|B - B bond frac.
id                                     ...                                
0                                 3.0  ...                             0.0
1                                 3.0  ...                             0.0
2                                 2.0  ...                             0.0
3                                 2.0  ...                             0.0
4                                 2.0  ...                             0.0
...                               ...  ...                             ...
106108                            3.0  ...                             0.0
106109                            2.0  ...                             0.0
106110                            3.0  ...                             0.0
106111                            3.0  ...                             0.0
106112                            1.0  ...                             0.0

[106113 rows x 1336 columns]
Shape of dataset to encode: (106113, 1264)
2022-12-28 16:07:18.909665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense (Dense)               (None, 1896)              2398440   
                                                                 
 batch_normalization (BatchN  (None, 1896)             7584      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1896)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              1917867   
                                                                 
 batch_normalization_1 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 1011)              0         
                                                                 
 dense_1 (Dense)             (None, 1896)              1918752   
                                                                 
 batch_normalization_2 (Batc  (None, 1896)             7584      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1896)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              2397808   
                                                                 
=================================================================
Total params: 8,652,079
Trainable params: 8,642,473
Non-trainable params: 9,606
_________________________________________________________________
Epoch 1/200
1493/1493 - 53s - loss: 0.0089 - val_loss: 0.0042 - 53s/epoch - 35ms/step
Epoch 2/200
1493/1493 - 52s - loss: 0.0028 - val_loss: 0.0027 - 52s/epoch - 35ms/step
Epoch 3/200
1493/1493 - 52s - loss: 0.0019 - val_loss: 0.0016 - 52s/epoch - 35ms/step
Epoch 4/200
1493/1493 - 52s - loss: 0.0016 - val_loss: 0.0028 - 52s/epoch - 35ms/step
Epoch 5/200
1493/1493 - 52s - loss: 0.0015 - val_loss: 0.0013 - 52s/epoch - 35ms/step
Epoch 6/200
1493/1493 - 52s - loss: 0.0012 - val_loss: 0.0012 - 52s/epoch - 35ms/step
Epoch 7/200
1493/1493 - 52s - loss: 0.0012 - val_loss: 0.0011 - 52s/epoch - 35ms/step
Epoch 8/200
1493/1493 - 52s - loss: 0.0011 - val_loss: 0.0013 - 52s/epoch - 35ms/step
Epoch 9/200
1493/1493 - 52s - loss: 9.8815e-04 - val_loss: 0.0020 - 52s/epoch - 35ms/step
Epoch 10/200
1493/1493 - 51s - loss: 0.0011 - val_loss: 8.3217e-04 - 51s/epoch - 34ms/step
Epoch 11/200
1493/1493 - 51s - loss: 8.5351e-04 - val_loss: 7.8621e-04 - 51s/epoch - 34ms/step
Epoch 12/200
1493/1493 - 51s - loss: 7.6548e-04 - val_loss: 9.1466e-04 - 51s/epoch - 34ms/step
Epoch 13/200
1493/1493 - 51s - loss: 7.6047e-04 - val_loss: 0.0020 - 51s/epoch - 34ms/step
Epoch 14/200
1493/1493 - 52s - loss: 7.8548e-04 - val_loss: 0.0012 - 52s/epoch - 35ms/step
Epoch 15/200
1493/1493 - 51s - loss: 7.3741e-04 - val_loss: 9.6485e-04 - 51s/epoch - 34ms/step
Epoch 16/200
1493/1493 - 51s - loss: 6.3843e-04 - val_loss: 5.5670e-04 - 51s/epoch - 34ms/step
Epoch 17/200
1493/1493 - 51s - loss: 5.8132e-04 - val_loss: 6.1091e-04 - 51s/epoch - 34ms/step
Epoch 18/200
1493/1493 - 51s - loss: 5.5129e-04 - val_loss: 7.6683e-04 - 51s/epoch - 34ms/step
Epoch 19/200
1493/1493 - 52s - loss: 5.4592e-04 - val_loss: 6.0212e-04 - 52s/epoch - 35ms/step
Epoch 20/200
1493/1493 - 51s - loss: 5.1377e-04 - val_loss: 5.0966e-04 - 51s/epoch - 34ms/step
Epoch 21/200
1493/1493 - 51s - loss: 4.9019e-04 - val_loss: 6.0148e-04 - 51s/epoch - 34ms/step
Epoch 22/200
1493/1493 - 52s - loss: 4.6607e-04 - val_loss: 5.5361e-04 - 52s/epoch - 35ms/step
Epoch 23/200
1493/1493 - 52s - loss: 4.5455e-04 - val_loss: 0.0010 - 52s/epoch - 35ms/step
Epoch 24/200
1493/1493 - 52s - loss: 4.6440e-04 - val_loss: 4.3684e-04 - 52s/epoch - 35ms/step
Epoch 25/200
1493/1493 - 51s - loss: 4.2881e-04 - val_loss: 4.4110e-04 - 51s/epoch - 34ms/step
Epoch 26/200
1493/1493 - 51s - loss: 3.9918e-04 - val_loss: 5.0041e-04 - 51s/epoch - 34ms/step
Epoch 27/200
1493/1493 - 52s - loss: 3.8208e-04 - val_loss: 4.0824e-04 - 52s/epoch - 35ms/step
Epoch 28/200
1493/1493 - 52s - loss: 3.6429e-04 - val_loss: 5.8755e-04 - 52s/epoch - 35ms/step
Epoch 29/200
1493/1493 - 52s - loss: 3.5932e-04 - val_loss: 5.3100e-04 - 52s/epoch - 35ms/step
Epoch 30/200
1493/1493 - 51s - loss: 3.6480e-04 - val_loss: 4.0133e-04 - 51s/epoch - 34ms/step
Epoch 31/200
1493/1493 - 51s - loss: 3.3533e-04 - val_loss: 7.8078e-04 - 51s/epoch - 34ms/step
Epoch 32/200
1493/1493 - 51s - loss: 3.8997e-04 - val_loss: 3.3494e-04 - 51s/epoch - 34ms/step
Epoch 33/200
1493/1493 - 52s - loss: 3.2467e-04 - val_loss: 3.9692e-04 - 52s/epoch - 35ms/step
Epoch 34/200
1493/1493 - 52s - loss: 3.1469e-04 - val_loss: 2.9164e-04 - 52s/epoch - 35ms/step
Epoch 35/200
1493/1493 - 52s - loss: 3.0111e-04 - val_loss: 5.9725e-04 - 52s/epoch - 35ms/step
Epoch 36/200
1493/1493 - 52s - loss: 3.1867e-04 - val_loss: 4.5931e-04 - 52s/epoch - 35ms/step
Epoch 37/200
1493/1493 - 52s - loss: 2.9310e-04 - val_loss: 8.9580e-04 - 52s/epoch - 35ms/step
Epoch 38/200
1493/1493 - 51s - loss: 3.4202e-04 - val_loss: 2.8357e-04 - 51s/epoch - 34ms/step
Epoch 39/200
1493/1493 - 52s - loss: 2.7892e-04 - val_loss: 2.4935e-04 - 52s/epoch - 35ms/step
Epoch 40/200
1493/1493 - 52s - loss: 2.6622e-04 - val_loss: 3.4661e-04 - 52s/epoch - 35ms/step
Epoch 41/200
1493/1493 - 52s - loss: 2.7020e-04 - val_loss: 2.4739e-04 - 52s/epoch - 35ms/step
Epoch 42/200
1493/1493 - 52s - loss: 2.5827e-04 - val_loss: 2.4893e-04 - 52s/epoch - 35ms/step
Epoch 43/200
1493/1493 - 52s - loss: 2.5860e-04 - val_loss: 4.6041e-04 - 52s/epoch - 35ms/step
Epoch 44/200
1493/1493 - 52s - loss: 2.6670e-04 - val_loss: 3.5595e-04 - 52s/epoch - 35ms/step
Epoch 45/200
1493/1493 - 52s - loss: 2.5719e-04 - val_loss: 2.1272e-04 - 52s/epoch - 35ms/step
Epoch 46/200
1493/1493 - 51s - loss: 2.4185e-04 - val_loss: 2.2750e-04 - 51s/epoch - 34ms/step
Epoch 47/200
1493/1493 - 52s - loss: 2.3916e-04 - val_loss: 2.4349e-04 - 52s/epoch - 35ms/step
Epoch 48/200
1493/1493 - 51s - loss: 2.3929e-04 - val_loss: 2.9793e-04 - 51s/epoch - 34ms/step
Epoch 49/200
1493/1493 - 52s - loss: 2.3425e-04 - val_loss: 4.8375e-04 - 52s/epoch - 35ms/step
Epoch 50/200
1493/1493 - 52s - loss: 2.4106e-04 - val_loss: 3.7051e-04 - 52s/epoch - 35ms/step
Epoch 51/200
1493/1493 - 52s - loss: 2.3336e-04 - val_loss: 2.6605e-04 - 52s/epoch - 35ms/step
Epoch 52/200
1493/1493 - 52s - loss: 2.1783e-04 - val_loss: 2.3922e-04 - 52s/epoch - 35ms/step
Epoch 53/200
1493/1493 - 52s - loss: 2.1914e-04 - val_loss: 2.0021e-04 - 52s/epoch - 35ms/step
Epoch 54/200
1493/1493 - 52s - loss: 2.1431e-04 - val_loss: 2.5749e-04 - 52s/epoch - 35ms/step
Epoch 55/200
1493/1493 - 51s - loss: 2.0679e-04 - val_loss: 2.1125e-04 - 51s/epoch - 34ms/step
Epoch 56/200
1493/1493 - 51s - loss: 2.0827e-04 - val_loss: 2.9420e-04 - 51s/epoch - 34ms/step
Epoch 57/200
1493/1493 - 51s - loss: 2.0193e-04 - val_loss: 2.3142e-04 - 51s/epoch - 34ms/step
Epoch 58/200
1493/1493 - 51s - loss: 2.0104e-04 - val_loss: 1.6835e-04 - 51s/epoch - 34ms/step
Epoch 59/200
1493/1493 - 52s - loss: 1.9807e-04 - val_loss: 2.1509e-04 - 52s/epoch - 35ms/step
Epoch 60/200
1493/1493 - 52s - loss: 1.9871e-04 - val_loss: 5.0473e-04 - 52s/epoch - 35ms/step
Epoch 61/200
1493/1493 - 51s - loss: 2.3285e-04 - val_loss: 1.9026e-04 - 51s/epoch - 34ms/step
Epoch 62/200
1493/1493 - 52s - loss: 1.9202e-04 - val_loss: 2.1927e-04 - 52s/epoch - 35ms/step
Epoch 63/200
1493/1493 - 52s - loss: 1.8980e-04 - val_loss: 2.6155e-04 - 52s/epoch - 35ms/step
Epoch 64/200
1493/1493 - 52s - loss: 1.9251e-04 - val_loss: 0.0019 - 52s/epoch - 35ms/step
Epoch 65/200
1493/1493 - 52s - loss: 3.0829e-04 - val_loss: 2.7104e-04 - 52s/epoch - 35ms/step
Epoch 66/200
1493/1493 - 51s - loss: 2.0267e-04 - val_loss: 1.9216e-04 - 51s/epoch - 34ms/step
Epoch 67/200
1493/1493 - 51s - loss: 1.8849e-04 - val_loss: 1.8533e-04 - 51s/epoch - 34ms/step
Epoch 68/200
1493/1493 - 51s - loss: 1.8266e-04 - val_loss: 2.2622e-04 - 51s/epoch - 34ms/step
Epoch 69/200
1493/1493 - 51s - loss: 1.8934e-04 - val_loss: 2.2010e-04 - 51s/epoch - 34ms/step
Epoch 70/200
1493/1493 - 51s - loss: 1.8053e-04 - val_loss: 4.2289e-04 - 51s/epoch - 34ms/step
Epoch 71/200
1493/1493 - 51s - loss: 1.9783e-04 - val_loss: 1.8155e-04 - 51s/epoch - 34ms/step
Epoch 72/200
1493/1493 - 52s - loss: 1.7742e-04 - val_loss: 2.1395e-04 - 52s/epoch - 35ms/step
Epoch 73/200
1493/1493 - 52s - loss: 1.7882e-04 - val_loss: 2.0515e-04 - 52s/epoch - 35ms/step
Epoch 74/200
1493/1493 - 52s - loss: 1.7454e-04 - val_loss: 1.7493e-04 - 52s/epoch - 35ms/step
Epoch 75/200
1493/1493 - 52s - loss: 1.6835e-04 - val_loss: 1.7233e-04 - 52s/epoch - 35ms/step
Epoch 76/200
1493/1493 - 52s - loss: 1.6634e-04 - val_loss: 1.6677e-04 - 52s/epoch - 35ms/step
Epoch 77/200
1493/1493 - 52s - loss: 1.6579e-04 - val_loss: 5.1511e-04 - 52s/epoch - 35ms/step
Epoch 78/200
1493/1493 - 51s - loss: 1.7703e-04 - val_loss: 4.7219e-04 - 51s/epoch - 34ms/step
Epoch 79/200
1493/1493 - 52s - loss: 1.9087e-04 - val_loss: 1.6770e-04 - 52s/epoch - 35ms/step
Epoch 80/200
1493/1493 - 51s - loss: 1.6524e-04 - val_loss: 1.6449e-04 - 51s/epoch - 34ms/step
Epoch 81/200
1493/1493 - 52s - loss: 1.6021e-04 - val_loss: 2.3112e-04 - 52s/epoch - 35ms/step
Epoch 82/200
1493/1493 - 51s - loss: 1.5791e-04 - val_loss: 1.6602e-04 - 51s/epoch - 34ms/step
Epoch 83/200
1493/1493 - 51s - loss: 1.5562e-04 - val_loss: 1.7313e-04 - 51s/epoch - 34ms/step
Epoch 84/200
1493/1493 - 51s - loss: 1.5503e-04 - val_loss: 1.9387e-04 - 51s/epoch - 34ms/step
Epoch 85/200
1493/1493 - 51s - loss: 1.5683e-04 - val_loss: 1.8646e-04 - 51s/epoch - 34ms/step
Epoch 86/200
1493/1493 - 52s - loss: 1.5283e-04 - val_loss: 1.6305e-04 - 52s/epoch - 35ms/step
Epoch 87/200
1493/1493 - 52s - loss: 1.5020e-04 - val_loss: 1.5040e-04 - 52s/epoch - 35ms/step
Epoch 88/200
1493/1493 - 52s - loss: 1.4921e-04 - val_loss: 1.5770e-04 - 52s/epoch - 35ms/step
Epoch 89/200
1493/1493 - 52s - loss: 1.5652e-04 - val_loss: 1.5047e-04 - 52s/epoch - 35ms/step
Epoch 90/200
1493/1493 - 52s - loss: 1.4817e-04 - val_loss: 1.7241e-04 - 52s/epoch - 35ms/step
Epoch 91/200
1493/1493 - 52s - loss: 1.4792e-04 - val_loss: 1.7015e-04 - 52s/epoch - 35ms/step
Epoch 92/200
1493/1493 - 52s - loss: 1.4756e-04 - val_loss: 7.3726e-04 - 52s/epoch - 35ms/step
Epoch 93/200
1493/1493 - 51s - loss: 2.0811e-04 - val_loss: 1.8130e-04 - 51s/epoch - 34ms/step
Epoch 94/200
1493/1493 - 52s - loss: 1.5488e-04 - val_loss: 1.2398e-04 - 52s/epoch - 35ms/step
Epoch 95/200
1493/1493 - 52s - loss: 1.4585e-04 - val_loss: 2.1917e-04 - 52s/epoch - 35ms/step
Epoch 96/200
1493/1493 - 51s - loss: 1.4756e-04 - val_loss: 1.7728e-04 - 51s/epoch - 34ms/step
Epoch 97/200
1493/1493 - 51s - loss: 1.4402e-04 - val_loss: 1.4547e-04 - 51s/epoch - 34ms/step
Epoch 98/200
1493/1493 - 51s - loss: 1.4444e-04 - val_loss: 7.7363e-04 - 51s/epoch - 34ms/step
Epoch 99/200
1493/1493 - 51s - loss: 2.2977e-04 - val_loss: 1.4574e-04 - 51s/epoch - 34ms/step
Epoch 100/200
1493/1493 - 52s - loss: 1.5283e-04 - val_loss: 1.3916e-04 - 52s/epoch - 35ms/step
Epoch 101/200
1493/1493 - 52s - loss: 1.4269e-04 - val_loss: 2.2648e-04 - 52s/epoch - 35ms/step
Epoch 102/200
1493/1493 - 51s - loss: 1.5007e-04 - val_loss: 2.3018e-04 - 51s/epoch - 34ms/step
Epoch 103/200
1493/1493 - 51s - loss: 1.4515e-04 - val_loss: 1.4034e-04 - 51s/epoch - 34ms/step
Epoch 104/200
1493/1493 - 52s - loss: 1.3667e-04 - val_loss: 2.8135e-04 - 52s/epoch - 35ms/step
Epoch 105/200
1493/1493 - 51s - loss: 1.4603e-04 - val_loss: 1.4315e-04 - 51s/epoch - 34ms/step
Epoch 106/200
1493/1493 - 51s - loss: 1.3528e-04 - val_loss: 1.5755e-04 - 51s/epoch - 34ms/step
Epoch 107/200
1493/1493 - 52s - loss: 1.3366e-04 - val_loss: 1.4820e-04 - 52s/epoch - 35ms/step
Epoch 108/200
1493/1493 - 51s - loss: 1.3531e-04 - val_loss: 1.5108e-04 - 51s/epoch - 34ms/step
Epoch 109/200
1493/1493 - 52s - loss: 1.3265e-04 - val_loss: 1.7188e-04 - 52s/epoch - 35ms/step
Epoch 110/200
1493/1493 - 51s - loss: 1.3118e-04 - val_loss: 1.4570e-04 - 51s/epoch - 34ms/step
Epoch 111/200
1493/1493 - 51s - loss: 1.3084e-04 - val_loss: 2.3970e-04 - 51s/epoch - 34ms/step
Epoch 112/200
1493/1493 - 52s - loss: 1.4410e-04 - val_loss: 1.2256e-04 - 52s/epoch - 35ms/step
Epoch 113/200
1493/1493 - 51s - loss: 1.2858e-04 - val_loss: 3.6133e-04 - 51s/epoch - 34ms/step
Epoch 114/200
1493/1493 - 52s - loss: 1.5620e-04 - val_loss: 1.1687e-04 - 52s/epoch - 35ms/step
Epoch 115/200
1493/1493 - 51s - loss: 1.3554e-04 - val_loss: 2.3708e-04 - 51s/epoch - 34ms/step
Epoch 116/200
1493/1493 - 51s - loss: 1.2962e-04 - val_loss: 1.4884e-04 - 51s/epoch - 34ms/step
Epoch 117/200
1493/1493 - 52s - loss: 1.2578e-04 - val_loss: 2.6555e-04 - 52s/epoch - 35ms/step
Epoch 118/200
1493/1493 - 52s - loss: 1.3811e-04 - val_loss: 1.3386e-04 - 52s/epoch - 35ms/step
Epoch 119/200
1493/1493 - 52s - loss: 1.2526e-04 - val_loss: 1.1611e-04 - 52s/epoch - 35ms/step
Epoch 120/200
1493/1493 - 52s - loss: 1.2438e-04 - val_loss: 1.2322e-04 - 52s/epoch - 35ms/step
Epoch 121/200
1493/1493 - 51s - loss: 1.2383e-04 - val_loss: 2.1466e-04 - 51s/epoch - 34ms/step
Epoch 122/200
1493/1493 - 51s - loss: 1.2760e-04 - val_loss: 1.2129e-04 - 51s/epoch - 34ms/step
Epoch 123/200
1493/1493 - 51s - loss: 1.2234e-04 - val_loss: 1.3368e-04 - 51s/epoch - 34ms/step
Epoch 124/200
1493/1493 - 52s - loss: 1.2205e-04 - val_loss: 4.3674e-04 - 52s/epoch - 35ms/step
Epoch 125/200
1493/1493 - 52s - loss: 1.6044e-04 - val_loss: 1.4482e-04 - 52s/epoch - 35ms/step
Epoch 126/200
1493/1493 - 51s - loss: 1.2487e-04 - val_loss: 1.8835e-04 - 51s/epoch - 34ms/step
Epoch 127/200
1493/1493 - 51s - loss: 1.2712e-04 - val_loss: 2.5579e-04 - 51s/epoch - 34ms/step
Epoch 128/200
1493/1493 - 52s - loss: 1.2948e-04 - val_loss: 1.1563e-04 - 52s/epoch - 35ms/step
Epoch 129/200
1493/1493 - 52s - loss: 1.1912e-04 - val_loss: 1.1762e-04 - 52s/epoch - 35ms/step
Epoch 130/200
1493/1493 - 52s - loss: 1.1839e-04 - val_loss: 1.0311e-04 - 52s/epoch - 35ms/step
Epoch 131/200
1493/1493 - 51s - loss: 1.2024e-04 - val_loss: 3.5507e-04 - 51s/epoch - 34ms/step
Epoch 132/200
1493/1493 - 51s - loss: 1.5240e-04 - val_loss: 1.0298e-04 - 51s/epoch - 34ms/step
Epoch 133/200
1493/1493 - 52s - loss: 1.1821e-04 - val_loss: 1.2271e-04 - 52s/epoch - 35ms/step
Epoch 134/200
1493/1493 - 52s - loss: 1.1639e-04 - val_loss: 1.1127e-04 - 52s/epoch - 35ms/step
Epoch 135/200
1493/1493 - 52s - loss: 1.1669e-04 - val_loss: 1.0773e-04 - 52s/epoch - 35ms/step
Epoch 136/200
1493/1493 - 51s - loss: 1.1696e-04 - val_loss: 2.9321e-04 - 51s/epoch - 34ms/step
Epoch 137/200
1493/1493 - 52s - loss: 1.4834e-04 - val_loss: 1.2561e-04 - 52s/epoch - 35ms/step
Epoch 138/200
1493/1493 - 52s - loss: 1.1783e-04 - val_loss: 1.1559e-04 - 52s/epoch - 35ms/step
Epoch 139/200
1493/1493 - 52s - loss: 1.1737e-04 - val_loss: 1.4826e-04 - 52s/epoch - 35ms/step
Epoch 140/200
1493/1493 - 51s - loss: 1.2247e-04 - val_loss: 1.0691e-04 - 51s/epoch - 34ms/step
Epoch 141/200
1493/1493 - 51s - loss: 1.1325e-04 - val_loss: 1.3698e-04 - 51s/epoch - 34ms/step
Epoch 142/200
1493/1493 - 52s - loss: 1.1628e-04 - val_loss: 1.2757e-04 - 52s/epoch - 35ms/step
Epoch 143/200
1493/1493 - 52s - loss: 1.1185e-04 - val_loss: 1.6875e-04 - 52s/epoch - 35ms/step
Epoch 144/200
1493/1493 - 52s - loss: 1.1570e-04 - val_loss: 1.2076e-04 - 52s/epoch - 35ms/step
Epoch 145/200
1493/1493 - 51s - loss: 1.1426e-04 - val_loss: 9.3524e-05 - 51s/epoch - 34ms/step
Epoch 146/200
1493/1493 - 52s - loss: 1.1060e-04 - val_loss: 1.0434e-04 - 52s/epoch - 35ms/step
Epoch 147/200
1493/1493 - 51s - loss: 1.0894e-04 - val_loss: 1.6740e-04 - 51s/epoch - 34ms/step
Epoch 148/200
1493/1493 - 52s - loss: 1.1265e-04 - val_loss: 1.8286e-04 - 52s/epoch - 35ms/step
Epoch 149/200
1493/1493 - 52s - loss: 1.0895e-04 - val_loss: 1.0180e-04 - 52s/epoch - 35ms/step
Epoch 150/200
1493/1493 - 52s - loss: 1.0818e-04 - val_loss: 1.1823e-04 - 52s/epoch - 35ms/step
Epoch 151/200
1493/1493 - 52s - loss: 1.1137e-04 - val_loss: 1.3044e-04 - 52s/epoch - 35ms/step
Epoch 152/200
1493/1493 - 52s - loss: 1.0827e-04 - val_loss: 1.5154e-04 - 52s/epoch - 35ms/step
Epoch 153/200
1493/1493 - 52s - loss: 1.1132e-04 - val_loss: 1.1924e-04 - 52s/epoch - 35ms/step
Epoch 154/200
1493/1493 - 52s - loss: 1.0675e-04 - val_loss: 1.4214e-04 - 52s/epoch - 35ms/step
Epoch 155/200
1493/1493 - 52s - loss: 1.0867e-04 - val_loss: 1.1855e-04 - 52s/epoch - 35ms/step
Epoch 156/200
1493/1493 - 52s - loss: 1.0907e-04 - val_loss: 1.1199e-04 - 52s/epoch - 35ms/step
Epoch 157/200
1493/1493 - 52s - loss: 1.0576e-04 - val_loss: 1.2640e-04 - 52s/epoch - 35ms/step
Epoch 158/200
1493/1493 - 52s - loss: 1.0746e-04 - val_loss: 1.1604e-04 - 52s/epoch - 35ms/step
Epoch 159/200
1493/1493 - 51s - loss: 1.0419e-04 - val_loss: 9.3753e-05 - 51s/epoch - 34ms/step
Epoch 160/200
1493/1493 - 51s - loss: 1.5075e-04 - val_loss: 2.4521e-04 - 51s/epoch - 34ms/step
Epoch 161/200
1493/1493 - 52s - loss: 2.1959e-04 - val_loss: 1.1412e-04 - 52s/epoch - 35ms/step
Epoch 162/200
1493/1493 - 52s - loss: 1.2213e-04 - val_loss: 9.7956e-05 - 52s/epoch - 35ms/step
Epoch 163/200
1493/1493 - 51s - loss: 1.1176e-04 - val_loss: 1.0946e-04 - 51s/epoch - 34ms/step
Epoch 164/200
1493/1493 - 51s - loss: 1.1099e-04 - val_loss: 1.0292e-04 - 51s/epoch - 34ms/step
Epoch 165/200
1493/1493 - 51s - loss: 1.0921e-04 - val_loss: 1.1808e-04 - 51s/epoch - 34ms/step
Epoch 166/200
1493/1493 - 51s - loss: 1.0676e-04 - val_loss: 1.1215e-04 - 51s/epoch - 34ms/step
Epoch 167/200
1493/1493 - 51s - loss: 1.0490e-04 - val_loss: 9.7973e-05 - 51s/epoch - 34ms/step
Epoch 168/200
1493/1493 - 51s - loss: 1.0493e-04 - val_loss: 9.3617e-05 - 51s/epoch - 34ms/step
Epoch 169/200
1493/1493 - 52s - loss: 1.0371e-04 - val_loss: 1.4456e-04 - 52s/epoch - 35ms/step
Epoch 170/200
1493/1493 - 52s - loss: 1.0337e-04 - val_loss: 2.3831e-04 - 52s/epoch - 35ms/step
Epoch 171/200
1493/1493 - 52s - loss: 1.2452e-04 - val_loss: 2.8441e-04 - 52s/epoch - 35ms/step
Epoch 172/200
1493/1493 - 52s - loss: 1.2069e-04 - val_loss: 1.1374e-04 - 52s/epoch - 35ms/step
Epoch 173/200
1493/1493 - 52s - loss: 1.0334e-04 - val_loss: 1.0103e-04 - 52s/epoch - 35ms/step
Epoch 174/200
1493/1493 - 52s - loss: 1.0275e-04 - val_loss: 3.6409e-04 - 52s/epoch - 35ms/step
Epoch 175/200
1493/1493 - 52s - loss: 1.2148e-04 - val_loss: 1.0625e-04 - 52s/epoch - 34ms/step
Epoch 176/200
1493/1493 - 51s - loss: 1.0359e-04 - val_loss: 1.0162e-04 - 51s/epoch - 34ms/step
Epoch 177/200
1493/1493 - 51s - loss: 1.0313e-04 - val_loss: 9.4205e-05 - 51s/epoch - 34ms/step
Epoch 178/200
1493/1493 - 52s - loss: 1.0061e-04 - val_loss: 9.6065e-05 - 52s/epoch - 35ms/step
Epoch 179/200
1493/1493 - 52s - loss: 9.9894e-05 - val_loss: 1.2246e-04 - 52s/epoch - 35ms/step
Epoch 180/200
1493/1493 - 52s - loss: 9.9547e-05 - val_loss: 1.2516e-04 - 52s/epoch - 35ms/step
Epoch 181/200
1493/1493 - 52s - loss: 1.0227e-04 - val_loss: 1.1580e-04 - 52s/epoch - 35ms/step
Epoch 182/200
1493/1493 - 52s - loss: 9.9477e-05 - val_loss: 1.2770e-04 - 52s/epoch - 35ms/step
Epoch 183/200
1493/1493 - 52s - loss: 9.8246e-05 - val_loss: 1.0963e-04 - 52s/epoch - 35ms/step
Epoch 184/200
1493/1493 - 52s - loss: 9.9019e-05 - val_loss: 1.0363e-04 - 52s/epoch - 35ms/step
Epoch 185/200
1493/1493 - 51s - loss: 9.9992e-05 - val_loss: 3.0619e-04 - 51s/epoch - 34ms/step
Epoch 186/200
1493/1493 - 52s - loss: 1.4269e-04 - val_loss: 8.8002e-05 - 52s/epoch - 35ms/step
Epoch 187/200
1493/1493 - 51s - loss: 1.0402e-04 - val_loss: 1.0814e-04 - 51s/epoch - 34ms/step
Epoch 188/200
1493/1493 - 51s - loss: 1.0430e-04 - val_loss: 1.2646e-04 - 51s/epoch - 34ms/step
Epoch 189/200
1493/1493 - 52s - loss: 1.0174e-04 - val_loss: 1.1140e-04 - 52s/epoch - 35ms/step
Epoch 190/200
1493/1493 - 52s - loss: 9.9866e-05 - val_loss: 1.6399e-04 - 52s/epoch - 35ms/step
Epoch 191/200
1493/1493 - 52s - loss: 1.0748e-04 - val_loss: 1.6326e-04 - 52s/epoch - 35ms/step
Epoch 192/200
1493/1493 - 51s - loss: 9.9170e-05 - val_loss: 1.1718e-04 - 51s/epoch - 34ms/step
Epoch 193/200
1493/1493 - 51s - loss: 9.9425e-05 - val_loss: 1.2473e-04 - 51s/epoch - 34ms/step
Epoch 194/200
1493/1493 - 52s - loss: 1.0450e-04 - val_loss: 4.6693e-04 - 52s/epoch - 35ms/step
Epoch 195/200
1493/1493 - 52s - loss: 1.4063e-04 - val_loss: 2.1031e-04 - 52s/epoch - 35ms/step
Epoch 196/200
1493/1493 - 52s - loss: 1.2157e-04 - val_loss: 7.7314e-05 - 52s/epoch - 35ms/step
Epoch 197/200
1493/1493 - 52s - loss: 9.9918e-05 - val_loss: 1.4726e-04 - 52s/epoch - 35ms/step
Epoch 198/200
1493/1493 - 52s - loss: 1.0837e-04 - val_loss: 1.4804e-04 - 52s/epoch - 35ms/step
Epoch 199/200
1493/1493 - 52s - loss: 1.0337e-04 - val_loss: 8.7836e-05 - 52s/epoch - 35ms/step
Epoch 200/200
1493/1493 - 52s - loss: 9.7070e-05 - val_loss: 9.2877e-05 - 52s/epoch - 35ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.287737339036539e-05
  1/332 [..............................] - ETA: 42s  8/332 [..............................] - ETA: 2s  16/332 [>.............................] - ETA: 2s 25/332 [=>............................] - ETA: 1s 35/332 [==>...........................] - ETA: 1s 45/332 [===>..........................] - ETA: 1s 55/332 [===>..........................] - ETA: 1s 65/332 [====>.........................] - ETA: 1s 75/332 [=====>........................] - ETA: 1s 84/332 [======>.......................] - ETA: 1s 94/332 [=======>......................] - ETA: 1s104/332 [========>.....................] - ETA: 1s113/332 [=========>....................] - ETA: 1s123/332 [==========>...................] - ETA: 1s133/332 [===========>..................] - ETA: 1s143/332 [===========>..................] - ETA: 1s153/332 [============>.................] - ETA: 0s163/332 [=============>................] - ETA: 0s173/332 [==============>...............] - ETA: 0s183/332 [===============>..............] - ETA: 0s193/332 [================>.............] - ETA: 0s203/332 [=================>............] - ETA: 0s213/332 [==================>...........] - ETA: 0s223/332 [===================>..........] - ETA: 0s233/332 [====================>.........] - ETA: 0s243/332 [====================>.........] - ETA: 0s253/332 [=====================>........] - ETA: 0s263/332 [======================>.......] - ETA: 0s273/332 [=======================>......] - ETA: 0s283/332 [========================>.....] - ETA: 0s293/332 [=========================>....] - ETA: 0s303/332 [==========================>...] - ETA: 0s313/332 [===========================>..] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 5ms/step
correlation 0.0010583579001047455
cosine 0.0008343523835129347
MAE: 0.005484353
RMSE: 0.009637289
r2: 0.993975369408023
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 1896)              2398440   
                                                                 
 batch_normalization (BatchN  (None, 1896)             7584      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1896)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              1917867   
                                                                 
 batch_normalization_1 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 1011)              0         
                                                                 
 dense_1 (Dense)             (None, 1896)              1918752   
                                                                 
 batch_normalization_2 (Batc  (None, 1896)             7584      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1896)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              2397808   
                                                                 
=================================================================
Total params: 8,652,079
Trainable params: 8,642,473
Non-trainable params: 9,606
_________________________________________________________________
Encoder
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_1 (InputLayer)        multiple                  0         
                                                                 
 dense (Dense)               (None, 1896)              2398440   
                                                                 
 batch_normalization (BatchN  (None, 1896)             7584      
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 1896)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              1917867   
                                                                 
=================================================================
Total params: 4,323,891
Trainable params: 4,320,099
Non-trainable params: 3,792
_________________________________________________________________
Decoder
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 1011)]            0         
                                                                 
 batch_normalization_1 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 1011)              0         
                                                                 
 dense_1 (Dense)             (None, 1896)              1918752   
                                                                 
 batch_normalization_2 (Batc  (None, 1896)             7584      
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 1896)              0         
                                                                 
 dense_2 (Dense)             (None, 1264)              2397808   
                                                                 
=================================================================
Total params: 4,328,188
Trainable params: 4,322,374
Non-trainable params: 5,814
_________________________________________________________________
['1.5custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 9.707005665404722e-05, 9.287737339036539e-05, 0.0010583579001047455, 0.0008343523835129347, 0.005484352819621563, 0.009637288749217987, 0.993975369408023, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_3 (Dense)             (None, 2022)              2557830   
                                                                 
 batch_normalization_3 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2022)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2045253   
                                                                 
 batch_normalization_4 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 1011)              0         
                                                                 
 dense_4 (Dense)             (None, 2022)              2046264   
                                                                 
 batch_normalization_5 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2022)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              2557072   
                                                                 
=================================================================
Total params: 9,226,639
Trainable params: 9,216,529
Non-trainable params: 10,110
_________________________________________________________________
Epoch 1/200
1493/1493 - 58s - loss: 0.0090 - val_loss: 0.0043 - 58s/epoch - 39ms/step
Epoch 2/200
1493/1493 - 57s - loss: 0.0028 - val_loss: 0.0025 - 57s/epoch - 38ms/step
Epoch 3/200
1493/1493 - 58s - loss: 0.0019 - val_loss: 0.0015 - 58s/epoch - 39ms/step
Epoch 4/200
1493/1493 - 58s - loss: 0.0016 - val_loss: 0.0021 - 58s/epoch - 39ms/step
Epoch 5/200
1493/1493 - 57s - loss: 0.0014 - val_loss: 0.0012 - 57s/epoch - 38ms/step
Epoch 6/200
1493/1493 - 57s - loss: 0.0013 - val_loss: 0.0012 - 57s/epoch - 38ms/step
Epoch 7/200
1493/1493 - 57s - loss: 0.0012 - val_loss: 9.4897e-04 - 57s/epoch - 38ms/step
Epoch 8/200
1493/1493 - 57s - loss: 0.0011 - val_loss: 9.7052e-04 - 57s/epoch - 38ms/step
Epoch 9/200
1493/1493 - 57s - loss: 9.6723e-04 - val_loss: 0.0012 - 57s/epoch - 38ms/step
Epoch 10/200
1493/1493 - 57s - loss: 9.2089e-04 - val_loss: 7.7723e-04 - 57s/epoch - 38ms/step
Epoch 11/200
1493/1493 - 56s - loss: 8.5563e-04 - val_loss: 7.8317e-04 - 56s/epoch - 38ms/step
Epoch 12/200
1493/1493 - 57s - loss: 7.5517e-04 - val_loss: 0.0022 - 57s/epoch - 38ms/step
Epoch 13/200
1493/1493 - 57s - loss: 7.7013e-04 - val_loss: 0.0020 - 57s/epoch - 38ms/step
Epoch 14/200
1493/1493 - 58s - loss: 7.9487e-04 - val_loss: 6.7614e-04 - 58s/epoch - 39ms/step
Epoch 15/200
1493/1493 - 57s - loss: 6.6779e-04 - val_loss: 6.9827e-04 - 57s/epoch - 38ms/step
Epoch 16/200
1493/1493 - 57s - loss: 6.1085e-04 - val_loss: 5.7346e-04 - 57s/epoch - 38ms/step
Epoch 17/200
1493/1493 - 58s - loss: 5.6727e-04 - val_loss: 0.0010 - 58s/epoch - 39ms/step
Epoch 18/200
1493/1493 - 58s - loss: 5.9529e-04 - val_loss: 5.6385e-04 - 58s/epoch - 39ms/step
Epoch 19/200
1493/1493 - 58s - loss: 5.1513e-04 - val_loss: 7.0718e-04 - 58s/epoch - 39ms/step
Epoch 20/200
1493/1493 - 57s - loss: 5.1617e-04 - val_loss: 4.8443e-04 - 57s/epoch - 39ms/step
Epoch 21/200
1493/1493 - 58s - loss: 4.7329e-04 - val_loss: 6.1242e-04 - 58s/epoch - 39ms/step
Epoch 22/200
1493/1493 - 57s - loss: 4.6844e-04 - val_loss: 7.5542e-04 - 57s/epoch - 38ms/step
Epoch 23/200
1493/1493 - 57s - loss: 4.6191e-04 - val_loss: 7.9130e-04 - 57s/epoch - 38ms/step
Epoch 24/200
1493/1493 - 57s - loss: 4.3531e-04 - val_loss: 3.9845e-04 - 57s/epoch - 38ms/step
Epoch 25/200
1493/1493 - 57s - loss: 3.9897e-04 - val_loss: 4.1580e-04 - 57s/epoch - 38ms/step
Epoch 26/200
1493/1493 - 57s - loss: 3.8552e-04 - val_loss: 4.4242e-04 - 57s/epoch - 38ms/step
Epoch 27/200
1493/1493 - 57s - loss: 3.7140e-04 - val_loss: 3.6675e-04 - 57s/epoch - 38ms/step
Epoch 28/200
1493/1493 - 57s - loss: 3.6713e-04 - val_loss: 4.7000e-04 - 57s/epoch - 38ms/step
Epoch 29/200
1493/1493 - 57s - loss: 3.4589e-04 - val_loss: 4.8618e-04 - 57s/epoch - 38ms/step
Epoch 30/200
1493/1493 - 57s - loss: 3.5202e-04 - val_loss: 3.9789e-04 - 57s/epoch - 38ms/step
Epoch 31/200
1493/1493 - 56s - loss: 3.2440e-04 - val_loss: 5.7797e-04 - 56s/epoch - 38ms/step
Epoch 32/200
1493/1493 - 58s - loss: 3.3803e-04 - val_loss: 3.2362e-04 - 58s/epoch - 39ms/step
Epoch 33/200
1493/1493 - 58s - loss: 3.1542e-04 - val_loss: 3.1610e-04 - 58s/epoch - 39ms/step
Epoch 34/200
1493/1493 - 58s - loss: 3.0665e-04 - val_loss: 2.6803e-04 - 58s/epoch - 39ms/step
Epoch 35/200
1493/1493 - 57s - loss: 2.9092e-04 - val_loss: 8.7643e-04 - 57s/epoch - 38ms/step
Epoch 36/200
1493/1493 - 57s - loss: 3.2779e-04 - val_loss: 4.3836e-04 - 57s/epoch - 38ms/step
Epoch 37/200
1493/1493 - 57s - loss: 2.9286e-04 - val_loss: 3.1047e-04 - 57s/epoch - 38ms/step
Epoch 38/200
1493/1493 - 57s - loss: 2.8260e-04 - val_loss: 2.8758e-04 - 57s/epoch - 38ms/step
Epoch 39/200
1493/1493 - 58s - loss: 2.7015e-04 - val_loss: 2.6642e-04 - 58s/epoch - 39ms/step
Epoch 40/200
1493/1493 - 58s - loss: 2.5853e-04 - val_loss: 3.8352e-04 - 58s/epoch - 39ms/step
Epoch 41/200
1493/1493 - 57s - loss: 2.6172e-04 - val_loss: 2.2383e-04 - 57s/epoch - 39ms/step
Epoch 42/200
1493/1493 - 57s - loss: 2.5020e-04 - val_loss: 2.5430e-04 - 57s/epoch - 38ms/step
Epoch 43/200
1493/1493 - 57s - loss: 2.4938e-04 - val_loss: 3.3920e-04 - 57s/epoch - 39ms/step
Epoch 44/200
1493/1493 - 57s - loss: 2.5696e-04 - val_loss: 3.1950e-04 - 57s/epoch - 38ms/step
Epoch 45/200
1493/1493 - 57s - loss: 2.4540e-04 - val_loss: 2.1637e-04 - 57s/epoch - 38ms/step
Epoch 46/200
1493/1493 - 57s - loss: 2.3628e-04 - val_loss: 2.1687e-04 - 57s/epoch - 38ms/step
Epoch 47/200
1493/1493 - 57s - loss: 2.3139e-04 - val_loss: 2.8760e-04 - 57s/epoch - 38ms/step
Epoch 48/200
1493/1493 - 57s - loss: 2.3165e-04 - val_loss: 2.8499e-04 - 57s/epoch - 38ms/step
Epoch 49/200
1493/1493 - 57s - loss: 2.2644e-04 - val_loss: 0.0010 - 57s/epoch - 38ms/step
Epoch 50/200
1493/1493 - 57s - loss: 2.7548e-04 - val_loss: 5.4619e-04 - 57s/epoch - 38ms/step
Epoch 51/200
1493/1493 - 57s - loss: 2.3855e-04 - val_loss: 2.3273e-04 - 57s/epoch - 38ms/step
Epoch 52/200
1493/1493 - 58s - loss: 2.1300e-04 - val_loss: 2.2374e-04 - 58s/epoch - 39ms/step
Epoch 53/200
1493/1493 - 58s - loss: 2.1561e-04 - val_loss: 2.2579e-04 - 58s/epoch - 39ms/step
Epoch 54/200
1493/1493 - 57s - loss: 2.1044e-04 - val_loss: 2.4397e-04 - 57s/epoch - 38ms/step
Epoch 55/200
1493/1493 - 57s - loss: 2.0217e-04 - val_loss: 2.0376e-04 - 57s/epoch - 38ms/step
Epoch 56/200
1493/1493 - 57s - loss: 2.0173e-04 - val_loss: 2.5447e-04 - 57s/epoch - 38ms/step
Epoch 57/200
1493/1493 - 57s - loss: 1.9629e-04 - val_loss: 2.0738e-04 - 57s/epoch - 38ms/step
Epoch 58/200
1493/1493 - 57s - loss: 1.9763e-04 - val_loss: 1.7815e-04 - 57s/epoch - 38ms/step
Epoch 59/200
1493/1493 - 57s - loss: 1.9107e-04 - val_loss: 2.1638e-04 - 57s/epoch - 38ms/step
Epoch 60/200
1493/1493 - 57s - loss: 1.8914e-04 - val_loss: 5.2175e-04 - 57s/epoch - 38ms/step
Epoch 61/200
1493/1493 - 57s - loss: 2.5018e-04 - val_loss: 1.7494e-04 - 57s/epoch - 38ms/step
Epoch 62/200
1493/1493 - 57s - loss: 1.8609e-04 - val_loss: 2.0966e-04 - 57s/epoch - 38ms/step
Epoch 63/200
1493/1493 - 57s - loss: 1.8577e-04 - val_loss: 2.6521e-04 - 57s/epoch - 38ms/step
Epoch 64/200
1493/1493 - 57s - loss: 1.8740e-04 - val_loss: 0.0016 - 57s/epoch - 38ms/step
Epoch 65/200
1493/1493 - 57s - loss: 3.2100e-04 - val_loss: 1.8730e-04 - 57s/epoch - 38ms/step
Epoch 66/200
1493/1493 - 57s - loss: 1.9058e-04 - val_loss: 2.1587e-04 - 57s/epoch - 38ms/step
Epoch 67/200
1493/1493 - 57s - loss: 1.8250e-04 - val_loss: 1.6983e-04 - 57s/epoch - 38ms/step
Epoch 68/200
1493/1493 - 56s - loss: 1.7982e-04 - val_loss: 7.5914e-04 - 56s/epoch - 38ms/step
Epoch 69/200
1493/1493 - 56s - loss: 2.5352e-04 - val_loss: 1.6840e-04 - 56s/epoch - 38ms/step
Epoch 70/200
1493/1493 - 56s - loss: 1.7800e-04 - val_loss: 3.8620e-04 - 56s/epoch - 38ms/step
Epoch 71/200
1493/1493 - 56s - loss: 1.9770e-04 - val_loss: 1.8556e-04 - 56s/epoch - 38ms/step
Epoch 72/200
1493/1493 - 57s - loss: 1.7610e-04 - val_loss: 2.2986e-04 - 57s/epoch - 38ms/step
Epoch 73/200
1493/1493 - 57s - loss: 1.7701e-04 - val_loss: 1.8647e-04 - 57s/epoch - 38ms/step
Epoch 74/200
1493/1493 - 57s - loss: 1.7213e-04 - val_loss: 1.7199e-04 - 57s/epoch - 38ms/step
Epoch 75/200
1493/1493 - 57s - loss: 1.6424e-04 - val_loss: 1.6614e-04 - 57s/epoch - 38ms/step
Epoch 76/200
1493/1493 - 57s - loss: 1.6521e-04 - val_loss: 1.6534e-04 - 57s/epoch - 38ms/step
Epoch 77/200
1493/1493 - 57s - loss: 1.5789e-04 - val_loss: 6.6690e-04 - 57s/epoch - 38ms/step
Epoch 78/200
1493/1493 - 57s - loss: 1.7857e-04 - val_loss: 1.7507e-04 - 57s/epoch - 38ms/step
Epoch 79/200
1493/1493 - 57s - loss: 1.6034e-04 - val_loss: 2.1889e-04 - 57s/epoch - 38ms/step
Epoch 80/200
1493/1493 - 57s - loss: 1.6802e-04 - val_loss: 1.5580e-04 - 57s/epoch - 38ms/step
Epoch 81/200
1493/1493 - 57s - loss: 1.5500e-04 - val_loss: 3.6811e-04 - 57s/epoch - 38ms/step
Epoch 82/200
1493/1493 - 57s - loss: 1.5833e-04 - val_loss: 1.5682e-04 - 57s/epoch - 38ms/step
Epoch 83/200
1493/1493 - 57s - loss: 1.5026e-04 - val_loss: 1.6138e-04 - 57s/epoch - 38ms/step
Epoch 84/200
1493/1493 - 57s - loss: 1.5127e-04 - val_loss: 1.7743e-04 - 57s/epoch - 38ms/step
Epoch 85/200
1493/1493 - 57s - loss: 1.5079e-04 - val_loss: 2.4811e-04 - 57s/epoch - 38ms/step
Epoch 86/200
1493/1493 - 57s - loss: 1.6219e-04 - val_loss: 1.6466e-04 - 57s/epoch - 38ms/step
Epoch 87/200
1493/1493 - 57s - loss: 1.4512e-04 - val_loss: 1.4770e-04 - 57s/epoch - 38ms/step
Epoch 88/200
1493/1493 - 57s - loss: 1.4592e-04 - val_loss: 2.0297e-04 - 57s/epoch - 38ms/step
Epoch 89/200
1493/1493 - 57s - loss: 1.4980e-04 - val_loss: 1.5862e-04 - 57s/epoch - 38ms/step
Epoch 90/200
1493/1493 - 57s - loss: 1.4288e-04 - val_loss: 1.8301e-04 - 57s/epoch - 38ms/step
Epoch 91/200
1493/1493 - 57s - loss: 1.4188e-04 - val_loss: 1.5496e-04 - 57s/epoch - 38ms/step
Epoch 92/200
1493/1493 - 57s - loss: 1.4181e-04 - val_loss: 5.4198e-04 - 57s/epoch - 38ms/step
Epoch 93/200
1493/1493 - 58s - loss: 1.8643e-04 - val_loss: 4.5808e-04 - 58s/epoch - 39ms/step
Epoch 94/200
1493/1493 - 58s - loss: 1.7148e-04 - val_loss: 1.1856e-04 - 58s/epoch - 39ms/step
Epoch 95/200
1493/1493 - 58s - loss: 1.4250e-04 - val_loss: 3.9352e-04 - 58s/epoch - 39ms/step
Epoch 96/200
1493/1493 - 58s - loss: 1.7024e-04 - val_loss: 1.5812e-04 - 58s/epoch - 39ms/step
Epoch 97/200
1493/1493 - 57s - loss: 1.4338e-04 - val_loss: 1.3100e-04 - 57s/epoch - 38ms/step
Epoch 98/200
1493/1493 - 57s - loss: 1.4375e-04 - val_loss: 7.8617e-04 - 57s/epoch - 38ms/step
Epoch 99/200
1493/1493 - 57s - loss: 2.2401e-04 - val_loss: 1.3324e-04 - 57s/epoch - 38ms/step
Epoch 100/200
1493/1493 - 57s - loss: 1.5203e-04 - val_loss: 1.2261e-04 - 57s/epoch - 38ms/step
Epoch 101/200
1493/1493 - 57s - loss: 1.3871e-04 - val_loss: 1.5232e-04 - 57s/epoch - 38ms/step
Epoch 102/200
1493/1493 - 57s - loss: 1.4023e-04 - val_loss: 2.3841e-04 - 57s/epoch - 38ms/step
Epoch 103/200
1493/1493 - 57s - loss: 1.4371e-04 - val_loss: 1.3519e-04 - 57s/epoch - 38ms/step
Epoch 104/200
1493/1493 - 57s - loss: 1.3408e-04 - val_loss: 3.8356e-04 - 57s/epoch - 38ms/step
Epoch 105/200
1493/1493 - 56s - loss: 1.5177e-04 - val_loss: 1.4106e-04 - 56s/epoch - 38ms/step
Epoch 106/200
1493/1493 - 57s - loss: 1.3229e-04 - val_loss: 1.3934e-04 - 57s/epoch - 38ms/step
Epoch 107/200
1493/1493 - 57s - loss: 1.3071e-04 - val_loss: 1.4715e-04 - 57s/epoch - 38ms/step
Epoch 108/200
1493/1493 - 57s - loss: 1.3043e-04 - val_loss: 1.3872e-04 - 57s/epoch - 38ms/step
Epoch 109/200
1493/1493 - 57s - loss: 1.2897e-04 - val_loss: 1.5795e-04 - 57s/epoch - 38ms/step
Epoch 110/200
1493/1493 - 58s - loss: 1.2747e-04 - val_loss: 1.4849e-04 - 58s/epoch - 39ms/step
Epoch 111/200
1493/1493 - 58s - loss: 1.2833e-04 - val_loss: 3.1964e-04 - 58s/epoch - 39ms/step
Epoch 112/200
1493/1493 - 58s - loss: 1.6300e-04 - val_loss: 1.1643e-04 - 58s/epoch - 39ms/step
Epoch 113/200
1493/1493 - 58s - loss: 1.2710e-04 - val_loss: 3.7675e-04 - 58s/epoch - 39ms/step
Epoch 114/200
1493/1493 - 58s - loss: 1.4978e-04 - val_loss: 1.4238e-04 - 58s/epoch - 39ms/step
Epoch 115/200
1493/1493 - 57s - loss: 1.2816e-04 - val_loss: 2.0392e-04 - 57s/epoch - 38ms/step
Epoch 116/200
1493/1493 - 58s - loss: 1.2549e-04 - val_loss: 1.5539e-04 - 58s/epoch - 39ms/step
Epoch 117/200
1493/1493 - 58s - loss: 1.2382e-04 - val_loss: 2.4622e-04 - 58s/epoch - 39ms/step
Epoch 118/200
1493/1493 - 58s - loss: 1.3352e-04 - val_loss: 1.2714e-04 - 58s/epoch - 39ms/step
Epoch 119/200
1493/1493 - 57s - loss: 1.2246e-04 - val_loss: 1.2115e-04 - 57s/epoch - 38ms/step
Epoch 120/200
1493/1493 - 57s - loss: 1.2048e-04 - val_loss: 1.3498e-04 - 57s/epoch - 38ms/step
Epoch 121/200
1493/1493 - 58s - loss: 1.1998e-04 - val_loss: 2.0885e-04 - 58s/epoch - 39ms/step
Epoch 122/200
1493/1493 - 57s - loss: 1.2244e-04 - val_loss: 1.2005e-04 - 57s/epoch - 38ms/step
Epoch 123/200
1493/1493 - 57s - loss: 1.1926e-04 - val_loss: 1.1868e-04 - 57s/epoch - 38ms/step
Epoch 124/200
1493/1493 - 57s - loss: 1.1777e-04 - val_loss: 3.6189e-04 - 57s/epoch - 38ms/step
Epoch 125/200
1493/1493 - 57s - loss: 1.4567e-04 - val_loss: 1.2292e-04 - 57s/epoch - 38ms/step
Epoch 126/200
1493/1493 - 57s - loss: 1.1982e-04 - val_loss: 1.9838e-04 - 57s/epoch - 38ms/step
Epoch 127/200
1493/1493 - 57s - loss: 1.2056e-04 - val_loss: 2.7663e-04 - 57s/epoch - 38ms/step
Epoch 128/200
1493/1493 - 56s - loss: 1.2465e-04 - val_loss: 1.0638e-04 - 56s/epoch - 38ms/step
Epoch 129/200
1493/1493 - 56s - loss: 1.1514e-04 - val_loss: 1.2831e-04 - 56s/epoch - 38ms/step
Epoch 130/200
1493/1493 - 56s - loss: 1.1424e-04 - val_loss: 1.1246e-04 - 56s/epoch - 38ms/step
Epoch 131/200
1493/1493 - 57s - loss: 1.1829e-04 - val_loss: 4.5317e-04 - 57s/epoch - 38ms/step
Epoch 132/200
1493/1493 - 57s - loss: 1.6314e-04 - val_loss: 1.0952e-04 - 57s/epoch - 38ms/step
Epoch 133/200
1493/1493 - 57s - loss: 1.1644e-04 - val_loss: 1.1175e-04 - 57s/epoch - 38ms/step
Epoch 134/200
1493/1493 - 57s - loss: 1.1384e-04 - val_loss: 1.1027e-04 - 57s/epoch - 38ms/step
Epoch 135/200
1493/1493 - 57s - loss: 1.1268e-04 - val_loss: 1.0145e-04 - 57s/epoch - 38ms/step
Epoch 136/200
1493/1493 - 57s - loss: 1.1204e-04 - val_loss: 1.3710e-04 - 57s/epoch - 38ms/step
Epoch 137/200
1493/1493 - 57s - loss: 1.1779e-04 - val_loss: 2.3144e-04 - 57s/epoch - 38ms/step
Epoch 138/200
1493/1493 - 57s - loss: 1.2780e-04 - val_loss: 1.1015e-04 - 57s/epoch - 38ms/step
Epoch 139/200
1493/1493 - 57s - loss: 1.1442e-04 - val_loss: 2.3102e-04 - 57s/epoch - 38ms/step
Epoch 140/200
1493/1493 - 56s - loss: 1.2702e-04 - val_loss: 9.6890e-05 - 56s/epoch - 38ms/step
Epoch 141/200
1493/1493 - 57s - loss: 1.1210e-04 - val_loss: 1.3573e-04 - 57s/epoch - 38ms/step
Epoch 142/200
1493/1493 - 57s - loss: 1.1484e-04 - val_loss: 1.1128e-04 - 57s/epoch - 38ms/step
Epoch 143/200
1493/1493 - 56s - loss: 1.1002e-04 - val_loss: 1.4412e-04 - 56s/epoch - 38ms/step
Epoch 144/200
1493/1493 - 57s - loss: 1.1271e-04 - val_loss: 1.1205e-04 - 57s/epoch - 38ms/step
Epoch 145/200
1493/1493 - 57s - loss: 1.0744e-04 - val_loss: 1.0074e-04 - 57s/epoch - 38ms/step
Epoch 146/200
1493/1493 - 57s - loss: 1.0749e-04 - val_loss: 1.1097e-04 - 57s/epoch - 38ms/step
Epoch 147/200
1493/1493 - 57s - loss: 1.0509e-04 - val_loss: 1.2238e-04 - 57s/epoch - 38ms/step
Epoch 148/200
1493/1493 - 57s - loss: 1.0612e-04 - val_loss: 2.0811e-04 - 57s/epoch - 38ms/step
Epoch 149/200
1493/1493 - 57s - loss: 1.0526e-04 - val_loss: 1.1248e-04 - 57s/epoch - 38ms/step
Epoch 150/200
1493/1493 - 57s - loss: 1.0387e-04 - val_loss: 1.0497e-04 - 57s/epoch - 38ms/step
Epoch 151/200
1493/1493 - 57s - loss: 1.1030e-04 - val_loss: 1.1879e-04 - 57s/epoch - 38ms/step
Epoch 152/200
1493/1493 - 57s - loss: 1.0557e-04 - val_loss: 1.7874e-04 - 57s/epoch - 38ms/step
Epoch 153/200
1493/1493 - 57s - loss: 1.0858e-04 - val_loss: 1.5863e-04 - 57s/epoch - 38ms/step
Epoch 154/200
1493/1493 - 57s - loss: 1.0340e-04 - val_loss: 1.6113e-04 - 57s/epoch - 38ms/step
Epoch 155/200
1493/1493 - 57s - loss: 1.1393e-04 - val_loss: 1.0133e-04 - 57s/epoch - 38ms/step
Epoch 156/200
1493/1493 - 58s - loss: 1.0574e-04 - val_loss: 1.0963e-04 - 58s/epoch - 39ms/step
Epoch 157/200
1493/1493 - 57s - loss: 1.0097e-04 - val_loss: 1.2087e-04 - 57s/epoch - 38ms/step
Epoch 158/200
1493/1493 - 57s - loss: 1.0286e-04 - val_loss: 1.2212e-04 - 57s/epoch - 38ms/step
Epoch 159/200
1493/1493 - 57s - loss: 1.0100e-04 - val_loss: 1.0041e-04 - 57s/epoch - 38ms/step
Epoch 160/200
1493/1493 - 57s - loss: 1.0132e-04 - val_loss: 1.4172e-04 - 57s/epoch - 38ms/step
Epoch 161/200
1493/1493 - 57s - loss: 1.1340e-04 - val_loss: 9.7917e-05 - 57s/epoch - 38ms/step
Epoch 162/200
1493/1493 - 57s - loss: 1.0159e-04 - val_loss: 1.0482e-04 - 57s/epoch - 38ms/step
Epoch 163/200
1493/1493 - 57s - loss: 1.0061e-04 - val_loss: 2.0594e-04 - 57s/epoch - 38ms/step
Epoch 164/200
1493/1493 - 57s - loss: 1.1536e-04 - val_loss: 1.0281e-04 - 57s/epoch - 38ms/step
Epoch 165/200
1493/1493 - 57s - loss: 1.0535e-04 - val_loss: 1.0172e-04 - 57s/epoch - 38ms/step
Epoch 166/200
1493/1493 - 56s - loss: 1.0149e-04 - val_loss: 1.1938e-04 - 56s/epoch - 38ms/step
Epoch 167/200
1493/1493 - 56s - loss: 1.0131e-04 - val_loss: 8.9271e-05 - 56s/epoch - 38ms/step
Epoch 168/200
1493/1493 - 56s - loss: 9.9692e-05 - val_loss: 1.0493e-04 - 56s/epoch - 38ms/step
Epoch 169/200
1493/1493 - 56s - loss: 9.8778e-05 - val_loss: 1.3417e-04 - 56s/epoch - 38ms/step
Epoch 170/200
1493/1493 - 56s - loss: 9.9809e-05 - val_loss: 3.4049e-04 - 56s/epoch - 38ms/step
Epoch 171/200
1493/1493 - 57s - loss: 1.3882e-04 - val_loss: 5.2343e-04 - 57s/epoch - 38ms/step
Epoch 172/200
1493/1493 - 57s - loss: 1.5100e-04 - val_loss: 1.2457e-04 - 57s/epoch - 38ms/step
Epoch 173/200
1493/1493 - 57s - loss: 1.0572e-04 - val_loss: 9.1348e-05 - 57s/epoch - 38ms/step
Epoch 174/200
1493/1493 - 57s - loss: 9.9892e-05 - val_loss: 8.9257e-05 - 57s/epoch - 38ms/step
Epoch 175/200
1493/1493 - 57s - loss: 1.0028e-04 - val_loss: 1.1245e-04 - 57s/epoch - 38ms/step
Epoch 176/200
1493/1493 - 57s - loss: 9.9552e-05 - val_loss: 1.1088e-04 - 57s/epoch - 38ms/step
Epoch 177/200
1493/1493 - 57s - loss: 9.9610e-05 - val_loss: 9.8633e-05 - 57s/epoch - 38ms/step
Epoch 178/200
1493/1493 - 57s - loss: 9.6744e-05 - val_loss: 1.0267e-04 - 57s/epoch - 38ms/step
Epoch 179/200
1493/1493 - 57s - loss: 9.5253e-05 - val_loss: 1.0972e-04 - 57s/epoch - 38ms/step
Epoch 180/200
1493/1493 - 57s - loss: 9.5499e-05 - val_loss: 1.1590e-04 - 57s/epoch - 38ms/step
Epoch 181/200
1493/1493 - 57s - loss: 9.6848e-05 - val_loss: 9.3873e-05 - 57s/epoch - 38ms/step
Epoch 182/200
1493/1493 - 57s - loss: 9.5609e-05 - val_loss: 1.2160e-04 - 57s/epoch - 38ms/step
Epoch 183/200
1493/1493 - 57s - loss: 9.4304e-05 - val_loss: 1.0017e-04 - 57s/epoch - 38ms/step
Epoch 184/200
1493/1493 - 57s - loss: 9.5917e-05 - val_loss: 9.1027e-05 - 57s/epoch - 38ms/step
Epoch 185/200
1493/1493 - 57s - loss: 9.6168e-05 - val_loss: 4.1658e-04 - 57s/epoch - 38ms/step
Epoch 186/200
1493/1493 - 57s - loss: 1.4282e-04 - val_loss: 8.6026e-05 - 57s/epoch - 38ms/step
Epoch 187/200
1493/1493 - 57s - loss: 1.0002e-04 - val_loss: 1.0792e-04 - 57s/epoch - 38ms/step
Epoch 188/200
1493/1493 - 57s - loss: 9.9349e-05 - val_loss: 1.0991e-04 - 57s/epoch - 38ms/step
Epoch 189/200
1493/1493 - 57s - loss: 9.5597e-05 - val_loss: 1.0850e-04 - 57s/epoch - 38ms/step
Epoch 190/200
1493/1493 - 57s - loss: 9.5635e-05 - val_loss: 1.4146e-04 - 57s/epoch - 38ms/step
Epoch 191/200
1493/1493 - 56s - loss: 9.8465e-05 - val_loss: 1.5590e-04 - 56s/epoch - 38ms/step
Epoch 192/200
1493/1493 - 57s - loss: 9.7522e-05 - val_loss: 1.7148e-04 - 57s/epoch - 38ms/step
Epoch 193/200
1493/1493 - 57s - loss: 1.0290e-04 - val_loss: 1.6448e-04 - 57s/epoch - 38ms/step
Epoch 194/200
1493/1493 - 57s - loss: 1.0630e-04 - val_loss: 4.1129e-04 - 57s/epoch - 38ms/step
Epoch 195/200
1493/1493 - 56s - loss: 1.4507e-04 - val_loss: 1.3984e-04 - 56s/epoch - 38ms/step
Epoch 196/200
1493/1493 - 57s - loss: 1.0511e-04 - val_loss: 7.9954e-05 - 57s/epoch - 38ms/step
Epoch 197/200
1493/1493 - 57s - loss: 9.6680e-05 - val_loss: 1.1926e-04 - 57s/epoch - 38ms/step
Epoch 198/200
1493/1493 - 57s - loss: 1.0028e-04 - val_loss: 1.2178e-04 - 57s/epoch - 38ms/step
Epoch 199/200
1493/1493 - 57s - loss: 9.6732e-05 - val_loss: 9.4231e-05 - 57s/epoch - 38ms/step
Epoch 200/200
1493/1493 - 57s - loss: 9.3086e-05 - val_loss: 9.9502e-05 - 57s/epoch - 38ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.950168896466494e-05
  1/332 [..............................] - ETA: 36s  8/332 [..............................] - ETA: 2s  16/332 [>.............................] - ETA: 2s 24/332 [=>............................] - ETA: 2s 33/332 [=>............................] - ETA: 1s 42/332 [==>...........................] - ETA: 1s 51/332 [===>..........................] - ETA: 1s 60/332 [====>.........................] - ETA: 1s 69/332 [=====>........................] - ETA: 1s 78/332 [======>.......................] - ETA: 1s 87/332 [======>.......................] - ETA: 1s 96/332 [=======>......................] - ETA: 1s105/332 [========>.....................] - ETA: 1s114/332 [=========>....................] - ETA: 1s123/332 [==========>...................] - ETA: 1s132/332 [==========>...................] - ETA: 1s141/332 [===========>..................] - ETA: 1s150/332 [============>.................] - ETA: 1s159/332 [=============>................] - ETA: 1s168/332 [==============>...............] - ETA: 0s177/332 [==============>...............] - ETA: 0s186/332 [===============>..............] - ETA: 0s195/332 [================>.............] - ETA: 0s204/332 [=================>............] - ETA: 0s213/332 [==================>...........] - ETA: 0s222/332 [===================>..........] - ETA: 0s231/332 [===================>..........] - ETA: 0s240/332 [====================>.........] - ETA: 0s249/332 [=====================>........] - ETA: 0s258/332 [======================>.......] - ETA: 0s267/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s285/332 [========================>.....] - ETA: 0s294/332 [=========================>....] - ETA: 0s303/332 [==========================>...] - ETA: 0s312/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s330/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 6ms/step
correlation 0.0011199877267058192
cosine 0.0008809587167336542
MAE: 0.005616302
RMSE: 0.009975049
r2: 0.993545635966073
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 2022)              2557830   
                                                                 
 batch_normalization_3 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2022)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2045253   
                                                                 
 batch_normalization_4 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 1011)              0         
                                                                 
 dense_4 (Dense)             (None, 2022)              2046264   
                                                                 
 batch_normalization_5 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2022)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              2557072   
                                                                 
=================================================================
Total params: 9,226,639
Trainable params: 9,216,529
Non-trainable params: 10,110
_________________________________________________________________
Encoder
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_4 (InputLayer)        multiple                  0         
                                                                 
 dense_3 (Dense)             (None, 2022)              2557830   
                                                                 
 batch_normalization_3 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 2022)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2045253   
                                                                 
=================================================================
Total params: 4,611,171
Trainable params: 4,607,127
Non-trainable params: 4,044
_________________________________________________________________
Decoder
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 1011)]            0         
                                                                 
 batch_normalization_4 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 1011)              0         
                                                                 
 dense_4 (Dense)             (None, 2022)              2046264   
                                                                 
 batch_normalization_5 (Batc  (None, 2022)             8088      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 2022)              0         
                                                                 
 dense_5 (Dense)             (None, 1264)              2557072   
                                                                 
=================================================================
Total params: 4,615,468
Trainable params: 4,609,402
Non-trainable params: 6,066
_________________________________________________________________
['1.6custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 9.308551670983434e-05, 9.950168896466494e-05, 0.0011199877267058192, 0.0008809587167336542, 0.005616302136331797, 0.009975048713386059, 0.993545635966073, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 1264)]            0         
                                                                 
 dense_6 (Dense)             (None, 2148)              2717220   
                                                                 
 batch_normalization_6 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2148)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2172639   
                                                                 
 batch_normalization_7 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 1011)              0         
                                                                 
 dense_7 (Dense)             (None, 2148)              2173776   
                                                                 
 batch_normalization_8 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2148)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              2716336   
                                                                 
=================================================================
Total params: 9,801,199
Trainable params: 9,790,585
Non-trainable params: 10,614
_________________________________________________________________
Epoch 1/200
1493/1493 - 60s - loss: 0.0090 - val_loss: 0.0037 - 60s/epoch - 40ms/step
Epoch 2/200
1493/1493 - 60s - loss: 0.0028 - val_loss: 0.0028 - 60s/epoch - 40ms/step
Epoch 3/200
1493/1493 - 60s - loss: 0.0020 - val_loss: 0.0017 - 60s/epoch - 40ms/step
Epoch 4/200
1493/1493 - 60s - loss: 0.0016 - val_loss: 0.0039 - 60s/epoch - 40ms/step
Epoch 5/200
1493/1493 - 59s - loss: 0.0016 - val_loss: 0.0012 - 59s/epoch - 40ms/step
Epoch 6/200
1493/1493 - 60s - loss: 0.0013 - val_loss: 0.0013 - 60s/epoch - 40ms/step
Epoch 7/200
1493/1493 - 60s - loss: 0.0012 - val_loss: 9.7628e-04 - 60s/epoch - 40ms/step
Epoch 8/200
1493/1493 - 60s - loss: 0.0011 - val_loss: 0.0012 - 60s/epoch - 40ms/step
Epoch 9/200
1493/1493 - 60s - loss: 0.0010 - val_loss: 8.3272e-04 - 60s/epoch - 40ms/step
Epoch 10/200
1493/1493 - 59s - loss: 9.0794e-04 - val_loss: 8.7587e-04 - 59s/epoch - 40ms/step
Epoch 11/200
1493/1493 - 59s - loss: 8.8505e-04 - val_loss: 7.6351e-04 - 59s/epoch - 40ms/step
Epoch 12/200
1493/1493 - 59s - loss: 7.4788e-04 - val_loss: 0.0011 - 59s/epoch - 40ms/step
Epoch 13/200
1493/1493 - 59s - loss: 7.5609e-04 - val_loss: 0.0016 - 59s/epoch - 40ms/step
Epoch 14/200
1493/1493 - 59s - loss: 7.2590e-04 - val_loss: 0.0010 - 59s/epoch - 40ms/step
Epoch 15/200
1493/1493 - 59s - loss: 6.9250e-04 - val_loss: 0.0013 - 59s/epoch - 40ms/step
Epoch 16/200
1493/1493 - 59s - loss: 6.7400e-04 - val_loss: 5.3593e-04 - 59s/epoch - 40ms/step
Epoch 17/200
1493/1493 - 59s - loss: 5.5592e-04 - val_loss: 7.2291e-04 - 59s/epoch - 40ms/step
Epoch 18/200
1493/1493 - 60s - loss: 5.5083e-04 - val_loss: 0.0015 - 60s/epoch - 40ms/step
Epoch 19/200
1493/1493 - 60s - loss: 5.9085e-04 - val_loss: 5.2529e-04 - 60s/epoch - 40ms/step
Epoch 20/200
1493/1493 - 59s - loss: 4.9514e-04 - val_loss: 5.1148e-04 - 59s/epoch - 40ms/step
Epoch 21/200
1493/1493 - 59s - loss: 4.6783e-04 - val_loss: 6.4119e-04 - 59s/epoch - 40ms/step
Epoch 22/200
1493/1493 - 59s - loss: 4.5237e-04 - val_loss: 5.9890e-04 - 59s/epoch - 40ms/step
Epoch 23/200
1493/1493 - 59s - loss: 4.5349e-04 - val_loss: 7.2584e-04 - 59s/epoch - 40ms/step
Epoch 24/200
1493/1493 - 59s - loss: 4.2485e-04 - val_loss: 4.2786e-04 - 59s/epoch - 40ms/step
Epoch 25/200
1493/1493 - 59s - loss: 4.1643e-04 - val_loss: 3.9906e-04 - 59s/epoch - 40ms/step
Epoch 26/200
1493/1493 - 59s - loss: 3.8576e-04 - val_loss: 4.5846e-04 - 59s/epoch - 40ms/step
Epoch 27/200
1493/1493 - 60s - loss: 3.6011e-04 - val_loss: 3.7942e-04 - 60s/epoch - 40ms/step
Epoch 28/200
1493/1493 - 60s - loss: 3.4425e-04 - val_loss: 5.5092e-04 - 60s/epoch - 40ms/step
Epoch 29/200
1493/1493 - 60s - loss: 3.3905e-04 - val_loss: 3.8689e-04 - 60s/epoch - 40ms/step
Epoch 30/200
1493/1493 - 60s - loss: 3.3683e-04 - val_loss: 3.6327e-04 - 60s/epoch - 40ms/step
Epoch 31/200
1493/1493 - 59s - loss: 3.1608e-04 - val_loss: 5.1691e-04 - 59s/epoch - 40ms/step
Epoch 32/200
1493/1493 - 60s - loss: 3.7453e-04 - val_loss: 3.2834e-04 - 60s/epoch - 40ms/step
Epoch 33/200
1493/1493 - 60s - loss: 3.1582e-04 - val_loss: 2.8745e-04 - 60s/epoch - 40ms/step
Epoch 34/200
1493/1493 - 60s - loss: 2.9618e-04 - val_loss: 2.7333e-04 - 60s/epoch - 40ms/step
Epoch 35/200
1493/1493 - 59s - loss: 2.8384e-04 - val_loss: 7.8156e-04 - 59s/epoch - 40ms/step
Epoch 36/200
1493/1493 - 60s - loss: 3.1025e-04 - val_loss: 3.6003e-04 - 60s/epoch - 40ms/step
Epoch 37/200
1493/1493 - 60s - loss: 2.7668e-04 - val_loss: 6.9226e-04 - 60s/epoch - 40ms/step
Epoch 38/200
1493/1493 - 59s - loss: 3.0571e-04 - val_loss: 2.5248e-04 - 59s/epoch - 40ms/step
Epoch 39/200
1493/1493 - 59s - loss: 2.5766e-04 - val_loss: 2.2934e-04 - 59s/epoch - 40ms/step
Epoch 40/200
1493/1493 - 60s - loss: 2.4984e-04 - val_loss: 3.3230e-04 - 60s/epoch - 40ms/step
Epoch 41/200
1493/1493 - 60s - loss: 2.5310e-04 - val_loss: 2.3473e-04 - 60s/epoch - 40ms/step
Epoch 42/200
1493/1493 - 60s - loss: 2.4222e-04 - val_loss: 2.3622e-04 - 60s/epoch - 40ms/step
Epoch 43/200
1493/1493 - 59s - loss: 2.4359e-04 - val_loss: 4.3776e-04 - 59s/epoch - 40ms/step
Epoch 44/200
1493/1493 - 59s - loss: 2.4990e-04 - val_loss: 3.2578e-04 - 59s/epoch - 40ms/step
Epoch 45/200
1493/1493 - 59s - loss: 2.3956e-04 - val_loss: 1.9731e-04 - 59s/epoch - 40ms/step
Epoch 46/200
1493/1493 - 59s - loss: 2.2689e-04 - val_loss: 2.2059e-04 - 59s/epoch - 40ms/step
Epoch 47/200
1493/1493 - 59s - loss: 2.2138e-04 - val_loss: 2.4188e-04 - 59s/epoch - 40ms/step
Epoch 48/200
1493/1493 - 59s - loss: 2.2191e-04 - val_loss: 3.6312e-04 - 59s/epoch - 40ms/step
Epoch 49/200
1493/1493 - 59s - loss: 2.1989e-04 - val_loss: 5.1766e-04 - 59s/epoch - 40ms/step
Epoch 50/200
1493/1493 - 59s - loss: 2.3478e-04 - val_loss: 4.4946e-04 - 59s/epoch - 40ms/step
Epoch 51/200
1493/1493 - 59s - loss: 2.4592e-04 - val_loss: 2.0937e-04 - 59s/epoch - 40ms/step
Epoch 52/200
1493/1493 - 59s - loss: 2.0419e-04 - val_loss: 2.0238e-04 - 59s/epoch - 40ms/step
Epoch 53/200
1493/1493 - 59s - loss: 2.0554e-04 - val_loss: 1.9409e-04 - 59s/epoch - 40ms/step
Epoch 54/200
1493/1493 - 59s - loss: 1.9993e-04 - val_loss: 2.7228e-04 - 59s/epoch - 40ms/step
Epoch 55/200
1493/1493 - 59s - loss: 1.9385e-04 - val_loss: 1.9296e-04 - 59s/epoch - 40ms/step
Epoch 56/200
1493/1493 - 59s - loss: 1.9502e-04 - val_loss: 2.5345e-04 - 59s/epoch - 40ms/step
Epoch 57/200
1493/1493 - 59s - loss: 1.8895e-04 - val_loss: 2.3610e-04 - 59s/epoch - 40ms/step
Epoch 58/200
1493/1493 - 59s - loss: 1.8923e-04 - val_loss: 1.6334e-04 - 59s/epoch - 40ms/step
Epoch 59/200
1493/1493 - 59s - loss: 1.8364e-04 - val_loss: 2.1201e-04 - 59s/epoch - 40ms/step
Epoch 60/200
1493/1493 - 59s - loss: 1.8583e-04 - val_loss: 7.9463e-04 - 59s/epoch - 40ms/step
Epoch 61/200
1493/1493 - 59s - loss: 3.4924e-04 - val_loss: 1.7907e-04 - 59s/epoch - 40ms/step
Epoch 62/200
1493/1493 - 59s - loss: 1.9418e-04 - val_loss: 2.3690e-04 - 59s/epoch - 40ms/step
Epoch 63/200
1493/1493 - 59s - loss: 1.8663e-04 - val_loss: 2.3551e-04 - 59s/epoch - 40ms/step
Epoch 64/200
1493/1493 - 59s - loss: 1.8292e-04 - val_loss: 0.0012 - 59s/epoch - 40ms/step
Epoch 65/200
1493/1493 - 59s - loss: 2.4482e-04 - val_loss: 1.7754e-04 - 59s/epoch - 40ms/step
Epoch 66/200
1493/1493 - 59s - loss: 1.8309e-04 - val_loss: 2.0716e-04 - 59s/epoch - 40ms/step
Epoch 67/200
1493/1493 - 59s - loss: 1.7576e-04 - val_loss: 1.8218e-04 - 59s/epoch - 40ms/step
Epoch 68/200
1493/1493 - 59s - loss: 1.7028e-04 - val_loss: 2.2896e-04 - 59s/epoch - 40ms/step
Epoch 69/200
1493/1493 - 59s - loss: 1.7380e-04 - val_loss: 1.8377e-04 - 59s/epoch - 40ms/step
Epoch 70/200
1493/1493 - 60s - loss: 1.6988e-04 - val_loss: 5.2095e-04 - 60s/epoch - 40ms/step
Epoch 71/200
1493/1493 - 59s - loss: 2.3256e-04 - val_loss: 1.5800e-04 - 59s/epoch - 40ms/step
Epoch 72/200
1493/1493 - 59s - loss: 1.7207e-04 - val_loss: 1.9689e-04 - 59s/epoch - 39ms/step
Epoch 73/200
1493/1493 - 59s - loss: 1.7131e-04 - val_loss: 1.8447e-04 - 59s/epoch - 40ms/step
Epoch 74/200
1493/1493 - 60s - loss: 1.6621e-04 - val_loss: 1.5407e-04 - 60s/epoch - 40ms/step
Epoch 75/200
1493/1493 - 60s - loss: 1.5927e-04 - val_loss: 1.4263e-04 - 60s/epoch - 40ms/step
Epoch 76/200
1493/1493 - 59s - loss: 1.5762e-04 - val_loss: 1.5439e-04 - 59s/epoch - 40ms/step
Epoch 77/200
1493/1493 - 59s - loss: 1.5663e-04 - val_loss: 5.4931e-04 - 59s/epoch - 40ms/step
Epoch 78/200
1493/1493 - 60s - loss: 1.7315e-04 - val_loss: 2.7797e-04 - 60s/epoch - 40ms/step
Epoch 79/200
1493/1493 - 59s - loss: 1.6679e-04 - val_loss: 1.6949e-04 - 59s/epoch - 40ms/step
Epoch 80/200
1493/1493 - 59s - loss: 1.5749e-04 - val_loss: 1.5405e-04 - 59s/epoch - 40ms/step
Epoch 81/200
1493/1493 - 59s - loss: 1.5148e-04 - val_loss: 3.9917e-04 - 59s/epoch - 40ms/step
Epoch 82/200
1493/1493 - 60s - loss: 1.4871e-04 - val_loss: 1.4946e-04 - 60s/epoch - 40ms/step
Epoch 83/200
1493/1493 - 60s - loss: 1.4619e-04 - val_loss: 1.6921e-04 - 60s/epoch - 40ms/step
Epoch 84/200
1493/1493 - 60s - loss: 1.4813e-04 - val_loss: 1.7245e-04 - 60s/epoch - 40ms/step
Epoch 85/200
1493/1493 - 60s - loss: 1.4926e-04 - val_loss: 2.1734e-04 - 60s/epoch - 40ms/step
Epoch 86/200
1493/1493 - 60s - loss: 1.5088e-04 - val_loss: 1.4668e-04 - 60s/epoch - 40ms/step
Epoch 87/200
1493/1493 - 60s - loss: 1.4182e-04 - val_loss: 1.3479e-04 - 60s/epoch - 40ms/step
Epoch 88/200
1493/1493 - 60s - loss: 1.4127e-04 - val_loss: 1.4788e-04 - 60s/epoch - 40ms/step
Epoch 89/200
1493/1493 - 59s - loss: 1.4652e-04 - val_loss: 1.4595e-04 - 59s/epoch - 40ms/step
Epoch 90/200
1493/1493 - 59s - loss: 1.4046e-04 - val_loss: 1.4981e-04 - 59s/epoch - 40ms/step
Epoch 91/200
1493/1493 - 60s - loss: 1.3894e-04 - val_loss: 1.5273e-04 - 60s/epoch - 40ms/step
Epoch 92/200
1493/1493 - 59s - loss: 1.3859e-04 - val_loss: 5.1825e-04 - 59s/epoch - 40ms/step
Epoch 93/200
1493/1493 - 60s - loss: 1.9032e-04 - val_loss: 1.5720e-04 - 60s/epoch - 40ms/step
Epoch 94/200
1493/1493 - 60s - loss: 1.4400e-04 - val_loss: 1.2499e-04 - 60s/epoch - 40ms/step
Epoch 95/200
1493/1493 - 60s - loss: 1.3769e-04 - val_loss: 2.3680e-04 - 60s/epoch - 40ms/step
Epoch 96/200
1493/1493 - 59s - loss: 1.3945e-04 - val_loss: 1.5644e-04 - 59s/epoch - 40ms/step
Epoch 97/200
1493/1493 - 60s - loss: 1.3525e-04 - val_loss: 1.3476e-04 - 60s/epoch - 40ms/step
Epoch 98/200
1493/1493 - 60s - loss: 1.3564e-04 - val_loss: 5.5275e-04 - 60s/epoch - 40ms/step
Epoch 99/200
1493/1493 - 60s - loss: 1.9514e-04 - val_loss: 1.2206e-04 - 60s/epoch - 40ms/step
Epoch 100/200
1493/1493 - 59s - loss: 1.4287e-04 - val_loss: 1.3320e-04 - 59s/epoch - 40ms/step
Epoch 101/200
1493/1493 - 60s - loss: 1.3410e-04 - val_loss: 3.1958e-04 - 60s/epoch - 40ms/step
Epoch 102/200
1493/1493 - 60s - loss: 1.5124e-04 - val_loss: 2.1052e-04 - 60s/epoch - 40ms/step
Epoch 103/200
1493/1493 - 60s - loss: 1.3942e-04 - val_loss: 1.3275e-04 - 60s/epoch - 40ms/step
Epoch 104/200
1493/1493 - 60s - loss: 1.3021e-04 - val_loss: 2.3075e-04 - 60s/epoch - 40ms/step
Epoch 105/200
1493/1493 - 60s - loss: 1.3521e-04 - val_loss: 1.3066e-04 - 60s/epoch - 40ms/step
Epoch 106/200
1493/1493 - 59s - loss: 1.2820e-04 - val_loss: 1.3625e-04 - 59s/epoch - 40ms/step
Epoch 107/200
1493/1493 - 59s - loss: 1.2692e-04 - val_loss: 1.4630e-04 - 59s/epoch - 40ms/step
Epoch 108/200
1493/1493 - 60s - loss: 1.2696e-04 - val_loss: 1.4787e-04 - 60s/epoch - 40ms/step
Epoch 109/200
1493/1493 - 59s - loss: 1.2610e-04 - val_loss: 1.5378e-04 - 59s/epoch - 40ms/step
Epoch 110/200
1493/1493 - 60s - loss: 1.2437e-04 - val_loss: 1.4190e-04 - 60s/epoch - 40ms/step
Epoch 111/200
1493/1493 - 60s - loss: 1.2398e-04 - val_loss: 1.6583e-04 - 60s/epoch - 40ms/step
Epoch 112/200
1493/1493 - 59s - loss: 1.3046e-04 - val_loss: 1.1670e-04 - 59s/epoch - 40ms/step
Epoch 113/200
1493/1493 - 60s - loss: 1.2177e-04 - val_loss: 3.6706e-04 - 60s/epoch - 40ms/step
Epoch 114/200
1493/1493 - 60s - loss: 1.5527e-04 - val_loss: 1.2010e-04 - 60s/epoch - 40ms/step
Epoch 115/200
1493/1493 - 60s - loss: 1.2537e-04 - val_loss: 2.0098e-04 - 60s/epoch - 40ms/step
Epoch 116/200
1493/1493 - 60s - loss: 1.2262e-04 - val_loss: 1.4191e-04 - 60s/epoch - 40ms/step
Epoch 117/200
1493/1493 - 60s - loss: 1.1987e-04 - val_loss: 2.4890e-04 - 60s/epoch - 40ms/step
Epoch 118/200
1493/1493 - 60s - loss: 1.3332e-04 - val_loss: 1.1764e-04 - 60s/epoch - 40ms/step
Epoch 119/200
1493/1493 - 60s - loss: 1.1981e-04 - val_loss: 1.1078e-04 - 60s/epoch - 40ms/step
Epoch 120/200
1493/1493 - 60s - loss: 1.1867e-04 - val_loss: 1.2399e-04 - 60s/epoch - 40ms/step
Epoch 121/200
1493/1493 - 60s - loss: 1.1785e-04 - val_loss: 1.9046e-04 - 60s/epoch - 40ms/step
Epoch 122/200
1493/1493 - 59s - loss: 1.2519e-04 - val_loss: 1.0977e-04 - 59s/epoch - 40ms/step
Epoch 123/200
1493/1493 - 60s - loss: 1.1799e-04 - val_loss: 1.2010e-04 - 60s/epoch - 40ms/step
Epoch 124/200
1493/1493 - 60s - loss: 1.1707e-04 - val_loss: 4.3430e-04 - 60s/epoch - 40ms/step
Epoch 125/200
1493/1493 - 60s - loss: 1.5224e-04 - val_loss: 1.2154e-04 - 60s/epoch - 40ms/step
Epoch 126/200
1493/1493 - 60s - loss: 1.1854e-04 - val_loss: 1.7103e-04 - 60s/epoch - 40ms/step
Epoch 127/200
1493/1493 - 60s - loss: 1.1903e-04 - val_loss: 4.6158e-04 - 60s/epoch - 40ms/step
Epoch 128/200
1493/1493 - 60s - loss: 1.4069e-04 - val_loss: 1.0575e-04 - 60s/epoch - 40ms/step
Epoch 129/200
1493/1493 - 59s - loss: 1.1494e-04 - val_loss: 1.1892e-04 - 59s/epoch - 40ms/step
Epoch 130/200
1493/1493 - 60s - loss: 1.1383e-04 - val_loss: 1.0728e-04 - 60s/epoch - 40ms/step
Epoch 131/200
1493/1493 - 60s - loss: 1.1524e-04 - val_loss: 3.5307e-04 - 60s/epoch - 40ms/step
Epoch 132/200
1493/1493 - 60s - loss: 1.4461e-04 - val_loss: 1.0814e-04 - 60s/epoch - 40ms/step
Epoch 133/200
1493/1493 - 60s - loss: 1.1349e-04 - val_loss: 1.1340e-04 - 60s/epoch - 40ms/step
Epoch 134/200
1493/1493 - 60s - loss: 1.1195e-04 - val_loss: 1.1543e-04 - 60s/epoch - 40ms/step
Epoch 135/200
1493/1493 - 59s - loss: 1.1139e-04 - val_loss: 1.0658e-04 - 59s/epoch - 40ms/step
Epoch 136/200
1493/1493 - 60s - loss: 1.1087e-04 - val_loss: 1.5167e-04 - 60s/epoch - 40ms/step
Epoch 137/200
1493/1493 - 60s - loss: 1.2407e-04 - val_loss: 1.3521e-04 - 60s/epoch - 40ms/step
Epoch 138/200
1493/1493 - 60s - loss: 1.1332e-04 - val_loss: 1.1757e-04 - 60s/epoch - 40ms/step
Epoch 139/200
1493/1493 - 60s - loss: 1.1122e-04 - val_loss: 1.6966e-04 - 60s/epoch - 40ms/step
Epoch 140/200
1493/1493 - 60s - loss: 1.2277e-04 - val_loss: 1.0007e-04 - 60s/epoch - 40ms/step
Epoch 141/200
1493/1493 - 59s - loss: 1.1005e-04 - val_loss: 1.1689e-04 - 59s/epoch - 40ms/step
Epoch 142/200
1493/1493 - 60s - loss: 1.1130e-04 - val_loss: 1.3022e-04 - 60s/epoch - 40ms/step
Epoch 143/200
1493/1493 - 60s - loss: 1.0726e-04 - val_loss: 1.4560e-04 - 60s/epoch - 40ms/step
Epoch 144/200
1493/1493 - 60s - loss: 1.0946e-04 - val_loss: 1.2083e-04 - 60s/epoch - 40ms/step
Epoch 145/200
1493/1493 - 59s - loss: 1.0714e-04 - val_loss: 1.0204e-04 - 59s/epoch - 40ms/step
Epoch 146/200
1493/1493 - 59s - loss: 1.0555e-04 - val_loss: 1.0302e-04 - 59s/epoch - 40ms/step
Epoch 147/200
1493/1493 - 60s - loss: 1.0416e-04 - val_loss: 1.4630e-04 - 60s/epoch - 40ms/step
Epoch 148/200
1493/1493 - 60s - loss: 1.0621e-04 - val_loss: 1.8823e-04 - 60s/epoch - 40ms/step
Epoch 149/200
1493/1493 - 59s - loss: 1.0435e-04 - val_loss: 1.0998e-04 - 59s/epoch - 40ms/step
Epoch 150/200
1493/1493 - 60s - loss: 1.0341e-04 - val_loss: 9.9688e-05 - 60s/epoch - 40ms/step
Epoch 151/200
1493/1493 - 59s - loss: 1.0503e-04 - val_loss: 1.4812e-04 - 59s/epoch - 40ms/step
Epoch 152/200
1493/1493 - 60s - loss: 1.0385e-04 - val_loss: 1.3499e-04 - 60s/epoch - 40ms/step
Epoch 153/200
1493/1493 - 60s - loss: 1.0488e-04 - val_loss: 1.2044e-04 - 60s/epoch - 40ms/step
Epoch 154/200
1493/1493 - 60s - loss: 1.0209e-04 - val_loss: 1.7195e-04 - 60s/epoch - 40ms/step
Epoch 155/200
1493/1493 - 60s - loss: 1.1410e-04 - val_loss: 1.0528e-04 - 60s/epoch - 40ms/step
Epoch 156/200
1493/1493 - 59s - loss: 1.0457e-04 - val_loss: 1.1171e-04 - 59s/epoch - 40ms/step
Epoch 157/200
1493/1493 - 59s - loss: 1.0101e-04 - val_loss: 1.1912e-04 - 59s/epoch - 40ms/step
Epoch 158/200
1493/1493 - 60s - loss: 1.0300e-04 - val_loss: 1.2959e-04 - 60s/epoch - 40ms/step
Epoch 159/200
1493/1493 - 59s - loss: 1.0010e-04 - val_loss: 9.7006e-05 - 59s/epoch - 40ms/step
Epoch 160/200
1493/1493 - 60s - loss: 1.0317e-04 - val_loss: 1.8838e-04 - 60s/epoch - 40ms/step
Epoch 161/200
1493/1493 - 60s - loss: 1.7520e-04 - val_loss: 9.4044e-05 - 60s/epoch - 40ms/step
Epoch 162/200
1493/1493 - 60s - loss: 1.0474e-04 - val_loss: 9.3905e-05 - 60s/epoch - 40ms/step
Epoch 163/200
1493/1493 - 60s - loss: 1.0122e-04 - val_loss: 1.5693e-04 - 60s/epoch - 40ms/step
Epoch 164/200
1493/1493 - 60s - loss: 1.0491e-04 - val_loss: 1.0184e-04 - 60s/epoch - 40ms/step
Epoch 165/200
1493/1493 - 60s - loss: 1.0230e-04 - val_loss: 1.0599e-04 - 60s/epoch - 40ms/step
Epoch 166/200
1493/1493 - 59s - loss: 1.0059e-04 - val_loss: 1.1595e-04 - 59s/epoch - 40ms/step
Epoch 167/200
1493/1493 - 60s - loss: 9.9249e-05 - val_loss: 1.0036e-04 - 60s/epoch - 40ms/step
Epoch 168/200
1493/1493 - 60s - loss: 9.9643e-05 - val_loss: 9.2738e-05 - 60s/epoch - 40ms/step
Epoch 169/200
1493/1493 - 60s - loss: 9.7814e-05 - val_loss: 1.2508e-04 - 60s/epoch - 40ms/step
Epoch 170/200
1493/1493 - 60s - loss: 1.0195e-04 - val_loss: 4.1408e-04 - 60s/epoch - 40ms/step
Epoch 171/200
1493/1493 - 60s - loss: 1.6611e-04 - val_loss: 2.0267e-04 - 60s/epoch - 40ms/step
Epoch 172/200
1493/1493 - 60s - loss: 1.2015e-04 - val_loss: 1.0316e-04 - 60s/epoch - 40ms/step
Epoch 173/200
1493/1493 - 59s - loss: 1.0272e-04 - val_loss: 9.2075e-05 - 59s/epoch - 40ms/step
Epoch 174/200
1493/1493 - 60s - loss: 9.9094e-05 - val_loss: 9.3786e-05 - 60s/epoch - 40ms/step
Epoch 175/200
1493/1493 - 60s - loss: 1.0012e-04 - val_loss: 1.2556e-04 - 60s/epoch - 40ms/step
Epoch 176/200
1493/1493 - 59s - loss: 9.9522e-05 - val_loss: 1.0350e-04 - 59s/epoch - 40ms/step
Epoch 177/200
1493/1493 - 59s - loss: 9.7502e-05 - val_loss: 8.8101e-05 - 59s/epoch - 40ms/step
Epoch 178/200
1493/1493 - 59s - loss: 9.6039e-05 - val_loss: 1.0237e-04 - 59s/epoch - 40ms/step
Epoch 179/200
1493/1493 - 60s - loss: 9.4924e-05 - val_loss: 1.0596e-04 - 60s/epoch - 40ms/step
Epoch 180/200
1493/1493 - 59s - loss: 9.4540e-05 - val_loss: 1.2545e-04 - 59s/epoch - 40ms/step
Epoch 181/200
1493/1493 - 60s - loss: 9.8464e-05 - val_loss: 9.4394e-05 - 60s/epoch - 40ms/step
Epoch 182/200
1493/1493 - 60s - loss: 9.4951e-05 - val_loss: 1.0468e-04 - 60s/epoch - 40ms/step
Epoch 183/200
1493/1493 - 60s - loss: 9.3298e-05 - val_loss: 1.0061e-04 - 60s/epoch - 40ms/step
Epoch 184/200
1493/1493 - 60s - loss: 9.3642e-05 - val_loss: 9.5723e-05 - 60s/epoch - 40ms/step
Epoch 185/200
1493/1493 - 60s - loss: 9.5532e-05 - val_loss: 3.2797e-04 - 60s/epoch - 40ms/step
Epoch 186/200
1493/1493 - 60s - loss: 1.3370e-04 - val_loss: 8.4198e-05 - 60s/epoch - 40ms/step
Epoch 187/200
1493/1493 - 60s - loss: 9.6750e-05 - val_loss: 1.4257e-04 - 60s/epoch - 40ms/step
Epoch 188/200
1493/1493 - 60s - loss: 1.0815e-04 - val_loss: 1.1706e-04 - 60s/epoch - 40ms/step
Epoch 189/200
1493/1493 - 60s - loss: 9.7763e-05 - val_loss: 1.1023e-04 - 60s/epoch - 40ms/step
Epoch 190/200
1493/1493 - 60s - loss: 9.6185e-05 - val_loss: 1.3620e-04 - 60s/epoch - 40ms/step
Epoch 191/200
1493/1493 - 59s - loss: 9.9678e-05 - val_loss: 1.1888e-04 - 59s/epoch - 40ms/step
Epoch 192/200
1493/1493 - 60s - loss: 9.3924e-05 - val_loss: 1.2093e-04 - 60s/epoch - 40ms/step
Epoch 193/200
1493/1493 - 60s - loss: 9.4677e-05 - val_loss: 1.3898e-04 - 60s/epoch - 40ms/step
Epoch 194/200
1493/1493 - 59s - loss: 1.0412e-04 - val_loss: 4.4840e-04 - 59s/epoch - 40ms/step
Epoch 195/200
1493/1493 - 59s - loss: 1.4383e-04 - val_loss: 3.4362e-04 - 59s/epoch - 40ms/step
Epoch 196/200
1493/1493 - 60s - loss: 1.3051e-04 - val_loss: 7.7735e-05 - 60s/epoch - 40ms/step
Epoch 197/200
1493/1493 - 60s - loss: 9.6620e-05 - val_loss: 1.0815e-04 - 60s/epoch - 40ms/step
Epoch 198/200
1493/1493 - 60s - loss: 9.8076e-05 - val_loss: 1.2444e-04 - 60s/epoch - 40ms/step
Epoch 199/200
1493/1493 - 60s - loss: 9.7820e-05 - val_loss: 8.6060e-05 - 60s/epoch - 40ms/step
Epoch 200/200
1493/1493 - 60s - loss: 9.2760e-05 - val_loss: 9.1979e-05 - 60s/epoch - 40ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.197860345011577e-05
  1/332 [..............................] - ETA: 50s  9/332 [..............................] - ETA: 2s  18/332 [>.............................] - ETA: 1s 27/332 [=>............................] - ETA: 1s 36/332 [==>...........................] - ETA: 1s 45/332 [===>..........................] - ETA: 1s 54/332 [===>..........................] - ETA: 1s 63/332 [====>.........................] - ETA: 1s 71/332 [=====>........................] - ETA: 1s 80/332 [======>.......................] - ETA: 1s 89/332 [=======>......................] - ETA: 1s 98/332 [=======>......................] - ETA: 1s107/332 [========>.....................] - ETA: 1s116/332 [=========>....................] - ETA: 1s125/332 [==========>...................] - ETA: 1s134/332 [===========>..................] - ETA: 1s143/332 [===========>..................] - ETA: 1s152/332 [============>.................] - ETA: 1s161/332 [=============>................] - ETA: 1s170/332 [==============>...............] - ETA: 0s179/332 [===============>..............] - ETA: 0s188/332 [===============>..............] - ETA: 0s197/332 [================>.............] - ETA: 0s206/332 [=================>............] - ETA: 0s215/332 [==================>...........] - ETA: 0s224/332 [===================>..........] - ETA: 0s233/332 [====================>.........] - ETA: 0s242/332 [====================>.........] - ETA: 0s251/332 [=====================>........] - ETA: 0s260/332 [======================>.......] - ETA: 0s269/332 [=======================>......] - ETA: 0s278/332 [========================>.....] - ETA: 0s287/332 [========================>.....] - ETA: 0s296/332 [=========================>....] - ETA: 0s305/332 [==========================>...] - ETA: 0s314/332 [===========================>..] - ETA: 0s323/332 [============================>.] - ETA: 0s332/332 [==============================] - ETA: 0s332/332 [==============================] - 2s 6ms/step
correlation 0.001049511693488235
cosine 0.0008276541065459786
MAE: 0.0053820526
RMSE: 0.009590543
r2: 0.9940337247807273
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 2148)              2717220   
                                                                 
 batch_normalization_6 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2148)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2172639   
                                                                 
 batch_normalization_7 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 1011)              0         
                                                                 
 dense_7 (Dense)             (None, 2148)              2173776   
                                                                 
 batch_normalization_8 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2148)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              2716336   
                                                                 
=================================================================
Total params: 9,801,199
Trainable params: 9,790,585
Non-trainable params: 10,614
_________________________________________________________________
Encoder
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 1264)]            0         
                                                                 
 input_7 (InputLayer)        multiple                  0         
                                                                 
 dense_6 (Dense)             (None, 2148)              2717220   
                                                                 
 batch_normalization_6 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_6 (ReLU)              (None, 2148)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2172639   
                                                                 
=================================================================
Total params: 4,898,451
Trainable params: 4,894,155
Non-trainable params: 4,296
_________________________________________________________________
Decoder
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 1011)]            0         
                                                                 
 batch_normalization_7 (Batc  (None, 1011)             4044      
 hNormalization)                                                 
                                                                 
 re_lu_7 (ReLU)              (None, 1011)              0         
                                                                 
 dense_7 (Dense)             (None, 2148)              2173776   
                                                                 
 batch_normalization_8 (Batc  (None, 2148)             8592      
 hNormalization)                                                 
                                                                 
 re_lu_8 (ReLU)              (None, 2148)              0         
                                                                 
 dense_8 (Dense)             (None, 1264)              2716336   
                                                                 
=================================================================
Total params: 4,902,748
Trainable params: 4,896,430
Non-trainable params: 6,318
_________________________________________________________________
['1.7custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 9.275991033064201e-05, 9.197860345011577e-05, 0.001049511693488235, 0.0008276541065459786, 0.0053820526227355, 0.009590542875230312, 0.9940337247807273, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_9 (Dense)             (None, 2275)              2877875   
                                                                 
 batch_normalization_9 (Batc  (None, 2275)             9100      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2275)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2301036   
                                                                 
 batch_normalization_10 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 1011)              0         
                                                                 
 dense_10 (Dense)            (None, 2275)              2302300   
                                                                 
 batch_normalization_11 (Bat  (None, 2275)             9100      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2275)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              2876864   
                                                                 
=================================================================
Total params: 10,380,319
Trainable params: 10,369,197
Non-trainable params: 11,122
_________________________________________________________________
Epoch 1/200
1493/1493 - 65s - loss: 0.0090 - val_loss: 0.0038 - 65s/epoch - 43ms/step
Epoch 2/200
1493/1493 - 64s - loss: 0.0028 - val_loss: 0.0031 - 64s/epoch - 43ms/step
Epoch 3/200
1493/1493 - 64s - loss: 0.0020 - val_loss: 0.0015 - 64s/epoch - 43ms/step
Epoch 4/200
1493/1493 - 64s - loss: 0.0016 - val_loss: 0.0040 - 64s/epoch - 43ms/step
Epoch 5/200
1493/1493 - 64s - loss: 0.0016 - val_loss: 0.0011 - 64s/epoch - 43ms/step
Epoch 6/200
1493/1493 - 63s - loss: 0.0013 - val_loss: 0.0014 - 63s/epoch - 42ms/step
Epoch 7/200
1493/1493 - 64s - loss: 0.0012 - val_loss: 0.0013 - 64s/epoch - 43ms/step
Epoch 8/200
1493/1493 - 64s - loss: 0.0011 - val_loss: 0.0011 - 64s/epoch - 43ms/step
Epoch 9/200
1493/1493 - 64s - loss: 0.0010 - val_loss: 0.0029 - 64s/epoch - 43ms/step
Epoch 10/200
1493/1493 - 64s - loss: 0.0011 - val_loss: 7.1254e-04 - 64s/epoch - 43ms/step
Epoch 11/200
1493/1493 - 64s - loss: 8.5718e-04 - val_loss: 8.2104e-04 - 64s/epoch - 43ms/step
Epoch 12/200
1493/1493 - 64s - loss: 7.5029e-04 - val_loss: 0.0011 - 64s/epoch - 43ms/step
Epoch 13/200
1493/1493 - 64s - loss: 7.5013e-04 - val_loss: 0.0012 - 64s/epoch - 43ms/step
Epoch 14/200
1493/1493 - 64s - loss: 7.4345e-04 - val_loss: 8.3903e-04 - 64s/epoch - 43ms/step
Epoch 15/200
1493/1493 - 64s - loss: 6.6114e-04 - val_loss: 5.6681e-04 - 64s/epoch - 43ms/step
Epoch 16/200
1493/1493 - 64s - loss: 5.8160e-04 - val_loss: 5.3492e-04 - 64s/epoch - 43ms/step
Epoch 17/200
1493/1493 - 64s - loss: 5.4117e-04 - val_loss: 7.2377e-04 - 64s/epoch - 43ms/step
Epoch 18/200
1493/1493 - 64s - loss: 5.2061e-04 - val_loss: 5.8977e-04 - 64s/epoch - 43ms/step
Epoch 19/200
1493/1493 - 64s - loss: 4.9670e-04 - val_loss: 5.5339e-04 - 64s/epoch - 43ms/step
Epoch 20/200
1493/1493 - 64s - loss: 4.7092e-04 - val_loss: 4.7425e-04 - 64s/epoch - 43ms/step
Epoch 21/200
1493/1493 - 64s - loss: 4.4994e-04 - val_loss: 5.6719e-04 - 64s/epoch - 43ms/step
Epoch 22/200
1493/1493 - 64s - loss: 4.2403e-04 - val_loss: 6.6900e-04 - 64s/epoch - 43ms/step
Epoch 23/200
1493/1493 - 64s - loss: 4.6108e-04 - val_loss: 7.9962e-04 - 64s/epoch - 43ms/step
Epoch 24/200
1493/1493 - 64s - loss: 4.1021e-04 - val_loss: 3.5981e-04 - 64s/epoch - 43ms/step
Epoch 25/200
1493/1493 - 64s - loss: 3.8293e-04 - val_loss: 3.8294e-04 - 64s/epoch - 43ms/step
Epoch 26/200
1493/1493 - 64s - loss: 3.5864e-04 - val_loss: 5.1415e-04 - 64s/epoch - 43ms/step
Epoch 27/200
1493/1493 - 64s - loss: 3.4109e-04 - val_loss: 3.5865e-04 - 64s/epoch - 43ms/step
Epoch 28/200
1493/1493 - 64s - loss: 3.2494e-04 - val_loss: 5.8031e-04 - 64s/epoch - 43ms/step
Epoch 29/200
1493/1493 - 64s - loss: 3.2016e-04 - val_loss: 4.2810e-04 - 64s/epoch - 43ms/step
Epoch 30/200
1493/1493 - 64s - loss: 3.1706e-04 - val_loss: 3.5781e-04 - 64s/epoch - 43ms/step
Epoch 31/200
1493/1493 - 63s - loss: 2.9883e-04 - val_loss: 5.1599e-04 - 63s/epoch - 42ms/step
Epoch 32/200
1493/1493 - 63s - loss: 3.4853e-04 - val_loss: 3.0575e-04 - 63s/epoch - 42ms/step
Epoch 33/200
1493/1493 - 63s - loss: 2.9442e-04 - val_loss: 2.7794e-04 - 63s/epoch - 43ms/step
Epoch 34/200
1493/1493 - 64s - loss: 2.7850e-04 - val_loss: 2.5643e-04 - 64s/epoch - 43ms/step
Epoch 35/200
1493/1493 - 63s - loss: 2.6513e-04 - val_loss: 8.8466e-04 - 63s/epoch - 42ms/step
Epoch 36/200
1493/1493 - 63s - loss: 2.9671e-04 - val_loss: 3.2240e-04 - 63s/epoch - 42ms/step
Epoch 37/200
1493/1493 - 64s - loss: 2.5897e-04 - val_loss: 2.8247e-04 - 64s/epoch - 43ms/step
Epoch 38/200
1493/1493 - 64s - loss: 2.5882e-04 - val_loss: 2.4155e-04 - 64s/epoch - 43ms/step
Epoch 39/200
1493/1493 - 64s - loss: 2.4476e-04 - val_loss: 2.2863e-04 - 64s/epoch - 43ms/step
Epoch 40/200
1493/1493 - 64s - loss: 2.3475e-04 - val_loss: 3.2882e-04 - 64s/epoch - 43ms/step
Epoch 41/200
1493/1493 - 64s - loss: 2.3608e-04 - val_loss: 2.2037e-04 - 64s/epoch - 43ms/step
Epoch 42/200
1493/1493 - 64s - loss: 2.2675e-04 - val_loss: 2.2745e-04 - 64s/epoch - 43ms/step
Epoch 43/200
1493/1493 - 63s - loss: 2.2808e-04 - val_loss: 3.1959e-04 - 63s/epoch - 42ms/step
Epoch 44/200
1493/1493 - 63s - loss: 2.3060e-04 - val_loss: 2.6969e-04 - 63s/epoch - 42ms/step
Epoch 45/200
1493/1493 - 63s - loss: 2.2326e-04 - val_loss: 1.8724e-04 - 63s/epoch - 42ms/step
Epoch 46/200
1493/1493 - 63s - loss: 2.1395e-04 - val_loss: 2.1146e-04 - 63s/epoch - 43ms/step
Epoch 47/200
1493/1493 - 63s - loss: 2.0872e-04 - val_loss: 2.1375e-04 - 63s/epoch - 42ms/step
Epoch 48/200
1493/1493 - 64s - loss: 2.0919e-04 - val_loss: 3.7415e-04 - 64s/epoch - 43ms/step
Epoch 49/200
1493/1493 - 63s - loss: 2.0529e-04 - val_loss: 0.0013 - 63s/epoch - 43ms/step
Epoch 50/200
1493/1493 - 64s - loss: 2.8239e-04 - val_loss: 7.9549e-04 - 64s/epoch - 43ms/step
Epoch 51/200
1493/1493 - 63s - loss: 2.4839e-04 - val_loss: 1.9565e-04 - 63s/epoch - 42ms/step
Epoch 52/200
1493/1493 - 64s - loss: 1.9660e-04 - val_loss: 1.8638e-04 - 64s/epoch - 43ms/step
Epoch 53/200
1493/1493 - 63s - loss: 1.9696e-04 - val_loss: 1.8253e-04 - 63s/epoch - 42ms/step
Epoch 54/200
1493/1493 - 63s - loss: 1.9032e-04 - val_loss: 2.3228e-04 - 63s/epoch - 43ms/step
Epoch 55/200
1493/1493 - 64s - loss: 1.8529e-04 - val_loss: 1.8030e-04 - 64s/epoch - 43ms/step
Epoch 56/200
1493/1493 - 63s - loss: 1.8493e-04 - val_loss: 2.5162e-04 - 63s/epoch - 42ms/step
Epoch 57/200
1493/1493 - 63s - loss: 1.7928e-04 - val_loss: 1.9440e-04 - 63s/epoch - 42ms/step
Epoch 58/200
1493/1493 - 64s - loss: 1.7863e-04 - val_loss: 1.6207e-04 - 64s/epoch - 43ms/step
Epoch 59/200
1493/1493 - 63s - loss: 1.7360e-04 - val_loss: 1.8789e-04 - 63s/epoch - 42ms/step
Epoch 60/200
1493/1493 - 64s - loss: 1.7451e-04 - val_loss: 5.7276e-04 - 64s/epoch - 43ms/step
Epoch 61/200
1493/1493 - 63s - loss: 2.7027e-04 - val_loss: 1.5557e-04 - 63s/epoch - 42ms/step
Epoch 62/200
1493/1493 - 64s - loss: 1.7511e-04 - val_loss: 2.1721e-04 - 64s/epoch - 43ms/step
Epoch 63/200
1493/1493 - 63s - loss: 1.7142e-04 - val_loss: 2.2767e-04 - 63s/epoch - 43ms/step
Epoch 64/200
1493/1493 - 64s - loss: 1.7120e-04 - val_loss: 0.0021 - 64s/epoch - 43ms/step
Epoch 65/200
1493/1493 - 63s - loss: 3.0169e-04 - val_loss: 2.6057e-04 - 63s/epoch - 43ms/step
Epoch 66/200
1493/1493 - 64s - loss: 1.8648e-04 - val_loss: 2.2106e-04 - 64s/epoch - 43ms/step
Epoch 67/200
1493/1493 - 63s - loss: 1.7047e-04 - val_loss: 1.6036e-04 - 63s/epoch - 42ms/step
Epoch 68/200
1493/1493 - 64s - loss: 1.6406e-04 - val_loss: 1.9575e-04 - 64s/epoch - 43ms/step
Epoch 69/200
1493/1493 - 63s - loss: 1.6950e-04 - val_loss: 1.7014e-04 - 63s/epoch - 43ms/step
Epoch 70/200
1493/1493 - 63s - loss: 1.6362e-04 - val_loss: 6.4277e-04 - 63s/epoch - 42ms/step
Epoch 71/200
1493/1493 - 63s - loss: 2.3801e-04 - val_loss: 1.5286e-04 - 63s/epoch - 42ms/step
Epoch 72/200
1493/1493 - 63s - loss: 1.6820e-04 - val_loss: 1.6007e-04 - 63s/epoch - 42ms/step
Epoch 73/200
1493/1493 - 63s - loss: 1.6270e-04 - val_loss: 2.1870e-04 - 63s/epoch - 42ms/step
Epoch 74/200
1493/1493 - 63s - loss: 1.6413e-04 - val_loss: 1.5395e-04 - 63s/epoch - 42ms/step
Epoch 75/200
1493/1493 - 63s - loss: 1.5256e-04 - val_loss: 1.4224e-04 - 63s/epoch - 42ms/step
Epoch 76/200
1493/1493 - 64s - loss: 1.5020e-04 - val_loss: 1.4194e-04 - 64s/epoch - 43ms/step
Epoch 77/200
1493/1493 - 63s - loss: 1.5320e-04 - val_loss: 4.9095e-04 - 63s/epoch - 42ms/step
Epoch 78/200
1493/1493 - 63s - loss: 1.6227e-04 - val_loss: 2.2352e-04 - 63s/epoch - 42ms/step
Epoch 79/200
1493/1493 - 64s - loss: 1.5570e-04 - val_loss: 2.9515e-04 - 64s/epoch - 43ms/step
Epoch 80/200
1493/1493 - 63s - loss: 1.7145e-04 - val_loss: 1.3612e-04 - 63s/epoch - 42ms/step
Epoch 81/200
1493/1493 - 63s - loss: 1.4523e-04 - val_loss: 2.6878e-04 - 63s/epoch - 43ms/step
Epoch 82/200
1493/1493 - 63s - loss: 1.4271e-04 - val_loss: 1.4183e-04 - 63s/epoch - 43ms/step
Epoch 83/200
1493/1493 - 64s - loss: 1.3976e-04 - val_loss: 1.5900e-04 - 64s/epoch - 43ms/step
Epoch 84/200
1493/1493 - 63s - loss: 1.4033e-04 - val_loss: 1.6171e-04 - 63s/epoch - 42ms/step
Epoch 85/200
1493/1493 - 63s - loss: 1.4327e-04 - val_loss: 1.8433e-04 - 63s/epoch - 43ms/step
Epoch 86/200
1493/1493 - 63s - loss: 1.4566e-04 - val_loss: 1.3305e-04 - 63s/epoch - 42ms/step
Epoch 87/200
1493/1493 - 64s - loss: 1.3403e-04 - val_loss: 1.2717e-04 - 64s/epoch - 43ms/step
Epoch 88/200
1493/1493 - 63s - loss: 1.3313e-04 - val_loss: 1.4435e-04 - 63s/epoch - 43ms/step
Epoch 89/200
1493/1493 - 63s - loss: 1.3611e-04 - val_loss: 1.3333e-04 - 63s/epoch - 42ms/step
Epoch 90/200
1493/1493 - 63s - loss: 1.3213e-04 - val_loss: 1.3869e-04 - 63s/epoch - 42ms/step
Epoch 91/200
1493/1493 - 64s - loss: 1.3077e-04 - val_loss: 1.3768e-04 - 64s/epoch - 43ms/step
Epoch 92/200
1493/1493 - 63s - loss: 1.3015e-04 - val_loss: 3.3875e-04 - 63s/epoch - 43ms/step
Epoch 93/200
1493/1493 - 64s - loss: 1.5528e-04 - val_loss: 1.6888e-04 - 64s/epoch - 43ms/step
Epoch 94/200
1493/1493 - 63s - loss: 1.3675e-04 - val_loss: 1.1529e-04 - 63s/epoch - 42ms/step
Epoch 95/200
1493/1493 - 64s - loss: 1.2871e-04 - val_loss: 1.9190e-04 - 64s/epoch - 43ms/step
Epoch 96/200
1493/1493 - 64s - loss: 1.3300e-04 - val_loss: 1.4906e-04 - 64s/epoch - 43ms/step
Epoch 97/200
1493/1493 - 64s - loss: 1.2691e-04 - val_loss: 1.2286e-04 - 64s/epoch - 43ms/step
Epoch 98/200
1493/1493 - 64s - loss: 1.3039e-04 - val_loss: 7.4209e-04 - 64s/epoch - 43ms/step
Epoch 99/200
1493/1493 - 64s - loss: 2.2977e-04 - val_loss: 1.2382e-04 - 64s/epoch - 43ms/step
Epoch 100/200
1493/1493 - 64s - loss: 1.4174e-04 - val_loss: 1.1819e-04 - 64s/epoch - 43ms/step
Epoch 101/200
1493/1493 - 64s - loss: 1.2986e-04 - val_loss: 2.2666e-04 - 64s/epoch - 43ms/step
Epoch 102/200
1493/1493 - 64s - loss: 1.3385e-04 - val_loss: 1.8122e-04 - 64s/epoch - 43ms/step
Epoch 103/200
1493/1493 - 64s - loss: 1.3178e-04 - val_loss: 1.3037e-04 - 64s/epoch - 43ms/step
Epoch 104/200
1493/1493 - 64s - loss: 1.2317e-04 - val_loss: 2.3631e-04 - 64s/epoch - 43ms/step
Epoch 105/200
1493/1493 - 64s - loss: 1.3489e-04 - val_loss: 1.1266e-04 - 64s/epoch - 43ms/step
Epoch 106/200
1493/1493 - 64s - loss: 1.2140e-04 - val_loss: 1.2837e-04 - 64s/epoch - 43ms/step
Epoch 107/200
1493/1493 - 64s - loss: 1.2039e-04 - val_loss: 1.4245e-04 - 64s/epoch - 43ms/step
Epoch 108/200
1493/1493 - 64s - loss: 1.2194e-04 - val_loss: 1.3091e-04 - 64s/epoch - 43ms/step
Epoch 109/200
1493/1493 - 64s - loss: 1.1986e-04 - val_loss: 1.4903e-04 - 64s/epoch - 43ms/step
Epoch 110/200
1493/1493 - 64s - loss: 1.1816e-04 - val_loss: 1.3118e-04 - 64s/epoch - 43ms/step
Epoch 111/200
1493/1493 - 64s - loss: 1.1742e-04 - val_loss: 1.6923e-04 - 64s/epoch - 43ms/step
Epoch 112/200
1493/1493 - 63s - loss: 1.2529e-04 - val_loss: 1.1057e-04 - 63s/epoch - 43ms/step
Epoch 113/200
1493/1493 - 64s - loss: 1.1643e-04 - val_loss: 4.1927e-04 - 64s/epoch - 43ms/step
Epoch 114/200
1493/1493 - 64s - loss: 1.6612e-04 - val_loss: 1.0265e-04 - 64s/epoch - 43ms/step
Epoch 115/200
1493/1493 - 63s - loss: 1.1961e-04 - val_loss: 1.9266e-04 - 63s/epoch - 43ms/step
Epoch 116/200
1493/1493 - 64s - loss: 1.1696e-04 - val_loss: 1.4164e-04 - 64s/epoch - 43ms/step
Epoch 117/200
1493/1493 - 64s - loss: 1.1454e-04 - val_loss: 4.8155e-04 - 64s/epoch - 43ms/step
Epoch 118/200
1493/1493 - 64s - loss: 1.4514e-04 - val_loss: 1.2289e-04 - 64s/epoch - 43ms/step
Epoch 119/200
1493/1493 - 64s - loss: 1.1709e-04 - val_loss: 1.0527e-04 - 64s/epoch - 43ms/step
Epoch 120/200
1493/1493 - 64s - loss: 1.1326e-04 - val_loss: 1.0398e-04 - 64s/epoch - 43ms/step
Epoch 121/200
1493/1493 - 64s - loss: 1.1230e-04 - val_loss: 1.4852e-04 - 64s/epoch - 43ms/step
Epoch 122/200
1493/1493 - 64s - loss: 1.1567e-04 - val_loss: 1.0476e-04 - 64s/epoch - 43ms/step
Epoch 123/200
1493/1493 - 64s - loss: 1.1069e-04 - val_loss: 1.2002e-04 - 64s/epoch - 43ms/step
Epoch 124/200
1493/1493 - 64s - loss: 1.0981e-04 - val_loss: 3.0099e-04 - 64s/epoch - 43ms/step
Epoch 125/200
1493/1493 - 64s - loss: 1.3267e-04 - val_loss: 1.4209e-04 - 64s/epoch - 43ms/step
Epoch 126/200
1493/1493 - 64s - loss: 1.1466e-04 - val_loss: 1.2163e-04 - 64s/epoch - 43ms/step
Epoch 127/200
1493/1493 - 64s - loss: 1.0931e-04 - val_loss: 1.5779e-04 - 64s/epoch - 43ms/step
Epoch 128/200
1493/1493 - 64s - loss: 1.1137e-04 - val_loss: 1.0751e-04 - 64s/epoch - 43ms/step
Epoch 129/200
1493/1493 - 65s - loss: 1.0667e-04 - val_loss: 1.0739e-04 - 65s/epoch - 43ms/step
Epoch 130/200
1493/1493 - 65s - loss: 1.0628e-04 - val_loss: 1.0485e-04 - 65s/epoch - 43ms/step
Epoch 131/200
1493/1493 - 64s - loss: 1.0758e-04 - val_loss: 2.6036e-04 - 64s/epoch - 43ms/step
Epoch 132/200
1493/1493 - 65s - loss: 1.3202e-04 - val_loss: 9.2918e-05 - 65s/epoch - 43ms/step
Epoch 133/200
1493/1493 - 64s - loss: 1.0672e-04 - val_loss: 1.0218e-04 - 64s/epoch - 43ms/step
Epoch 134/200
1493/1493 - 64s - loss: 1.0460e-04 - val_loss: 1.0914e-04 - 64s/epoch - 43ms/step
Epoch 135/200
1493/1493 - 64s - loss: 1.0421e-04 - val_loss: 9.9758e-05 - 64s/epoch - 43ms/step
Epoch 136/200
1493/1493 - 64s - loss: 1.0577e-04 - val_loss: 2.9123e-04 - 64s/epoch - 43ms/step
Epoch 137/200
1493/1493 - 64s - loss: 1.4854e-04 - val_loss: 1.2872e-04 - 64s/epoch - 43ms/step
Epoch 138/200
1493/1493 - 64s - loss: 1.1140e-04 - val_loss: 9.9804e-05 - 64s/epoch - 43ms/step
Epoch 139/200
1493/1493 - 64s - loss: 1.0736e-04 - val_loss: 1.3705e-04 - 64s/epoch - 43ms/step
Epoch 140/200
1493/1493 - 64s - loss: 1.1169e-04 - val_loss: 9.1149e-05 - 64s/epoch - 43ms/step
Epoch 141/200
1493/1493 - 64s - loss: 1.0408e-04 - val_loss: 1.2007e-04 - 64s/epoch - 43ms/step
Epoch 142/200
1493/1493 - 65s - loss: 1.0560e-04 - val_loss: 1.1464e-04 - 65s/epoch - 43ms/step
Epoch 143/200
1493/1493 - 64s - loss: 1.0112e-04 - val_loss: 1.4028e-04 - 64s/epoch - 43ms/step
Epoch 144/200
1493/1493 - 64s - loss: 1.0414e-04 - val_loss: 1.0113e-04 - 64s/epoch - 43ms/step
Epoch 145/200
1493/1493 - 64s - loss: 1.0116e-04 - val_loss: 9.3798e-05 - 64s/epoch - 43ms/step
Epoch 146/200
1493/1493 - 64s - loss: 9.9561e-05 - val_loss: 8.7808e-05 - 64s/epoch - 43ms/step
Epoch 147/200
1493/1493 - 64s - loss: 9.8355e-05 - val_loss: 1.0575e-04 - 64s/epoch - 43ms/step
Epoch 148/200
1493/1493 - 64s - loss: 9.8149e-05 - val_loss: 1.5652e-04 - 64s/epoch - 43ms/step
Epoch 149/200
1493/1493 - 64s - loss: 9.8235e-05 - val_loss: 9.9655e-05 - 64s/epoch - 43ms/step
Epoch 150/200
1493/1493 - 64s - loss: 9.7279e-05 - val_loss: 1.0084e-04 - 64s/epoch - 43ms/step
Epoch 151/200
1493/1493 - 64s - loss: 1.0079e-04 - val_loss: 1.2651e-04 - 64s/epoch - 43ms/step
Epoch 152/200
1493/1493 - 64s - loss: 9.8414e-05 - val_loss: 1.4055e-04 - 64s/epoch - 43ms/step
Epoch 153/200
1493/1493 - 64s - loss: 1.0040e-04 - val_loss: 1.0086e-04 - 64s/epoch - 43ms/step
Epoch 154/200
1493/1493 - 64s - loss: 9.5753e-05 - val_loss: 1.2309e-04 - 64s/epoch - 43ms/step
Epoch 155/200
1493/1493 - 64s - loss: 1.0029e-04 - val_loss: 9.8122e-05 - 64s/epoch - 43ms/step
Epoch 156/200
1493/1493 - 64s - loss: 9.8242e-05 - val_loss: 9.9574e-05 - 64s/epoch - 43ms/step
Epoch 157/200
1493/1493 - 64s - loss: 9.5635e-05 - val_loss: 9.9044e-05 - 64s/epoch - 43ms/step
Epoch 158/200
1493/1493 - 64s - loss: 9.5583e-05 - val_loss: 1.1132e-04 - 64s/epoch - 43ms/step
Epoch 159/200
1493/1493 - 64s - loss: 9.4233e-05 - val_loss: 8.4092e-05 - 64s/epoch - 43ms/step
Epoch 160/200
1493/1493 - 64s - loss: 9.8330e-05 - val_loss: 1.7774e-04 - 64s/epoch - 43ms/step
Epoch 161/200
1493/1493 - 64s - loss: 1.2957e-04 - val_loss: 9.0127e-05 - 64s/epoch - 43ms/step
Epoch 162/200
1493/1493 - 64s - loss: 9.8630e-05 - val_loss: 9.2419e-05 - 64s/epoch - 43ms/step
Epoch 163/200
1493/1493 - 64s - loss: 9.5361e-05 - val_loss: 1.1774e-04 - 64s/epoch - 43ms/step
Epoch 164/200
1493/1493 - 64s - loss: 9.8414e-05 - val_loss: 9.4099e-05 - 64s/epoch - 43ms/step
Epoch 165/200
1493/1493 - 64s - loss: 1.0766e-04 - val_loss: 9.9129e-05 - 64s/epoch - 43ms/step
Epoch 166/200
1493/1493 - 64s - loss: 9.4698e-05 - val_loss: 1.0205e-04 - 64s/epoch - 43ms/step
Epoch 167/200
1493/1493 - 64s - loss: 9.3957e-05 - val_loss: 8.4989e-05 - 64s/epoch - 43ms/step
Epoch 168/200
1493/1493 - 64s - loss: 9.2647e-05 - val_loss: 8.7753e-05 - 64s/epoch - 43ms/step
Epoch 169/200
1493/1493 - 64s - loss: 9.2299e-05 - val_loss: 1.1534e-04 - 64s/epoch - 43ms/step
Epoch 170/200
1493/1493 - 64s - loss: 9.3376e-05 - val_loss: 2.6086e-04 - 64s/epoch - 43ms/step
Epoch 171/200
1493/1493 - 64s - loss: 1.2863e-04 - val_loss: 2.7741e-04 - 64s/epoch - 43ms/step
Epoch 172/200
1493/1493 - 64s - loss: 1.2201e-04 - val_loss: 1.0490e-04 - 64s/epoch - 43ms/step
Epoch 173/200
1493/1493 - 64s - loss: 9.7646e-05 - val_loss: 8.5686e-05 - 64s/epoch - 43ms/step
Epoch 174/200
1493/1493 - 64s - loss: 9.2904e-05 - val_loss: 1.0092e-04 - 64s/epoch - 43ms/step
Epoch 175/200
1493/1493 - 64s - loss: 9.3590e-05 - val_loss: 1.1949e-04 - 64s/epoch - 43ms/step
Epoch 176/200
1493/1493 - 64s - loss: 9.3702e-05 - val_loss: 9.1856e-05 - 64s/epoch - 43ms/step
Epoch 177/200
1493/1493 - 64s - loss: 9.2602e-05 - val_loss: 8.0097e-05 - 64s/epoch - 43ms/step
Epoch 178/200
1493/1493 - 64s - loss: 9.0422e-05 - val_loss: 9.2237e-05 - 64s/epoch - 43ms/step
Epoch 179/200
1493/1493 - 64s - loss: 8.9377e-05 - val_loss: 1.0065e-04 - 64s/epoch - 43ms/step
Epoch 180/200
1493/1493 - 64s - loss: 8.9495e-05 - val_loss: 1.0777e-04 - 64s/epoch - 43ms/step
Epoch 181/200
1493/1493 - 64s - loss: 9.0310e-05 - val_loss: 8.8857e-05 - 64s/epoch - 43ms/step
Epoch 182/200
1493/1493 - 64s - loss: 8.9041e-05 - val_loss: 1.0275e-04 - 64s/epoch - 43ms/step
Epoch 183/200
1493/1493 - 64s - loss: 8.7933e-05 - val_loss: 9.1164e-05 - 64s/epoch - 43ms/step
Epoch 184/200
1493/1493 - 64s - loss: 8.9089e-05 - val_loss: 8.4071e-05 - 64s/epoch - 43ms/step
Epoch 185/200
1493/1493 - 64s - loss: 8.6646e-05 - val_loss: 1.1648e-04 - 64s/epoch - 43ms/step
Epoch 186/200
1493/1493 - 64s - loss: 8.9266e-05 - val_loss: 9.1538e-05 - 64s/epoch - 43ms/step
Epoch 187/200
1493/1493 - 64s - loss: 8.6795e-05 - val_loss: 1.1062e-04 - 64s/epoch - 43ms/step
Epoch 188/200
1493/1493 - 64s - loss: 9.0741e-05 - val_loss: 1.1707e-04 - 64s/epoch - 43ms/step
Epoch 189/200
1493/1493 - 64s - loss: 9.4231e-05 - val_loss: 1.0206e-04 - 64s/epoch - 43ms/step
Epoch 190/200
1493/1493 - 64s - loss: 8.9409e-05 - val_loss: 1.2529e-04 - 64s/epoch - 43ms/step
Epoch 191/200
1493/1493 - 64s - loss: 9.5528e-05 - val_loss: 1.4043e-04 - 64s/epoch - 43ms/step
Epoch 192/200
1493/1493 - 64s - loss: 8.9471e-05 - val_loss: 1.2267e-04 - 64s/epoch - 43ms/step
Epoch 193/200
1493/1493 - 64s - loss: 9.2602e-05 - val_loss: 1.9950e-04 - 64s/epoch - 43ms/step
Epoch 194/200
1493/1493 - 64s - loss: 1.1116e-04 - val_loss: 4.8864e-04 - 64s/epoch - 43ms/step
Epoch 195/200
1493/1493 - 64s - loss: 1.3020e-04 - val_loss: 1.0364e-04 - 64s/epoch - 43ms/step
Epoch 196/200
1493/1493 - 64s - loss: 9.7325e-05 - val_loss: 7.3701e-05 - 64s/epoch - 43ms/step
Epoch 197/200
1493/1493 - 64s - loss: 8.9920e-05 - val_loss: 1.0270e-04 - 64s/epoch - 43ms/step
Epoch 198/200
1493/1493 - 64s - loss: 9.4153e-05 - val_loss: 1.0668e-04 - 64s/epoch - 43ms/step
Epoch 199/200
1493/1493 - 64s - loss: 9.0661e-05 - val_loss: 7.6998e-05 - 64s/epoch - 43ms/step
Epoch 200/200
1493/1493 - 64s - loss: 8.6801e-05 - val_loss: 9.1772e-05 - 64s/epoch - 43ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.177216270472854e-05
  1/332 [..............................] - ETA: 45s  8/332 [..............................] - ETA: 2s  16/332 [>.............................] - ETA: 2s 23/332 [=>............................] - ETA: 2s 31/332 [=>............................] - ETA: 2s 39/332 [==>...........................] - ETA: 2s 47/332 [===>..........................] - ETA: 1s 55/332 [===>..........................] - ETA: 1s 63/332 [====>.........................] - ETA: 1s 71/332 [=====>........................] - ETA: 1s 79/332 [======>.......................] - ETA: 1s 87/332 [======>.......................] - ETA: 1s 95/332 [=======>......................] - ETA: 1s103/332 [========>.....................] - ETA: 1s111/332 [=========>....................] - ETA: 1s119/332 [=========>....................] - ETA: 1s127/332 [==========>...................] - ETA: 1s135/332 [===========>..................] - ETA: 1s143/332 [===========>..................] - ETA: 1s151/332 [============>.................] - ETA: 1s159/332 [=============>................] - ETA: 1s167/332 [==============>...............] - ETA: 1s175/332 [==============>...............] - ETA: 1s183/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 0s199/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s215/332 [==================>...........] - ETA: 0s223/332 [===================>..........] - ETA: 0s231/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s247/332 [=====================>........] - ETA: 0s255/332 [======================>.......] - ETA: 0s263/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s279/332 [========================>.....] - ETA: 0s287/332 [========================>.....] - ETA: 0s295/332 [=========================>....] - ETA: 0s303/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s319/332 [===========================>..] - ETA: 0s327/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 7ms/step
correlation 0.0010412319500492152
cosine 0.0008196632760091409
MAE: 0.0052977414
RMSE: 0.009579775
r2: 0.9940471927206831
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 2275)              2877875   
                                                                 
 batch_normalization_9 (Batc  (None, 2275)             9100      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2275)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2301036   
                                                                 
 batch_normalization_10 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 1011)              0         
                                                                 
 dense_10 (Dense)            (None, 2275)              2302300   
                                                                 
 batch_normalization_11 (Bat  (None, 2275)             9100      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2275)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              2876864   
                                                                 
=================================================================
Total params: 10,380,319
Trainable params: 10,369,197
Non-trainable params: 11,122
_________________________________________________________________
Encoder
Model: "model_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_11 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_10 (InputLayer)       multiple                  0         
                                                                 
 dense_9 (Dense)             (None, 2275)              2877875   
                                                                 
 batch_normalization_9 (Batc  (None, 2275)             9100      
 hNormalization)                                                 
                                                                 
 re_lu_9 (ReLU)              (None, 2275)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2301036   
                                                                 
=================================================================
Total params: 5,188,011
Trainable params: 5,183,461
Non-trainable params: 4,550
_________________________________________________________________
Decoder
Model: "model_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_12 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_10 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_10 (ReLU)             (None, 1011)              0         
                                                                 
 dense_10 (Dense)            (None, 2275)              2302300   
                                                                 
 batch_normalization_11 (Bat  (None, 2275)             9100      
 chNormalization)                                                
                                                                 
 re_lu_11 (ReLU)             (None, 2275)              0         
                                                                 
 dense_11 (Dense)            (None, 1264)              2876864   
                                                                 
=================================================================
Total params: 5,192,308
Trainable params: 5,185,736
Non-trainable params: 6,572
_________________________________________________________________
['1.8custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.680085011292249e-05, 9.177216270472854e-05, 0.0010412319500492152, 0.0008196632760091409, 0.005297741387039423, 0.009579774923622608, 0.9940471927206831, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_12 (Dense)            (None, 2401)              3037265   
                                                                 
 batch_normalization_12 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2401)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2428422   
                                                                 
 batch_normalization_13 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 1011)              0         
                                                                 
 dense_13 (Dense)            (None, 2401)              2429812   
                                                                 
 batch_normalization_14 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2401)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3036128   
                                                                 
=================================================================
Total params: 10,954,879
Trainable params: 10,943,253
Non-trainable params: 11,626
_________________________________________________________________
Epoch 1/200
1493/1493 - 66s - loss: 0.0090 - val_loss: 0.0043 - 66s/epoch - 44ms/step
Epoch 2/200
1493/1493 - 65s - loss: 0.0028 - val_loss: 0.0031 - 65s/epoch - 44ms/step
Epoch 3/200
1493/1493 - 65s - loss: 0.0020 - val_loss: 0.0017 - 65s/epoch - 44ms/step
Epoch 4/200
1493/1493 - 65s - loss: 0.0016 - val_loss: 0.0041 - 65s/epoch - 44ms/step
Epoch 5/200
1493/1493 - 65s - loss: 0.0016 - val_loss: 0.0012 - 65s/epoch - 44ms/step
Epoch 6/200
1493/1493 - 65s - loss: 0.0013 - val_loss: 0.0012 - 65s/epoch - 44ms/step
Epoch 7/200
1493/1493 - 66s - loss: 0.0013 - val_loss: 0.0010 - 66s/epoch - 44ms/step
Epoch 8/200
1493/1493 - 65s - loss: 0.0011 - val_loss: 0.0010 - 65s/epoch - 44ms/step
Epoch 9/200
1493/1493 - 65s - loss: 9.9604e-04 - val_loss: 8.9330e-04 - 65s/epoch - 44ms/step
Epoch 10/200
1493/1493 - 65s - loss: 8.9812e-04 - val_loss: 7.4453e-04 - 65s/epoch - 44ms/step
Epoch 11/200
1493/1493 - 65s - loss: 8.4738e-04 - val_loss: 7.1845e-04 - 65s/epoch - 44ms/step
Epoch 12/200
1493/1493 - 66s - loss: 7.5250e-04 - val_loss: 0.0015 - 66s/epoch - 44ms/step
Epoch 13/200
1493/1493 - 66s - loss: 8.5826e-04 - val_loss: 0.0019 - 66s/epoch - 44ms/step
Epoch 14/200
1493/1493 - 66s - loss: 7.5837e-04 - val_loss: 6.8342e-04 - 66s/epoch - 44ms/step
Epoch 15/200
1493/1493 - 66s - loss: 6.3357e-04 - val_loss: 8.3530e-04 - 66s/epoch - 44ms/step
Epoch 16/200
1493/1493 - 66s - loss: 6.0328e-04 - val_loss: 5.1405e-04 - 66s/epoch - 44ms/step
Epoch 17/200
1493/1493 - 65s - loss: 5.2944e-04 - val_loss: 7.3999e-04 - 65s/epoch - 44ms/step
Epoch 18/200
1493/1493 - 65s - loss: 5.2445e-04 - val_loss: 0.0012 - 65s/epoch - 44ms/step
Epoch 19/200
1493/1493 - 65s - loss: 5.9321e-04 - val_loss: 5.9930e-04 - 65s/epoch - 44ms/step
Epoch 20/200
1493/1493 - 65s - loss: 4.6670e-04 - val_loss: 3.9367e-04 - 65s/epoch - 44ms/step
Epoch 21/200
1493/1493 - 66s - loss: 4.4395e-04 - val_loss: 4.9355e-04 - 66s/epoch - 44ms/step
Epoch 22/200
1493/1493 - 66s - loss: 4.1872e-04 - val_loss: 6.0832e-04 - 66s/epoch - 44ms/step
Epoch 23/200
1493/1493 - 65s - loss: 4.2326e-04 - val_loss: 8.9767e-04 - 65s/epoch - 44ms/step
Epoch 24/200
1493/1493 - 65s - loss: 4.1575e-04 - val_loss: 3.5594e-04 - 65s/epoch - 44ms/step
Epoch 25/200
1493/1493 - 65s - loss: 3.5995e-04 - val_loss: 3.3422e-04 - 65s/epoch - 44ms/step
Epoch 26/200
1493/1493 - 66s - loss: 3.4830e-04 - val_loss: 4.0043e-04 - 66s/epoch - 44ms/step
Epoch 27/200
1493/1493 - 66s - loss: 3.3251e-04 - val_loss: 3.0416e-04 - 66s/epoch - 44ms/step
Epoch 28/200
1493/1493 - 65s - loss: 3.1676e-04 - val_loss: 4.5713e-04 - 65s/epoch - 44ms/step
Epoch 29/200
1493/1493 - 66s - loss: 3.0596e-04 - val_loss: 5.2473e-04 - 66s/epoch - 44ms/step
Epoch 30/200
1493/1493 - 66s - loss: 3.2670e-04 - val_loss: 3.1815e-04 - 66s/epoch - 44ms/step
Epoch 31/200
1493/1493 - 66s - loss: 2.8842e-04 - val_loss: 4.7430e-04 - 66s/epoch - 44ms/step
Epoch 32/200
1493/1493 - 66s - loss: 2.9775e-04 - val_loss: 3.0446e-04 - 66s/epoch - 44ms/step
Epoch 33/200
1493/1493 - 66s - loss: 2.8270e-04 - val_loss: 3.0320e-04 - 66s/epoch - 44ms/step
Epoch 34/200
1493/1493 - 65s - loss: 2.6733e-04 - val_loss: 2.3007e-04 - 65s/epoch - 44ms/step
Epoch 35/200
1493/1493 - 66s - loss: 2.5710e-04 - val_loss: 7.1735e-04 - 66s/epoch - 44ms/step
Epoch 36/200
1493/1493 - 66s - loss: 2.9034e-04 - val_loss: 3.7043e-04 - 66s/epoch - 44ms/step
Epoch 37/200
1493/1493 - 66s - loss: 2.6309e-04 - val_loss: 4.6493e-04 - 66s/epoch - 44ms/step
Epoch 38/200
1493/1493 - 66s - loss: 2.7715e-04 - val_loss: 2.2108e-04 - 66s/epoch - 44ms/step
Epoch 39/200
1493/1493 - 66s - loss: 2.3744e-04 - val_loss: 2.3642e-04 - 66s/epoch - 44ms/step
Epoch 40/200
1493/1493 - 66s - loss: 2.2872e-04 - val_loss: 3.1557e-04 - 66s/epoch - 44ms/step
Epoch 41/200
1493/1493 - 66s - loss: 2.2952e-04 - val_loss: 2.0568e-04 - 66s/epoch - 44ms/step
Epoch 42/200
1493/1493 - 66s - loss: 2.2258e-04 - val_loss: 2.2431e-04 - 66s/epoch - 44ms/step
Epoch 43/200
1493/1493 - 66s - loss: 2.2128e-04 - val_loss: 4.4801e-04 - 66s/epoch - 44ms/step
Epoch 44/200
1493/1493 - 65s - loss: 2.3921e-04 - val_loss: 0.0010 - 65s/epoch - 44ms/step
Epoch 45/200
1493/1493 - 66s - loss: 2.9504e-04 - val_loss: 1.7423e-04 - 66s/epoch - 44ms/step
Epoch 46/200
1493/1493 - 66s - loss: 2.1128e-04 - val_loss: 1.8818e-04 - 66s/epoch - 44ms/step
Epoch 47/200
1493/1493 - 65s - loss: 2.0991e-04 - val_loss: 2.6761e-04 - 65s/epoch - 44ms/step
Epoch 48/200
1493/1493 - 65s - loss: 2.0524e-04 - val_loss: 2.4504e-04 - 65s/epoch - 44ms/step
Epoch 49/200
1493/1493 - 66s - loss: 2.0466e-04 - val_loss: 9.5205e-04 - 66s/epoch - 44ms/step
Epoch 50/200
1493/1493 - 65s - loss: 2.7314e-04 - val_loss: 0.0015 - 65s/epoch - 44ms/step
Epoch 51/200
1493/1493 - 65s - loss: 2.5997e-04 - val_loss: 2.0628e-04 - 65s/epoch - 44ms/step
Epoch 52/200
1493/1493 - 65s - loss: 1.9175e-04 - val_loss: 1.8955e-04 - 65s/epoch - 44ms/step
Epoch 53/200
1493/1493 - 65s - loss: 1.9148e-04 - val_loss: 1.7351e-04 - 65s/epoch - 44ms/step
Epoch 54/200
1493/1493 - 66s - loss: 1.8467e-04 - val_loss: 2.0355e-04 - 66s/epoch - 44ms/step
Epoch 55/200
1493/1493 - 66s - loss: 1.8039e-04 - val_loss: 1.8664e-04 - 66s/epoch - 44ms/step
Epoch 56/200
1493/1493 - 66s - loss: 1.7960e-04 - val_loss: 2.1668e-04 - 66s/epoch - 44ms/step
Epoch 57/200
1493/1493 - 66s - loss: 1.7666e-04 - val_loss: 1.8221e-04 - 66s/epoch - 44ms/step
Epoch 58/200
1493/1493 - 66s - loss: 1.7686e-04 - val_loss: 1.5831e-04 - 66s/epoch - 44ms/step
Epoch 59/200
1493/1493 - 66s - loss: 1.6960e-04 - val_loss: 1.8096e-04 - 66s/epoch - 44ms/step
Epoch 60/200
1493/1493 - 66s - loss: 1.6999e-04 - val_loss: 3.3095e-04 - 66s/epoch - 44ms/step
Epoch 61/200
1493/1493 - 66s - loss: 2.0499e-04 - val_loss: 1.5707e-04 - 66s/epoch - 44ms/step
Epoch 62/200
1493/1493 - 66s - loss: 1.6532e-04 - val_loss: 1.8892e-04 - 66s/epoch - 44ms/step
Epoch 63/200
1493/1493 - 66s - loss: 1.6918e-04 - val_loss: 2.3757e-04 - 66s/epoch - 44ms/step
Epoch 64/200
1493/1493 - 66s - loss: 1.6820e-04 - val_loss: 0.0026 - 66s/epoch - 44ms/step
Epoch 65/200
1493/1493 - 66s - loss: 3.4263e-04 - val_loss: 2.8299e-04 - 66s/epoch - 44ms/step
Epoch 66/200
1493/1493 - 66s - loss: 1.9185e-04 - val_loss: 2.1180e-04 - 66s/epoch - 44ms/step
Epoch 67/200
1493/1493 - 66s - loss: 1.6980e-04 - val_loss: 1.4628e-04 - 66s/epoch - 44ms/step
Epoch 68/200
1493/1493 - 66s - loss: 1.6537e-04 - val_loss: 4.7654e-04 - 66s/epoch - 44ms/step
Epoch 69/200
1493/1493 - 66s - loss: 2.1130e-04 - val_loss: 1.6660e-04 - 66s/epoch - 44ms/step
Epoch 70/200
1493/1493 - 66s - loss: 1.6227e-04 - val_loss: 3.4633e-04 - 66s/epoch - 44ms/step
Epoch 71/200
1493/1493 - 66s - loss: 1.7660e-04 - val_loss: 1.5559e-04 - 66s/epoch - 44ms/step
Epoch 72/200
1493/1493 - 66s - loss: 1.5949e-04 - val_loss: 2.2687e-04 - 66s/epoch - 44ms/step
Epoch 73/200
1493/1493 - 66s - loss: 1.6178e-04 - val_loss: 1.6248e-04 - 66s/epoch - 44ms/step
Epoch 74/200
1493/1493 - 66s - loss: 1.5397e-04 - val_loss: 1.6805e-04 - 66s/epoch - 44ms/step
Epoch 75/200
1493/1493 - 66s - loss: 1.4833e-04 - val_loss: 1.3896e-04 - 66s/epoch - 44ms/step
Epoch 76/200
1493/1493 - 65s - loss: 1.4917e-04 - val_loss: 1.4194e-04 - 65s/epoch - 44ms/step
Epoch 77/200
1493/1493 - 66s - loss: 1.4294e-04 - val_loss: 7.6056e-04 - 66s/epoch - 44ms/step
Epoch 78/200
1493/1493 - 66s - loss: 1.6958e-04 - val_loss: 2.2592e-04 - 66s/epoch - 44ms/step
Epoch 79/200
1493/1493 - 65s - loss: 1.5403e-04 - val_loss: 2.7742e-04 - 65s/epoch - 44ms/step
Epoch 80/200
1493/1493 - 66s - loss: 1.7233e-04 - val_loss: 1.7155e-04 - 66s/epoch - 44ms/step
Epoch 81/200
1493/1493 - 66s - loss: 1.4634e-04 - val_loss: 3.6647e-04 - 66s/epoch - 44ms/step
Epoch 82/200
1493/1493 - 66s - loss: 1.4773e-04 - val_loss: 1.3755e-04 - 66s/epoch - 44ms/step
Epoch 83/200
1493/1493 - 66s - loss: 1.3769e-04 - val_loss: 1.4900e-04 - 66s/epoch - 44ms/step
Epoch 84/200
1493/1493 - 66s - loss: 1.3748e-04 - val_loss: 1.4488e-04 - 66s/epoch - 44ms/step
Epoch 85/200
1493/1493 - 66s - loss: 1.3779e-04 - val_loss: 1.7050e-04 - 66s/epoch - 44ms/step
Epoch 86/200
1493/1493 - 66s - loss: 1.4027e-04 - val_loss: 1.6040e-04 - 66s/epoch - 44ms/step
Epoch 87/200
1493/1493 - 66s - loss: 1.3096e-04 - val_loss: 1.2700e-04 - 66s/epoch - 44ms/step
Epoch 88/200
1493/1493 - 66s - loss: 1.3371e-04 - val_loss: 1.6476e-04 - 66s/epoch - 44ms/step
Epoch 89/200
1493/1493 - 66s - loss: 1.3706e-04 - val_loss: 1.4059e-04 - 66s/epoch - 44ms/step
Epoch 90/200
1493/1493 - 66s - loss: 1.2955e-04 - val_loss: 1.3802e-04 - 66s/epoch - 44ms/step
Epoch 91/200
1493/1493 - 66s - loss: 1.2828e-04 - val_loss: 1.4319e-04 - 66s/epoch - 44ms/step
Epoch 92/200
1493/1493 - 65s - loss: 1.2948e-04 - val_loss: 4.0928e-04 - 65s/epoch - 44ms/step
Epoch 93/200
1493/1493 - 65s - loss: 1.6897e-04 - val_loss: 2.2599e-04 - 65s/epoch - 44ms/step
Epoch 94/200
1493/1493 - 65s - loss: 1.4094e-04 - val_loss: 1.1112e-04 - 65s/epoch - 44ms/step
Epoch 95/200
1493/1493 - 65s - loss: 1.3089e-04 - val_loss: 8.0887e-04 - 65s/epoch - 44ms/step
Epoch 96/200
1493/1493 - 65s - loss: 2.0408e-04 - val_loss: 1.4356e-04 - 65s/epoch - 44ms/step
Epoch 97/200
1493/1493 - 66s - loss: 1.3573e-04 - val_loss: 1.3795e-04 - 66s/epoch - 44ms/step
Epoch 98/200
1493/1493 - 66s - loss: 1.3390e-04 - val_loss: 6.9050e-04 - 66s/epoch - 44ms/step
Epoch 99/200
1493/1493 - 66s - loss: 2.0765e-04 - val_loss: 1.0967e-04 - 66s/epoch - 44ms/step
Epoch 100/200
1493/1493 - 66s - loss: 1.3951e-04 - val_loss: 1.2357e-04 - 66s/epoch - 44ms/step
Epoch 101/200
1493/1493 - 66s - loss: 1.2925e-04 - val_loss: 5.0908e-04 - 66s/epoch - 44ms/step
Epoch 102/200
1493/1493 - 66s - loss: 1.4998e-04 - val_loss: 1.8273e-04 - 66s/epoch - 44ms/step
Epoch 103/200
1493/1493 - 66s - loss: 1.3230e-04 - val_loss: 1.2525e-04 - 66s/epoch - 44ms/step
Epoch 104/200
1493/1493 - 66s - loss: 1.2436e-04 - val_loss: 5.4342e-04 - 66s/epoch - 44ms/step
Epoch 105/200
1493/1493 - 66s - loss: 1.5011e-04 - val_loss: 1.0543e-04 - 66s/epoch - 44ms/step
Epoch 106/200
1493/1493 - 66s - loss: 1.2303e-04 - val_loss: 1.2968e-04 - 66s/epoch - 44ms/step
Epoch 107/200
1493/1493 - 66s - loss: 1.2164e-04 - val_loss: 1.3377e-04 - 66s/epoch - 44ms/step
Epoch 108/200
1493/1493 - 65s - loss: 1.2452e-04 - val_loss: 1.3178e-04 - 65s/epoch - 44ms/step
Epoch 109/200
1493/1493 - 65s - loss: 1.1939e-04 - val_loss: 1.3550e-04 - 65s/epoch - 44ms/step
Epoch 110/200
1493/1493 - 65s - loss: 1.1733e-04 - val_loss: 1.3126e-04 - 65s/epoch - 44ms/step
Epoch 111/200
1493/1493 - 65s - loss: 1.1644e-04 - val_loss: 1.0874e-04 - 65s/epoch - 44ms/step
Epoch 112/200
1493/1493 - 65s - loss: 1.1501e-04 - val_loss: 1.1532e-04 - 65s/epoch - 44ms/step
Epoch 113/200
1493/1493 - 65s - loss: 1.1468e-04 - val_loss: 4.6523e-04 - 65s/epoch - 44ms/step
Epoch 114/200
1493/1493 - 65s - loss: 1.5074e-04 - val_loss: 1.2674e-04 - 65s/epoch - 44ms/step
Epoch 115/200
1493/1493 - 66s - loss: 1.2581e-04 - val_loss: 2.2134e-04 - 66s/epoch - 44ms/step
Epoch 116/200
1493/1493 - 65s - loss: 1.1673e-04 - val_loss: 1.4267e-04 - 65s/epoch - 44ms/step
Epoch 117/200
1493/1493 - 65s - loss: 1.1431e-04 - val_loss: 3.2971e-04 - 65s/epoch - 44ms/step
Epoch 118/200
1493/1493 - 65s - loss: 1.2795e-04 - val_loss: 1.1028e-04 - 65s/epoch - 44ms/step
Epoch 119/200
1493/1493 - 66s - loss: 1.1312e-04 - val_loss: 1.0901e-04 - 66s/epoch - 44ms/step
Epoch 120/200
1493/1493 - 65s - loss: 1.1112e-04 - val_loss: 1.1011e-04 - 65s/epoch - 44ms/step
Epoch 121/200
1493/1493 - 65s - loss: 1.1058e-04 - val_loss: 1.6506e-04 - 65s/epoch - 44ms/step
Epoch 122/200
1493/1493 - 66s - loss: 1.1196e-04 - val_loss: 1.0259e-04 - 66s/epoch - 44ms/step
Epoch 123/200
1493/1493 - 65s - loss: 1.0827e-04 - val_loss: 1.1817e-04 - 65s/epoch - 44ms/step
Epoch 124/200
1493/1493 - 65s - loss: 1.0994e-04 - val_loss: 3.9357e-04 - 65s/epoch - 44ms/step
Epoch 125/200
1493/1493 - 65s - loss: 1.5921e-04 - val_loss: 1.9096e-04 - 65s/epoch - 44ms/step
Epoch 126/200
1493/1493 - 65s - loss: 1.1844e-04 - val_loss: 1.2335e-04 - 65s/epoch - 44ms/step
Epoch 127/200
1493/1493 - 65s - loss: 1.0964e-04 - val_loss: 1.7164e-04 - 65s/epoch - 44ms/step
Epoch 128/200
1493/1493 - 66s - loss: 1.1193e-04 - val_loss: 1.0219e-04 - 66s/epoch - 44ms/step
Epoch 129/200
1493/1493 - 66s - loss: 1.0688e-04 - val_loss: 1.1228e-04 - 66s/epoch - 44ms/step
Epoch 130/200
1493/1493 - 65s - loss: 1.0543e-04 - val_loss: 1.0352e-04 - 65s/epoch - 44ms/step
Epoch 131/200
1493/1493 - 65s - loss: 1.0955e-04 - val_loss: 4.9415e-04 - 65s/epoch - 44ms/step
Epoch 132/200
1493/1493 - 65s - loss: 1.5571e-04 - val_loss: 1.0022e-04 - 65s/epoch - 44ms/step
Epoch 133/200
1493/1493 - 65s - loss: 1.0937e-04 - val_loss: 1.0445e-04 - 65s/epoch - 44ms/step
Epoch 134/200
1493/1493 - 65s - loss: 1.0624e-04 - val_loss: 9.9580e-05 - 65s/epoch - 43ms/step
Epoch 135/200
1493/1493 - 65s - loss: 1.0477e-04 - val_loss: 9.5374e-05 - 65s/epoch - 43ms/step
Epoch 136/200
1493/1493 - 65s - loss: 1.0471e-04 - val_loss: 1.4706e-04 - 65s/epoch - 44ms/step
Epoch 137/200
1493/1493 - 65s - loss: 1.1338e-04 - val_loss: 1.2527e-04 - 65s/epoch - 44ms/step
Epoch 138/200
1493/1493 - 65s - loss: 1.0652e-04 - val_loss: 9.8332e-05 - 65s/epoch - 43ms/step
Epoch 139/200
1493/1493 - 65s - loss: 1.0475e-04 - val_loss: 1.4021e-04 - 65s/epoch - 43ms/step
Epoch 140/200
1493/1493 - 65s - loss: 1.1103e-04 - val_loss: 9.1770e-05 - 65s/epoch - 44ms/step
Epoch 141/200
1493/1493 - 65s - loss: 1.0249e-04 - val_loss: 1.4249e-04 - 65s/epoch - 43ms/step
Epoch 142/200
1493/1493 - 65s - loss: 1.0447e-04 - val_loss: 1.1475e-04 - 65s/epoch - 43ms/step
Epoch 143/200
1493/1493 - 65s - loss: 1.0146e-04 - val_loss: 1.2907e-04 - 65s/epoch - 44ms/step
Epoch 144/200
1493/1493 - 65s - loss: 1.0385e-04 - val_loss: 1.0947e-04 - 65s/epoch - 44ms/step
Epoch 145/200
1493/1493 - 65s - loss: 9.9625e-05 - val_loss: 9.2266e-05 - 65s/epoch - 44ms/step
Epoch 146/200
1493/1493 - 65s - loss: 9.8495e-05 - val_loss: 9.1945e-05 - 65s/epoch - 44ms/step
Epoch 147/200
1493/1493 - 64s - loss: 9.7013e-05 - val_loss: 1.1613e-04 - 64s/epoch - 43ms/step
Epoch 148/200
1493/1493 - 65s - loss: 9.7873e-05 - val_loss: 1.8337e-04 - 65s/epoch - 43ms/step
Epoch 149/200
1493/1493 - 65s - loss: 9.7248e-05 - val_loss: 9.3439e-05 - 65s/epoch - 43ms/step
Epoch 150/200
1493/1493 - 65s - loss: 9.6368e-05 - val_loss: 9.2551e-05 - 65s/epoch - 43ms/step
Epoch 151/200
1493/1493 - 65s - loss: 9.7233e-05 - val_loss: 1.5183e-04 - 65s/epoch - 43ms/step
Epoch 152/200
1493/1493 - 65s - loss: 1.0116e-04 - val_loss: 1.9858e-04 - 65s/epoch - 44ms/step
Epoch 153/200
1493/1493 - 65s - loss: 1.0564e-04 - val_loss: 1.0408e-04 - 65s/epoch - 44ms/step
Epoch 154/200
1493/1493 - 65s - loss: 9.5274e-05 - val_loss: 9.9978e-05 - 65s/epoch - 44ms/step
Epoch 155/200
1493/1493 - 65s - loss: 9.3614e-05 - val_loss: 1.0400e-04 - 65s/epoch - 44ms/step
Epoch 156/200
1493/1493 - 65s - loss: 9.7836e-05 - val_loss: 9.6163e-05 - 65s/epoch - 43ms/step
Epoch 157/200
1493/1493 - 65s - loss: 9.3727e-05 - val_loss: 1.0789e-04 - 65s/epoch - 43ms/step
Epoch 158/200
1493/1493 - 65s - loss: 9.4849e-05 - val_loss: 1.1441e-04 - 65s/epoch - 43ms/step
Epoch 159/200
1493/1493 - 65s - loss: 9.3197e-05 - val_loss: 9.7994e-05 - 65s/epoch - 43ms/step
Epoch 160/200
1493/1493 - 65s - loss: 9.5937e-05 - val_loss: 1.9981e-04 - 65s/epoch - 43ms/step
Epoch 161/200
1493/1493 - 65s - loss: 1.4527e-04 - val_loss: 8.7901e-05 - 65s/epoch - 43ms/step
Epoch 162/200
1493/1493 - 65s - loss: 9.7439e-05 - val_loss: 8.8990e-05 - 65s/epoch - 44ms/step
Epoch 163/200
1493/1493 - 65s - loss: 9.5089e-05 - val_loss: 1.3095e-04 - 65s/epoch - 43ms/step
Epoch 164/200
1493/1493 - 65s - loss: 1.0196e-04 - val_loss: 9.4710e-05 - 65s/epoch - 44ms/step
Epoch 165/200
1493/1493 - 65s - loss: 1.1293e-04 - val_loss: 9.0449e-05 - 65s/epoch - 44ms/step
Epoch 166/200
1493/1493 - 65s - loss: 9.5554e-05 - val_loss: 1.0094e-04 - 65s/epoch - 44ms/step
Epoch 167/200
1493/1493 - 65s - loss: 9.3789e-05 - val_loss: 8.6193e-05 - 65s/epoch - 43ms/step
Epoch 168/200
1493/1493 - 65s - loss: 9.2448e-05 - val_loss: 9.2534e-05 - 65s/epoch - 43ms/step
Epoch 169/200
1493/1493 - 65s - loss: 9.1830e-05 - val_loss: 1.1365e-04 - 65s/epoch - 43ms/step
Epoch 170/200
1493/1493 - 65s - loss: 9.4055e-05 - val_loss: 2.9538e-04 - 65s/epoch - 44ms/step
Epoch 171/200
1493/1493 - 65s - loss: 1.3730e-04 - val_loss: 5.5172e-04 - 65s/epoch - 44ms/step
Epoch 172/200
1493/1493 - 65s - loss: 1.4778e-04 - val_loss: 1.1226e-04 - 65s/epoch - 43ms/step
Epoch 173/200
1493/1493 - 65s - loss: 9.9613e-05 - val_loss: 8.6681e-05 - 65s/epoch - 43ms/step
Epoch 174/200
1493/1493 - 65s - loss: 9.4312e-05 - val_loss: 9.3134e-05 - 65s/epoch - 43ms/step
Epoch 175/200
1493/1493 - 65s - loss: 9.4998e-05 - val_loss: 1.0001e-04 - 65s/epoch - 44ms/step
Epoch 176/200
1493/1493 - 65s - loss: 9.3552e-05 - val_loss: 9.9814e-05 - 65s/epoch - 44ms/step
Epoch 177/200
1493/1493 - 65s - loss: 9.2891e-05 - val_loss: 7.9347e-05 - 65s/epoch - 43ms/step
Epoch 178/200
1493/1493 - 65s - loss: 9.0634e-05 - val_loss: 8.9249e-05 - 65s/epoch - 44ms/step
Epoch 179/200
1493/1493 - 65s - loss: 8.9422e-05 - val_loss: 9.4685e-05 - 65s/epoch - 44ms/step
Epoch 180/200
1493/1493 - 65s - loss: 8.9756e-05 - val_loss: 9.7761e-05 - 65s/epoch - 43ms/step
Epoch 181/200
1493/1493 - 65s - loss: 8.9841e-05 - val_loss: 9.3310e-05 - 65s/epoch - 43ms/step
Epoch 182/200
1493/1493 - 65s - loss: 9.0050e-05 - val_loss: 1.2504e-04 - 65s/epoch - 43ms/step
Epoch 183/200
1493/1493 - 65s - loss: 9.0876e-05 - val_loss: 8.6426e-05 - 65s/epoch - 43ms/step
Epoch 184/200
1493/1493 - 65s - loss: 8.9383e-05 - val_loss: 8.3824e-05 - 65s/epoch - 43ms/step
Epoch 185/200
1493/1493 - 65s - loss: 8.6606e-05 - val_loss: 1.2723e-04 - 65s/epoch - 44ms/step
Epoch 186/200
1493/1493 - 65s - loss: 9.0019e-05 - val_loss: 8.7451e-05 - 65s/epoch - 44ms/step
Epoch 187/200
1493/1493 - 65s - loss: 8.8166e-05 - val_loss: 1.6348e-04 - 65s/epoch - 43ms/step
Epoch 188/200
1493/1493 - 65s - loss: 1.0827e-04 - val_loss: 8.4528e-05 - 65s/epoch - 44ms/step
Epoch 189/200
1493/1493 - 65s - loss: 8.9065e-05 - val_loss: 9.7657e-05 - 65s/epoch - 43ms/step
Epoch 190/200
1493/1493 - 65s - loss: 8.8580e-05 - val_loss: 1.0571e-04 - 65s/epoch - 43ms/step
Epoch 191/200
1493/1493 - 65s - loss: 8.8438e-05 - val_loss: 1.3784e-04 - 65s/epoch - 44ms/step
Epoch 192/200
1493/1493 - 65s - loss: 9.0311e-05 - val_loss: 9.9398e-05 - 65s/epoch - 44ms/step
Epoch 193/200
1493/1493 - 65s - loss: 9.2212e-05 - val_loss: 3.2937e-04 - 65s/epoch - 44ms/step
Epoch 194/200
1493/1493 - 65s - loss: 1.3957e-04 - val_loss: 7.8799e-04 - 65s/epoch - 44ms/step
Epoch 195/200
1493/1493 - 65s - loss: 1.4142e-04 - val_loss: 1.8123e-04 - 65s/epoch - 43ms/step
Epoch 196/200
1493/1493 - 65s - loss: 1.1068e-04 - val_loss: 7.4224e-05 - 65s/epoch - 44ms/step
Epoch 197/200
1493/1493 - 65s - loss: 9.1590e-05 - val_loss: 1.0259e-04 - 65s/epoch - 44ms/step
Epoch 198/200
1493/1493 - 65s - loss: 9.4704e-05 - val_loss: 1.2524e-04 - 65s/epoch - 43ms/step
Epoch 199/200
1493/1493 - 65s - loss: 9.2845e-05 - val_loss: 7.5047e-05 - 65s/epoch - 44ms/step
Epoch 200/200
1493/1493 - 65s - loss: 8.7314e-05 - val_loss: 9.0373e-05 - 65s/epoch - 44ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.037289419211447e-05
  1/332 [..............................] - ETA: 38s  7/332 [..............................] - ETA: 3s  13/332 [>.............................] - ETA: 2s 20/332 [>.............................] - ETA: 2s 27/332 [=>............................] - ETA: 2s 35/332 [==>...........................] - ETA: 2s 43/332 [==>...........................] - ETA: 2s 51/332 [===>..........................] - ETA: 2s 59/332 [====>.........................] - ETA: 2s 67/332 [=====>........................] - ETA: 1s 75/332 [=====>........................] - ETA: 1s 83/332 [======>.......................] - ETA: 1s 91/332 [=======>......................] - ETA: 1s 99/332 [=======>......................] - ETA: 1s107/332 [========>.....................] - ETA: 1s115/332 [=========>....................] - ETA: 1s123/332 [==========>...................] - ETA: 1s131/332 [==========>...................] - ETA: 1s138/332 [===========>..................] - ETA: 1s146/332 [============>.................] - ETA: 1s154/332 [============>.................] - ETA: 1s162/332 [=============>................] - ETA: 1s170/332 [==============>...............] - ETA: 1s178/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s194/332 [================>.............] - ETA: 0s202/332 [=================>............] - ETA: 0s210/332 [=================>............] - ETA: 0s218/332 [==================>...........] - ETA: 0s226/332 [===================>..........] - ETA: 0s234/332 [====================>.........] - ETA: 0s242/332 [====================>.........] - ETA: 0s250/332 [=====================>........] - ETA: 0s258/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s274/332 [=======================>......] - ETA: 0s282/332 [========================>.....] - ETA: 0s290/332 [=========================>....] - ETA: 0s298/332 [=========================>....] - ETA: 0s306/332 [==========================>...] - ETA: 0s314/332 [===========================>..] - ETA: 0s322/332 [============================>.] - ETA: 0s330/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 7ms/step
correlation 0.0010241586511376844
cosine 0.0008061270735374361
MAE: 0.005246572
RMSE: 0.009506462
r2: 0.9941386288835073
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 2401)              3037265   
                                                                 
 batch_normalization_12 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2401)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2428422   
                                                                 
 batch_normalization_13 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 1011)              0         
                                                                 
 dense_13 (Dense)            (None, 2401)              2429812   
                                                                 
 batch_normalization_14 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2401)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3036128   
                                                                 
=================================================================
Total params: 10,954,879
Trainable params: 10,943,253
Non-trainable params: 11,626
_________________________________________________________________
Encoder
Model: "model_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_14 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_13 (InputLayer)       multiple                  0         
                                                                 
 dense_12 (Dense)            (None, 2401)              3037265   
                                                                 
 batch_normalization_12 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_12 (ReLU)             (None, 2401)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2428422   
                                                                 
=================================================================
Total params: 5,475,291
Trainable params: 5,470,489
Non-trainable params: 4,802
_________________________________________________________________
Decoder
Model: "model_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_15 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_13 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_13 (ReLU)             (None, 1011)              0         
                                                                 
 dense_13 (Dense)            (None, 2401)              2429812   
                                                                 
 batch_normalization_14 (Bat  (None, 2401)             9604      
 chNormalization)                                                
                                                                 
 re_lu_14 (ReLU)             (None, 2401)              0         
                                                                 
 dense_14 (Dense)            (None, 1264)              3036128   
                                                                 
=================================================================
Total params: 5,479,588
Trainable params: 5,472,764
Non-trainable params: 6,824
_________________________________________________________________
['1.9custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.731397247174755e-05, 9.037289419211447e-05, 0.0010241586511376844, 0.0008061270735374361, 0.005246572196483612, 0.009506462141871452, 0.9941386288835073, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_15 (Dense)            (None, 2528)              3197920   
                                                                 
 batch_normalization_15 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2528)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2556819   
                                                                 
 batch_normalization_16 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 1011)              0         
                                                                 
 dense_16 (Dense)            (None, 2528)              2558336   
                                                                 
 batch_normalization_17 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2528)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3196656   
                                                                 
=================================================================
Total params: 11,533,999
Trainable params: 11,521,865
Non-trainable params: 12,134
_________________________________________________________________
Epoch 1/200
1493/1493 - 63s - loss: 0.0089 - val_loss: 0.0039 - 63s/epoch - 42ms/step
Epoch 2/200
1493/1493 - 62s - loss: 0.0028 - val_loss: 0.0028 - 62s/epoch - 42ms/step
Epoch 3/200
1493/1493 - 62s - loss: 0.0020 - val_loss: 0.0017 - 62s/epoch - 42ms/step
Epoch 4/200
1493/1493 - 62s - loss: 0.0016 - val_loss: 0.0020 - 62s/epoch - 42ms/step
Epoch 5/200
1493/1493 - 62s - loss: 0.0015 - val_loss: 0.0016 - 62s/epoch - 42ms/step
Epoch 6/200
1493/1493 - 62s - loss: 0.0013 - val_loss: 0.0013 - 62s/epoch - 42ms/step
Epoch 7/200
1493/1493 - 62s - loss: 0.0013 - val_loss: 0.0012 - 62s/epoch - 42ms/step
Epoch 8/200
1493/1493 - 62s - loss: 0.0011 - val_loss: 9.5147e-04 - 62s/epoch - 42ms/step
Epoch 9/200
1493/1493 - 62s - loss: 9.9693e-04 - val_loss: 0.0013 - 62s/epoch - 42ms/step
Epoch 10/200
1493/1493 - 62s - loss: 9.7660e-04 - val_loss: 7.6919e-04 - 62s/epoch - 42ms/step
Epoch 11/200
1493/1493 - 62s - loss: 8.7832e-04 - val_loss: 7.1335e-04 - 62s/epoch - 42ms/step
Epoch 12/200
1493/1493 - 62s - loss: 7.3650e-04 - val_loss: 0.0014 - 62s/epoch - 42ms/step
Epoch 13/200
1493/1493 - 62s - loss: 7.1616e-04 - val_loss: 0.0012 - 62s/epoch - 42ms/step
Epoch 14/200
1493/1493 - 62s - loss: 6.9162e-04 - val_loss: 5.3689e-04 - 62s/epoch - 42ms/step
Epoch 15/200
1493/1493 - 62s - loss: 6.0727e-04 - val_loss: 6.6909e-04 - 62s/epoch - 42ms/step
Epoch 16/200
1493/1493 - 62s - loss: 5.8184e-04 - val_loss: 5.2319e-04 - 62s/epoch - 42ms/step
Epoch 17/200
1493/1493 - 63s - loss: 5.2116e-04 - val_loss: 6.6580e-04 - 63s/epoch - 42ms/step
Epoch 18/200
1493/1493 - 62s - loss: 4.9406e-04 - val_loss: 0.0012 - 62s/epoch - 42ms/step
Epoch 19/200
1493/1493 - 62s - loss: 5.3814e-04 - val_loss: 7.1550e-04 - 62s/epoch - 42ms/step
Epoch 20/200
1493/1493 - 62s - loss: 4.5832e-04 - val_loss: 4.3408e-04 - 62s/epoch - 42ms/step
Epoch 21/200
1493/1493 - 62s - loss: 4.1702e-04 - val_loss: 5.0023e-04 - 62s/epoch - 42ms/step
Epoch 22/200
1493/1493 - 62s - loss: 4.2584e-04 - val_loss: 4.4980e-04 - 62s/epoch - 42ms/step
Epoch 23/200
1493/1493 - 62s - loss: 3.9735e-04 - val_loss: 0.0014 - 62s/epoch - 42ms/step
Epoch 24/200
1493/1493 - 62s - loss: 4.4586e-04 - val_loss: 4.4419e-04 - 62s/epoch - 42ms/step
Epoch 25/200
1493/1493 - 62s - loss: 3.7618e-04 - val_loss: 3.1558e-04 - 62s/epoch - 42ms/step
Epoch 26/200
1493/1493 - 62s - loss: 3.4846e-04 - val_loss: 3.5354e-04 - 62s/epoch - 42ms/step
Epoch 27/200
1493/1493 - 62s - loss: 3.2714e-04 - val_loss: 3.2215e-04 - 62s/epoch - 42ms/step
Epoch 28/200
1493/1493 - 62s - loss: 3.1385e-04 - val_loss: 4.2391e-04 - 62s/epoch - 42ms/step
Epoch 29/200
1493/1493 - 62s - loss: 3.0362e-04 - val_loss: 4.7654e-04 - 62s/epoch - 42ms/step
Epoch 30/200
1493/1493 - 62s - loss: 3.3004e-04 - val_loss: 3.1828e-04 - 62s/epoch - 42ms/step
Epoch 31/200
1493/1493 - 62s - loss: 2.8450e-04 - val_loss: 6.4629e-04 - 62s/epoch - 42ms/step
Epoch 32/200
1493/1493 - 62s - loss: 3.1007e-04 - val_loss: 3.4376e-04 - 62s/epoch - 42ms/step
Epoch 33/200
1493/1493 - 62s - loss: 2.8568e-04 - val_loss: 2.6196e-04 - 62s/epoch - 42ms/step
Epoch 34/200
1493/1493 - 62s - loss: 2.6486e-04 - val_loss: 2.2141e-04 - 62s/epoch - 42ms/step
Epoch 35/200
1493/1493 - 62s - loss: 2.5488e-04 - val_loss: 9.0745e-04 - 62s/epoch - 42ms/step
Epoch 36/200
1493/1493 - 62s - loss: 2.9702e-04 - val_loss: 3.2552e-04 - 62s/epoch - 42ms/step
Epoch 37/200
1493/1493 - 62s - loss: 2.5212e-04 - val_loss: 3.2627e-04 - 62s/epoch - 42ms/step
Epoch 38/200
1493/1493 - 62s - loss: 2.6157e-04 - val_loss: 2.2871e-04 - 62s/epoch - 42ms/step
Epoch 39/200
1493/1493 - 62s - loss: 2.3411e-04 - val_loss: 2.1290e-04 - 62s/epoch - 42ms/step
Epoch 40/200
1493/1493 - 62s - loss: 2.2410e-04 - val_loss: 3.0983e-04 - 62s/epoch - 42ms/step
Epoch 41/200
1493/1493 - 62s - loss: 2.2743e-04 - val_loss: 2.0044e-04 - 62s/epoch - 42ms/step
Epoch 42/200
1493/1493 - 62s - loss: 2.1873e-04 - val_loss: 2.2376e-04 - 62s/epoch - 42ms/step
Epoch 43/200
1493/1493 - 62s - loss: 2.2257e-04 - val_loss: 3.2971e-04 - 62s/epoch - 42ms/step
Epoch 44/200
1493/1493 - 62s - loss: 2.2504e-04 - val_loss: 2.4764e-04 - 62s/epoch - 42ms/step
Epoch 45/200
1493/1493 - 62s - loss: 2.1409e-04 - val_loss: 1.8268e-04 - 62s/epoch - 42ms/step
Epoch 46/200
1493/1493 - 62s - loss: 2.0295e-04 - val_loss: 1.9139e-04 - 62s/epoch - 42ms/step
Epoch 47/200
1493/1493 - 62s - loss: 2.0163e-04 - val_loss: 2.5358e-04 - 62s/epoch - 42ms/step
Epoch 48/200
1493/1493 - 62s - loss: 2.0004e-04 - val_loss: 2.5369e-04 - 62s/epoch - 42ms/step
Epoch 49/200
1493/1493 - 63s - loss: 1.9695e-04 - val_loss: 9.7173e-04 - 63s/epoch - 42ms/step
Epoch 50/200
1493/1493 - 62s - loss: 2.7309e-04 - val_loss: 0.0015 - 62s/epoch - 42ms/step
Epoch 51/200
1493/1493 - 63s - loss: 2.7070e-04 - val_loss: 2.4866e-04 - 63s/epoch - 42ms/step
Epoch 52/200
1493/1493 - 62s - loss: 1.9127e-04 - val_loss: 1.9016e-04 - 62s/epoch - 42ms/step
Epoch 53/200
1493/1493 - 62s - loss: 2.0118e-04 - val_loss: 1.6869e-04 - 62s/epoch - 42ms/step
Epoch 54/200
1493/1493 - 62s - loss: 1.8723e-04 - val_loss: 2.0221e-04 - 62s/epoch - 42ms/step
Epoch 55/200
1493/1493 - 63s - loss: 1.7869e-04 - val_loss: 1.9090e-04 - 63s/epoch - 42ms/step
Epoch 56/200
1493/1493 - 62s - loss: 1.7760e-04 - val_loss: 2.1153e-04 - 62s/epoch - 42ms/step
Epoch 57/200
1493/1493 - 62s - loss: 1.7274e-04 - val_loss: 1.7974e-04 - 62s/epoch - 42ms/step
Epoch 58/200
1493/1493 - 62s - loss: 1.7236e-04 - val_loss: 1.5828e-04 - 62s/epoch - 42ms/step
Epoch 59/200
1493/1493 - 63s - loss: 1.6788e-04 - val_loss: 1.8714e-04 - 63s/epoch - 42ms/step
Epoch 60/200
1493/1493 - 63s - loss: 1.6758e-04 - val_loss: 2.7963e-04 - 63s/epoch - 42ms/step
Epoch 61/200
1493/1493 - 62s - loss: 1.9855e-04 - val_loss: 1.6304e-04 - 62s/epoch - 42ms/step
Epoch 62/200
1493/1493 - 63s - loss: 1.6186e-04 - val_loss: 1.8308e-04 - 63s/epoch - 42ms/step
Epoch 63/200
1493/1493 - 62s - loss: 1.6418e-04 - val_loss: 2.1932e-04 - 62s/epoch - 42ms/step
Epoch 64/200
1493/1493 - 62s - loss: 1.6262e-04 - val_loss: 7.7710e-04 - 62s/epoch - 42ms/step
Epoch 65/200
1493/1493 - 62s - loss: 2.0116e-04 - val_loss: 1.9589e-04 - 62s/epoch - 42ms/step
Epoch 66/200
1493/1493 - 62s - loss: 1.6703e-04 - val_loss: 1.6052e-04 - 62s/epoch - 42ms/step
Epoch 67/200
1493/1493 - 62s - loss: 1.5610e-04 - val_loss: 1.4698e-04 - 62s/epoch - 42ms/step
Epoch 68/200
1493/1493 - 63s - loss: 1.5206e-04 - val_loss: 2.1130e-04 - 63s/epoch - 42ms/step
Epoch 69/200
1493/1493 - 62s - loss: 1.6486e-04 - val_loss: 1.7145e-04 - 62s/epoch - 42ms/step
Epoch 70/200
1493/1493 - 62s - loss: 1.4970e-04 - val_loss: 2.1861e-04 - 62s/epoch - 42ms/step
Epoch 71/200
1493/1493 - 62s - loss: 1.5344e-04 - val_loss: 1.3883e-04 - 62s/epoch - 42ms/step
Epoch 72/200
1493/1493 - 62s - loss: 1.4922e-04 - val_loss: 2.4853e-04 - 62s/epoch - 42ms/step
Epoch 73/200
1493/1493 - 62s - loss: 1.5719e-04 - val_loss: 1.4778e-04 - 62s/epoch - 42ms/step
Epoch 74/200
1493/1493 - 62s - loss: 1.4700e-04 - val_loss: 1.4996e-04 - 62s/epoch - 42ms/step
Epoch 75/200
1493/1493 - 62s - loss: 1.4163e-04 - val_loss: 1.3241e-04 - 62s/epoch - 42ms/step
Epoch 76/200
1493/1493 - 62s - loss: 1.4268e-04 - val_loss: 1.3931e-04 - 62s/epoch - 42ms/step
Epoch 77/200
1493/1493 - 62s - loss: 1.3832e-04 - val_loss: 0.0011 - 62s/epoch - 42ms/step
Epoch 78/200
1493/1493 - 62s - loss: 2.1295e-04 - val_loss: 1.5484e-04 - 62s/epoch - 42ms/step
Epoch 79/200
1493/1493 - 62s - loss: 1.4617e-04 - val_loss: 4.0304e-04 - 62s/epoch - 42ms/step
Epoch 80/200
1493/1493 - 62s - loss: 1.8412e-04 - val_loss: 1.5417e-04 - 62s/epoch - 42ms/step
Epoch 81/200
1493/1493 - 62s - loss: 1.4122e-04 - val_loss: 5.2110e-04 - 62s/epoch - 42ms/step
Epoch 82/200
1493/1493 - 62s - loss: 1.5006e-04 - val_loss: 1.3676e-04 - 62s/epoch - 42ms/step
Epoch 83/200
1493/1493 - 62s - loss: 1.3434e-04 - val_loss: 1.3943e-04 - 62s/epoch - 42ms/step
Epoch 84/200
1493/1493 - 62s - loss: 1.3321e-04 - val_loss: 1.4334e-04 - 62s/epoch - 42ms/step
Epoch 85/200
1493/1493 - 62s - loss: 1.3365e-04 - val_loss: 1.5416e-04 - 62s/epoch - 42ms/step
Epoch 86/200
1493/1493 - 63s - loss: 1.3507e-04 - val_loss: 1.5376e-04 - 63s/epoch - 42ms/step
Epoch 87/200
1493/1493 - 62s - loss: 1.2771e-04 - val_loss: 1.2857e-04 - 62s/epoch - 42ms/step
Epoch 88/200
1493/1493 - 62s - loss: 1.2756e-04 - val_loss: 1.4045e-04 - 62s/epoch - 42ms/step
Epoch 89/200
1493/1493 - 62s - loss: 1.3092e-04 - val_loss: 1.2628e-04 - 62s/epoch - 42ms/step
Epoch 90/200
1493/1493 - 62s - loss: 1.2581e-04 - val_loss: 1.3845e-04 - 62s/epoch - 42ms/step
Epoch 91/200
1493/1493 - 62s - loss: 1.2527e-04 - val_loss: 1.4266e-04 - 62s/epoch - 42ms/step
Epoch 92/200
1493/1493 - 62s - loss: 1.2702e-04 - val_loss: 5.6132e-04 - 62s/epoch - 42ms/step
Epoch 93/200
1493/1493 - 62s - loss: 1.9361e-04 - val_loss: 2.2647e-04 - 62s/epoch - 42ms/step
Epoch 94/200
1493/1493 - 62s - loss: 1.4146e-04 - val_loss: 1.0943e-04 - 62s/epoch - 42ms/step
Epoch 95/200
1493/1493 - 62s - loss: 1.3322e-04 - val_loss: 0.0019 - 62s/epoch - 42ms/step
Epoch 96/200
1493/1493 - 62s - loss: 2.5721e-04 - val_loss: 1.3889e-04 - 62s/epoch - 42ms/step
Epoch 97/200
1493/1493 - 62s - loss: 1.4480e-04 - val_loss: 1.2398e-04 - 62s/epoch - 42ms/step
Epoch 98/200
1493/1493 - 62s - loss: 1.3844e-04 - val_loss: 6.3911e-04 - 62s/epoch - 42ms/step
Epoch 99/200
1493/1493 - 62s - loss: 2.1019e-04 - val_loss: 1.1097e-04 - 62s/epoch - 42ms/step
Epoch 100/200
1493/1493 - 62s - loss: 1.4029e-04 - val_loss: 1.2638e-04 - 62s/epoch - 42ms/step
Epoch 101/200
1493/1493 - 62s - loss: 1.3045e-04 - val_loss: 3.0921e-04 - 62s/epoch - 42ms/step
Epoch 102/200
1493/1493 - 62s - loss: 1.5352e-04 - val_loss: 3.2080e-04 - 62s/epoch - 42ms/step
Epoch 103/200
1493/1493 - 62s - loss: 1.4304e-04 - val_loss: 1.1403e-04 - 62s/epoch - 42ms/step
Epoch 104/200
1493/1493 - 62s - loss: 1.2445e-04 - val_loss: 4.7062e-04 - 62s/epoch - 42ms/step
Epoch 105/200
1493/1493 - 62s - loss: 1.5180e-04 - val_loss: 9.9759e-05 - 62s/epoch - 42ms/step
Epoch 106/200
1493/1493 - 62s - loss: 1.2274e-04 - val_loss: 1.2042e-04 - 62s/epoch - 42ms/step
Epoch 107/200
1493/1493 - 62s - loss: 1.2084e-04 - val_loss: 1.3210e-04 - 62s/epoch - 42ms/step
Epoch 108/200
1493/1493 - 62s - loss: 1.2259e-04 - val_loss: 1.2113e-04 - 62s/epoch - 42ms/step
Epoch 109/200
1493/1493 - 62s - loss: 1.1751e-04 - val_loss: 1.3303e-04 - 62s/epoch - 42ms/step
Epoch 110/200
1493/1493 - 62s - loss: 1.1628e-04 - val_loss: 1.2514e-04 - 62s/epoch - 42ms/step
Epoch 111/200
1493/1493 - 62s - loss: 1.1457e-04 - val_loss: 1.1114e-04 - 62s/epoch - 42ms/step
Epoch 112/200
1493/1493 - 62s - loss: 1.1351e-04 - val_loss: 1.0831e-04 - 62s/epoch - 42ms/step
Epoch 113/200
1493/1493 - 62s - loss: 1.1352e-04 - val_loss: 5.2212e-04 - 62s/epoch - 42ms/step
Epoch 114/200
1493/1493 - 62s - loss: 1.5968e-04 - val_loss: 9.2230e-05 - 62s/epoch - 42ms/step
Epoch 115/200
1493/1493 - 62s - loss: 1.2282e-04 - val_loss: 2.1452e-04 - 62s/epoch - 42ms/step
Epoch 116/200
1493/1493 - 62s - loss: 1.1639e-04 - val_loss: 1.1627e-04 - 62s/epoch - 42ms/step
Epoch 117/200
1493/1493 - 62s - loss: 1.1166e-04 - val_loss: 2.3447e-04 - 62s/epoch - 42ms/step
Epoch 118/200
1493/1493 - 62s - loss: 1.2060e-04 - val_loss: 1.1921e-04 - 62s/epoch - 42ms/step
Epoch 119/200
1493/1493 - 62s - loss: 1.1177e-04 - val_loss: 1.0264e-04 - 62s/epoch - 42ms/step
Epoch 120/200
1493/1493 - 62s - loss: 1.0904e-04 - val_loss: 1.1150e-04 - 62s/epoch - 42ms/step
Epoch 121/200
1493/1493 - 62s - loss: 1.0844e-04 - val_loss: 1.6635e-04 - 62s/epoch - 42ms/step
Epoch 122/200
1493/1493 - 62s - loss: 1.1060e-04 - val_loss: 9.8317e-05 - 62s/epoch - 42ms/step
Epoch 123/200
1493/1493 - 62s - loss: 1.0625e-04 - val_loss: 1.1639e-04 - 62s/epoch - 42ms/step
Epoch 124/200
1493/1493 - 62s - loss: 1.0671e-04 - val_loss: 3.6424e-04 - 62s/epoch - 42ms/step
Epoch 125/200
1493/1493 - 62s - loss: 1.3745e-04 - val_loss: 1.5549e-04 - 62s/epoch - 42ms/step
Epoch 126/200
1493/1493 - 62s - loss: 1.1077e-04 - val_loss: 1.2609e-04 - 62s/epoch - 42ms/step
Epoch 127/200
1493/1493 - 62s - loss: 1.0777e-04 - val_loss: 3.3222e-04 - 62s/epoch - 42ms/step
Epoch 128/200
1493/1493 - 62s - loss: 1.2837e-04 - val_loss: 9.3348e-05 - 62s/epoch - 42ms/step
Epoch 129/200
1493/1493 - 62s - loss: 1.0537e-04 - val_loss: 1.0701e-04 - 62s/epoch - 42ms/step
Epoch 130/200
1493/1493 - 62s - loss: 1.0407e-04 - val_loss: 1.0146e-04 - 62s/epoch - 42ms/step
Epoch 131/200
1493/1493 - 62s - loss: 1.0501e-04 - val_loss: 2.3756e-04 - 62s/epoch - 42ms/step
Epoch 132/200
1493/1493 - 62s - loss: 1.2884e-04 - val_loss: 1.0350e-04 - 62s/epoch - 42ms/step
Epoch 133/200
1493/1493 - 62s - loss: 1.0489e-04 - val_loss: 1.1143e-04 - 62s/epoch - 42ms/step
Epoch 134/200
1493/1493 - 62s - loss: 1.0274e-04 - val_loss: 1.0321e-04 - 62s/epoch - 42ms/step
Epoch 135/200
1493/1493 - 63s - loss: 1.0163e-04 - val_loss: 9.1144e-05 - 63s/epoch - 42ms/step
Epoch 136/200
1493/1493 - 62s - loss: 1.0132e-04 - val_loss: 1.1914e-04 - 62s/epoch - 42ms/step
Epoch 137/200
1493/1493 - 62s - loss: 1.0695e-04 - val_loss: 1.5138e-04 - 62s/epoch - 42ms/step
Epoch 138/200
1493/1493 - 63s - loss: 1.0542e-04 - val_loss: 1.1410e-04 - 63s/epoch - 42ms/step
Epoch 139/200
1493/1493 - 63s - loss: 1.0491e-04 - val_loss: 1.7117e-04 - 63s/epoch - 42ms/step
Epoch 140/200
1493/1493 - 62s - loss: 1.1202e-04 - val_loss: 8.7045e-05 - 62s/epoch - 42ms/step
Epoch 141/200
1493/1493 - 62s - loss: 9.9431e-05 - val_loss: 1.2153e-04 - 62s/epoch - 42ms/step
Epoch 142/200
1493/1493 - 62s - loss: 1.0202e-04 - val_loss: 1.0591e-04 - 62s/epoch - 42ms/step
Epoch 143/200
1493/1493 - 62s - loss: 9.8022e-05 - val_loss: 1.3361e-04 - 62s/epoch - 42ms/step
Epoch 144/200
1493/1493 - 62s - loss: 1.0005e-04 - val_loss: 1.1715e-04 - 62s/epoch - 42ms/step
Epoch 145/200
1493/1493 - 62s - loss: 9.7720e-05 - val_loss: 9.9438e-05 - 62s/epoch - 42ms/step
Epoch 146/200
1493/1493 - 62s - loss: 9.6111e-05 - val_loss: 9.6033e-05 - 62s/epoch - 42ms/step
Epoch 147/200
1493/1493 - 62s - loss: 9.4895e-05 - val_loss: 1.1155e-04 - 62s/epoch - 42ms/step
Epoch 148/200
1493/1493 - 62s - loss: 9.5259e-05 - val_loss: 1.9173e-04 - 62s/epoch - 42ms/step
Epoch 149/200
1493/1493 - 62s - loss: 9.4856e-05 - val_loss: 9.6257e-05 - 62s/epoch - 42ms/step
Epoch 150/200
1493/1493 - 62s - loss: 9.3672e-05 - val_loss: 8.9601e-05 - 62s/epoch - 42ms/step
Epoch 151/200
1493/1493 - 62s - loss: 9.5700e-05 - val_loss: 1.8445e-04 - 62s/epoch - 42ms/step
Epoch 152/200
1493/1493 - 62s - loss: 1.0183e-04 - val_loss: 1.1342e-04 - 62s/epoch - 42ms/step
Epoch 153/200
1493/1493 - 62s - loss: 9.5070e-05 - val_loss: 1.0841e-04 - 62s/epoch - 42ms/step
Epoch 154/200
1493/1493 - 62s - loss: 9.2932e-05 - val_loss: 1.0974e-04 - 62s/epoch - 42ms/step
Epoch 155/200
1493/1493 - 62s - loss: 9.3882e-05 - val_loss: 9.5493e-05 - 62s/epoch - 42ms/step
Epoch 156/200
1493/1493 - 62s - loss: 9.3914e-05 - val_loss: 1.0022e-04 - 62s/epoch - 42ms/step
Epoch 157/200
1493/1493 - 62s - loss: 9.0834e-05 - val_loss: 1.0509e-04 - 62s/epoch - 42ms/step
Epoch 158/200
1493/1493 - 62s - loss: 9.2042e-05 - val_loss: 1.0184e-04 - 62s/epoch - 42ms/step
Epoch 159/200
1493/1493 - 62s - loss: 9.0803e-05 - val_loss: 9.5668e-05 - 62s/epoch - 42ms/step
Epoch 160/200
1493/1493 - 62s - loss: 9.0468e-05 - val_loss: 1.0235e-04 - 62s/epoch - 42ms/step
Epoch 161/200
1493/1493 - 62s - loss: 9.8379e-05 - val_loss: 8.7055e-05 - 62s/epoch - 42ms/step
Epoch 162/200
1493/1493 - 62s - loss: 9.0370e-05 - val_loss: 9.2062e-05 - 62s/epoch - 42ms/step
Epoch 163/200
1493/1493 - 63s - loss: 8.9366e-05 - val_loss: 1.0180e-04 - 63s/epoch - 42ms/step
Epoch 164/200
1493/1493 - 62s - loss: 9.2289e-05 - val_loss: 9.5236e-05 - 62s/epoch - 42ms/step
Epoch 165/200
1493/1493 - 63s - loss: 1.0096e-04 - val_loss: 8.7233e-05 - 63s/epoch - 42ms/step
Epoch 166/200
1493/1493 - 62s - loss: 9.0312e-05 - val_loss: 9.5273e-05 - 62s/epoch - 42ms/step
Epoch 167/200
1493/1493 - 62s - loss: 9.0419e-05 - val_loss: 8.0094e-05 - 62s/epoch - 42ms/step
Epoch 168/200
1493/1493 - 63s - loss: 8.8545e-05 - val_loss: 8.2280e-05 - 63s/epoch - 42ms/step
Epoch 169/200
1493/1493 - 63s - loss: 8.8848e-05 - val_loss: 1.0671e-04 - 63s/epoch - 42ms/step
Epoch 170/200
1493/1493 - 63s - loss: 9.2717e-05 - val_loss: 4.0417e-04 - 63s/epoch - 42ms/step
Epoch 171/200
1493/1493 - 63s - loss: 1.4824e-04 - val_loss: 2.5292e-04 - 63s/epoch - 42ms/step
Epoch 172/200
1493/1493 - 62s - loss: 1.1433e-04 - val_loss: 8.6702e-05 - 62s/epoch - 42ms/step
Epoch 173/200
1493/1493 - 62s - loss: 9.3456e-05 - val_loss: 8.9143e-05 - 62s/epoch - 42ms/step
Epoch 174/200
1493/1493 - 62s - loss: 9.0178e-05 - val_loss: 8.7223e-05 - 62s/epoch - 42ms/step
Epoch 175/200
1493/1493 - 62s - loss: 9.0958e-05 - val_loss: 1.0864e-04 - 62s/epoch - 42ms/step
Epoch 176/200
1493/1493 - 63s - loss: 8.9967e-05 - val_loss: 9.2735e-05 - 63s/epoch - 42ms/step
Epoch 177/200
1493/1493 - 62s - loss: 8.9816e-05 - val_loss: 8.3012e-05 - 62s/epoch - 42ms/step
Epoch 178/200
1493/1493 - 62s - loss: 8.7935e-05 - val_loss: 8.6261e-05 - 62s/epoch - 42ms/step
Epoch 179/200
1493/1493 - 63s - loss: 8.6289e-05 - val_loss: 9.1777e-05 - 63s/epoch - 42ms/step
Epoch 180/200
1493/1493 - 63s - loss: 8.6875e-05 - val_loss: 1.3715e-04 - 63s/epoch - 42ms/step
Epoch 181/200
1493/1493 - 63s - loss: 9.4989e-05 - val_loss: 8.6535e-05 - 63s/epoch - 42ms/step
Epoch 182/200
1493/1493 - 63s - loss: 8.7209e-05 - val_loss: 1.1348e-04 - 63s/epoch - 42ms/step
Epoch 183/200
1493/1493 - 63s - loss: 8.5943e-05 - val_loss: 8.8903e-05 - 63s/epoch - 42ms/step
Epoch 184/200
1493/1493 - 63s - loss: 8.6440e-05 - val_loss: 8.9846e-05 - 63s/epoch - 42ms/step
Epoch 185/200
1493/1493 - 62s - loss: 8.8276e-05 - val_loss: 3.6468e-04 - 62s/epoch - 42ms/step
Epoch 186/200
1493/1493 - 62s - loss: 1.3785e-04 - val_loss: 8.5597e-05 - 62s/epoch - 42ms/step
Epoch 187/200
1493/1493 - 62s - loss: 9.2224e-05 - val_loss: 8.2931e-05 - 62s/epoch - 42ms/step
Epoch 188/200
1493/1493 - 62s - loss: 9.0899e-05 - val_loss: 1.0131e-04 - 62s/epoch - 42ms/step
Epoch 189/200
1493/1493 - 62s - loss: 8.7925e-05 - val_loss: 1.1389e-04 - 62s/epoch - 42ms/step
Epoch 190/200
1493/1493 - 62s - loss: 8.8141e-05 - val_loss: 1.1884e-04 - 62s/epoch - 42ms/step
Epoch 191/200
1493/1493 - 62s - loss: 9.0125e-05 - val_loss: 1.6415e-04 - 62s/epoch - 42ms/step
Epoch 192/200
1493/1493 - 62s - loss: 8.8068e-05 - val_loss: 9.4412e-05 - 62s/epoch - 42ms/step
Epoch 193/200
1493/1493 - 63s - loss: 8.5848e-05 - val_loss: 1.3200e-04 - 63s/epoch - 42ms/step
Epoch 194/200
1493/1493 - 63s - loss: 9.6663e-05 - val_loss: 3.8497e-04 - 63s/epoch - 42ms/step
Epoch 195/200
1493/1493 - 63s - loss: 1.4285e-04 - val_loss: 1.3697e-04 - 63s/epoch - 42ms/step
Epoch 196/200
1493/1493 - 62s - loss: 1.0061e-04 - val_loss: 7.2601e-05 - 62s/epoch - 42ms/step
Epoch 197/200
1493/1493 - 62s - loss: 8.9398e-05 - val_loss: 1.1579e-04 - 62s/epoch - 42ms/step
Epoch 198/200
1493/1493 - 62s - loss: 9.4058e-05 - val_loss: 1.1270e-04 - 62s/epoch - 42ms/step
Epoch 199/200
1493/1493 - 63s - loss: 8.9803e-05 - val_loss: 7.8150e-05 - 63s/epoch - 42ms/step
Epoch 200/200
1493/1493 - 62s - loss: 8.5140e-05 - val_loss: 9.0441e-05 - 62s/epoch - 42ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 9.044126636581495e-05
  1/332 [..............................] - ETA: 44s  8/332 [..............................] - ETA: 2s  16/332 [>.............................] - ETA: 2s 24/332 [=>............................] - ETA: 2s 32/332 [=>............................] - ETA: 2s 40/332 [==>...........................] - ETA: 1s 48/332 [===>..........................] - ETA: 1s 56/332 [====>.........................] - ETA: 1s 64/332 [====>.........................] - ETA: 1s 72/332 [=====>........................] - ETA: 1s 80/332 [======>.......................] - ETA: 1s 88/332 [======>.......................] - ETA: 1s 96/332 [=======>......................] - ETA: 1s104/332 [========>.....................] - ETA: 1s112/332 [=========>....................] - ETA: 1s120/332 [=========>....................] - ETA: 1s128/332 [==========>...................] - ETA: 1s136/332 [===========>..................] - ETA: 1s144/332 [============>.................] - ETA: 1s152/332 [============>.................] - ETA: 1s160/332 [=============>................] - ETA: 1s168/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s183/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 0s199/332 [================>.............] - ETA: 0s207/332 [=================>............] - ETA: 0s215/332 [==================>...........] - ETA: 0s223/332 [===================>..........] - ETA: 0s231/332 [===================>..........] - ETA: 0s239/332 [====================>.........] - ETA: 0s247/332 [=====================>........] - ETA: 0s255/332 [======================>.......] - ETA: 0s263/332 [======================>.......] - ETA: 0s271/332 [=======================>......] - ETA: 0s279/332 [========================>.....] - ETA: 0s287/332 [========================>.....] - ETA: 0s295/332 [=========================>....] - ETA: 0s303/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s319/332 [===========================>..] - ETA: 0s327/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 7ms/step
correlation 0.0010179330044047948
cosine 0.000801902327544726
MAE: 0.005298399
RMSE: 0.009510057
r2: 0.9941329624846672
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 2528)              3197920   
                                                                 
 batch_normalization_15 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2528)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2556819   
                                                                 
 batch_normalization_16 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 1011)              0         
                                                                 
 dense_16 (Dense)            (None, 2528)              2558336   
                                                                 
 batch_normalization_17 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2528)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3196656   
                                                                 
=================================================================
Total params: 11,533,999
Trainable params: 11,521,865
Non-trainable params: 12,134
_________________________________________________________________
Encoder
Model: "model_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_17 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_16 (InputLayer)       multiple                  0         
                                                                 
 dense_15 (Dense)            (None, 2528)              3197920   
                                                                 
 batch_normalization_15 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_15 (ReLU)             (None, 2528)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2556819   
                                                                 
=================================================================
Total params: 5,764,851
Trainable params: 5,759,795
Non-trainable params: 5,056
_________________________________________________________________
Decoder
Model: "model_17"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_18 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_16 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_16 (ReLU)             (None, 1011)              0         
                                                                 
 dense_16 (Dense)            (None, 2528)              2558336   
                                                                 
 batch_normalization_17 (Bat  (None, 2528)             10112     
 chNormalization)                                                
                                                                 
 re_lu_17 (ReLU)             (None, 2528)              0         
                                                                 
 dense_17 (Dense)            (None, 1264)              3196656   
                                                                 
=================================================================
Total params: 5,769,148
Trainable params: 5,762,070
Non-trainable params: 7,078
_________________________________________________________________
['2.0custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.513961802236736e-05, 9.044126636581495e-05, 0.0010179330044047948, 0.000801902327544726, 0.0052983989007771015, 0.009510057047009468, 0.9941329624846672, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_18 (Dense)            (None, 2654)              3357310   
                                                                 
 batch_normalization_18 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2654)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2684205   
                                                                 
 batch_normalization_19 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 1011)              0         
                                                                 
 dense_19 (Dense)            (None, 2654)              2685848   
                                                                 
 batch_normalization_20 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2654)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3355920   
                                                                 
=================================================================
Total params: 12,108,559
Trainable params: 12,095,921
Non-trainable params: 12,638
_________________________________________________________________
Epoch 1/200
1493/1493 - 75s - loss: 0.0090 - val_loss: 0.0049 - 75s/epoch - 50ms/step
Epoch 2/200
1493/1493 - 77s - loss: 0.0028 - val_loss: 0.0035 - 77s/epoch - 51ms/step
Epoch 3/200
1493/1493 - 77s - loss: 0.0020 - val_loss: 0.0015 - 77s/epoch - 52ms/step
Epoch 4/200
1493/1493 - 77s - loss: 0.0016 - val_loss: 0.0058 - 77s/epoch - 52ms/step
Epoch 5/200
1493/1493 - 77s - loss: 0.0018 - val_loss: 0.0012 - 77s/epoch - 52ms/step
Epoch 6/200
1493/1493 - 77s - loss: 0.0014 - val_loss: 0.0013 - 77s/epoch - 52ms/step
Epoch 7/200
1493/1493 - 77s - loss: 0.0013 - val_loss: 9.0204e-04 - 77s/epoch - 52ms/step
Epoch 8/200
1493/1493 - 77s - loss: 0.0012 - val_loss: 0.0015 - 77s/epoch - 51ms/step
Epoch 9/200
1493/1493 - 76s - loss: 0.0011 - val_loss: 0.0011 - 76s/epoch - 51ms/step
Epoch 10/200
1493/1493 - 77s - loss: 0.0010 - val_loss: 9.9531e-04 - 77s/epoch - 52ms/step
Epoch 11/200
1493/1493 - 76s - loss: 8.6221e-04 - val_loss: 7.2606e-04 - 76s/epoch - 51ms/step
Epoch 12/200
1493/1493 - 77s - loss: 7.2589e-04 - val_loss: 7.6914e-04 - 77s/epoch - 52ms/step
Epoch 13/200
1493/1493 - 76s - loss: 6.9225e-04 - val_loss: 0.0025 - 76s/epoch - 51ms/step
Epoch 14/200
1493/1493 - 76s - loss: 8.9603e-04 - val_loss: 5.0028e-04 - 76s/epoch - 51ms/step
Epoch 15/200
1493/1493 - 76s - loss: 6.2610e-04 - val_loss: 6.6031e-04 - 76s/epoch - 51ms/step
Epoch 16/200
1493/1493 - 76s - loss: 5.6560e-04 - val_loss: 4.9637e-04 - 76s/epoch - 51ms/step
Epoch 17/200
1493/1493 - 76s - loss: 5.1412e-04 - val_loss: 6.3112e-04 - 76s/epoch - 51ms/step
Epoch 18/200
1493/1493 - 76s - loss: 5.0591e-04 - val_loss: 0.0018 - 76s/epoch - 51ms/step
Epoch 19/200
1493/1493 - 77s - loss: 5.7103e-04 - val_loss: 4.7909e-04 - 77s/epoch - 51ms/step
Epoch 20/200
1493/1493 - 76s - loss: 4.4591e-04 - val_loss: 4.5710e-04 - 76s/epoch - 51ms/step
Epoch 21/200
1493/1493 - 77s - loss: 4.2193e-04 - val_loss: 5.3894e-04 - 77s/epoch - 51ms/step
Epoch 22/200
1493/1493 - 76s - loss: 4.0277e-04 - val_loss: 4.3876e-04 - 76s/epoch - 51ms/step
Epoch 23/200
1493/1493 - 76s - loss: 3.8428e-04 - val_loss: 4.9316e-04 - 76s/epoch - 51ms/step
Epoch 24/200
1493/1493 - 77s - loss: 3.7351e-04 - val_loss: 3.4109e-04 - 77s/epoch - 51ms/step
Epoch 25/200
1493/1493 - 77s - loss: 3.5531e-04 - val_loss: 3.3576e-04 - 77s/epoch - 51ms/step
Epoch 26/200
1493/1493 - 77s - loss: 3.3197e-04 - val_loss: 3.7618e-04 - 77s/epoch - 51ms/step
Epoch 27/200
1493/1493 - 76s - loss: 3.1358e-04 - val_loss: 3.1556e-04 - 76s/epoch - 51ms/step
Epoch 28/200
1493/1493 - 77s - loss: 2.9870e-04 - val_loss: 5.2009e-04 - 77s/epoch - 52ms/step
Epoch 29/200
1493/1493 - 77s - loss: 2.9880e-04 - val_loss: 4.5594e-04 - 77s/epoch - 51ms/step
Epoch 30/200
1493/1493 - 76s - loss: 3.1733e-04 - val_loss: 3.0552e-04 - 76s/epoch - 51ms/step
Epoch 31/200
1493/1493 - 77s - loss: 2.7605e-04 - val_loss: 4.1631e-04 - 77s/epoch - 51ms/step
Epoch 32/200
1493/1493 - 78s - loss: 3.0822e-04 - val_loss: 3.0426e-04 - 78s/epoch - 52ms/step
Epoch 33/200
1493/1493 - 77s - loss: 2.7559e-04 - val_loss: 2.7125e-04 - 77s/epoch - 52ms/step
Epoch 34/200
1493/1493 - 77s - loss: 2.5689e-04 - val_loss: 2.4230e-04 - 77s/epoch - 52ms/step
Epoch 35/200
1493/1493 - 77s - loss: 2.4743e-04 - val_loss: 7.3329e-04 - 77s/epoch - 51ms/step
Epoch 36/200
1493/1493 - 76s - loss: 2.7887e-04 - val_loss: 2.9625e-04 - 76s/epoch - 51ms/step
Epoch 37/200
1493/1493 - 77s - loss: 2.4002e-04 - val_loss: 6.4217e-04 - 77s/epoch - 51ms/step
Epoch 38/200
1493/1493 - 77s - loss: 2.8461e-04 - val_loss: 2.1435e-04 - 77s/epoch - 52ms/step
Epoch 39/200
1493/1493 - 77s - loss: 2.2912e-04 - val_loss: 2.1456e-04 - 77s/epoch - 52ms/step
Epoch 40/200
1493/1493 - 76s - loss: 2.2027e-04 - val_loss: 2.8130e-04 - 76s/epoch - 51ms/step
Epoch 41/200
1493/1493 - 77s - loss: 2.2506e-04 - val_loss: 2.1177e-04 - 77s/epoch - 51ms/step
Epoch 42/200
1493/1493 - 77s - loss: 2.1402e-04 - val_loss: 2.1800e-04 - 77s/epoch - 52ms/step
Epoch 43/200
1493/1493 - 77s - loss: 2.1400e-04 - val_loss: 3.3294e-04 - 77s/epoch - 51ms/step
Epoch 44/200
1493/1493 - 77s - loss: 2.1840e-04 - val_loss: 4.7521e-04 - 77s/epoch - 52ms/step
Epoch 45/200
1493/1493 - 76s - loss: 2.2779e-04 - val_loss: 1.7843e-04 - 76s/epoch - 51ms/step
Epoch 46/200
1493/1493 - 76s - loss: 2.0115e-04 - val_loss: 1.9551e-04 - 76s/epoch - 51ms/step
Epoch 47/200
1493/1493 - 76s - loss: 1.9793e-04 - val_loss: 2.2443e-04 - 76s/epoch - 51ms/step
Epoch 48/200
1493/1493 - 77s - loss: 1.9770e-04 - val_loss: 2.4773e-04 - 77s/epoch - 52ms/step
Epoch 49/200
1493/1493 - 77s - loss: 1.9586e-04 - val_loss: 0.0014 - 77s/epoch - 51ms/step
Epoch 50/200
1493/1493 - 76s - loss: 3.4099e-04 - val_loss: 0.0010 - 76s/epoch - 51ms/step
Epoch 51/200
1493/1493 - 77s - loss: 2.7825e-04 - val_loss: 1.7081e-04 - 77s/epoch - 52ms/step
Epoch 52/200
1493/1493 - 77s - loss: 1.9824e-04 - val_loss: 1.7500e-04 - 77s/epoch - 52ms/step
Epoch 53/200
1493/1493 - 76s - loss: 1.9338e-04 - val_loss: 1.6165e-04 - 76s/epoch - 51ms/step
Epoch 54/200
1493/1493 - 77s - loss: 1.8443e-04 - val_loss: 2.1025e-04 - 77s/epoch - 51ms/step
Epoch 55/200
1493/1493 - 77s - loss: 1.8025e-04 - val_loss: 1.8800e-04 - 77s/epoch - 51ms/step
Epoch 56/200
1493/1493 - 76s - loss: 1.7947e-04 - val_loss: 2.0423e-04 - 76s/epoch - 51ms/step
Epoch 57/200
1493/1493 - 77s - loss: 1.7273e-04 - val_loss: 1.9166e-04 - 77s/epoch - 51ms/step
Epoch 58/200
1493/1493 - 77s - loss: 1.7249e-04 - val_loss: 1.5222e-04 - 77s/epoch - 52ms/step
Epoch 59/200
1493/1493 - 77s - loss: 1.6709e-04 - val_loss: 1.8003e-04 - 77s/epoch - 52ms/step
Epoch 60/200
1493/1493 - 77s - loss: 1.6844e-04 - val_loss: 4.6420e-04 - 77s/epoch - 52ms/step
Epoch 61/200
1493/1493 - 77s - loss: 2.1060e-04 - val_loss: 1.7159e-04 - 77s/epoch - 52ms/step
Epoch 62/200
1493/1493 - 77s - loss: 1.6418e-04 - val_loss: 2.0204e-04 - 77s/epoch - 52ms/step
Epoch 63/200
1493/1493 - 76s - loss: 1.6177e-04 - val_loss: 2.2296e-04 - 76s/epoch - 51ms/step
Epoch 64/200
1493/1493 - 76s - loss: 1.6102e-04 - val_loss: 3.7815e-04 - 76s/epoch - 51ms/step
Epoch 65/200
1493/1493 - 77s - loss: 1.7680e-04 - val_loss: 1.6860e-04 - 77s/epoch - 52ms/step
Epoch 66/200
1493/1493 - 77s - loss: 1.6092e-04 - val_loss: 1.8520e-04 - 77s/epoch - 51ms/step
Epoch 67/200
1493/1493 - 77s - loss: 1.5263e-04 - val_loss: 1.5805e-04 - 77s/epoch - 52ms/step
Epoch 68/200
1493/1493 - 77s - loss: 1.5063e-04 - val_loss: 2.5130e-04 - 77s/epoch - 52ms/step
Epoch 69/200
1493/1493 - 78s - loss: 1.7447e-04 - val_loss: 1.5689e-04 - 78s/epoch - 52ms/step
Epoch 70/200
1493/1493 - 77s - loss: 1.5300e-04 - val_loss: 4.2843e-04 - 77s/epoch - 52ms/step
Epoch 71/200
1493/1493 - 77s - loss: 1.9120e-04 - val_loss: 1.5044e-04 - 77s/epoch - 52ms/step
Epoch 72/200
1493/1493 - 77s - loss: 1.5269e-04 - val_loss: 1.5643e-04 - 77s/epoch - 51ms/step
Epoch 73/200
1493/1493 - 77s - loss: 1.5071e-04 - val_loss: 1.6363e-04 - 77s/epoch - 51ms/step
Epoch 74/200
1493/1493 - 76s - loss: 1.4837e-04 - val_loss: 1.4415e-04 - 76s/epoch - 51ms/step
Epoch 75/200
1493/1493 - 76s - loss: 1.4265e-04 - val_loss: 1.3058e-04 - 76s/epoch - 51ms/step
Epoch 76/200
1493/1493 - 77s - loss: 1.4048e-04 - val_loss: 1.3621e-04 - 77s/epoch - 51ms/step
Epoch 77/200
1493/1493 - 76s - loss: 1.4312e-04 - val_loss: 2.7255e-04 - 76s/epoch - 51ms/step
Epoch 78/200
1493/1493 - 77s - loss: 1.4521e-04 - val_loss: 1.9578e-04 - 77s/epoch - 51ms/step
Epoch 79/200
1493/1493 - 77s - loss: 1.4466e-04 - val_loss: 4.3140e-04 - 77s/epoch - 51ms/step
Epoch 80/200
1493/1493 - 77s - loss: 2.0103e-04 - val_loss: 1.4579e-04 - 77s/epoch - 51ms/step
Epoch 81/200
1493/1493 - 77s - loss: 1.4329e-04 - val_loss: 2.2366e-04 - 77s/epoch - 52ms/step
Epoch 82/200
1493/1493 - 77s - loss: 1.3943e-04 - val_loss: 1.3371e-04 - 77s/epoch - 51ms/step
Epoch 83/200
1493/1493 - 76s - loss: 1.3354e-04 - val_loss: 1.4818e-04 - 76s/epoch - 51ms/step
Epoch 84/200
1493/1493 - 77s - loss: 1.3249e-04 - val_loss: 1.5325e-04 - 77s/epoch - 51ms/step
Epoch 85/200
1493/1493 - 77s - loss: 1.3658e-04 - val_loss: 1.4403e-04 - 77s/epoch - 52ms/step
Epoch 86/200
1493/1493 - 77s - loss: 1.3267e-04 - val_loss: 1.3231e-04 - 77s/epoch - 51ms/step
Epoch 87/200
1493/1493 - 77s - loss: 1.2803e-04 - val_loss: 1.2466e-04 - 77s/epoch - 51ms/step
Epoch 88/200
1493/1493 - 77s - loss: 1.2677e-04 - val_loss: 1.3569e-04 - 77s/epoch - 51ms/step
Epoch 89/200
1493/1493 - 77s - loss: 1.3056e-04 - val_loss: 1.1983e-04 - 77s/epoch - 52ms/step
Epoch 90/200
1493/1493 - 77s - loss: 1.2547e-04 - val_loss: 1.2822e-04 - 77s/epoch - 52ms/step
Epoch 91/200
1493/1493 - 77s - loss: 1.2423e-04 - val_loss: 1.4813e-04 - 77s/epoch - 52ms/step
Epoch 92/200
1493/1493 - 77s - loss: 1.2402e-04 - val_loss: 4.6578e-04 - 77s/epoch - 52ms/step
Epoch 93/200
1493/1493 - 77s - loss: 1.6163e-04 - val_loss: 3.4730e-04 - 77s/epoch - 52ms/step
Epoch 94/200
1493/1493 - 78s - loss: 1.5365e-04 - val_loss: 1.1188e-04 - 78s/epoch - 52ms/step
Epoch 95/200
1493/1493 - 77s - loss: 1.2585e-04 - val_loss: 1.4133e-04 - 77s/epoch - 51ms/step
Epoch 96/200
1493/1493 - 77s - loss: 1.2424e-04 - val_loss: 1.4843e-04 - 77s/epoch - 52ms/step
Epoch 97/200
1493/1493 - 78s - loss: 1.2234e-04 - val_loss: 1.2489e-04 - 78s/epoch - 52ms/step
Epoch 98/200
1493/1493 - 77s - loss: 1.2383e-04 - val_loss: 0.0011 - 77s/epoch - 52ms/step
Epoch 99/200
1493/1493 - 77s - loss: 2.2013e-04 - val_loss: 1.1132e-04 - 77s/epoch - 52ms/step
Epoch 100/200
1493/1493 - 77s - loss: 1.4033e-04 - val_loss: 1.0604e-04 - 77s/epoch - 51ms/step
Epoch 101/200
1493/1493 - 77s - loss: 1.2775e-04 - val_loss: 1.4848e-04 - 77s/epoch - 51ms/step
Epoch 102/200
1493/1493 - 77s - loss: 1.3307e-04 - val_loss: 1.8607e-04 - 77s/epoch - 51ms/step
Epoch 103/200
1493/1493 - 76s - loss: 1.2626e-04 - val_loss: 1.1680e-04 - 76s/epoch - 51ms/step
Epoch 104/200
1493/1493 - 76s - loss: 1.1874e-04 - val_loss: 2.5535e-04 - 76s/epoch - 51ms/step
Epoch 105/200
1493/1493 - 77s - loss: 1.3091e-04 - val_loss: 1.0682e-04 - 77s/epoch - 52ms/step
Epoch 106/200
1493/1493 - 75s - loss: 1.1693e-04 - val_loss: 1.3022e-04 - 75s/epoch - 51ms/step
Epoch 107/200
1493/1493 - 74s - loss: 1.1554e-04 - val_loss: 1.1822e-04 - 74s/epoch - 50ms/step
Epoch 108/200
1493/1493 - 74s - loss: 1.1669e-04 - val_loss: 1.2708e-04 - 74s/epoch - 50ms/step
Epoch 109/200
1493/1493 - 74s - loss: 1.1436e-04 - val_loss: 1.3945e-04 - 74s/epoch - 50ms/step
Epoch 110/200
1493/1493 - 74s - loss: 1.1290e-04 - val_loss: 1.2171e-04 - 74s/epoch - 49ms/step
Epoch 111/200
1493/1493 - 74s - loss: 1.1154e-04 - val_loss: 1.1559e-04 - 74s/epoch - 49ms/step
Epoch 112/200
1493/1493 - 74s - loss: 1.1295e-04 - val_loss: 1.0499e-04 - 74s/epoch - 50ms/step
Epoch 113/200
1493/1493 - 74s - loss: 1.1094e-04 - val_loss: 2.8083e-04 - 74s/epoch - 50ms/step
Epoch 114/200
1493/1493 - 74s - loss: 1.5449e-04 - val_loss: 1.0462e-04 - 74s/epoch - 50ms/step
Epoch 115/200
1493/1493 - 74s - loss: 1.1900e-04 - val_loss: 1.8437e-04 - 74s/epoch - 50ms/step
Epoch 116/200
1493/1493 - 74s - loss: 1.1351e-04 - val_loss: 1.2178e-04 - 74s/epoch - 49ms/step
Epoch 117/200
1493/1493 - 74s - loss: 1.0927e-04 - val_loss: 2.8691e-04 - 74s/epoch - 49ms/step
Epoch 118/200
1493/1493 - 74s - loss: 1.2408e-04 - val_loss: 1.2209e-04 - 74s/epoch - 49ms/step
Epoch 119/200
1493/1493 - 74s - loss: 1.1041e-04 - val_loss: 9.4114e-05 - 74s/epoch - 50ms/step
Epoch 120/200
1493/1493 - 74s - loss: 1.0774e-04 - val_loss: 1.0775e-04 - 74s/epoch - 50ms/step
Epoch 121/200
1493/1493 - 74s - loss: 1.0727e-04 - val_loss: 2.4099e-04 - 74s/epoch - 49ms/step
Epoch 122/200
1493/1493 - 74s - loss: 1.1878e-04 - val_loss: 9.3716e-05 - 74s/epoch - 50ms/step
Epoch 123/200
1493/1493 - 74s - loss: 1.0690e-04 - val_loss: 1.0946e-04 - 74s/epoch - 50ms/step
Epoch 124/200
1493/1493 - 74s - loss: 1.0579e-04 - val_loss: 2.9699e-04 - 74s/epoch - 50ms/step
Epoch 125/200
1493/1493 - 74s - loss: 1.3692e-04 - val_loss: 1.3542e-04 - 74s/epoch - 50ms/step
Epoch 126/200
1493/1493 - 74s - loss: 1.1074e-04 - val_loss: 1.3764e-04 - 74s/epoch - 50ms/step
Epoch 127/200
1493/1493 - 74s - loss: 1.0588e-04 - val_loss: 1.3330e-04 - 74s/epoch - 50ms/step
Epoch 128/200
1493/1493 - 74s - loss: 1.0528e-04 - val_loss: 9.1202e-05 - 74s/epoch - 50ms/step
Epoch 129/200
1493/1493 - 74s - loss: 1.0268e-04 - val_loss: 1.0707e-04 - 74s/epoch - 50ms/step
Epoch 130/200
1493/1493 - 74s - loss: 1.0199e-04 - val_loss: 9.3316e-05 - 74s/epoch - 50ms/step
Epoch 131/200
1493/1493 - 74s - loss: 1.0503e-04 - val_loss: 4.0979e-04 - 74s/epoch - 50ms/step
Epoch 132/200
1493/1493 - 74s - loss: 1.5679e-04 - val_loss: 9.0765e-05 - 74s/epoch - 50ms/step
Epoch 133/200
1493/1493 - 74s - loss: 1.0509e-04 - val_loss: 9.8981e-05 - 74s/epoch - 50ms/step
Epoch 134/200
1493/1493 - 74s - loss: 1.0182e-04 - val_loss: 9.7145e-05 - 74s/epoch - 50ms/step
Epoch 135/200
1493/1493 - 74s - loss: 1.0063e-04 - val_loss: 9.2487e-05 - 74s/epoch - 50ms/step
Epoch 136/200
1493/1493 - 74s - loss: 1.0048e-04 - val_loss: 1.5217e-04 - 74s/epoch - 50ms/step
Epoch 137/200
1493/1493 - 74s - loss: 1.1217e-04 - val_loss: 2.0680e-04 - 74s/epoch - 50ms/step
Epoch 138/200
1493/1493 - 74s - loss: 1.2288e-04 - val_loss: 1.4722e-04 - 74s/epoch - 50ms/step
Epoch 139/200
1493/1493 - 74s - loss: 1.1535e-04 - val_loss: 1.7898e-04 - 74s/epoch - 50ms/step
Epoch 140/200
1493/1493 - 74s - loss: 1.1809e-04 - val_loss: 8.5022e-05 - 74s/epoch - 50ms/step
Epoch 141/200
1493/1493 - 74s - loss: 1.0038e-04 - val_loss: 1.2324e-04 - 74s/epoch - 50ms/step
Epoch 142/200
1493/1493 - 74s - loss: 1.0279e-04 - val_loss: 1.0627e-04 - 74s/epoch - 50ms/step
Epoch 143/200
1493/1493 - 74s - loss: 9.7844e-05 - val_loss: 1.2473e-04 - 74s/epoch - 50ms/step
Epoch 144/200
1493/1493 - 74s - loss: 9.9522e-05 - val_loss: 9.9869e-05 - 74s/epoch - 50ms/step
Epoch 145/200
1493/1493 - 74s - loss: 9.7085e-05 - val_loss: 9.3098e-05 - 74s/epoch - 50ms/step
Epoch 146/200
1493/1493 - 74s - loss: 9.5991e-05 - val_loss: 1.0232e-04 - 74s/epoch - 50ms/step
Epoch 147/200
1493/1493 - 74s - loss: 9.5295e-05 - val_loss: 1.0006e-04 - 74s/epoch - 50ms/step
Epoch 148/200
1493/1493 - 74s - loss: 9.4200e-05 - val_loss: 1.4389e-04 - 74s/epoch - 50ms/step
Epoch 149/200
1493/1493 - 74s - loss: 9.4361e-05 - val_loss: 9.2365e-05 - 74s/epoch - 50ms/step
Epoch 150/200
1493/1493 - 74s - loss: 9.3323e-05 - val_loss: 9.6080e-05 - 74s/epoch - 50ms/step
Epoch 151/200
1493/1493 - 74s - loss: 9.3014e-05 - val_loss: 1.4152e-04 - 74s/epoch - 50ms/step
Epoch 152/200
1493/1493 - 74s - loss: 9.6253e-05 - val_loss: 1.1528e-04 - 74s/epoch - 50ms/step
Epoch 153/200
1493/1493 - 74s - loss: 9.3338e-05 - val_loss: 1.0883e-04 - 74s/epoch - 50ms/step
Epoch 154/200
1493/1493 - 74s - loss: 9.2104e-05 - val_loss: 9.7842e-05 - 74s/epoch - 50ms/step
Epoch 155/200
1493/1493 - 74s - loss: 9.1413e-05 - val_loss: 9.0775e-05 - 74s/epoch - 49ms/step
Epoch 156/200
1493/1493 - 74s - loss: 9.4820e-05 - val_loss: 9.5449e-05 - 74s/epoch - 50ms/step
Epoch 157/200
1493/1493 - 74s - loss: 9.0881e-05 - val_loss: 1.1263e-04 - 74s/epoch - 50ms/step
Epoch 158/200
1493/1493 - 74s - loss: 9.2372e-05 - val_loss: 1.0105e-04 - 74s/epoch - 50ms/step
Epoch 159/200
1493/1493 - 75s - loss: 9.0154e-05 - val_loss: 8.4109e-05 - 75s/epoch - 50ms/step
Epoch 160/200
1493/1493 - 74s - loss: 9.4706e-05 - val_loss: 1.5898e-04 - 74s/epoch - 50ms/step
Epoch 161/200
1493/1493 - 74s - loss: 1.3410e-04 - val_loss: 8.4926e-05 - 74s/epoch - 50ms/step
Epoch 162/200
1493/1493 - 74s - loss: 9.3866e-05 - val_loss: 9.0714e-05 - 74s/epoch - 50ms/step
Epoch 163/200
1493/1493 - 74s - loss: 9.1104e-05 - val_loss: 1.0418e-04 - 74s/epoch - 50ms/step
Epoch 164/200
1493/1493 - 74s - loss: 9.2647e-05 - val_loss: 9.6315e-05 - 74s/epoch - 50ms/step
Epoch 165/200
1493/1493 - 75s - loss: 9.3869e-05 - val_loss: 9.3618e-05 - 75s/epoch - 50ms/step
Epoch 166/200
1493/1493 - 74s - loss: 9.0474e-05 - val_loss: 1.0062e-04 - 74s/epoch - 50ms/step
Epoch 167/200
1493/1493 - 74s - loss: 8.9643e-05 - val_loss: 8.5136e-05 - 74s/epoch - 50ms/step
Epoch 168/200
1493/1493 - 74s - loss: 8.7926e-05 - val_loss: 8.1532e-05 - 74s/epoch - 50ms/step
Epoch 169/200
1493/1493 - 74s - loss: 8.7903e-05 - val_loss: 1.3662e-04 - 74s/epoch - 50ms/step
Epoch 170/200
1493/1493 - 74s - loss: 8.9409e-05 - val_loss: 2.6003e-04 - 74s/epoch - 50ms/step
Epoch 171/200
1493/1493 - 74s - loss: 1.2342e-04 - val_loss: 2.2579e-04 - 74s/epoch - 49ms/step
Epoch 172/200
1493/1493 - 74s - loss: 1.0664e-04 - val_loss: 1.0399e-04 - 74s/epoch - 50ms/step
Epoch 173/200
1493/1493 - 74s - loss: 9.1935e-05 - val_loss: 8.2600e-05 - 74s/epoch - 50ms/step
Epoch 174/200
1493/1493 - 74s - loss: 8.8215e-05 - val_loss: 9.0718e-05 - 74s/epoch - 50ms/step
Epoch 175/200
1493/1493 - 74s - loss: 8.8970e-05 - val_loss: 1.1051e-04 - 74s/epoch - 50ms/step
Epoch 176/200
1493/1493 - 74s - loss: 8.8848e-05 - val_loss: 8.9862e-05 - 74s/epoch - 50ms/step
Epoch 177/200
1493/1493 - 74s - loss: 8.7059e-05 - val_loss: 7.7144e-05 - 74s/epoch - 50ms/step
Epoch 178/200
1493/1493 - 74s - loss: 8.6320e-05 - val_loss: 8.7138e-05 - 74s/epoch - 50ms/step
Epoch 179/200
1493/1493 - 74s - loss: 8.6067e-05 - val_loss: 1.1193e-04 - 74s/epoch - 50ms/step
Epoch 180/200
1493/1493 - 74s - loss: 8.7676e-05 - val_loss: 8.5718e-05 - 74s/epoch - 50ms/step
Epoch 181/200
1493/1493 - 74s - loss: 8.6174e-05 - val_loss: 8.7912e-05 - 74s/epoch - 50ms/step
Epoch 182/200
1493/1493 - 74s - loss: 8.4990e-05 - val_loss: 1.1441e-04 - 74s/epoch - 50ms/step
Epoch 183/200
1493/1493 - 74s - loss: 8.4848e-05 - val_loss: 8.8492e-05 - 74s/epoch - 50ms/step
Epoch 184/200
1493/1493 - 75s - loss: 8.4491e-05 - val_loss: 8.5155e-05 - 75s/epoch - 50ms/step
Epoch 185/200
1493/1493 - 74s - loss: 8.5933e-05 - val_loss: 3.4047e-04 - 74s/epoch - 50ms/step
Epoch 186/200
1493/1493 - 74s - loss: 1.2720e-04 - val_loss: 7.7096e-05 - 74s/epoch - 50ms/step
Epoch 187/200
1493/1493 - 74s - loss: 8.9291e-05 - val_loss: 9.0228e-05 - 74s/epoch - 50ms/step
Epoch 188/200
1493/1493 - 74s - loss: 9.5444e-05 - val_loss: 8.9481e-05 - 74s/epoch - 50ms/step
Epoch 189/200
1493/1493 - 74s - loss: 8.6515e-05 - val_loss: 9.0962e-05 - 74s/epoch - 50ms/step
Epoch 190/200
1493/1493 - 74s - loss: 8.6222e-05 - val_loss: 9.5560e-05 - 74s/epoch - 50ms/step
Epoch 191/200
1493/1493 - 74s - loss: 8.6433e-05 - val_loss: 1.0541e-04 - 74s/epoch - 50ms/step
Epoch 192/200
1493/1493 - 74s - loss: 8.5110e-05 - val_loss: 1.0398e-04 - 74s/epoch - 50ms/step
Epoch 193/200
1493/1493 - 74s - loss: 8.5607e-05 - val_loss: 1.9308e-04 - 74s/epoch - 49ms/step
Epoch 194/200
1493/1493 - 74s - loss: 1.0160e-04 - val_loss: 6.7323e-04 - 74s/epoch - 50ms/step
Epoch 195/200
1493/1493 - 74s - loss: 1.3918e-04 - val_loss: 1.6329e-04 - 74s/epoch - 49ms/step
Epoch 196/200
1493/1493 - 74s - loss: 1.0426e-04 - val_loss: 7.7443e-05 - 74s/epoch - 49ms/step
Epoch 197/200
1493/1493 - 74s - loss: 8.8573e-05 - val_loss: 1.4175e-04 - 74s/epoch - 50ms/step
Epoch 198/200
1493/1493 - 74s - loss: 9.5985e-05 - val_loss: 3.1247e-04 - 74s/epoch - 49ms/step
Epoch 199/200
1493/1493 - 74s - loss: 1.0769e-04 - val_loss: 7.7928e-05 - 74s/epoch - 50ms/step
Epoch 200/200
1493/1493 - 74s - loss: 8.6246e-05 - val_loss: 7.9727e-05 - 74s/epoch - 49ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 7.972709863679484e-05
  1/332 [..............................] - ETA: 39s  7/332 [..............................] - ETA: 2s  14/332 [>.............................] - ETA: 2s 21/332 [>.............................] - ETA: 2s 28/332 [=>............................] - ETA: 2s 36/332 [==>...........................] - ETA: 2s 43/332 [==>...........................] - ETA: 2s 51/332 [===>..........................] - ETA: 2s 59/332 [====>.........................] - ETA: 2s 66/332 [====>.........................] - ETA: 1s 74/332 [=====>........................] - ETA: 1s 82/332 [======>.......................] - ETA: 1s 90/332 [=======>......................] - ETA: 1s 98/332 [=======>......................] - ETA: 1s105/332 [========>.....................] - ETA: 1s113/332 [=========>....................] - ETA: 1s121/332 [=========>....................] - ETA: 1s128/332 [==========>...................] - ETA: 1s136/332 [===========>..................] - ETA: 1s143/332 [===========>..................] - ETA: 1s150/332 [============>.................] - ETA: 1s158/332 [=============>................] - ETA: 1s165/332 [=============>................] - ETA: 1s173/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s189/332 [================>.............] - ETA: 1s197/332 [================>.............] - ETA: 0s204/332 [=================>............] - ETA: 0s211/332 [==================>...........] - ETA: 0s219/332 [==================>...........] - ETA: 0s227/332 [===================>..........] - ETA: 0s235/332 [====================>.........] - ETA: 0s243/332 [====================>.........] - ETA: 0s251/332 [=====================>........] - ETA: 0s259/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s273/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s289/332 [=========================>....] - ETA: 0s297/332 [=========================>....] - ETA: 0s305/332 [==========================>...] - ETA: 0s313/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s328/332 [============================>.] - ETA: 0s332/332 [==============================] - 2s 7ms/step
correlation 0.0008986511973673292
cosine 0.0007086222716830067
MAE: 0.0050231456
RMSE: 0.008929001
r2: 0.9948290420514337
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_18"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 2654)              3357310   
                                                                 
 batch_normalization_18 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2654)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2684205   
                                                                 
 batch_normalization_19 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 1011)              0         
                                                                 
 dense_19 (Dense)            (None, 2654)              2685848   
                                                                 
 batch_normalization_20 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2654)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3355920   
                                                                 
=================================================================
Total params: 12,108,559
Trainable params: 12,095,921
Non-trainable params: 12,638
_________________________________________________________________
Encoder
Model: "model_19"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_20 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_19 (InputLayer)       multiple                  0         
                                                                 
 dense_18 (Dense)            (None, 2654)              3357310   
                                                                 
 batch_normalization_18 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_18 (ReLU)             (None, 2654)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2684205   
                                                                 
=================================================================
Total params: 6,052,131
Trainable params: 6,046,823
Non-trainable params: 5,308
_________________________________________________________________
Decoder
Model: "model_20"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_21 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_19 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_19 (ReLU)             (None, 1011)              0         
                                                                 
 dense_19 (Dense)            (None, 2654)              2685848   
                                                                 
 batch_normalization_20 (Bat  (None, 2654)             10616     
 chNormalization)                                                
                                                                 
 re_lu_20 (ReLU)             (None, 2654)              0         
                                                                 
 dense_20 (Dense)            (None, 1264)              3355920   
                                                                 
=================================================================
Total params: 6,056,428
Trainable params: 6,049,098
Non-trainable params: 7,330
_________________________________________________________________
['2.1custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.624602924101055e-05, 7.972709863679484e-05, 0.0008986511973673292, 0.0007086222716830067, 0.005023145582526922, 0.008929001167416573, 0.9948290420514337, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_21 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_21 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2811591   
                                                                 
 batch_normalization_22 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 1011)              0         
                                                                 
 dense_22 (Dense)            (None, 2780)              2813360   
                                                                 
 batch_normalization_23 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 2780)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 12,683,119
Trainable params: 12,669,977
Non-trainable params: 13,142
_________________________________________________________________
Epoch 1/200
1493/1493 - 95s - loss: 0.0090 - val_loss: 0.0044 - 95s/epoch - 64ms/step
Epoch 2/200
1493/1493 - 94s - loss: 0.0028 - val_loss: 0.0029 - 94s/epoch - 63ms/step
Epoch 3/200
1493/1493 - 94s - loss: 0.0020 - val_loss: 0.0015 - 94s/epoch - 63ms/step
Epoch 4/200
1493/1493 - 94s - loss: 0.0016 - val_loss: 0.0041 - 94s/epoch - 63ms/step
Epoch 5/200
1493/1493 - 96s - loss: 0.0016 - val_loss: 0.0018 - 96s/epoch - 64ms/step
Epoch 6/200
1493/1493 - 96s - loss: 0.0014 - val_loss: 0.0012 - 96s/epoch - 64ms/step
Epoch 7/200
1493/1493 - 95s - loss: 0.0014 - val_loss: 0.0012 - 95s/epoch - 64ms/step
Epoch 8/200
1493/1493 - 95s - loss: 0.0011 - val_loss: 0.0010 - 95s/epoch - 64ms/step
Epoch 9/200
1493/1493 - 96s - loss: 0.0010 - val_loss: 9.2708e-04 - 96s/epoch - 64ms/step
Epoch 10/200
1493/1493 - 95s - loss: 8.9797e-04 - val_loss: 6.7506e-04 - 95s/epoch - 64ms/step
Epoch 11/200
1493/1493 - 95s - loss: 8.2415e-04 - val_loss: 6.1435e-04 - 95s/epoch - 64ms/step
Epoch 12/200
1493/1493 - 95s - loss: 7.1759e-04 - val_loss: 0.0013 - 95s/epoch - 64ms/step
Epoch 13/200
1493/1493 - 95s - loss: 7.1728e-04 - val_loss: 0.0022 - 95s/epoch - 64ms/step
Epoch 14/200
1493/1493 - 96s - loss: 7.7824e-04 - val_loss: 5.8966e-04 - 96s/epoch - 64ms/step
Epoch 15/200
1493/1493 - 96s - loss: 5.9555e-04 - val_loss: 8.1410e-04 - 96s/epoch - 64ms/step
Epoch 16/200
1493/1493 - 95s - loss: 5.7312e-04 - val_loss: 4.9631e-04 - 95s/epoch - 64ms/step
Epoch 17/200
1493/1493 - 95s - loss: 4.9256e-04 - val_loss: 5.0694e-04 - 95s/epoch - 64ms/step
Epoch 18/200
1493/1493 - 95s - loss: 4.6194e-04 - val_loss: 6.5586e-04 - 95s/epoch - 63ms/step
Epoch 19/200
1493/1493 - 77s - loss: 4.5801e-04 - val_loss: 6.4646e-04 - 77s/epoch - 51ms/step
Epoch 20/200
1493/1493 - 76s - loss: 4.3595e-04 - val_loss: 4.2388e-04 - 76s/epoch - 51ms/step
Epoch 21/200
1493/1493 - 76s - loss: 3.9495e-04 - val_loss: 4.9836e-04 - 76s/epoch - 51ms/step
Epoch 22/200
1493/1493 - 76s - loss: 4.0646e-04 - val_loss: 6.0030e-04 - 76s/epoch - 51ms/step
Epoch 23/200
1493/1493 - 76s - loss: 4.2784e-04 - val_loss: 0.0011 - 76s/epoch - 51ms/step
Epoch 24/200
1493/1493 - 76s - loss: 4.1743e-04 - val_loss: 4.8204e-04 - 76s/epoch - 51ms/step
Epoch 25/200
1493/1493 - 76s - loss: 3.5330e-04 - val_loss: 3.0936e-04 - 76s/epoch - 51ms/step
Epoch 26/200
1493/1493 - 76s - loss: 3.2403e-04 - val_loss: 3.4869e-04 - 76s/epoch - 51ms/step
Epoch 27/200
1493/1493 - 77s - loss: 3.0753e-04 - val_loss: 2.9618e-04 - 77s/epoch - 52ms/step
Epoch 28/200
1493/1493 - 77s - loss: 2.9535e-04 - val_loss: 4.6241e-04 - 77s/epoch - 51ms/step
Epoch 29/200
1493/1493 - 77s - loss: 2.8544e-04 - val_loss: 4.9856e-04 - 77s/epoch - 51ms/step
Epoch 30/200
1493/1493 - 76s - loss: 3.0768e-04 - val_loss: 2.8574e-04 - 76s/epoch - 51ms/step
Epoch 31/200
1493/1493 - 77s - loss: 2.6753e-04 - val_loss: 5.7020e-04 - 77s/epoch - 51ms/step
Epoch 32/200
1493/1493 - 76s - loss: 3.0176e-04 - val_loss: 2.8837e-04 - 76s/epoch - 51ms/step
Epoch 33/200
1493/1493 - 77s - loss: 2.6432e-04 - val_loss: 2.5320e-04 - 77s/epoch - 51ms/step
Epoch 34/200
1493/1493 - 76s - loss: 2.5125e-04 - val_loss: 2.1596e-04 - 76s/epoch - 51ms/step
Epoch 35/200
1493/1493 - 76s - loss: 2.4033e-04 - val_loss: 7.9058e-04 - 76s/epoch - 51ms/step
Epoch 36/200
1493/1493 - 77s - loss: 2.8591e-04 - val_loss: 2.6101e-04 - 77s/epoch - 51ms/step
Epoch 37/200
1493/1493 - 76s - loss: 2.3463e-04 - val_loss: 2.4467e-04 - 76s/epoch - 51ms/step
Epoch 38/200
1493/1493 - 76s - loss: 2.3794e-04 - val_loss: 2.2401e-04 - 76s/epoch - 51ms/step
Epoch 39/200
1493/1493 - 76s - loss: 2.2260e-04 - val_loss: 2.1795e-04 - 76s/epoch - 51ms/step
Epoch 40/200
1493/1493 - 76s - loss: 2.1109e-04 - val_loss: 2.9734e-04 - 76s/epoch - 51ms/step
Epoch 41/200
1493/1493 - 76s - loss: 2.1307e-04 - val_loss: 1.8708e-04 - 76s/epoch - 51ms/step
Epoch 42/200
1493/1493 - 76s - loss: 2.0651e-04 - val_loss: 2.0253e-04 - 76s/epoch - 51ms/step
Epoch 43/200
1493/1493 - 76s - loss: 2.0999e-04 - val_loss: 3.6138e-04 - 76s/epoch - 51ms/step
Epoch 44/200
1493/1493 - 76s - loss: 2.1589e-04 - val_loss: 5.7344e-04 - 76s/epoch - 51ms/step
Epoch 45/200
1493/1493 - 77s - loss: 2.3548e-04 - val_loss: 1.8151e-04 - 77s/epoch - 51ms/step
Epoch 46/200
1493/1493 - 77s - loss: 1.9382e-04 - val_loss: 1.8163e-04 - 77s/epoch - 51ms/step
Epoch 47/200
1493/1493 - 77s - loss: 1.9084e-04 - val_loss: 2.4771e-04 - 77s/epoch - 51ms/step
Epoch 48/200
1493/1493 - 77s - loss: 1.9052e-04 - val_loss: 2.3311e-04 - 77s/epoch - 51ms/step
Epoch 49/200
1493/1493 - 76s - loss: 1.8865e-04 - val_loss: 0.0015 - 76s/epoch - 51ms/step
Epoch 50/200
1493/1493 - 76s - loss: 3.0919e-04 - val_loss: 0.0019 - 76s/epoch - 51ms/step
Epoch 51/200
1493/1493 - 77s - loss: 3.0979e-04 - val_loss: 1.9793e-04 - 77s/epoch - 51ms/step
Epoch 52/200
1493/1493 - 77s - loss: 1.8854e-04 - val_loss: 1.9023e-04 - 77s/epoch - 51ms/step
Epoch 53/200
1493/1493 - 77s - loss: 1.8453e-04 - val_loss: 1.5878e-04 - 77s/epoch - 51ms/step
Epoch 54/200
1493/1493 - 77s - loss: 1.7595e-04 - val_loss: 2.1000e-04 - 77s/epoch - 51ms/step
Epoch 55/200
1493/1493 - 77s - loss: 1.7261e-04 - val_loss: 1.6988e-04 - 77s/epoch - 51ms/step
Epoch 56/200
1493/1493 - 77s - loss: 1.7111e-04 - val_loss: 2.0869e-04 - 77s/epoch - 51ms/step
Epoch 57/200
1493/1493 - 77s - loss: 1.6718e-04 - val_loss: 1.7742e-04 - 77s/epoch - 51ms/step
Epoch 58/200
1493/1493 - 76s - loss: 1.6579e-04 - val_loss: 1.5492e-04 - 76s/epoch - 51ms/step
Epoch 59/200
1493/1493 - 77s - loss: 1.6052e-04 - val_loss: 1.7686e-04 - 77s/epoch - 51ms/step
Epoch 60/200
1493/1493 - 76s - loss: 1.6242e-04 - val_loss: 5.8973e-04 - 76s/epoch - 51ms/step
Epoch 61/200
1493/1493 - 77s - loss: 3.0767e-04 - val_loss: 1.5280e-04 - 77s/epoch - 51ms/step
Epoch 62/200
1493/1493 - 77s - loss: 1.7121e-04 - val_loss: 1.7837e-04 - 77s/epoch - 51ms/step
Epoch 63/200
1493/1493 - 77s - loss: 1.6880e-04 - val_loss: 1.9988e-04 - 77s/epoch - 51ms/step
Epoch 64/200
1493/1493 - 76s - loss: 1.5922e-04 - val_loss: 1.8877e-04 - 76s/epoch - 51ms/step
Epoch 65/200
1493/1493 - 77s - loss: 1.5545e-04 - val_loss: 1.6375e-04 - 77s/epoch - 51ms/step
Epoch 66/200
1493/1493 - 76s - loss: 1.5339e-04 - val_loss: 2.5422e-04 - 76s/epoch - 51ms/step
Epoch 67/200
1493/1493 - 77s - loss: 1.5343e-04 - val_loss: 1.4852e-04 - 77s/epoch - 51ms/step
Epoch 68/200
1493/1493 - 76s - loss: 1.4573e-04 - val_loss: 2.5144e-04 - 76s/epoch - 51ms/step
Epoch 69/200
1493/1493 - 76s - loss: 1.6187e-04 - val_loss: 1.5276e-04 - 76s/epoch - 51ms/step
Epoch 70/200
1493/1493 - 76s - loss: 1.4641e-04 - val_loss: 5.7782e-04 - 76s/epoch - 51ms/step
Epoch 71/200
1493/1493 - 77s - loss: 1.9961e-04 - val_loss: 1.3965e-04 - 77s/epoch - 51ms/step
Epoch 72/200
1493/1493 - 76s - loss: 1.4942e-04 - val_loss: 1.8572e-04 - 76s/epoch - 51ms/step
Epoch 73/200
1493/1493 - 76s - loss: 1.4963e-04 - val_loss: 1.4724e-04 - 76s/epoch - 51ms/step
Epoch 74/200
1493/1493 - 77s - loss: 1.4494e-04 - val_loss: 1.4638e-04 - 77s/epoch - 51ms/step
Epoch 75/200
1493/1493 - 76s - loss: 1.3790e-04 - val_loss: 1.2504e-04 - 76s/epoch - 51ms/step
Epoch 76/200
1493/1493 - 77s - loss: 1.3814e-04 - val_loss: 1.3054e-04 - 77s/epoch - 51ms/step
Epoch 77/200
1493/1493 - 76s - loss: 1.3376e-04 - val_loss: 8.8899e-04 - 76s/epoch - 51ms/step
Epoch 78/200
1493/1493 - 75s - loss: 1.7172e-04 - val_loss: 1.4616e-04 - 75s/epoch - 50ms/step
Epoch 79/200
1493/1493 - 75s - loss: 1.4139e-04 - val_loss: 3.9276e-04 - 75s/epoch - 50ms/step
Epoch 80/200
1493/1493 - 75s - loss: 1.9412e-04 - val_loss: 1.3467e-04 - 75s/epoch - 50ms/step
Epoch 81/200
1493/1493 - 75s - loss: 1.4131e-04 - val_loss: 3.7695e-04 - 75s/epoch - 50ms/step
Epoch 82/200
1493/1493 - 75s - loss: 1.3843e-04 - val_loss: 1.3036e-04 - 75s/epoch - 50ms/step
Epoch 83/200
1493/1493 - 75s - loss: 1.3045e-04 - val_loss: 1.3261e-04 - 75s/epoch - 50ms/step
Epoch 84/200
1493/1493 - 75s - loss: 1.2934e-04 - val_loss: 1.3511e-04 - 75s/epoch - 50ms/step
Epoch 85/200
1493/1493 - 75s - loss: 1.3010e-04 - val_loss: 1.3480e-04 - 75s/epoch - 51ms/step
Epoch 86/200
1493/1493 - 75s - loss: 1.2833e-04 - val_loss: 1.4463e-04 - 75s/epoch - 50ms/step
Epoch 87/200
1493/1493 - 75s - loss: 1.2378e-04 - val_loss: 1.1485e-04 - 75s/epoch - 50ms/step
Epoch 88/200
1493/1493 - 75s - loss: 1.2414e-04 - val_loss: 1.3615e-04 - 75s/epoch - 50ms/step
Epoch 89/200
1493/1493 - 76s - loss: 1.2646e-04 - val_loss: 1.2702e-04 - 76s/epoch - 51ms/step
Epoch 90/200
1493/1493 - 75s - loss: 1.2191e-04 - val_loss: 1.3668e-04 - 75s/epoch - 51ms/step
Epoch 91/200
1493/1493 - 75s - loss: 1.2041e-04 - val_loss: 1.2963e-04 - 75s/epoch - 50ms/step
Epoch 92/200
1493/1493 - 75s - loss: 1.2364e-04 - val_loss: 4.1079e-04 - 75s/epoch - 50ms/step
Epoch 93/200
1493/1493 - 75s - loss: 1.5814e-04 - val_loss: 3.4557e-04 - 75s/epoch - 50ms/step
Epoch 94/200
1493/1493 - 75s - loss: 1.4747e-04 - val_loss: 1.0636e-04 - 75s/epoch - 50ms/step
Epoch 95/200
1493/1493 - 75s - loss: 1.2385e-04 - val_loss: 7.2832e-04 - 75s/epoch - 50ms/step
Epoch 96/200
1493/1493 - 75s - loss: 1.9495e-04 - val_loss: 1.3639e-04 - 75s/epoch - 50ms/step
Epoch 97/200
1493/1493 - 75s - loss: 1.2971e-04 - val_loss: 1.1517e-04 - 75s/epoch - 50ms/step
Epoch 98/200
1493/1493 - 75s - loss: 1.2362e-04 - val_loss: 2.2460e-04 - 75s/epoch - 51ms/step
Epoch 99/200
1493/1493 - 75s - loss: 1.3517e-04 - val_loss: 1.0974e-04 - 75s/epoch - 50ms/step
Epoch 100/200
1493/1493 - 75s - loss: 1.2344e-04 - val_loss: 1.1093e-04 - 75s/epoch - 50ms/step
Epoch 101/200
1493/1493 - 75s - loss: 1.1800e-04 - val_loss: 2.2276e-04 - 75s/epoch - 50ms/step
Epoch 102/200
1493/1493 - 75s - loss: 1.3633e-04 - val_loss: 1.3564e-04 - 75s/epoch - 50ms/step
Epoch 103/200
1493/1493 - 75s - loss: 1.1826e-04 - val_loss: 1.1602e-04 - 75s/epoch - 50ms/step
Epoch 104/200
1493/1493 - 75s - loss: 1.1453e-04 - val_loss: 4.5892e-04 - 75s/epoch - 50ms/step
Epoch 105/200
1493/1493 - 75s - loss: 1.4267e-04 - val_loss: 9.2164e-05 - 75s/epoch - 51ms/step
Epoch 106/200
1493/1493 - 76s - loss: 1.1414e-04 - val_loss: 1.1261e-04 - 76s/epoch - 51ms/step
Epoch 107/200
1493/1493 - 76s - loss: 1.1320e-04 - val_loss: 1.1680e-04 - 76s/epoch - 51ms/step
Epoch 108/200
1493/1493 - 75s - loss: 1.1733e-04 - val_loss: 1.2317e-04 - 75s/epoch - 50ms/step
Epoch 109/200
1493/1493 - 75s - loss: 1.1134e-04 - val_loss: 1.2590e-04 - 75s/epoch - 50ms/step
Epoch 110/200
1493/1493 - 75s - loss: 1.1015e-04 - val_loss: 1.2375e-04 - 75s/epoch - 50ms/step
Epoch 111/200
1493/1493 - 75s - loss: 1.0893e-04 - val_loss: 9.7053e-05 - 75s/epoch - 50ms/step
Epoch 112/200
1493/1493 - 75s - loss: 1.0665e-04 - val_loss: 1.0463e-04 - 75s/epoch - 50ms/step
Epoch 113/200
1493/1493 - 75s - loss: 1.0551e-04 - val_loss: 1.6599e-04 - 75s/epoch - 50ms/step
Epoch 114/200
1493/1493 - 75s - loss: 1.1915e-04 - val_loss: 1.0077e-04 - 75s/epoch - 50ms/step
Epoch 115/200
1493/1493 - 75s - loss: 1.2471e-04 - val_loss: 2.0617e-04 - 75s/epoch - 50ms/step
Epoch 116/200
1493/1493 - 75s - loss: 1.0964e-04 - val_loss: 1.1152e-04 - 75s/epoch - 50ms/step
Epoch 117/200
1493/1493 - 75s - loss: 1.0498e-04 - val_loss: 1.7757e-04 - 75s/epoch - 50ms/step
Epoch 118/200
1493/1493 - 75s - loss: 1.1053e-04 - val_loss: 1.0298e-04 - 75s/epoch - 50ms/step
Epoch 119/200
1493/1493 - 75s - loss: 1.0443e-04 - val_loss: 9.9980e-05 - 75s/epoch - 50ms/step
Epoch 120/200
1493/1493 - 75s - loss: 1.0332e-04 - val_loss: 1.0571e-04 - 75s/epoch - 50ms/step
Epoch 121/200
1493/1493 - 75s - loss: 1.0276e-04 - val_loss: 1.6093e-04 - 75s/epoch - 50ms/step
Epoch 122/200
1493/1493 - 75s - loss: 1.0531e-04 - val_loss: 9.4353e-05 - 75s/epoch - 51ms/step
Epoch 123/200
1493/1493 - 75s - loss: 1.0073e-04 - val_loss: 1.0540e-04 - 75s/epoch - 50ms/step
Epoch 124/200
1493/1493 - 75s - loss: 1.0154e-04 - val_loss: 3.3040e-04 - 75s/epoch - 50ms/step
Epoch 125/200
1493/1493 - 75s - loss: 1.4125e-04 - val_loss: 2.0434e-04 - 75s/epoch - 50ms/step
Epoch 126/200
1493/1493 - 75s - loss: 1.1236e-04 - val_loss: 1.2126e-04 - 75s/epoch - 50ms/step
Epoch 127/200
1493/1493 - 75s - loss: 1.0249e-04 - val_loss: 1.1532e-04 - 75s/epoch - 50ms/step
Epoch 128/200
1493/1493 - 75s - loss: 1.0077e-04 - val_loss: 8.9909e-05 - 75s/epoch - 51ms/step
Epoch 129/200
1493/1493 - 76s - loss: 9.9383e-05 - val_loss: 9.8344e-05 - 76s/epoch - 51ms/step
Epoch 130/200
1493/1493 - 76s - loss: 9.8343e-05 - val_loss: 9.3133e-05 - 76s/epoch - 51ms/step
Epoch 131/200
1493/1493 - 75s - loss: 1.0099e-04 - val_loss: 3.2988e-04 - 75s/epoch - 50ms/step
Epoch 132/200
1493/1493 - 75s - loss: 1.4202e-04 - val_loss: 9.1217e-05 - 75s/epoch - 50ms/step
Epoch 133/200
1493/1493 - 75s - loss: 1.0194e-04 - val_loss: 9.6976e-05 - 75s/epoch - 51ms/step
Epoch 134/200
1493/1493 - 75s - loss: 9.8333e-05 - val_loss: 9.5179e-05 - 75s/epoch - 50ms/step
Epoch 135/200
1493/1493 - 75s - loss: 9.7404e-05 - val_loss: 8.9800e-05 - 75s/epoch - 50ms/step
Epoch 136/200
1493/1493 - 75s - loss: 9.7430e-05 - val_loss: 1.6009e-04 - 75s/epoch - 50ms/step
Epoch 137/200
1493/1493 - 75s - loss: 1.1048e-04 - val_loss: 1.3326e-04 - 75s/epoch - 50ms/step
Epoch 138/200
1493/1493 - 75s - loss: 1.0756e-04 - val_loss: 2.6757e-04 - 75s/epoch - 50ms/step
Epoch 139/200
1493/1493 - 75s - loss: 1.3400e-04 - val_loss: 3.7775e-04 - 75s/epoch - 50ms/step
Epoch 140/200
1493/1493 - 76s - loss: 1.3768e-04 - val_loss: 8.8820e-05 - 76s/epoch - 51ms/step
Epoch 141/200
1493/1493 - 75s - loss: 1.0084e-04 - val_loss: 1.1199e-04 - 75s/epoch - 50ms/step
Epoch 142/200
1493/1493 - 75s - loss: 1.0126e-04 - val_loss: 1.0755e-04 - 75s/epoch - 50ms/step
Epoch 143/200
1493/1493 - 75s - loss: 9.8017e-05 - val_loss: 1.2941e-04 - 75s/epoch - 50ms/step
Epoch 144/200
1493/1493 - 75s - loss: 9.9859e-05 - val_loss: 9.3215e-05 - 75s/epoch - 50ms/step
Epoch 145/200
1493/1493 - 75s - loss: 9.4420e-05 - val_loss: 9.0591e-05 - 75s/epoch - 50ms/step
Epoch 146/200
1493/1493 - 75s - loss: 9.3902e-05 - val_loss: 8.6758e-05 - 75s/epoch - 50ms/step
Epoch 147/200
1493/1493 - 75s - loss: 9.2619e-05 - val_loss: 1.5299e-04 - 75s/epoch - 50ms/step
Epoch 148/200
1493/1493 - 75s - loss: 9.7379e-05 - val_loss: 1.5598e-04 - 75s/epoch - 50ms/step
Epoch 149/200
1493/1493 - 75s - loss: 9.2541e-05 - val_loss: 9.3593e-05 - 75s/epoch - 50ms/step
Epoch 150/200
1493/1493 - 75s - loss: 9.1465e-05 - val_loss: 9.1042e-05 - 75s/epoch - 50ms/step
Epoch 151/200
1493/1493 - 75s - loss: 9.1629e-05 - val_loss: 1.0490e-04 - 75s/epoch - 50ms/step
Epoch 152/200
1493/1493 - 75s - loss: 9.1283e-05 - val_loss: 1.4568e-04 - 75s/epoch - 50ms/step
Epoch 153/200
1493/1493 - 75s - loss: 9.4944e-05 - val_loss: 1.0022e-04 - 75s/epoch - 50ms/step
Epoch 154/200
1493/1493 - 75s - loss: 8.9250e-05 - val_loss: 8.6705e-05 - 75s/epoch - 50ms/step
Epoch 155/200
1493/1493 - 75s - loss: 8.7744e-05 - val_loss: 8.8529e-05 - 75s/epoch - 50ms/step
Epoch 156/200
1493/1493 - 75s - loss: 8.9580e-05 - val_loss: 9.2271e-05 - 75s/epoch - 50ms/step
Epoch 157/200
1493/1493 - 75s - loss: 8.7309e-05 - val_loss: 1.0581e-04 - 75s/epoch - 51ms/step
Epoch 158/200
1493/1493 - 75s - loss: 8.8833e-05 - val_loss: 1.0443e-04 - 75s/epoch - 50ms/step
Epoch 159/200
1493/1493 - 75s - loss: 8.7341e-05 - val_loss: 8.6836e-05 - 75s/epoch - 50ms/step
Epoch 160/200
1493/1493 - 75s - loss: 8.8467e-05 - val_loss: 1.5305e-04 - 75s/epoch - 50ms/step
Epoch 161/200
1493/1493 - 75s - loss: 1.1228e-04 - val_loss: 8.9599e-05 - 75s/epoch - 50ms/step
Epoch 162/200
1493/1493 - 75s - loss: 8.8756e-05 - val_loss: 7.9602e-05 - 75s/epoch - 50ms/step
Epoch 163/200
1493/1493 - 75s - loss: 8.7910e-05 - val_loss: 1.5986e-04 - 75s/epoch - 50ms/step
Epoch 164/200
1493/1493 - 75s - loss: 1.0144e-04 - val_loss: 8.3737e-05 - 75s/epoch - 50ms/step
Epoch 165/200
1493/1493 - 75s - loss: 1.2494e-04 - val_loss: 8.6778e-05 - 75s/epoch - 50ms/step
Epoch 166/200
1493/1493 - 75s - loss: 9.0568e-05 - val_loss: 9.1273e-05 - 75s/epoch - 50ms/step
Epoch 167/200
1493/1493 - 75s - loss: 8.8280e-05 - val_loss: 8.2980e-05 - 75s/epoch - 50ms/step
Epoch 168/200
1493/1493 - 75s - loss: 8.7155e-05 - val_loss: 9.2873e-05 - 75s/epoch - 50ms/step
Epoch 169/200
1493/1493 - 75s - loss: 8.6768e-05 - val_loss: 1.1218e-04 - 75s/epoch - 50ms/step
Epoch 170/200
1493/1493 - 75s - loss: 8.5720e-05 - val_loss: 1.2974e-04 - 75s/epoch - 50ms/step
Epoch 171/200
1493/1493 - 75s - loss: 9.7433e-05 - val_loss: 2.8313e-04 - 75s/epoch - 50ms/step
Epoch 172/200
1493/1493 - 75s - loss: 1.1829e-04 - val_loss: 1.8034e-04 - 75s/epoch - 50ms/step
Epoch 173/200
1493/1493 - 75s - loss: 9.8088e-05 - val_loss: 7.8769e-05 - 75s/epoch - 50ms/step
Epoch 174/200
1493/1493 - 76s - loss: 8.6485e-05 - val_loss: 7.9205e-05 - 76s/epoch - 51ms/step
Epoch 175/200
1493/1493 - 75s - loss: 8.6667e-05 - val_loss: 9.8301e-05 - 75s/epoch - 51ms/step
Epoch 176/200
1493/1493 - 75s - loss: 8.7011e-05 - val_loss: 8.8743e-05 - 75s/epoch - 51ms/step
Epoch 177/200
1493/1493 - 75s - loss: 8.6123e-05 - val_loss: 7.7029e-05 - 75s/epoch - 50ms/step
Epoch 178/200
1493/1493 - 75s - loss: 8.4301e-05 - val_loss: 7.6160e-05 - 75s/epoch - 50ms/step
Epoch 179/200
1493/1493 - 75s - loss: 8.2645e-05 - val_loss: 1.0217e-04 - 75s/epoch - 50ms/step
Epoch 180/200
1493/1493 - 75s - loss: 8.3820e-05 - val_loss: 1.0715e-04 - 75s/epoch - 50ms/step
Epoch 181/200
1493/1493 - 75s - loss: 8.7784e-05 - val_loss: 8.4424e-05 - 75s/epoch - 50ms/step
Epoch 182/200
1493/1493 - 75s - loss: 8.4314e-05 - val_loss: 1.0850e-04 - 75s/epoch - 50ms/step
Epoch 183/200
1493/1493 - 75s - loss: 8.3637e-05 - val_loss: 8.0870e-05 - 75s/epoch - 50ms/step
Epoch 184/200
1493/1493 - 75s - loss: 8.2925e-05 - val_loss: 8.3139e-05 - 75s/epoch - 50ms/step
Epoch 185/200
1493/1493 - 75s - loss: 8.0994e-05 - val_loss: 1.3468e-04 - 75s/epoch - 50ms/step
Epoch 186/200
1493/1493 - 75s - loss: 8.7259e-05 - val_loss: 7.9645e-05 - 75s/epoch - 50ms/step
Epoch 187/200
1493/1493 - 75s - loss: 8.1708e-05 - val_loss: 1.2760e-04 - 75s/epoch - 50ms/step
Epoch 188/200
1493/1493 - 75s - loss: 1.0039e-04 - val_loss: 8.5056e-05 - 75s/epoch - 50ms/step
Epoch 189/200
1493/1493 - 75s - loss: 8.3462e-05 - val_loss: 9.2827e-05 - 75s/epoch - 50ms/step
Epoch 190/200
1493/1493 - 75s - loss: 8.3289e-05 - val_loss: 9.3798e-05 - 75s/epoch - 51ms/step
Epoch 191/200
1493/1493 - 75s - loss: 8.3654e-05 - val_loss: 1.0837e-04 - 75s/epoch - 50ms/step
Epoch 192/200
1493/1493 - 75s - loss: 8.2868e-05 - val_loss: 9.8310e-05 - 75s/epoch - 50ms/step
Epoch 193/200
1493/1493 - 75s - loss: 8.5439e-05 - val_loss: 2.3737e-04 - 75s/epoch - 50ms/step
Epoch 194/200
1493/1493 - 75s - loss: 1.1682e-04 - val_loss: 4.8654e-04 - 75s/epoch - 50ms/step
Epoch 195/200
1493/1493 - 75s - loss: 1.2540e-04 - val_loss: 2.2459e-04 - 75s/epoch - 50ms/step
Epoch 196/200
1493/1493 - 75s - loss: 1.1151e-04 - val_loss: 7.4889e-05 - 75s/epoch - 50ms/step
Epoch 197/200
1493/1493 - 75s - loss: 8.6045e-05 - val_loss: 1.0110e-04 - 75s/epoch - 51ms/step
Epoch 198/200
1493/1493 - 75s - loss: 8.7448e-05 - val_loss: 1.1308e-04 - 75s/epoch - 50ms/step
Epoch 199/200
1493/1493 - 75s - loss: 8.9523e-05 - val_loss: 7.0401e-05 - 75s/epoch - 50ms/step
Epoch 200/200
1493/1493 - 75s - loss: 8.1696e-05 - val_loss: 7.9479e-05 - 75s/epoch - 50ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 7.947896665427834e-05
  1/332 [..............................] - ETA: 40s  6/332 [..............................] - ETA: 3s  12/332 [>.............................] - ETA: 3s 19/332 [>.............................] - ETA: 2s 26/332 [=>............................] - ETA: 2s 33/332 [=>............................] - ETA: 2s 40/332 [==>...........................] - ETA: 2s 48/332 [===>..........................] - ETA: 2s 55/332 [===>..........................] - ETA: 2s 62/332 [====>.........................] - ETA: 2s 69/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 1s 84/332 [======>.......................] - ETA: 1s 91/332 [=======>......................] - ETA: 1s 98/332 [=======>......................] - ETA: 1s105/332 [========>.....................] - ETA: 1s112/332 [=========>....................] - ETA: 1s120/332 [=========>....................] - ETA: 1s128/332 [==========>...................] - ETA: 1s136/332 [===========>..................] - ETA: 1s143/332 [===========>..................] - ETA: 1s150/332 [============>.................] - ETA: 1s157/332 [=============>................] - ETA: 1s165/332 [=============>................] - ETA: 1s173/332 [==============>...............] - ETA: 1s180/332 [===============>..............] - ETA: 1s188/332 [===============>..............] - ETA: 1s196/332 [================>.............] - ETA: 1s203/332 [=================>............] - ETA: 0s210/332 [=================>............] - ETA: 0s218/332 [==================>...........] - ETA: 0s226/332 [===================>..........] - ETA: 0s233/332 [====================>.........] - ETA: 0s240/332 [====================>.........] - ETA: 0s247/332 [=====================>........] - ETA: 0s254/332 [=====================>........] - ETA: 0s262/332 [======================>.......] - ETA: 0s269/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s283/332 [========================>.....] - ETA: 0s290/332 [=========================>....] - ETA: 0s297/332 [=========================>....] - ETA: 0s304/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s318/332 [===========================>..] - ETA: 0s326/332 [============================>.] - ETA: 0s332/332 [==============================] - 3s 7ms/step
correlation 0.0009026662093758179
cosine 0.0007106810190342437
MAE: 0.0048800893
RMSE: 0.008915094
r2: 0.9948442030112171
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_21"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_22 (InputLayer)       multiple                  0         
                                                                 
 dense_21 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_21 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2811591   
                                                                 
 batch_normalization_22 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 1011)              0         
                                                                 
 dense_22 (Dense)            (None, 2780)              2813360   
                                                                 
 batch_normalization_23 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 2780)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 12,683,119
Trainable params: 12,669,977
Non-trainable params: 13,142
_________________________________________________________________
Encoder
Model: "model_22"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_23 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_22 (InputLayer)       multiple                  0         
                                                                 
 dense_21 (Dense)            (None, 2780)              3516700   
                                                                 
 batch_normalization_21 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_21 (ReLU)             (None, 2780)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2811591   
                                                                 
=================================================================
Total params: 6,339,411
Trainable params: 6,333,851
Non-trainable params: 5,560
_________________________________________________________________
Decoder
Model: "model_23"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_24 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_22 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_22 (ReLU)             (None, 1011)              0         
                                                                 
 dense_22 (Dense)            (None, 2780)              2813360   
                                                                 
 batch_normalization_23 (Bat  (None, 2780)             11120     
 chNormalization)                                                
                                                                 
 re_lu_23 (ReLU)             (None, 2780)              0         
                                                                 
 dense_23 (Dense)            (None, 1264)              3515184   
                                                                 
=================================================================
Total params: 6,343,708
Trainable params: 6,336,126
Non-trainable params: 7,582
_________________________________________________________________
['2.2custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.169573993654922e-05, 7.947896665427834e-05, 0.0009026662093758179, 0.0007106810190342437, 0.004880089312791824, 0.00891509372740984, 0.9948442030112171, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_24 (Dense)            (None, 2907)              3677355   
                                                                 
 batch_normalization_24 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 2907)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2939988   
                                                                 
 batch_normalization_25 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 1011)              0         
                                                                 
 dense_25 (Dense)            (None, 2907)              2941884   
                                                                 
 batch_normalization_26 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 2907)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              3675712   
                                                                 
=================================================================
Total params: 13,262,239
Trainable params: 13,248,589
Non-trainable params: 13,650
_________________________________________________________________
Epoch 1/200
1493/1493 - 100s - loss: 0.0090 - val_loss: 0.0040 - 100s/epoch - 67ms/step
Epoch 2/200
1493/1493 - 100s - loss: 0.0028 - val_loss: 0.0031 - 100s/epoch - 67ms/step
Epoch 3/200
1493/1493 - 101s - loss: 0.0020 - val_loss: 0.0015 - 101s/epoch - 67ms/step
Epoch 4/200
1493/1493 - 101s - loss: 0.0016 - val_loss: 0.0025 - 101s/epoch - 68ms/step
Epoch 5/200
1493/1493 - 102s - loss: 0.0015 - val_loss: 0.0013 - 102s/epoch - 68ms/step
Epoch 6/200
1493/1493 - 103s - loss: 0.0014 - val_loss: 0.0019 - 103s/epoch - 69ms/step
Epoch 7/200
1493/1493 - 103s - loss: 0.0013 - val_loss: 8.4864e-04 - 103s/epoch - 69ms/step
Epoch 8/200
1493/1493 - 103s - loss: 0.0011 - val_loss: 0.0012 - 103s/epoch - 69ms/step
Epoch 9/200
1493/1493 - 101s - loss: 9.9517e-04 - val_loss: 0.0015 - 101s/epoch - 68ms/step
Epoch 10/200
1493/1493 - 102s - loss: 0.0010 - val_loss: 7.4121e-04 - 102s/epoch - 68ms/step
Epoch 11/200
1493/1493 - 102s - loss: 8.2587e-04 - val_loss: 6.6936e-04 - 102s/epoch - 68ms/step
Epoch 12/200
1493/1493 - 102s - loss: 7.1381e-04 - val_loss: 7.6375e-04 - 102s/epoch - 68ms/step
Epoch 13/200
1493/1493 - 101s - loss: 6.7820e-04 - val_loss: 0.0016 - 101s/epoch - 67ms/step
Epoch 14/200
1493/1493 - 97s - loss: 7.1714e-04 - val_loss: 4.8756e-04 - 97s/epoch - 65ms/step
Epoch 15/200
1493/1493 - 97s - loss: 5.7631e-04 - val_loss: 8.4431e-04 - 97s/epoch - 65ms/step
Epoch 16/200
1493/1493 - 97s - loss: 5.5912e-04 - val_loss: 4.7569e-04 - 97s/epoch - 65ms/step
Epoch 17/200
1493/1493 - 96s - loss: 4.7769e-04 - val_loss: 6.6990e-04 - 96s/epoch - 65ms/step
Epoch 18/200
1493/1493 - 97s - loss: 4.7545e-04 - val_loss: 7.6929e-04 - 97s/epoch - 65ms/step
Epoch 19/200
1493/1493 - 97s - loss: 4.5669e-04 - val_loss: 5.8605e-04 - 97s/epoch - 65ms/step
Epoch 20/200
1493/1493 - 97s - loss: 4.2718e-04 - val_loss: 4.4200e-04 - 97s/epoch - 65ms/step
Epoch 21/200
1493/1493 - 96s - loss: 3.8839e-04 - val_loss: 5.2338e-04 - 96s/epoch - 65ms/step
Epoch 22/200
1493/1493 - 97s - loss: 3.7432e-04 - val_loss: 5.8471e-04 - 97s/epoch - 65ms/step
Epoch 23/200
1493/1493 - 96s - loss: 4.0672e-04 - val_loss: 6.7958e-04 - 96s/epoch - 65ms/step
Epoch 24/200
1493/1493 - 96s - loss: 3.7314e-04 - val_loss: 3.1139e-04 - 96s/epoch - 64ms/step
Epoch 25/200
1493/1493 - 96s - loss: 3.3665e-04 - val_loss: 3.1944e-04 - 96s/epoch - 64ms/step
Epoch 26/200
1493/1493 - 96s - loss: 3.1417e-04 - val_loss: 3.9279e-04 - 96s/epoch - 65ms/step
Epoch 27/200
1493/1493 - 96s - loss: 2.9529e-04 - val_loss: 2.9338e-04 - 96s/epoch - 64ms/step
Epoch 28/200
1493/1493 - 97s - loss: 2.8046e-04 - val_loss: 4.3358e-04 - 97s/epoch - 65ms/step
Epoch 29/200
1493/1493 - 96s - loss: 2.8023e-04 - val_loss: 3.3096e-04 - 96s/epoch - 64ms/step
Epoch 30/200
1493/1493 - 97s - loss: 2.7630e-04 - val_loss: 3.0451e-04 - 97s/epoch - 65ms/step
Epoch 31/200
1493/1493 - 96s - loss: 2.5940e-04 - val_loss: 5.1758e-04 - 96s/epoch - 64ms/step
Epoch 32/200
1493/1493 - 97s - loss: 3.3090e-04 - val_loss: 2.9238e-04 - 97s/epoch - 65ms/step
Epoch 33/200
1493/1493 - 96s - loss: 2.6536e-04 - val_loss: 2.4421e-04 - 96s/epoch - 64ms/step
Epoch 34/200
1493/1493 - 97s - loss: 2.4708e-04 - val_loss: 2.1508e-04 - 97s/epoch - 65ms/step
Epoch 35/200
1493/1493 - 97s - loss: 2.3361e-04 - val_loss: 7.0486e-04 - 97s/epoch - 65ms/step
Epoch 36/200
1493/1493 - 97s - loss: 2.6525e-04 - val_loss: 2.5939e-04 - 97s/epoch - 65ms/step
Epoch 37/200
1493/1493 - 96s - loss: 2.2552e-04 - val_loss: 4.0978e-04 - 96s/epoch - 64ms/step
Epoch 38/200
1493/1493 - 96s - loss: 2.4791e-04 - val_loss: 2.2031e-04 - 96s/epoch - 64ms/step
Epoch 39/200
1493/1493 - 97s - loss: 2.1571e-04 - val_loss: 1.8872e-04 - 97s/epoch - 65ms/step
Epoch 40/200
1493/1493 - 97s - loss: 2.0844e-04 - val_loss: 2.7064e-04 - 97s/epoch - 65ms/step
Epoch 41/200
1493/1493 - 97s - loss: 2.0947e-04 - val_loss: 1.9244e-04 - 97s/epoch - 65ms/step
Epoch 42/200
1493/1493 - 97s - loss: 2.0044e-04 - val_loss: 2.0615e-04 - 97s/epoch - 65ms/step
Epoch 43/200
1493/1493 - 97s - loss: 1.9927e-04 - val_loss: 3.0492e-04 - 97s/epoch - 65ms/step
Epoch 44/200
1493/1493 - 96s - loss: 2.0547e-04 - val_loss: 4.4534e-04 - 96s/epoch - 64ms/step
Epoch 45/200
1493/1493 - 97s - loss: 2.1656e-04 - val_loss: 1.6674e-04 - 97s/epoch - 65ms/step
Epoch 46/200
1493/1493 - 97s - loss: 1.8927e-04 - val_loss: 1.7740e-04 - 97s/epoch - 65ms/step
Epoch 47/200
1493/1493 - 96s - loss: 1.9120e-04 - val_loss: 1.8837e-04 - 96s/epoch - 64ms/step
Epoch 48/200
1493/1493 - 96s - loss: 1.8393e-04 - val_loss: 2.4066e-04 - 96s/epoch - 64ms/step
Epoch 49/200
1493/1493 - 96s - loss: 1.8336e-04 - val_loss: 2.9815e-04 - 96s/epoch - 64ms/step
Epoch 50/200
1493/1493 - 96s - loss: 1.8850e-04 - val_loss: 7.6079e-04 - 96s/epoch - 64ms/step
Epoch 51/200
1493/1493 - 96s - loss: 2.1933e-04 - val_loss: 1.9983e-04 - 96s/epoch - 64ms/step
Epoch 52/200
1493/1493 - 95s - loss: 1.7253e-04 - val_loss: 1.6692e-04 - 95s/epoch - 64ms/step
Epoch 53/200
1493/1493 - 95s - loss: 1.7268e-04 - val_loss: 1.5897e-04 - 95s/epoch - 64ms/step
Epoch 54/200
1493/1493 - 95s - loss: 1.6699e-04 - val_loss: 1.9373e-04 - 95s/epoch - 64ms/step
Epoch 55/200
1493/1493 - 95s - loss: 1.6244e-04 - val_loss: 1.7922e-04 - 95s/epoch - 63ms/step
Epoch 56/200
1493/1493 - 95s - loss: 1.6340e-04 - val_loss: 2.1544e-04 - 95s/epoch - 64ms/step
Epoch 57/200
1493/1493 - 95s - loss: 1.5968e-04 - val_loss: 1.8572e-04 - 95s/epoch - 64ms/step
Epoch 58/200
1493/1493 - 95s - loss: 1.5885e-04 - val_loss: 1.5099e-04 - 95s/epoch - 64ms/step
Epoch 59/200
1493/1493 - 95s - loss: 1.5515e-04 - val_loss: 1.6920e-04 - 95s/epoch - 64ms/step
Epoch 60/200
1493/1493 - 95s - loss: 1.5435e-04 - val_loss: 2.0752e-04 - 95s/epoch - 63ms/step
Epoch 61/200
1493/1493 - 95s - loss: 1.5782e-04 - val_loss: 1.5968e-04 - 95s/epoch - 63ms/step
Epoch 62/200
1493/1493 - 95s - loss: 1.5070e-04 - val_loss: 1.9847e-04 - 95s/epoch - 64ms/step
Epoch 63/200
1493/1493 - 95s - loss: 1.4911e-04 - val_loss: 1.8398e-04 - 95s/epoch - 64ms/step
Epoch 64/200
1493/1493 - 95s - loss: 1.4826e-04 - val_loss: 8.2137e-04 - 95s/epoch - 64ms/step
Epoch 65/200
1493/1493 - 95s - loss: 1.8155e-04 - val_loss: 1.9634e-04 - 95s/epoch - 63ms/step
Epoch 66/200
1493/1493 - 95s - loss: 1.5374e-04 - val_loss: 1.6721e-04 - 95s/epoch - 63ms/step
Epoch 67/200
1493/1493 - 95s - loss: 1.4295e-04 - val_loss: 1.4560e-04 - 95s/epoch - 64ms/step
Epoch 68/200
1493/1493 - 95s - loss: 1.4260e-04 - val_loss: 6.0996e-04 - 95s/epoch - 64ms/step
Epoch 69/200
1493/1493 - 95s - loss: 2.4057e-04 - val_loss: 1.6116e-04 - 95s/epoch - 64ms/step
Epoch 70/200
1493/1493 - 95s - loss: 1.5183e-04 - val_loss: 8.0751e-04 - 95s/epoch - 64ms/step
Epoch 71/200
1493/1493 - 95s - loss: 2.4776e-04 - val_loss: 1.4065e-04 - 95s/epoch - 64ms/step
Epoch 72/200
1493/1493 - 95s - loss: 1.5537e-04 - val_loss: 1.8582e-04 - 95s/epoch - 64ms/step
Epoch 73/200
1493/1493 - 95s - loss: 1.5316e-04 - val_loss: 1.5094e-04 - 95s/epoch - 64ms/step
Epoch 74/200
1493/1493 - 95s - loss: 1.4497e-04 - val_loss: 1.5130e-04 - 95s/epoch - 63ms/step
Epoch 75/200
1493/1493 - 95s - loss: 1.3925e-04 - val_loss: 1.2382e-04 - 95s/epoch - 64ms/step
Epoch 76/200
1493/1493 - 95s - loss: 1.3624e-04 - val_loss: 1.2474e-04 - 95s/epoch - 64ms/step
Epoch 77/200
1493/1493 - 95s - loss: 1.3610e-04 - val_loss: 4.7066e-04 - 95s/epoch - 64ms/step
Epoch 78/200
1493/1493 - 95s - loss: 1.5146e-04 - val_loss: 2.0960e-04 - 95s/epoch - 64ms/step
Epoch 79/200
1493/1493 - 95s - loss: 1.3804e-04 - val_loss: 1.3722e-04 - 95s/epoch - 64ms/step
Epoch 80/200
1493/1493 - 95s - loss: 1.2997e-04 - val_loss: 1.4145e-04 - 95s/epoch - 63ms/step
Epoch 81/200
1493/1493 - 95s - loss: 1.3011e-04 - val_loss: 2.5655e-04 - 95s/epoch - 64ms/step
Epoch 82/200
1493/1493 - 95s - loss: 1.2716e-04 - val_loss: 1.3353e-04 - 95s/epoch - 64ms/step
Epoch 83/200
1493/1493 - 95s - loss: 1.2430e-04 - val_loss: 1.4244e-04 - 95s/epoch - 64ms/step
Epoch 84/200
1493/1493 - 95s - loss: 1.2619e-04 - val_loss: 1.5554e-04 - 95s/epoch - 64ms/step
Epoch 85/200
1493/1493 - 95s - loss: 1.2551e-04 - val_loss: 1.5748e-04 - 95s/epoch - 64ms/step
Epoch 86/200
1493/1493 - 95s - loss: 1.2455e-04 - val_loss: 1.3258e-04 - 95s/epoch - 64ms/step
Epoch 87/200
1493/1493 - 95s - loss: 1.2080e-04 - val_loss: 1.2284e-04 - 95s/epoch - 64ms/step
Epoch 88/200
1493/1493 - 95s - loss: 1.1975e-04 - val_loss: 1.2985e-04 - 95s/epoch - 64ms/step
Epoch 89/200
1493/1493 - 95s - loss: 1.2361e-04 - val_loss: 1.1913e-04 - 95s/epoch - 64ms/step
Epoch 90/200
1493/1493 - 95s - loss: 1.1886e-04 - val_loss: 1.3123e-04 - 95s/epoch - 64ms/step
Epoch 91/200
1493/1493 - 96s - loss: 1.1737e-04 - val_loss: 1.3596e-04 - 96s/epoch - 64ms/step
Epoch 92/200
1493/1493 - 95s - loss: 1.1855e-04 - val_loss: 5.8031e-04 - 95s/epoch - 64ms/step
Epoch 93/200
1493/1493 - 95s - loss: 1.9042e-04 - val_loss: 7.4267e-04 - 95s/epoch - 64ms/step
Epoch 94/200
1493/1493 - 95s - loss: 2.2004e-04 - val_loss: 1.1298e-04 - 95s/epoch - 64ms/step
Epoch 95/200
1493/1493 - 95s - loss: 1.3558e-04 - val_loss: 1.4342e-04 - 95s/epoch - 64ms/step
Epoch 96/200
1493/1493 - 96s - loss: 1.2755e-04 - val_loss: 1.4097e-04 - 96s/epoch - 64ms/step
Epoch 97/200
1493/1493 - 95s - loss: 1.2217e-04 - val_loss: 1.1515e-04 - 95s/epoch - 64ms/step
Epoch 98/200
1493/1493 - 96s - loss: 1.2199e-04 - val_loss: 8.5726e-04 - 96s/epoch - 64ms/step
Epoch 99/200
1493/1493 - 96s - loss: 2.1949e-04 - val_loss: 1.0115e-04 - 96s/epoch - 64ms/step
Epoch 100/200
1493/1493 - 96s - loss: 1.3223e-04 - val_loss: 1.1126e-04 - 96s/epoch - 64ms/step
Epoch 101/200
1493/1493 - 95s - loss: 1.2202e-04 - val_loss: 2.0040e-04 - 95s/epoch - 64ms/step
Epoch 102/200
1493/1493 - 95s - loss: 1.2931e-04 - val_loss: 1.9507e-04 - 95s/epoch - 64ms/step
Epoch 103/200
1493/1493 - 96s - loss: 1.2293e-04 - val_loss: 1.1466e-04 - 96s/epoch - 64ms/step
Epoch 104/200
1493/1493 - 96s - loss: 1.1526e-04 - val_loss: 4.1972e-04 - 96s/epoch - 64ms/step
Epoch 105/200
1493/1493 - 96s - loss: 1.3483e-04 - val_loss: 1.0238e-04 - 96s/epoch - 64ms/step
Epoch 106/200
1493/1493 - 95s - loss: 1.1356e-04 - val_loss: 1.1887e-04 - 95s/epoch - 64ms/step
Epoch 107/200
1493/1493 - 95s - loss: 1.1153e-04 - val_loss: 1.1929e-04 - 95s/epoch - 64ms/step
Epoch 108/200
1493/1493 - 96s - loss: 1.1423e-04 - val_loss: 1.3355e-04 - 96s/epoch - 64ms/step
Epoch 109/200
1493/1493 - 95s - loss: 1.1055e-04 - val_loss: 1.3714e-04 - 95s/epoch - 64ms/step
Epoch 110/200
1493/1493 - 96s - loss: 1.0804e-04 - val_loss: 1.1481e-04 - 96s/epoch - 64ms/step
Epoch 111/200
1493/1493 - 96s - loss: 1.0752e-04 - val_loss: 1.1768e-04 - 96s/epoch - 64ms/step
Epoch 112/200
1493/1493 - 96s - loss: 1.0751e-04 - val_loss: 1.0846e-04 - 96s/epoch - 64ms/step
Epoch 113/200
1493/1493 - 95s - loss: 1.0870e-04 - val_loss: 5.4978e-04 - 95s/epoch - 64ms/step
Epoch 114/200
1493/1493 - 96s - loss: 1.8424e-04 - val_loss: 1.0635e-04 - 96s/epoch - 64ms/step
Epoch 115/200
1493/1493 - 95s - loss: 1.1765e-04 - val_loss: 2.9796e-04 - 95s/epoch - 64ms/step
Epoch 116/200
1493/1493 - 96s - loss: 1.1422e-04 - val_loss: 1.1321e-04 - 96s/epoch - 64ms/step
Epoch 117/200
1493/1493 - 95s - loss: 1.0682e-04 - val_loss: 2.3197e-04 - 95s/epoch - 64ms/step
Epoch 118/200
1493/1493 - 95s - loss: 1.1645e-04 - val_loss: 1.0583e-04 - 95s/epoch - 64ms/step
Epoch 119/200
1493/1493 - 96s - loss: 1.0675e-04 - val_loss: 9.9296e-05 - 96s/epoch - 64ms/step
Epoch 120/200
1493/1493 - 96s - loss: 1.0398e-04 - val_loss: 1.0471e-04 - 96s/epoch - 64ms/step
Epoch 121/200
1493/1493 - 95s - loss: 1.0330e-04 - val_loss: 1.4512e-04 - 95s/epoch - 64ms/step
Epoch 122/200
1493/1493 - 95s - loss: 1.0801e-04 - val_loss: 1.0036e-04 - 95s/epoch - 64ms/step
Epoch 123/200
1493/1493 - 96s - loss: 1.0216e-04 - val_loss: 1.0795e-04 - 96s/epoch - 64ms/step
Epoch 124/200
1493/1493 - 96s - loss: 1.0321e-04 - val_loss: 4.2461e-04 - 96s/epoch - 64ms/step
Epoch 125/200
1493/1493 - 96s - loss: 1.5785e-04 - val_loss: 2.0309e-04 - 96s/epoch - 64ms/step
Epoch 126/200
1493/1493 - 94s - loss: 1.1458e-04 - val_loss: 1.2634e-04 - 94s/epoch - 63ms/step
Epoch 127/200
1493/1493 - 94s - loss: 1.0460e-04 - val_loss: 2.2369e-04 - 94s/epoch - 63ms/step
Epoch 128/200
1493/1493 - 94s - loss: 1.0959e-04 - val_loss: 8.9573e-05 - 94s/epoch - 63ms/step
Epoch 129/200
1493/1493 - 93s - loss: 1.0002e-04 - val_loss: 1.0699e-04 - 93s/epoch - 62ms/step
Epoch 130/200
1493/1493 - 93s - loss: 9.9278e-05 - val_loss: 8.7360e-05 - 93s/epoch - 62ms/step
Epoch 131/200
1493/1493 - 93s - loss: 1.0224e-04 - val_loss: 5.0792e-04 - 93s/epoch - 62ms/step
Epoch 132/200
1493/1493 - 93s - loss: 1.6035e-04 - val_loss: 8.7674e-05 - 93s/epoch - 62ms/step
Epoch 133/200
1493/1493 - 93s - loss: 1.0379e-04 - val_loss: 9.7830e-05 - 93s/epoch - 62ms/step
Epoch 134/200
1493/1493 - 93s - loss: 1.0045e-04 - val_loss: 1.0039e-04 - 93s/epoch - 62ms/step
Epoch 135/200
1493/1493 - 93s - loss: 9.8467e-05 - val_loss: 9.0825e-05 - 93s/epoch - 62ms/step
Epoch 136/200
1493/1493 - 93s - loss: 9.7495e-05 - val_loss: 1.9076e-04 - 93s/epoch - 62ms/step
Epoch 137/200
1493/1493 - 93s - loss: 1.1021e-04 - val_loss: 1.0985e-04 - 93s/epoch - 62ms/step
Epoch 138/200
1493/1493 - 93s - loss: 9.8705e-05 - val_loss: 9.0091e-05 - 93s/epoch - 62ms/step
Epoch 139/200
1493/1493 - 93s - loss: 9.6489e-05 - val_loss: 1.0578e-04 - 93s/epoch - 62ms/step
Epoch 140/200
1493/1493 - 93s - loss: 1.0185e-04 - val_loss: 8.7745e-05 - 93s/epoch - 62ms/step
Epoch 141/200
1493/1493 - 93s - loss: 9.4494e-05 - val_loss: 1.0113e-04 - 93s/epoch - 62ms/step
Epoch 142/200
1493/1493 - 93s - loss: 9.6537e-05 - val_loss: 1.0693e-04 - 93s/epoch - 62ms/step
Epoch 143/200
1493/1493 - 93s - loss: 9.3418e-05 - val_loss: 1.2160e-04 - 93s/epoch - 62ms/step
Epoch 144/200
1493/1493 - 93s - loss: 9.5575e-05 - val_loss: 9.4011e-05 - 93s/epoch - 62ms/step
Epoch 145/200
1493/1493 - 93s - loss: 9.2488e-05 - val_loss: 8.9129e-05 - 93s/epoch - 62ms/step
Epoch 146/200
1493/1493 - 93s - loss: 9.1447e-05 - val_loss: 8.3358e-05 - 93s/epoch - 62ms/step
Epoch 147/200
1493/1493 - 93s - loss: 9.0394e-05 - val_loss: 1.1521e-04 - 93s/epoch - 62ms/step
Epoch 148/200
1493/1493 - 93s - loss: 9.1791e-05 - val_loss: 1.4008e-04 - 93s/epoch - 62ms/step
Epoch 149/200
1493/1493 - 93s - loss: 9.0869e-05 - val_loss: 9.0198e-05 - 93s/epoch - 62ms/step
Epoch 150/200
1493/1493 - 93s - loss: 8.9442e-05 - val_loss: 8.9660e-05 - 93s/epoch - 62ms/step
Epoch 151/200
1493/1493 - 93s - loss: 8.8788e-05 - val_loss: 9.6682e-05 - 93s/epoch - 62ms/step
Epoch 152/200
1493/1493 - 93s - loss: 8.8529e-05 - val_loss: 1.0598e-04 - 93s/epoch - 62ms/step
Epoch 153/200
1493/1493 - 93s - loss: 8.9784e-05 - val_loss: 9.8932e-05 - 93s/epoch - 62ms/step
Epoch 154/200
1493/1493 - 93s - loss: 8.7733e-05 - val_loss: 9.0018e-05 - 93s/epoch - 62ms/step
Epoch 155/200
1493/1493 - 93s - loss: 8.6394e-05 - val_loss: 9.6537e-05 - 93s/epoch - 62ms/step
Epoch 156/200
1493/1493 - 93s - loss: 1.0132e-04 - val_loss: 9.6114e-05 - 93s/epoch - 62ms/step
Epoch 157/200
1493/1493 - 93s - loss: 8.8710e-05 - val_loss: 1.0284e-04 - 93s/epoch - 62ms/step
Epoch 158/200
1493/1493 - 94s - loss: 8.9775e-05 - val_loss: 8.9356e-05 - 94s/epoch - 63ms/step
Epoch 159/200
1493/1493 - 94s - loss: 8.6448e-05 - val_loss: 8.4534e-05 - 94s/epoch - 63ms/step
Epoch 160/200
1493/1493 - 94s - loss: 8.9201e-05 - val_loss: 1.5152e-04 - 94s/epoch - 63ms/step
Epoch 161/200
1493/1493 - 94s - loss: 1.1347e-04 - val_loss: 9.1532e-05 - 94s/epoch - 63ms/step
Epoch 162/200
1493/1493 - 94s - loss: 8.8892e-05 - val_loss: 7.9806e-05 - 94s/epoch - 63ms/step
Epoch 163/200
1493/1493 - 94s - loss: 8.7162e-05 - val_loss: 1.0605e-04 - 94s/epoch - 63ms/step
Epoch 164/200
1493/1493 - 94s - loss: 8.9156e-05 - val_loss: 9.3897e-05 - 94s/epoch - 63ms/step
Epoch 165/200
1493/1493 - 94s - loss: 8.7933e-05 - val_loss: 9.1191e-05 - 94s/epoch - 63ms/step
Epoch 166/200
1493/1493 - 94s - loss: 8.6504e-05 - val_loss: 9.4511e-05 - 94s/epoch - 63ms/step
Epoch 167/200
1493/1493 - 94s - loss: 8.5602e-05 - val_loss: 8.3378e-05 - 94s/epoch - 63ms/step
Epoch 168/200
1493/1493 - 94s - loss: 8.6946e-05 - val_loss: 7.5602e-05 - 94s/epoch - 63ms/step
Epoch 169/200
1493/1493 - 94s - loss: 8.4806e-05 - val_loss: 9.1409e-05 - 94s/epoch - 63ms/step
Epoch 170/200
1493/1493 - 94s - loss: 8.5628e-05 - val_loss: 3.4398e-04 - 94s/epoch - 63ms/step
Epoch 171/200
1493/1493 - 93s - loss: 1.2381e-04 - val_loss: 4.5046e-04 - 93s/epoch - 62ms/step
Epoch 172/200
1493/1493 - 93s - loss: 1.2769e-04 - val_loss: 9.7843e-05 - 93s/epoch - 62ms/step
Epoch 173/200
1493/1493 - 93s - loss: 9.0730e-05 - val_loss: 8.1686e-05 - 93s/epoch - 62ms/step
Epoch 174/200
1493/1493 - 93s - loss: 8.6532e-05 - val_loss: 1.0313e-04 - 93s/epoch - 62ms/step
Epoch 175/200
1493/1493 - 93s - loss: 8.7820e-05 - val_loss: 9.6467e-05 - 93s/epoch - 63ms/step
Epoch 176/200
1493/1493 - 94s - loss: 8.5929e-05 - val_loss: 8.6522e-05 - 94s/epoch - 63ms/step
Epoch 177/200
1493/1493 - 93s - loss: 8.5037e-05 - val_loss: 7.5974e-05 - 93s/epoch - 63ms/step
Epoch 178/200
1493/1493 - 94s - loss: 8.3445e-05 - val_loss: 8.1437e-05 - 94s/epoch - 63ms/step
Epoch 179/200
1493/1493 - 94s - loss: 8.2656e-05 - val_loss: 9.4883e-05 - 94s/epoch - 63ms/step
Epoch 180/200
1493/1493 - 93s - loss: 8.3014e-05 - val_loss: 8.4677e-05 - 93s/epoch - 63ms/step
Epoch 181/200
1493/1493 - 94s - loss: 8.1732e-05 - val_loss: 7.8944e-05 - 94s/epoch - 63ms/step
Epoch 182/200
1493/1493 - 94s - loss: 8.2276e-05 - val_loss: 1.0322e-04 - 94s/epoch - 63ms/step
Epoch 183/200
1493/1493 - 93s - loss: 8.3877e-05 - val_loss: 8.1688e-05 - 93s/epoch - 63ms/step
Epoch 184/200
1493/1493 - 94s - loss: 8.1946e-05 - val_loss: 7.9865e-05 - 94s/epoch - 63ms/step
Epoch 185/200
1493/1493 - 93s - loss: 8.3132e-05 - val_loss: 2.5913e-04 - 93s/epoch - 63ms/step
Epoch 186/200
1493/1493 - 94s - loss: 1.2185e-04 - val_loss: 7.5918e-05 - 94s/epoch - 63ms/step
Epoch 187/200
1493/1493 - 93s - loss: 8.6874e-05 - val_loss: 1.5900e-04 - 93s/epoch - 62ms/step
Epoch 188/200
1493/1493 - 93s - loss: 1.1003e-04 - val_loss: 9.1203e-05 - 93s/epoch - 63ms/step
Epoch 189/200
1493/1493 - 93s - loss: 8.7582e-05 - val_loss: 9.1775e-05 - 93s/epoch - 62ms/step
Epoch 190/200
1493/1493 - 94s - loss: 8.6339e-05 - val_loss: 1.0361e-04 - 94s/epoch - 63ms/step
Epoch 191/200
1493/1493 - 93s - loss: 8.6318e-05 - val_loss: 1.0313e-04 - 93s/epoch - 62ms/step
Epoch 192/200
1493/1493 - 93s - loss: 8.4437e-05 - val_loss: 8.5212e-05 - 93s/epoch - 63ms/step
Epoch 193/200
1493/1493 - 93s - loss: 8.2073e-05 - val_loss: 1.5587e-04 - 93s/epoch - 63ms/step
Epoch 194/200
1493/1493 - 93s - loss: 1.0188e-04 - val_loss: 4.3932e-04 - 93s/epoch - 62ms/step
Epoch 195/200
1493/1493 - 93s - loss: 1.5342e-04 - val_loss: 3.0204e-04 - 93s/epoch - 63ms/step
Epoch 196/200
1493/1493 - 93s - loss: 1.2539e-04 - val_loss: 7.6054e-05 - 93s/epoch - 63ms/step
Epoch 197/200
1493/1493 - 94s - loss: 8.9775e-05 - val_loss: 1.2675e-04 - 94s/epoch - 63ms/step
Epoch 198/200
1493/1493 - 93s - loss: 9.3248e-05 - val_loss: 1.4501e-04 - 93s/epoch - 62ms/step
Epoch 199/200
1493/1493 - 93s - loss: 9.0844e-05 - val_loss: 7.1177e-05 - 93s/epoch - 63ms/step
Epoch 200/200
1493/1493 - 93s - loss: 8.3005e-05 - val_loss: 8.2415e-05 - 93s/epoch - 63ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 8.24151502456516e-05
  1/332 [..............................] - ETA: 58s  6/332 [..............................] - ETA: 3s  11/332 [..............................] - ETA: 3s 16/332 [>.............................] - ETA: 3s 21/332 [>.............................] - ETA: 3s 26/332 [=>............................] - ETA: 3s 30/332 [=>............................] - ETA: 3s 35/332 [==>...........................] - ETA: 3s 40/332 [==>...........................] - ETA: 3s 45/332 [===>..........................] - ETA: 3s 50/332 [===>..........................] - ETA: 2s 55/332 [===>..........................] - ETA: 2s 60/332 [====>.........................] - ETA: 2s 65/332 [====>.........................] - ETA: 2s 71/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 2s 81/332 [======>.......................] - ETA: 2s 86/332 [======>.......................] - ETA: 2s 91/332 [=======>......................] - ETA: 2s 96/332 [=======>......................] - ETA: 2s101/332 [========>.....................] - ETA: 2s106/332 [========>.....................] - ETA: 2s111/332 [=========>....................] - ETA: 2s116/332 [=========>....................] - ETA: 2s121/332 [=========>....................] - ETA: 2s126/332 [==========>...................] - ETA: 2s131/332 [==========>...................] - ETA: 2s136/332 [===========>..................] - ETA: 2s141/332 [===========>..................] - ETA: 1s146/332 [============>.................] - ETA: 1s151/332 [============>.................] - ETA: 1s156/332 [=============>................] - ETA: 1s161/332 [=============>................] - ETA: 1s166/332 [==============>...............] - ETA: 1s171/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s181/332 [===============>..............] - ETA: 1s186/332 [===============>..............] - ETA: 1s191/332 [================>.............] - ETA: 1s196/332 [================>.............] - ETA: 1s201/332 [=================>............] - ETA: 1s206/332 [=================>............] - ETA: 1s211/332 [==================>...........] - ETA: 1s216/332 [==================>...........] - ETA: 1s221/332 [==================>...........] - ETA: 1s226/332 [===================>..........] - ETA: 1s231/332 [===================>..........] - ETA: 1s236/332 [====================>.........] - ETA: 0s241/332 [====================>.........] - ETA: 0s246/332 [=====================>........] - ETA: 0s251/332 [=====================>........] - ETA: 0s256/332 [======================>.......] - ETA: 0s261/332 [======================>.......] - ETA: 0s266/332 [=======================>......] - ETA: 0s271/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s281/332 [========================>.....] - ETA: 0s286/332 [========================>.....] - ETA: 0s291/332 [=========================>....] - ETA: 0s296/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s306/332 [==========================>...] - ETA: 0s311/332 [===========================>..] - ETA: 0s316/332 [===========================>..] - ETA: 0s321/332 [============================>.] - ETA: 0s326/332 [============================>.] - ETA: 0s331/332 [============================>.] - ETA: 0s332/332 [==============================] - 4s 10ms/step
correlation 0.0009302553133473862
cosine 0.0007334647147645601
MAE: 0.0050676614
RMSE: 0.009078275
r2: 0.9946540329165434
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_24"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_25 (InputLayer)       multiple                  0         
                                                                 
 dense_24 (Dense)            (None, 2907)              3677355   
                                                                 
 batch_normalization_24 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 2907)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2939988   
                                                                 
 batch_normalization_25 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 1011)              0         
                                                                 
 dense_25 (Dense)            (None, 2907)              2941884   
                                                                 
 batch_normalization_26 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 2907)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              3675712   
                                                                 
=================================================================
Total params: 13,262,239
Trainable params: 13,248,589
Non-trainable params: 13,650
_________________________________________________________________
Encoder
Model: "model_25"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_26 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_25 (InputLayer)       multiple                  0         
                                                                 
 dense_24 (Dense)            (None, 2907)              3677355   
                                                                 
 batch_normalization_24 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_24 (ReLU)             (None, 2907)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              2939988   
                                                                 
=================================================================
Total params: 6,628,971
Trainable params: 6,623,157
Non-trainable params: 5,814
_________________________________________________________________
Decoder
Model: "model_26"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_27 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_25 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_25 (ReLU)             (None, 1011)              0         
                                                                 
 dense_25 (Dense)            (None, 2907)              2941884   
                                                                 
 batch_normalization_26 (Bat  (None, 2907)             11628     
 chNormalization)                                                
                                                                 
 re_lu_26 (ReLU)             (None, 2907)              0         
                                                                 
 dense_26 (Dense)            (None, 1264)              3675712   
                                                                 
=================================================================
Total params: 6,633,268
Trainable params: 6,625,432
Non-trainable params: 7,836
_________________________________________________________________
['2.3custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.300480840262026e-05, 8.24151502456516e-05, 0.0009302553133473862, 0.0007334647147645601, 0.00506766140460968, 0.00907827541232109, 0.9946540329165434, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_27 (Dense)            (None, 3033)              3836745   
                                                                 
 batch_normalization_27 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 3033)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3067374   
                                                                 
 batch_normalization_28 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 1011)              0         
                                                                 
 dense_28 (Dense)            (None, 3033)              3069396   
                                                                 
 batch_normalization_29 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 3033)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              3834976   
                                                                 
=================================================================
Total params: 13,836,799
Trainable params: 13,822,645
Non-trainable params: 14,154
_________________________________________________________________
Epoch 1/200
1493/1493 - 100s - loss: 0.0091 - val_loss: 0.0039 - 100s/epoch - 67ms/step
Epoch 2/200
1493/1493 - 100s - loss: 0.0028 - val_loss: 0.0035 - 100s/epoch - 67ms/step
Epoch 3/200
1493/1493 - 99s - loss: 0.0020 - val_loss: 0.0017 - 99s/epoch - 67ms/step
Epoch 4/200
1493/1493 - 100s - loss: 0.0016 - val_loss: 0.0021 - 100s/epoch - 67ms/step
Epoch 5/200
1493/1493 - 101s - loss: 0.0016 - val_loss: 0.0021 - 101s/epoch - 67ms/step
Epoch 6/200
1493/1493 - 101s - loss: 0.0014 - val_loss: 0.0012 - 101s/epoch - 68ms/step
Epoch 7/200
1493/1493 - 101s - loss: 0.0013 - val_loss: 0.0012 - 101s/epoch - 68ms/step
Epoch 8/200
1493/1493 - 101s - loss: 0.0012 - val_loss: 9.3326e-04 - 101s/epoch - 68ms/step
Epoch 9/200
1493/1493 - 100s - loss: 0.0010 - val_loss: 0.0012 - 100s/epoch - 67ms/step
Epoch 10/200
1493/1493 - 100s - loss: 9.5795e-04 - val_loss: 6.3929e-04 - 100s/epoch - 67ms/step
Epoch 11/200
1493/1493 - 101s - loss: 8.1847e-04 - val_loss: 6.3140e-04 - 101s/epoch - 68ms/step
Epoch 12/200
1493/1493 - 97s - loss: 6.8475e-04 - val_loss: 6.6986e-04 - 97s/epoch - 65ms/step
Epoch 13/200
1493/1493 - 83s - loss: 6.4544e-04 - val_loss: 0.0013 - 83s/epoch - 55ms/step
Epoch 14/200
1493/1493 - 83s - loss: 6.9795e-04 - val_loss: 4.8908e-04 - 83s/epoch - 55ms/step
Epoch 15/200
1493/1493 - 83s - loss: 5.6915e-04 - val_loss: 8.0165e-04 - 83s/epoch - 55ms/step
Epoch 16/200
1493/1493 - 83s - loss: 5.3789e-04 - val_loss: 4.5352e-04 - 83s/epoch - 55ms/step
Epoch 17/200
1493/1493 - 83s - loss: 4.6505e-04 - val_loss: 0.0012 - 83s/epoch - 55ms/step
Epoch 18/200
1493/1493 - 82s - loss: 5.1243e-04 - val_loss: 6.7763e-04 - 82s/epoch - 55ms/step
Epoch 19/200
1493/1493 - 83s - loss: 4.4040e-04 - val_loss: 4.1807e-04 - 83s/epoch - 55ms/step
Epoch 20/200
1493/1493 - 83s - loss: 4.0231e-04 - val_loss: 3.8949e-04 - 83s/epoch - 56ms/step
Epoch 21/200
1493/1493 - 83s - loss: 3.7665e-04 - val_loss: 5.3578e-04 - 83s/epoch - 55ms/step
Epoch 22/200
1493/1493 - 82s - loss: 3.6890e-04 - val_loss: 4.0097e-04 - 82s/epoch - 55ms/step
Epoch 23/200
1493/1493 - 83s - loss: 3.4880e-04 - val_loss: 5.3440e-04 - 83s/epoch - 55ms/step
Epoch 24/200
1493/1493 - 82s - loss: 3.3977e-04 - val_loss: 2.8928e-04 - 82s/epoch - 55ms/step
Epoch 25/200
1493/1493 - 83s - loss: 3.1059e-04 - val_loss: 3.0306e-04 - 83s/epoch - 55ms/step
Epoch 26/200
1493/1493 - 83s - loss: 3.1502e-04 - val_loss: 3.1027e-04 - 83s/epoch - 55ms/step
Epoch 27/200
1493/1493 - 83s - loss: 2.8464e-04 - val_loss: 2.7794e-04 - 83s/epoch - 55ms/step
Epoch 28/200
1493/1493 - 83s - loss: 2.7126e-04 - val_loss: 4.5966e-04 - 83s/epoch - 55ms/step
Epoch 29/200
1493/1493 - 83s - loss: 2.6927e-04 - val_loss: 2.8088e-04 - 83s/epoch - 55ms/step
Epoch 30/200
1493/1493 - 83s - loss: 2.6484e-04 - val_loss: 2.7301e-04 - 83s/epoch - 55ms/step
Epoch 31/200
1493/1493 - 83s - loss: 2.5072e-04 - val_loss: 4.8790e-04 - 83s/epoch - 55ms/step
Epoch 32/200
1493/1493 - 83s - loss: 3.2043e-04 - val_loss: 4.7847e-04 - 83s/epoch - 55ms/step
Epoch 33/200
1493/1493 - 82s - loss: 2.8142e-04 - val_loss: 2.3094e-04 - 82s/epoch - 55ms/step
Epoch 34/200
1493/1493 - 83s - loss: 2.3881e-04 - val_loss: 2.1067e-04 - 83s/epoch - 55ms/step
Epoch 35/200
1493/1493 - 83s - loss: 2.2843e-04 - val_loss: 7.1455e-04 - 83s/epoch - 55ms/step
Epoch 36/200
1493/1493 - 82s - loss: 2.6111e-04 - val_loss: 2.4343e-04 - 82s/epoch - 55ms/step
Epoch 37/200
1493/1493 - 82s - loss: 2.2526e-04 - val_loss: 2.8681e-04 - 82s/epoch - 55ms/step
Epoch 38/200
1493/1493 - 83s - loss: 2.3564e-04 - val_loss: 1.9937e-04 - 83s/epoch - 55ms/step
Epoch 39/200
1493/1493 - 81s - loss: 2.1093e-04 - val_loss: 2.0051e-04 - 81s/epoch - 54ms/step
Epoch 40/200
1493/1493 - 79s - loss: 2.0184e-04 - val_loss: 2.4737e-04 - 79s/epoch - 53ms/step
Epoch 41/200
1493/1493 - 78s - loss: 2.0350e-04 - val_loss: 1.8870e-04 - 78s/epoch - 53ms/step
Epoch 42/200
1493/1493 - 79s - loss: 1.9737e-04 - val_loss: 2.0416e-04 - 79s/epoch - 53ms/step
Epoch 43/200
1493/1493 - 79s - loss: 1.9475e-04 - val_loss: 3.0086e-04 - 79s/epoch - 53ms/step
Epoch 44/200
1493/1493 - 78s - loss: 2.0534e-04 - val_loss: 7.2708e-04 - 78s/epoch - 53ms/step
Epoch 45/200
1493/1493 - 78s - loss: 2.4967e-04 - val_loss: 1.5692e-04 - 78s/epoch - 52ms/step
Epoch 46/200
1493/1493 - 78s - loss: 1.8852e-04 - val_loss: 1.7559e-04 - 78s/epoch - 53ms/step
Epoch 47/200
1493/1493 - 78s - loss: 1.8503e-04 - val_loss: 2.4980e-04 - 78s/epoch - 52ms/step
Epoch 48/200
1493/1493 - 79s - loss: 1.8325e-04 - val_loss: 2.2164e-04 - 79s/epoch - 53ms/step
Epoch 49/200
1493/1493 - 79s - loss: 1.7899e-04 - val_loss: 5.2056e-04 - 79s/epoch - 53ms/step
Epoch 50/200
1493/1493 - 78s - loss: 2.1796e-04 - val_loss: 5.7857e-04 - 78s/epoch - 53ms/step
Epoch 51/200
1493/1493 - 79s - loss: 2.1453e-04 - val_loss: 1.8344e-04 - 79s/epoch - 53ms/step
Epoch 52/200
1493/1493 - 78s - loss: 1.7163e-04 - val_loss: 1.7884e-04 - 78s/epoch - 53ms/step
Epoch 53/200
1493/1493 - 78s - loss: 1.7069e-04 - val_loss: 1.5597e-04 - 78s/epoch - 53ms/step
Epoch 54/200
1493/1493 - 78s - loss: 1.6852e-04 - val_loss: 1.9654e-04 - 78s/epoch - 53ms/step
Epoch 55/200
1493/1493 - 78s - loss: 1.6141e-04 - val_loss: 1.6452e-04 - 78s/epoch - 52ms/step
Epoch 56/200
1493/1493 - 79s - loss: 1.5968e-04 - val_loss: 1.8837e-04 - 79s/epoch - 53ms/step
Epoch 57/200
1493/1493 - 79s - loss: 1.6134e-04 - val_loss: 1.6415e-04 - 79s/epoch - 53ms/step
Epoch 58/200
1493/1493 - 79s - loss: 1.5463e-04 - val_loss: 1.3715e-04 - 79s/epoch - 53ms/step
Epoch 59/200
1493/1493 - 79s - loss: 1.5211e-04 - val_loss: 1.5775e-04 - 79s/epoch - 53ms/step
Epoch 60/200
1493/1493 - 78s - loss: 1.5240e-04 - val_loss: 6.0915e-04 - 78s/epoch - 53ms/step
Epoch 61/200
1493/1493 - 78s - loss: 5.4181e-04 - val_loss: 1.6682e-04 - 78s/epoch - 52ms/step
Epoch 62/200
1493/1493 - 78s - loss: 1.8897e-04 - val_loss: 1.8342e-04 - 78s/epoch - 52ms/step
Epoch 63/200
1493/1493 - 78s - loss: 1.6638e-04 - val_loss: 2.1038e-04 - 78s/epoch - 52ms/step
Epoch 64/200
1493/1493 - 78s - loss: 1.5908e-04 - val_loss: 3.5817e-04 - 78s/epoch - 53ms/step
Epoch 65/200
1493/1493 - 79s - loss: 1.7309e-04 - val_loss: 2.0464e-04 - 79s/epoch - 53ms/step
Epoch 66/200
1493/1493 - 78s - loss: 1.5782e-04 - val_loss: 1.5661e-04 - 78s/epoch - 53ms/step
Epoch 67/200
1493/1493 - 78s - loss: 1.4724e-04 - val_loss: 1.4343e-04 - 78s/epoch - 53ms/step
Epoch 68/200
1493/1493 - 78s - loss: 1.4306e-04 - val_loss: 3.2620e-04 - 78s/epoch - 53ms/step
Epoch 69/200
1493/1493 - 79s - loss: 1.6319e-04 - val_loss: 1.4023e-04 - 79s/epoch - 53ms/step
Epoch 70/200
1493/1493 - 79s - loss: 1.4084e-04 - val_loss: 2.9006e-04 - 79s/epoch - 53ms/step
Epoch 71/200
1493/1493 - 79s - loss: 1.6188e-04 - val_loss: 1.2994e-04 - 79s/epoch - 53ms/step
Epoch 72/200
1493/1493 - 79s - loss: 1.4134e-04 - val_loss: 1.8997e-04 - 79s/epoch - 53ms/step
Epoch 73/200
1493/1493 - 79s - loss: 1.4260e-04 - val_loss: 1.3570e-04 - 79s/epoch - 53ms/step
Epoch 74/200
1493/1493 - 78s - loss: 1.3802e-04 - val_loss: 1.4036e-04 - 78s/epoch - 52ms/step
Epoch 75/200
1493/1493 - 78s - loss: 1.3247e-04 - val_loss: 1.2584e-04 - 78s/epoch - 53ms/step
Epoch 76/200
1493/1493 - 78s - loss: 1.3086e-04 - val_loss: 1.3454e-04 - 78s/epoch - 53ms/step
Epoch 77/200
1493/1493 - 79s - loss: 1.2826e-04 - val_loss: 5.8285e-04 - 79s/epoch - 53ms/step
Epoch 78/200
1493/1493 - 79s - loss: 1.5190e-04 - val_loss: 1.5425e-04 - 79s/epoch - 53ms/step
Epoch 79/200
1493/1493 - 79s - loss: 1.3284e-04 - val_loss: 2.2177e-04 - 79s/epoch - 53ms/step
Epoch 80/200
1493/1493 - 78s - loss: 1.5083e-04 - val_loss: 1.4410e-04 - 78s/epoch - 52ms/step
Epoch 81/200
1493/1493 - 78s - loss: 1.3067e-04 - val_loss: 2.5223e-04 - 78s/epoch - 52ms/step
Epoch 82/200
1493/1493 - 78s - loss: 1.2645e-04 - val_loss: 1.1705e-04 - 78s/epoch - 52ms/step
Epoch 83/200
1493/1493 - 78s - loss: 1.2303e-04 - val_loss: 1.2997e-04 - 78s/epoch - 52ms/step
Epoch 84/200
1493/1493 - 78s - loss: 1.2269e-04 - val_loss: 1.3060e-04 - 78s/epoch - 52ms/step
Epoch 85/200
1493/1493 - 78s - loss: 1.3319e-04 - val_loss: 1.2762e-04 - 78s/epoch - 52ms/step
Epoch 86/200
1493/1493 - 78s - loss: 1.2416e-04 - val_loss: 1.2799e-04 - 78s/epoch - 52ms/step
Epoch 87/200
1493/1493 - 78s - loss: 1.1832e-04 - val_loss: 1.1964e-04 - 78s/epoch - 52ms/step
Epoch 88/200
1493/1493 - 78s - loss: 1.1763e-04 - val_loss: 1.2835e-04 - 78s/epoch - 52ms/step
Epoch 89/200
1493/1493 - 78s - loss: 1.2388e-04 - val_loss: 1.1841e-04 - 78s/epoch - 52ms/step
Epoch 90/200
1493/1493 - 78s - loss: 1.1645e-04 - val_loss: 1.3460e-04 - 78s/epoch - 52ms/step
Epoch 91/200
1493/1493 - 78s - loss: 1.1534e-04 - val_loss: 1.3003e-04 - 78s/epoch - 52ms/step
Epoch 92/200
1493/1493 - 78s - loss: 1.1463e-04 - val_loss: 3.8477e-04 - 78s/epoch - 52ms/step
Epoch 93/200
1493/1493 - 78s - loss: 1.4622e-04 - val_loss: 1.3198e-04 - 78s/epoch - 52ms/step
Epoch 94/200
1493/1493 - 78s - loss: 1.2213e-04 - val_loss: 1.0534e-04 - 78s/epoch - 52ms/step
Epoch 95/200
1493/1493 - 78s - loss: 1.1528e-04 - val_loss: 3.1586e-04 - 78s/epoch - 52ms/step
Epoch 96/200
1493/1493 - 78s - loss: 1.3710e-04 - val_loss: 1.2515e-04 - 78s/epoch - 52ms/step
Epoch 97/200
1493/1493 - 78s - loss: 1.1706e-04 - val_loss: 1.1358e-04 - 78s/epoch - 52ms/step
Epoch 98/200
1493/1493 - 78s - loss: 1.1522e-04 - val_loss: 4.6263e-04 - 78s/epoch - 52ms/step
Epoch 99/200
1493/1493 - 78s - loss: 1.6392e-04 - val_loss: 9.7449e-05 - 78s/epoch - 52ms/step
Epoch 100/200
1493/1493 - 78s - loss: 1.1900e-04 - val_loss: 1.0653e-04 - 78s/epoch - 52ms/step
Epoch 101/200
1493/1493 - 78s - loss: 1.1330e-04 - val_loss: 2.2858e-04 - 78s/epoch - 52ms/step
Epoch 102/200
1493/1493 - 78s - loss: 1.3507e-04 - val_loss: 1.3103e-04 - 78s/epoch - 52ms/step
Epoch 103/200
1493/1493 - 78s - loss: 1.1558e-04 - val_loss: 1.0822e-04 - 78s/epoch - 52ms/step
Epoch 104/200
1493/1493 - 78s - loss: 1.1028e-04 - val_loss: 4.4143e-04 - 78s/epoch - 52ms/step
Epoch 105/200
1493/1493 - 78s - loss: 1.4656e-04 - val_loss: 9.1709e-05 - 78s/epoch - 52ms/step
Epoch 106/200
1493/1493 - 78s - loss: 1.1134e-04 - val_loss: 1.0296e-04 - 78s/epoch - 52ms/step
Epoch 107/200
1493/1493 - 78s - loss: 1.0902e-04 - val_loss: 1.1041e-04 - 78s/epoch - 53ms/step
Epoch 108/200
1493/1493 - 78s - loss: 1.1121e-04 - val_loss: 1.2269e-04 - 78s/epoch - 52ms/step
Epoch 109/200
1493/1493 - 78s - loss: 1.0773e-04 - val_loss: 1.2138e-04 - 78s/epoch - 52ms/step
Epoch 110/200
1493/1493 - 78s - loss: 1.0555e-04 - val_loss: 1.1884e-04 - 78s/epoch - 52ms/step
Epoch 111/200
1493/1493 - 78s - loss: 1.0467e-04 - val_loss: 9.5148e-05 - 78s/epoch - 52ms/step
Epoch 112/200
1493/1493 - 79s - loss: 1.0290e-04 - val_loss: 9.8340e-05 - 79s/epoch - 53ms/step
Epoch 113/200
1493/1493 - 78s - loss: 1.0115e-04 - val_loss: 1.6268e-04 - 78s/epoch - 53ms/step
Epoch 114/200
1493/1493 - 78s - loss: 1.1035e-04 - val_loss: 9.9139e-05 - 78s/epoch - 52ms/step
Epoch 115/200
1493/1493 - 78s - loss: 1.0910e-04 - val_loss: 1.7990e-04 - 78s/epoch - 53ms/step
Epoch 116/200
1493/1493 - 78s - loss: 1.0322e-04 - val_loss: 1.0821e-04 - 78s/epoch - 53ms/step
Epoch 117/200
1493/1493 - 78s - loss: 1.0018e-04 - val_loss: 2.4439e-04 - 78s/epoch - 52ms/step
Epoch 118/200
1493/1493 - 78s - loss: 1.1462e-04 - val_loss: 1.0162e-04 - 78s/epoch - 53ms/step
Epoch 119/200
1493/1493 - 78s - loss: 9.9851e-05 - val_loss: 1.0122e-04 - 78s/epoch - 52ms/step
Epoch 120/200
1493/1493 - 78s - loss: 9.9095e-05 - val_loss: 9.7074e-05 - 78s/epoch - 52ms/step
Epoch 121/200
1493/1493 - 78s - loss: 9.9361e-05 - val_loss: 1.4962e-04 - 78s/epoch - 52ms/step
Epoch 122/200
1493/1493 - 78s - loss: 1.0215e-04 - val_loss: 8.7207e-05 - 78s/epoch - 52ms/step
Epoch 123/200
1493/1493 - 78s - loss: 9.7167e-05 - val_loss: 9.9065e-05 - 78s/epoch - 52ms/step
Epoch 124/200
1493/1493 - 78s - loss: 9.7147e-05 - val_loss: 2.1848e-04 - 78s/epoch - 52ms/step
Epoch 125/200
1493/1493 - 78s - loss: 1.2386e-04 - val_loss: 1.3409e-04 - 78s/epoch - 53ms/step
Epoch 126/200
1493/1493 - 78s - loss: 1.0127e-04 - val_loss: 1.2486e-04 - 78s/epoch - 52ms/step
Epoch 127/200
1493/1493 - 78s - loss: 9.8298e-05 - val_loss: 2.2654e-04 - 78s/epoch - 52ms/step
Epoch 128/200
1493/1493 - 78s - loss: 1.0564e-04 - val_loss: 9.1755e-05 - 78s/epoch - 52ms/step
Epoch 129/200
1493/1493 - 78s - loss: 9.5574e-05 - val_loss: 9.5841e-05 - 78s/epoch - 52ms/step
Epoch 130/200
1493/1493 - 78s - loss: 9.4641e-05 - val_loss: 9.0280e-05 - 78s/epoch - 52ms/step
Epoch 131/200
1493/1493 - 79s - loss: 9.7849e-05 - val_loss: 3.1841e-04 - 79s/epoch - 53ms/step
Epoch 132/200
1493/1493 - 79s - loss: 1.3415e-04 - val_loss: 9.0569e-05 - 79s/epoch - 53ms/step
Epoch 133/200
1493/1493 - 79s - loss: 9.8990e-05 - val_loss: 1.0242e-04 - 79s/epoch - 53ms/step
Epoch 134/200
1493/1493 - 79s - loss: 9.7038e-05 - val_loss: 9.6826e-05 - 79s/epoch - 53ms/step
Epoch 135/200
1493/1493 - 79s - loss: 9.3995e-05 - val_loss: 9.2536e-05 - 79s/epoch - 53ms/step
Epoch 136/200
1493/1493 - 79s - loss: 9.3245e-05 - val_loss: 1.0045e-04 - 79s/epoch - 53ms/step
Epoch 137/200
1493/1493 - 79s - loss: 9.9146e-05 - val_loss: 1.2722e-04 - 79s/epoch - 53ms/step
Epoch 138/200
1493/1493 - 79s - loss: 9.5588e-05 - val_loss: 9.1013e-05 - 79s/epoch - 53ms/step
Epoch 139/200
1493/1493 - 79s - loss: 9.3826e-05 - val_loss: 1.7338e-04 - 79s/epoch - 53ms/step
Epoch 140/200
1493/1493 - 79s - loss: 1.1415e-04 - val_loss: 8.0705e-05 - 79s/epoch - 53ms/step
Epoch 141/200
1493/1493 - 79s - loss: 9.3390e-05 - val_loss: 1.0634e-04 - 79s/epoch - 53ms/step
Epoch 142/200
1493/1493 - 79s - loss: 9.7946e-05 - val_loss: 9.1980e-05 - 79s/epoch - 53ms/step
Epoch 143/200
1493/1493 - 79s - loss: 9.1774e-05 - val_loss: 1.2226e-04 - 79s/epoch - 53ms/step
Epoch 144/200
1493/1493 - 79s - loss: 9.6983e-05 - val_loss: 9.1821e-05 - 79s/epoch - 53ms/step
Epoch 145/200
1493/1493 - 79s - loss: 9.0114e-05 - val_loss: 8.1739e-05 - 79s/epoch - 53ms/step
Epoch 146/200
1493/1493 - 79s - loss: 8.9305e-05 - val_loss: 7.8943e-05 - 79s/epoch - 53ms/step
Epoch 147/200
1493/1493 - 79s - loss: 8.7860e-05 - val_loss: 9.6753e-05 - 79s/epoch - 53ms/step
Epoch 148/200
1493/1493 - 79s - loss: 8.7861e-05 - val_loss: 1.5155e-04 - 79s/epoch - 53ms/step
Epoch 149/200
1493/1493 - 79s - loss: 8.7762e-05 - val_loss: 8.8886e-05 - 79s/epoch - 53ms/step
Epoch 150/200
1493/1493 - 79s - loss: 8.6548e-05 - val_loss: 8.3818e-05 - 79s/epoch - 53ms/step
Epoch 151/200
1493/1493 - 79s - loss: 8.7067e-05 - val_loss: 1.1449e-04 - 79s/epoch - 53ms/step
Epoch 152/200
1493/1493 - 79s - loss: 8.8390e-05 - val_loss: 1.4315e-04 - 79s/epoch - 53ms/step
Epoch 153/200
1493/1493 - 79s - loss: 9.3165e-05 - val_loss: 9.5536e-05 - 79s/epoch - 53ms/step
Epoch 154/200
1493/1493 - 79s - loss: 8.5838e-05 - val_loss: 8.7412e-05 - 79s/epoch - 53ms/step
Epoch 155/200
1493/1493 - 79s - loss: 8.5386e-05 - val_loss: 8.9905e-05 - 79s/epoch - 53ms/step
Epoch 156/200
1493/1493 - 79s - loss: 8.9911e-05 - val_loss: 8.7779e-05 - 79s/epoch - 53ms/step
Epoch 157/200
1493/1493 - 79s - loss: 8.4332e-05 - val_loss: 1.0737e-04 - 79s/epoch - 53ms/step
Epoch 158/200
1493/1493 - 79s - loss: 9.2753e-05 - val_loss: 8.9950e-05 - 79s/epoch - 53ms/step
Epoch 159/200
1493/1493 - 79s - loss: 8.4636e-05 - val_loss: 7.7285e-05 - 79s/epoch - 53ms/step
Epoch 160/200
1493/1493 - 79s - loss: 8.5298e-05 - val_loss: 1.2166e-04 - 79s/epoch - 53ms/step
Epoch 161/200
1493/1493 - 79s - loss: 1.0631e-04 - val_loss: 8.1672e-05 - 79s/epoch - 53ms/step
Epoch 162/200
1493/1493 - 79s - loss: 8.6416e-05 - val_loss: 7.7217e-05 - 79s/epoch - 53ms/step
Epoch 163/200
1493/1493 - 79s - loss: 8.4989e-05 - val_loss: 1.0366e-04 - 79s/epoch - 53ms/step
Epoch 164/200
1493/1493 - 79s - loss: 8.7715e-05 - val_loss: 8.4246e-05 - 79s/epoch - 53ms/step
Epoch 165/200
1493/1493 - 79s - loss: 1.0638e-04 - val_loss: 8.0421e-05 - 79s/epoch - 53ms/step
Epoch 166/200
1493/1493 - 79s - loss: 8.4797e-05 - val_loss: 8.6390e-05 - 79s/epoch - 53ms/step
Epoch 167/200
1493/1493 - 79s - loss: 8.3999e-05 - val_loss: 7.5709e-05 - 79s/epoch - 53ms/step
Epoch 168/200
1493/1493 - 79s - loss: 8.3021e-05 - val_loss: 7.7615e-05 - 79s/epoch - 53ms/step
Epoch 169/200
1493/1493 - 79s - loss: 8.3605e-05 - val_loss: 1.0557e-04 - 79s/epoch - 53ms/step
Epoch 170/200
1493/1493 - 79s - loss: 8.2597e-05 - val_loss: 1.6008e-04 - 79s/epoch - 53ms/step
Epoch 171/200
1493/1493 - 79s - loss: 1.0306e-04 - val_loss: 2.2076e-04 - 79s/epoch - 53ms/step
Epoch 172/200
1493/1493 - 79s - loss: 1.1356e-04 - val_loss: 9.6959e-05 - 79s/epoch - 53ms/step
Epoch 173/200
1493/1493 - 79s - loss: 8.6694e-05 - val_loss: 8.3213e-05 - 79s/epoch - 53ms/step
Epoch 174/200
1493/1493 - 79s - loss: 8.2957e-05 - val_loss: 8.3375e-05 - 79s/epoch - 53ms/step
Epoch 175/200
1493/1493 - 79s - loss: 8.3801e-05 - val_loss: 1.0211e-04 - 79s/epoch - 53ms/step
Epoch 176/200
1493/1493 - 79s - loss: 8.3602e-05 - val_loss: 8.3760e-05 - 79s/epoch - 53ms/step
Epoch 177/200
1493/1493 - 79s - loss: 8.2535e-05 - val_loss: 7.7168e-05 - 79s/epoch - 53ms/step
Epoch 178/200
1493/1493 - 79s - loss: 8.0749e-05 - val_loss: 7.5347e-05 - 79s/epoch - 53ms/step
Epoch 179/200
1493/1493 - 79s - loss: 8.0163e-05 - val_loss: 8.2496e-05 - 79s/epoch - 53ms/step
Epoch 180/200
1493/1493 - 78s - loss: 8.0789e-05 - val_loss: 8.4906e-05 - 78s/epoch - 53ms/step
Epoch 181/200
1493/1493 - 78s - loss: 7.9771e-05 - val_loss: 8.0403e-05 - 78s/epoch - 52ms/step
Epoch 182/200
1493/1493 - 78s - loss: 8.0457e-05 - val_loss: 8.5372e-05 - 78s/epoch - 53ms/step
Epoch 183/200
1493/1493 - 79s - loss: 7.9586e-05 - val_loss: 9.9671e-05 - 79s/epoch - 53ms/step
Epoch 184/200
1493/1493 - 79s - loss: 7.9949e-05 - val_loss: 7.7544e-05 - 79s/epoch - 53ms/step
Epoch 185/200
1493/1493 - 78s - loss: 7.7695e-05 - val_loss: 1.2867e-04 - 78s/epoch - 52ms/step
Epoch 186/200
1493/1493 - 78s - loss: 8.5724e-05 - val_loss: 7.7807e-05 - 78s/epoch - 52ms/step
Epoch 187/200
1493/1493 - 78s - loss: 7.8661e-05 - val_loss: 1.4732e-04 - 78s/epoch - 53ms/step
Epoch 188/200
1493/1493 - 79s - loss: 9.6512e-05 - val_loss: 7.8428e-05 - 79s/epoch - 53ms/step
Epoch 189/200
1493/1493 - 79s - loss: 8.0520e-05 - val_loss: 1.0287e-04 - 79s/epoch - 53ms/step
Epoch 190/200
1493/1493 - 78s - loss: 8.0446e-05 - val_loss: 1.0963e-04 - 78s/epoch - 52ms/step
Epoch 191/200
1493/1493 - 78s - loss: 8.2039e-05 - val_loss: 3.1498e-04 - 78s/epoch - 52ms/step
Epoch 192/200
1493/1493 - 78s - loss: 9.4834e-05 - val_loss: 9.0610e-05 - 78s/epoch - 53ms/step
Epoch 193/200
1493/1493 - 78s - loss: 8.5374e-05 - val_loss: 3.0992e-04 - 78s/epoch - 52ms/step
Epoch 194/200
1493/1493 - 79s - loss: 1.2259e-04 - val_loss: 9.9527e-04 - 79s/epoch - 53ms/step
Epoch 195/200
1493/1493 - 78s - loss: 1.4479e-04 - val_loss: 4.9442e-04 - 78s/epoch - 52ms/step
Epoch 196/200
1493/1493 - 78s - loss: 1.5080e-04 - val_loss: 8.0409e-05 - 78s/epoch - 52ms/step
Epoch 197/200
1493/1493 - 78s - loss: 9.4085e-05 - val_loss: 1.9785e-04 - 78s/epoch - 52ms/step
Epoch 198/200
1493/1493 - 78s - loss: 1.0759e-04 - val_loss: 1.0471e-04 - 78s/epoch - 52ms/step
Epoch 199/200
1493/1493 - 78s - loss: 8.7896e-05 - val_loss: 7.1166e-05 - 78s/epoch - 53ms/step
Epoch 200/200
1493/1493 - 79s - loss: 8.3058e-05 - val_loss: 7.7861e-05 - 79s/epoch - 53ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 7.786070636939257e-05
  1/332 [..............................] - ETA: 54s  6/332 [..............................] - ETA: 3s  12/332 [>.............................] - ETA: 3s 19/332 [>.............................] - ETA: 2s 27/332 [=>............................] - ETA: 2s 34/332 [==>...........................] - ETA: 2s 41/332 [==>...........................] - ETA: 2s 48/332 [===>..........................] - ETA: 2s 55/332 [===>..........................] - ETA: 2s 62/332 [====>.........................] - ETA: 2s 69/332 [=====>........................] - ETA: 2s 76/332 [=====>........................] - ETA: 1s 84/332 [======>.......................] - ETA: 1s 91/332 [=======>......................] - ETA: 1s 98/332 [=======>......................] - ETA: 1s105/332 [========>.....................] - ETA: 1s113/332 [=========>....................] - ETA: 1s121/332 [=========>....................] - ETA: 1s128/332 [==========>...................] - ETA: 1s136/332 [===========>..................] - ETA: 1s144/332 [============>.................] - ETA: 1s152/332 [============>.................] - ETA: 1s160/332 [=============>................] - ETA: 1s168/332 [==============>...............] - ETA: 1s176/332 [==============>...............] - ETA: 1s183/332 [===============>..............] - ETA: 1s190/332 [================>.............] - ETA: 1s198/332 [================>.............] - ETA: 0s206/332 [=================>............] - ETA: 0s214/332 [==================>...........] - ETA: 0s222/332 [===================>..........] - ETA: 0s230/332 [===================>..........] - ETA: 0s237/332 [====================>.........] - ETA: 0s245/332 [=====================>........] - ETA: 0s253/332 [=====================>........] - ETA: 0s261/332 [======================>.......] - ETA: 0s269/332 [=======================>......] - ETA: 0s277/332 [========================>.....] - ETA: 0s285/332 [========================>.....] - ETA: 0s293/332 [=========================>....] - ETA: 0s301/332 [==========================>...] - ETA: 0s309/332 [==========================>...] - ETA: 0s317/332 [===========================>..] - ETA: 0s325/332 [============================>.] - ETA: 0s332/332 [==============================] - ETA: 0s332/332 [==============================] - 3s 7ms/step
correlation 0.0008840391456609037
cosine 0.0006972216139907348
MAE: 0.0048865075
RMSE: 0.008823869
r2: 0.9949496509045306
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_27"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_28 (InputLayer)       multiple                  0         
                                                                 
 dense_27 (Dense)            (None, 3033)              3836745   
                                                                 
 batch_normalization_27 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 3033)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3067374   
                                                                 
 batch_normalization_28 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 1011)              0         
                                                                 
 dense_28 (Dense)            (None, 3033)              3069396   
                                                                 
 batch_normalization_29 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 3033)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              3834976   
                                                                 
=================================================================
Total params: 13,836,799
Trainable params: 13,822,645
Non-trainable params: 14,154
_________________________________________________________________
Encoder
Model: "model_28"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_29 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_28 (InputLayer)       multiple                  0         
                                                                 
 dense_27 (Dense)            (None, 3033)              3836745   
                                                                 
 batch_normalization_27 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_27 (ReLU)             (None, 3033)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3067374   
                                                                 
=================================================================
Total params: 6,916,251
Trainable params: 6,910,185
Non-trainable params: 6,066
_________________________________________________________________
Decoder
Model: "model_29"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_30 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_28 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_28 (ReLU)             (None, 1011)              0         
                                                                 
 dense_28 (Dense)            (None, 3033)              3069396   
                                                                 
 batch_normalization_29 (Bat  (None, 3033)             12132     
 chNormalization)                                                
                                                                 
 re_lu_29 (ReLU)             (None, 3033)              0         
                                                                 
 dense_29 (Dense)            (None, 1264)              3834976   
                                                                 
=================================================================
Total params: 6,920,548
Trainable params: 6,912,460
Non-trainable params: 8,088
_________________________________________________________________
['2.4custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 8.30577700980939e-05, 7.786070636939257e-05, 0.0008840391456609037, 0.0006972216139907348, 0.004886507522314787, 0.008823868818581104, 0.9949496509045306, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
./DATAFILES/MP_GapFeats3_custom_n_b already created.
Shape of dataset to encode: (106113, 1264)
Model: "model_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_31 (InputLayer)       [(None, 1264)]            0         
                                                                 
 dense_30 (Dense)            (None, 3160)              3997400   
                                                                 
 batch_normalization_30 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 3160)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3195771   
                                                                 
 batch_normalization_31 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 1011)              0         
                                                                 
 dense_31 (Dense)            (None, 3160)              3197920   
                                                                 
 batch_normalization_32 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 3160)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              3995504   
                                                                 
=================================================================
Total params: 14,415,919
Trainable params: 14,401,257
Non-trainable params: 14,662
_________________________________________________________________
Epoch 1/200
1493/1493 - 82s - loss: 0.0091 - val_loss: 0.0040 - 82s/epoch - 55ms/step
Epoch 2/200
1493/1493 - 80s - loss: 0.0028 - val_loss: 0.0027 - 80s/epoch - 54ms/step
Epoch 3/200
1493/1493 - 80s - loss: 0.0020 - val_loss: 0.0014 - 80s/epoch - 54ms/step
Epoch 4/200
1493/1493 - 80s - loss: 0.0016 - val_loss: 0.0029 - 80s/epoch - 54ms/step
Epoch 5/200
1493/1493 - 81s - loss: 0.0016 - val_loss: 0.0013 - 81s/epoch - 55ms/step
Epoch 6/200
1493/1493 - 82s - loss: 0.0015 - val_loss: 0.0011 - 82s/epoch - 55ms/step
Epoch 7/200
1493/1493 - 82s - loss: 0.0013 - val_loss: 0.0013 - 82s/epoch - 55ms/step
Epoch 8/200
1493/1493 - 81s - loss: 0.0012 - val_loss: 9.2531e-04 - 81s/epoch - 54ms/step
Epoch 9/200
1493/1493 - 81s - loss: 9.8799e-04 - val_loss: 0.0010 - 81s/epoch - 54ms/step
Epoch 10/200
1493/1493 - 81s - loss: 9.0565e-04 - val_loss: 7.7540e-04 - 81s/epoch - 54ms/step
Epoch 11/200
1493/1493 - 81s - loss: 8.2128e-04 - val_loss: 6.0231e-04 - 81s/epoch - 54ms/step
Epoch 12/200
1493/1493 - 81s - loss: 6.8987e-04 - val_loss: 0.0018 - 81s/epoch - 54ms/step
Epoch 13/200
1493/1493 - 82s - loss: 7.4550e-04 - val_loss: 7.5927e-04 - 82s/epoch - 55ms/step
Epoch 14/200
1493/1493 - 82s - loss: 6.1007e-04 - val_loss: 7.8815e-04 - 82s/epoch - 55ms/step
Epoch 15/200
1493/1493 - 82s - loss: 5.8837e-04 - val_loss: 6.3428e-04 - 82s/epoch - 55ms/step
Epoch 16/200
1493/1493 - 81s - loss: 5.0505e-04 - val_loss: 4.5014e-04 - 81s/epoch - 55ms/step
Epoch 17/200
1493/1493 - 82s - loss: 4.6426e-04 - val_loss: 0.0015 - 82s/epoch - 55ms/step
Epoch 18/200
1493/1493 - 82s - loss: 5.2758e-04 - val_loss: 4.3179e-04 - 82s/epoch - 55ms/step
Epoch 19/200
1493/1493 - 82s - loss: 4.1083e-04 - val_loss: 6.2312e-04 - 82s/epoch - 55ms/step
Epoch 20/200
1493/1493 - 81s - loss: 4.1909e-04 - val_loss: 3.5535e-04 - 81s/epoch - 54ms/step
Epoch 21/200
1493/1493 - 81s - loss: 3.7266e-04 - val_loss: 4.8862e-04 - 81s/epoch - 54ms/step
Epoch 22/200
1493/1493 - 81s - loss: 3.6131e-04 - val_loss: 0.0013 - 81s/epoch - 54ms/step
Epoch 23/200
1493/1493 - 81s - loss: 4.6429e-04 - val_loss: 5.3787e-04 - 81s/epoch - 54ms/step
Epoch 24/200
1493/1493 - 81s - loss: 3.5133e-04 - val_loss: 2.9787e-04 - 81s/epoch - 54ms/step
Epoch 25/200
1493/1493 - 81s - loss: 3.1447e-04 - val_loss: 2.9991e-04 - 81s/epoch - 54ms/step
Epoch 26/200
1493/1493 - 81s - loss: 3.2330e-04 - val_loss: 3.6688e-04 - 81s/epoch - 54ms/step
Epoch 27/200
1493/1493 - 81s - loss: 2.8670e-04 - val_loss: 2.9062e-04 - 81s/epoch - 54ms/step
Epoch 28/200
1493/1493 - 81s - loss: 2.7372e-04 - val_loss: 4.6016e-04 - 81s/epoch - 54ms/step
Epoch 29/200
1493/1493 - 81s - loss: 2.7192e-04 - val_loss: 3.8193e-04 - 81s/epoch - 54ms/step
Epoch 30/200
1493/1493 - 81s - loss: 2.8984e-04 - val_loss: 2.7860e-04 - 81s/epoch - 54ms/step
Epoch 31/200
1493/1493 - 81s - loss: 2.5147e-04 - val_loss: 3.4744e-04 - 81s/epoch - 54ms/step
Epoch 32/200
1493/1493 - 81s - loss: 2.7528e-04 - val_loss: 4.1579e-04 - 81s/epoch - 54ms/step
Epoch 33/200
1493/1493 - 81s - loss: 2.6713e-04 - val_loss: 2.1881e-04 - 81s/epoch - 54ms/step
Epoch 34/200
1493/1493 - 81s - loss: 2.3593e-04 - val_loss: 2.0429e-04 - 81s/epoch - 54ms/step
Epoch 35/200
1493/1493 - 81s - loss: 2.2559e-04 - val_loss: 3.4165e-04 - 81s/epoch - 54ms/step
Epoch 36/200
1493/1493 - 81s - loss: 2.3815e-04 - val_loss: 2.6930e-04 - 81s/epoch - 54ms/step
Epoch 37/200
1493/1493 - 81s - loss: 2.2093e-04 - val_loss: 2.4491e-04 - 81s/epoch - 54ms/step
Epoch 38/200
1493/1493 - 81s - loss: 2.2244e-04 - val_loss: 2.1451e-04 - 81s/epoch - 54ms/step
Epoch 39/200
1493/1493 - 81s - loss: 2.0801e-04 - val_loss: 2.0403e-04 - 81s/epoch - 54ms/step
Epoch 40/200
1493/1493 - 81s - loss: 1.9845e-04 - val_loss: 2.5778e-04 - 81s/epoch - 54ms/step
Epoch 41/200
1493/1493 - 81s - loss: 2.0051e-04 - val_loss: 1.8868e-04 - 81s/epoch - 54ms/step
Epoch 42/200
1493/1493 - 81s - loss: 1.9562e-04 - val_loss: 1.9439e-04 - 81s/epoch - 54ms/step
Epoch 43/200
1493/1493 - 81s - loss: 1.9290e-04 - val_loss: 3.0246e-04 - 81s/epoch - 54ms/step
Epoch 44/200
1493/1493 - 81s - loss: 2.0091e-04 - val_loss: 4.0482e-04 - 81s/epoch - 54ms/step
Epoch 45/200
1493/1493 - 81s - loss: 2.1537e-04 - val_loss: 1.5678e-04 - 81s/epoch - 54ms/step
Epoch 46/200
1493/1493 - 81s - loss: 1.8384e-04 - val_loss: 1.8061e-04 - 81s/epoch - 54ms/step
Epoch 47/200
1493/1493 - 81s - loss: 1.8026e-04 - val_loss: 2.5277e-04 - 81s/epoch - 54ms/step
Epoch 48/200
1493/1493 - 81s - loss: 1.8241e-04 - val_loss: 2.0666e-04 - 81s/epoch - 54ms/step
Epoch 49/200
1493/1493 - 81s - loss: 1.7719e-04 - val_loss: 4.5020e-04 - 81s/epoch - 54ms/step
Epoch 50/200
1493/1493 - 81s - loss: 2.2437e-04 - val_loss: 7.3873e-04 - 81s/epoch - 54ms/step
Epoch 51/200
1493/1493 - 81s - loss: 2.3598e-04 - val_loss: 1.7676e-04 - 81s/epoch - 54ms/step
Epoch 52/200
1493/1493 - 81s - loss: 1.7358e-04 - val_loss: 1.7296e-04 - 81s/epoch - 54ms/step
Epoch 53/200
1493/1493 - 81s - loss: 1.7186e-04 - val_loss: 1.5173e-04 - 81s/epoch - 54ms/step
Epoch 54/200
1493/1493 - 81s - loss: 1.6505e-04 - val_loss: 2.0050e-04 - 81s/epoch - 54ms/step
Epoch 55/200
1493/1493 - 81s - loss: 1.6057e-04 - val_loss: 1.5077e-04 - 81s/epoch - 54ms/step
Epoch 56/200
1493/1493 - 81s - loss: 1.5877e-04 - val_loss: 1.9963e-04 - 81s/epoch - 54ms/step
Epoch 57/200
1493/1493 - 81s - loss: 1.6019e-04 - val_loss: 1.5977e-04 - 81s/epoch - 54ms/step
Epoch 58/200
1493/1493 - 81s - loss: 1.5363e-04 - val_loss: 1.3858e-04 - 81s/epoch - 55ms/step
Epoch 59/200
1493/1493 - 81s - loss: 1.5054e-04 - val_loss: 1.5712e-04 - 81s/epoch - 55ms/step
Epoch 60/200
1493/1493 - 82s - loss: 1.5468e-04 - val_loss: 7.0577e-04 - 82s/epoch - 55ms/step
Epoch 61/200
1493/1493 - 81s - loss: 5.2944e-04 - val_loss: 1.7524e-04 - 81s/epoch - 55ms/step
Epoch 62/200
1493/1493 - 81s - loss: 1.9551e-04 - val_loss: 1.6480e-04 - 81s/epoch - 54ms/step
Epoch 63/200
1493/1493 - 81s - loss: 1.7139e-04 - val_loss: 1.8091e-04 - 81s/epoch - 54ms/step
Epoch 64/200
1493/1493 - 81s - loss: 1.6261e-04 - val_loss: 8.6679e-04 - 81s/epoch - 54ms/step
Epoch 65/200
1493/1493 - 81s - loss: 2.0918e-04 - val_loss: 8.7708e-04 - 81s/epoch - 54ms/step
Epoch 66/200
1493/1493 - 82s - loss: 2.1284e-04 - val_loss: 1.5749e-04 - 82s/epoch - 55ms/step
Epoch 67/200
1493/1493 - 81s - loss: 1.5640e-04 - val_loss: 1.3254e-04 - 81s/epoch - 55ms/step
Epoch 68/200
1493/1493 - 81s - loss: 1.4996e-04 - val_loss: 2.3073e-04 - 81s/epoch - 54ms/step
Epoch 69/200
1493/1493 - 81s - loss: 1.5615e-04 - val_loss: 1.3762e-04 - 81s/epoch - 55ms/step
Epoch 70/200
1493/1493 - 82s - loss: 1.4547e-04 - val_loss: 3.8898e-04 - 82s/epoch - 55ms/step
Epoch 71/200
1493/1493 - 81s - loss: 1.9356e-04 - val_loss: 1.2598e-04 - 81s/epoch - 55ms/step
Epoch 72/200
1493/1493 - 81s - loss: 1.4848e-04 - val_loss: 1.8178e-04 - 81s/epoch - 55ms/step
Epoch 73/200
1493/1493 - 81s - loss: 1.4639e-04 - val_loss: 1.3702e-04 - 81s/epoch - 55ms/step
Epoch 74/200
1493/1493 - 81s - loss: 1.4154e-04 - val_loss: 1.5470e-04 - 81s/epoch - 54ms/step
Epoch 75/200
1493/1493 - 81s - loss: 1.3558e-04 - val_loss: 1.1533e-04 - 81s/epoch - 54ms/step
Epoch 76/200
1493/1493 - 81s - loss: 1.3346e-04 - val_loss: 1.2211e-04 - 81s/epoch - 54ms/step
Epoch 77/200
1493/1493 - 81s - loss: 1.3100e-04 - val_loss: 0.0011 - 81s/epoch - 54ms/step
Epoch 78/200
1493/1493 - 81s - loss: 2.2501e-04 - val_loss: 1.5435e-04 - 81s/epoch - 54ms/step
Epoch 79/200
1493/1493 - 81s - loss: 1.4753e-04 - val_loss: 2.3926e-04 - 81s/epoch - 54ms/step
Epoch 80/200
1493/1493 - 81s - loss: 1.6369e-04 - val_loss: 1.7984e-04 - 81s/epoch - 54ms/step
Epoch 81/200
1493/1493 - 81s - loss: 1.3727e-04 - val_loss: 2.5414e-04 - 81s/epoch - 54ms/step
Epoch 82/200
1493/1493 - 81s - loss: 1.3235e-04 - val_loss: 1.2721e-04 - 81s/epoch - 54ms/step
Epoch 83/200
1493/1493 - 81s - loss: 1.2593e-04 - val_loss: 1.1998e-04 - 81s/epoch - 54ms/step
Epoch 84/200
1493/1493 - 81s - loss: 1.2467e-04 - val_loss: 1.2892e-04 - 81s/epoch - 54ms/step
Epoch 85/200
1493/1493 - 81s - loss: 1.2612e-04 - val_loss: 1.2719e-04 - 81s/epoch - 54ms/step
Epoch 86/200
1493/1493 - 81s - loss: 1.2313e-04 - val_loss: 1.2888e-04 - 81s/epoch - 54ms/step
Epoch 87/200
1493/1493 - 81s - loss: 1.1931e-04 - val_loss: 1.1212e-04 - 81s/epoch - 54ms/step
Epoch 88/200
1493/1493 - 81s - loss: 1.1857e-04 - val_loss: 1.3498e-04 - 81s/epoch - 54ms/step
Epoch 89/200
1493/1493 - 81s - loss: 1.2174e-04 - val_loss: 1.2159e-04 - 81s/epoch - 54ms/step
Epoch 90/200
1493/1493 - 82s - loss: 1.1715e-04 - val_loss: 1.2911e-04 - 82s/epoch - 55ms/step
Epoch 91/200
1493/1493 - 81s - loss: 1.1555e-04 - val_loss: 1.2116e-04 - 81s/epoch - 54ms/step
Epoch 92/200
1493/1493 - 81s - loss: 1.1648e-04 - val_loss: 2.8896e-04 - 81s/epoch - 54ms/step
Epoch 93/200
1493/1493 - 81s - loss: 1.5566e-04 - val_loss: 1.3122e-04 - 81s/epoch - 54ms/step
Epoch 94/200
1493/1493 - 81s - loss: 1.2862e-04 - val_loss: 1.0678e-04 - 81s/epoch - 54ms/step
Epoch 95/200
1493/1493 - 81s - loss: 1.1671e-04 - val_loss: 2.4952e-04 - 81s/epoch - 54ms/step
Epoch 96/200
1493/1493 - 81s - loss: 1.3288e-04 - val_loss: 1.2666e-04 - 81s/epoch - 55ms/step
Epoch 97/200
1493/1493 - 81s - loss: 1.1573e-04 - val_loss: 1.0339e-04 - 81s/epoch - 54ms/step
Epoch 98/200
1493/1493 - 82s - loss: 1.1334e-04 - val_loss: 2.6765e-04 - 82s/epoch - 55ms/step
Epoch 99/200
1493/1493 - 81s - loss: 1.3398e-04 - val_loss: 9.8470e-05 - 81s/epoch - 54ms/step
Epoch 100/200
1493/1493 - 81s - loss: 1.1620e-04 - val_loss: 1.0499e-04 - 81s/epoch - 54ms/step
Epoch 101/200
1493/1493 - 81s - loss: 1.1045e-04 - val_loss: 1.3052e-04 - 81s/epoch - 54ms/step
Epoch 102/200
1493/1493 - 81s - loss: 1.1579e-04 - val_loss: 1.6421e-04 - 81s/epoch - 54ms/step
Epoch 103/200
1493/1493 - 81s - loss: 1.1622e-04 - val_loss: 1.0394e-04 - 81s/epoch - 54ms/step
Epoch 104/200
1493/1493 - 81s - loss: 1.0895e-04 - val_loss: 5.9163e-04 - 81s/epoch - 54ms/step
Epoch 105/200
1493/1493 - 81s - loss: 1.5110e-04 - val_loss: 9.0724e-05 - 81s/epoch - 54ms/step
Epoch 106/200
1493/1493 - 81s - loss: 1.0987e-04 - val_loss: 1.0426e-04 - 81s/epoch - 54ms/step
Epoch 107/200
1493/1493 - 81s - loss: 1.0810e-04 - val_loss: 1.0649e-04 - 81s/epoch - 54ms/step
Epoch 108/200
1493/1493 - 81s - loss: 1.1092e-04 - val_loss: 1.1820e-04 - 81s/epoch - 54ms/step
Epoch 109/200
1493/1493 - 81s - loss: 1.0689e-04 - val_loss: 1.0695e-04 - 81s/epoch - 54ms/step
Epoch 110/200
1493/1493 - 81s - loss: 1.0521e-04 - val_loss: 1.1459e-04 - 81s/epoch - 54ms/step
Epoch 111/200
1493/1493 - 81s - loss: 1.0435e-04 - val_loss: 9.7126e-05 - 81s/epoch - 54ms/step
Epoch 112/200
1493/1493 - 81s - loss: 1.0299e-04 - val_loss: 9.3594e-05 - 81s/epoch - 54ms/step
Epoch 113/200
1493/1493 - 81s - loss: 1.0167e-04 - val_loss: 2.8423e-04 - 81s/epoch - 54ms/step
Epoch 114/200
1493/1493 - 81s - loss: 1.2924e-04 - val_loss: 1.0714e-04 - 81s/epoch - 54ms/step
Epoch 115/200
1493/1493 - 81s - loss: 1.1134e-04 - val_loss: 1.4827e-04 - 81s/epoch - 55ms/step
Epoch 116/200
1493/1493 - 82s - loss: 1.0413e-04 - val_loss: 1.0464e-04 - 82s/epoch - 55ms/step
Epoch 117/200
1493/1493 - 81s - loss: 1.0096e-04 - val_loss: 1.9893e-04 - 81s/epoch - 55ms/step
Epoch 118/200
1493/1493 - 81s - loss: 1.0946e-04 - val_loss: 1.2111e-04 - 81s/epoch - 54ms/step
Epoch 119/200
1493/1493 - 81s - loss: 1.0391e-04 - val_loss: 9.0943e-05 - 81s/epoch - 54ms/step
Epoch 120/200
1493/1493 - 81s - loss: 9.9125e-05 - val_loss: 9.7713e-05 - 81s/epoch - 54ms/step
Epoch 121/200
1493/1493 - 81s - loss: 9.9067e-05 - val_loss: 1.4129e-04 - 81s/epoch - 54ms/step
Epoch 122/200
1493/1493 - 82s - loss: 9.9116e-05 - val_loss: 8.8154e-05 - 82s/epoch - 55ms/step
Epoch 123/200
1493/1493 - 82s - loss: 9.6444e-05 - val_loss: 9.9009e-05 - 82s/epoch - 55ms/step
Epoch 124/200
1493/1493 - 82s - loss: 9.6112e-05 - val_loss: 2.1391e-04 - 82s/epoch - 55ms/step
Epoch 125/200
1493/1493 - 81s - loss: 1.1127e-04 - val_loss: 1.2090e-04 - 81s/epoch - 54ms/step
Epoch 126/200
1493/1493 - 81s - loss: 9.9462e-05 - val_loss: 1.1171e-04 - 81s/epoch - 54ms/step
Epoch 127/200
1493/1493 - 81s - loss: 9.7947e-05 - val_loss: 3.6043e-04 - 81s/epoch - 54ms/step
Epoch 128/200
1493/1493 - 81s - loss: 1.3124e-04 - val_loss: 8.5441e-05 - 81s/epoch - 54ms/step
Epoch 129/200
1493/1493 - 81s - loss: 9.8268e-05 - val_loss: 8.8951e-05 - 81s/epoch - 54ms/step
Epoch 130/200
1493/1493 - 81s - loss: 9.5577e-05 - val_loss: 9.3101e-05 - 81s/epoch - 55ms/step
Epoch 131/200
1493/1493 - 82s - loss: 9.7803e-05 - val_loss: 2.4419e-04 - 82s/epoch - 55ms/step
Epoch 132/200
1493/1493 - 81s - loss: 1.2983e-04 - val_loss: 8.9895e-05 - 81s/epoch - 55ms/step
Epoch 133/200
1493/1493 - 82s - loss: 9.8708e-05 - val_loss: 9.6131e-05 - 82s/epoch - 55ms/step
Epoch 134/200
1493/1493 - 81s - loss: 9.6122e-05 - val_loss: 9.3998e-05 - 81s/epoch - 55ms/step
Epoch 135/200
1493/1493 - 81s - loss: 9.3842e-05 - val_loss: 8.2851e-05 - 81s/epoch - 55ms/step
Epoch 136/200
1493/1493 - 81s - loss: 9.3463e-05 - val_loss: 1.1121e-04 - 81s/epoch - 54ms/step
Epoch 137/200
1493/1493 - 81s - loss: 9.9589e-05 - val_loss: 1.2034e-04 - 81s/epoch - 54ms/step
Epoch 138/200
1493/1493 - 81s - loss: 9.7279e-05 - val_loss: 8.5483e-05 - 81s/epoch - 54ms/step
Epoch 139/200
1493/1493 - 81s - loss: 9.3168e-05 - val_loss: 1.1935e-04 - 81s/epoch - 54ms/step
Epoch 140/200
1493/1493 - 81s - loss: 1.0040e-04 - val_loss: 7.7816e-05 - 81s/epoch - 54ms/step
Epoch 141/200
1493/1493 - 81s - loss: 9.1702e-05 - val_loss: 1.2163e-04 - 81s/epoch - 54ms/step
Epoch 142/200
1493/1493 - 81s - loss: 9.7921e-05 - val_loss: 9.5970e-05 - 81s/epoch - 54ms/step
Epoch 143/200
1493/1493 - 82s - loss: 8.9779e-05 - val_loss: 1.3082e-04 - 82s/epoch - 55ms/step
Epoch 144/200
1493/1493 - 81s - loss: 9.2728e-05 - val_loss: 9.2728e-05 - 81s/epoch - 54ms/step
Epoch 145/200
1493/1493 - 81s - loss: 8.9044e-05 - val_loss: 8.3168e-05 - 81s/epoch - 55ms/step
Epoch 146/200
1493/1493 - 82s - loss: 8.8887e-05 - val_loss: 7.7768e-05 - 82s/epoch - 55ms/step
Epoch 147/200
1493/1493 - 81s - loss: 8.7110e-05 - val_loss: 8.7024e-05 - 81s/epoch - 54ms/step
Epoch 148/200
1493/1493 - 80s - loss: 8.7498e-05 - val_loss: 1.3323e-04 - 80s/epoch - 53ms/step
Epoch 149/200
1493/1493 - 80s - loss: 8.8141e-05 - val_loss: 8.9948e-05 - 80s/epoch - 53ms/step
Epoch 150/200
1493/1493 - 80s - loss: 8.5956e-05 - val_loss: 8.2107e-05 - 80s/epoch - 53ms/step
Epoch 151/200
1493/1493 - 80s - loss: 8.7656e-05 - val_loss: 1.0995e-04 - 80s/epoch - 53ms/step
Epoch 152/200
1493/1493 - 80s - loss: 8.8237e-05 - val_loss: 1.0808e-04 - 80s/epoch - 53ms/step
Epoch 153/200
1493/1493 - 80s - loss: 8.8776e-05 - val_loss: 9.0813e-05 - 80s/epoch - 53ms/step
Epoch 154/200
1493/1493 - 80s - loss: 8.4840e-05 - val_loss: 8.2205e-05 - 80s/epoch - 54ms/step
Epoch 155/200
1493/1493 - 80s - loss: 8.3838e-05 - val_loss: 8.2026e-05 - 80s/epoch - 54ms/step
Epoch 156/200
1493/1493 - 80s - loss: 8.6659e-05 - val_loss: 8.6074e-05 - 80s/epoch - 54ms/step
Epoch 157/200
1493/1493 - 80s - loss: 8.3396e-05 - val_loss: 9.4985e-05 - 80s/epoch - 54ms/step
Epoch 158/200
1493/1493 - 80s - loss: 8.3904e-05 - val_loss: 9.4786e-05 - 80s/epoch - 54ms/step
Epoch 159/200
1493/1493 - 80s - loss: 8.3317e-05 - val_loss: 7.8162e-05 - 80s/epoch - 54ms/step
Epoch 160/200
1493/1493 - 80s - loss: 8.4742e-05 - val_loss: 1.5882e-04 - 80s/epoch - 54ms/step
Epoch 161/200
1493/1493 - 80s - loss: 1.5809e-04 - val_loss: 8.6660e-05 - 80s/epoch - 54ms/step
Epoch 162/200
1493/1493 - 80s - loss: 9.0984e-05 - val_loss: 7.7044e-05 - 80s/epoch - 54ms/step
Epoch 163/200
1493/1493 - 80s - loss: 8.7305e-05 - val_loss: 9.8986e-05 - 80s/epoch - 54ms/step
Epoch 164/200
1493/1493 - 80s - loss: 8.8993e-05 - val_loss: 8.6435e-05 - 80s/epoch - 54ms/step
Epoch 165/200
1493/1493 - 80s - loss: 1.1189e-04 - val_loss: 7.7166e-05 - 80s/epoch - 54ms/step
Epoch 166/200
1493/1493 - 80s - loss: 8.6229e-05 - val_loss: 9.5069e-05 - 80s/epoch - 54ms/step
Epoch 167/200
1493/1493 - 80s - loss: 8.5005e-05 - val_loss: 7.2937e-05 - 80s/epoch - 54ms/step
Epoch 168/200
1493/1493 - 80s - loss: 8.3472e-05 - val_loss: 8.2398e-05 - 80s/epoch - 54ms/step
Epoch 169/200
1493/1493 - 80s - loss: 8.3227e-05 - val_loss: 8.8534e-05 - 80s/epoch - 54ms/step
Epoch 170/200
1493/1493 - 80s - loss: 8.2007e-05 - val_loss: 1.3139e-04 - 80s/epoch - 54ms/step
Epoch 171/200
1493/1493 - 80s - loss: 9.4634e-05 - val_loss: 2.7072e-04 - 80s/epoch - 54ms/step
Epoch 172/200
1493/1493 - 80s - loss: 1.1772e-04 - val_loss: 1.1993e-04 - 80s/epoch - 54ms/step
Epoch 173/200
1493/1493 - 80s - loss: 8.8055e-05 - val_loss: 7.3604e-05 - 80s/epoch - 53ms/step
Epoch 174/200
1493/1493 - 79s - loss: 8.2359e-05 - val_loss: 8.5232e-05 - 79s/epoch - 53ms/step
Epoch 175/200
1493/1493 - 79s - loss: 8.2634e-05 - val_loss: 1.0060e-04 - 79s/epoch - 53ms/step
Epoch 176/200
1493/1493 - 79s - loss: 8.4426e-05 - val_loss: 7.9041e-05 - 79s/epoch - 53ms/step
Epoch 177/200
1493/1493 - 79s - loss: 8.1715e-05 - val_loss: 7.0695e-05 - 79s/epoch - 53ms/step
Epoch 178/200
1493/1493 - 79s - loss: 8.0391e-05 - val_loss: 7.9533e-05 - 79s/epoch - 53ms/step
Epoch 179/200
1493/1493 - 79s - loss: 7.9866e-05 - val_loss: 8.3848e-05 - 79s/epoch - 53ms/step
Epoch 180/200
1493/1493 - 80s - loss: 8.2147e-05 - val_loss: 7.4760e-05 - 80s/epoch - 53ms/step
Epoch 181/200
1493/1493 - 80s - loss: 8.0052e-05 - val_loss: 9.4276e-05 - 80s/epoch - 53ms/step
Epoch 182/200
1493/1493 - 79s - loss: 8.1332e-05 - val_loss: 9.5513e-05 - 79s/epoch - 53ms/step
Epoch 183/200
1493/1493 - 79s - loss: 8.0615e-05 - val_loss: 9.2435e-05 - 79s/epoch - 53ms/step
Epoch 184/200
1493/1493 - 80s - loss: 8.0438e-05 - val_loss: 7.3984e-05 - 80s/epoch - 53ms/step
Epoch 185/200
1493/1493 - 79s - loss: 7.7337e-05 - val_loss: 9.5190e-05 - 79s/epoch - 53ms/step
Epoch 186/200
1493/1493 - 79s - loss: 7.8944e-05 - val_loss: 7.5434e-05 - 79s/epoch - 53ms/step
Epoch 187/200
1493/1493 - 80s - loss: 7.6978e-05 - val_loss: 7.5692e-05 - 80s/epoch - 53ms/step
Epoch 188/200
1493/1493 - 80s - loss: 7.8778e-05 - val_loss: 8.3515e-05 - 80s/epoch - 53ms/step
Epoch 189/200
1493/1493 - 80s - loss: 7.8427e-05 - val_loss: 9.2136e-05 - 80s/epoch - 53ms/step
Epoch 190/200
1493/1493 - 79s - loss: 7.8949e-05 - val_loss: 1.3499e-04 - 79s/epoch - 53ms/step
Epoch 191/200
1493/1493 - 79s - loss: 8.5418e-05 - val_loss: 1.8820e-04 - 79s/epoch - 53ms/step
Epoch 192/200
1493/1493 - 79s - loss: 8.2872e-05 - val_loss: 8.0522e-05 - 79s/epoch - 53ms/step
Epoch 193/200
1493/1493 - 80s - loss: 7.8425e-05 - val_loss: 1.2532e-04 - 80s/epoch - 53ms/step
Epoch 194/200
1493/1493 - 80s - loss: 9.2847e-05 - val_loss: 3.9008e-04 - 80s/epoch - 54ms/step
Epoch 195/200
1493/1493 - 80s - loss: 1.6015e-04 - val_loss: 2.2934e-04 - 80s/epoch - 54ms/step
Epoch 196/200
1493/1493 - 80s - loss: 1.1947e-04 - val_loss: 7.4876e-05 - 80s/epoch - 54ms/step
Epoch 197/200
1493/1493 - 79s - loss: 8.7424e-05 - val_loss: 8.3608e-05 - 79s/epoch - 53ms/step
Epoch 198/200
1493/1493 - 79s - loss: 8.6035e-05 - val_loss: 9.0158e-05 - 79s/epoch - 53ms/step
Epoch 199/200
1493/1493 - 80s - loss: 8.2110e-05 - val_loss: 7.3239e-05 - 80s/epoch - 53ms/step
Epoch 200/200
1493/1493 - 80s - loss: 7.9497e-05 - val_loss: 7.5844e-05 - 80s/epoch - 54ms/step
COMPRESSED VECTOR SIZE: 1011
Loss in the autoencoder: 7.584418926853687e-05
  1/332 [..............................] - ETA: 35s  6/332 [..............................] - ETA: 3s  13/332 [>.............................] - ETA: 2s 20/332 [>.............................] - ETA: 2s 28/332 [=>............................] - ETA: 2s 36/332 [==>...........................] - ETA: 2s 44/332 [==>...........................] - ETA: 2s 52/332 [===>..........................] - ETA: 2s 60/332 [====>.........................] - ETA: 1s 68/332 [=====>........................] - ETA: 1s 76/332 [=====>........................] - ETA: 1s 84/332 [======>.......................] - ETA: 1s 92/332 [=======>......................] - ETA: 1s100/332 [========>.....................] - ETA: 1s108/332 [========>.....................] - ETA: 1s116/332 [=========>....................] - ETA: 1s124/332 [==========>...................] - ETA: 1s132/332 [==========>...................] - ETA: 1s140/332 [===========>..................] - ETA: 1s148/332 [============>.................] - ETA: 1s156/332 [=============>................] - ETA: 1s164/332 [=============>................] - ETA: 1s172/332 [==============>...............] - ETA: 1s180/332 [===============>..............] - ETA: 1s188/332 [===============>..............] - ETA: 0s196/332 [================>.............] - ETA: 0s204/332 [=================>............] - ETA: 0s212/332 [==================>...........] - ETA: 0s220/332 [==================>...........] - ETA: 0s228/332 [===================>..........] - ETA: 0s236/332 [====================>.........] - ETA: 0s244/332 [=====================>........] - ETA: 0s252/332 [=====================>........] - ETA: 0s260/332 [======================>.......] - ETA: 0s268/332 [=======================>......] - ETA: 0s276/332 [=======================>......] - ETA: 0s284/332 [========================>.....] - ETA: 0s292/332 [=========================>....] - ETA: 0s300/332 [==========================>...] - ETA: 0s308/332 [==========================>...] - ETA: 0s316/332 [===========================>..] - ETA: 0s324/332 [============================>.] - ETA: 0s332/332 [==============================] - ETA: 0s332/332 [==============================] - 2s 7ms/step
correlation 0.0008559743054084763
cosine 0.0006741350141058676
MAE: 0.0048754946
RMSE: 0.008708854
r2: 0.995080446868171
RMSE zero-vector: 0.23411466903540806
Full AutoEncoder
Model: "model_30"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_31 (InputLayer)       multiple                  0         
                                                                 
 dense_30 (Dense)            (None, 3160)              3997400   
                                                                 
 batch_normalization_30 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 3160)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3195771   
                                                                 
 batch_normalization_31 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 1011)              0         
                                                                 
 dense_31 (Dense)            (None, 3160)              3197920   
                                                                 
 batch_normalization_32 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 3160)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              3995504   
                                                                 
=================================================================
Total params: 14,415,919
Trainable params: 14,401,257
Non-trainable params: 14,662
_________________________________________________________________
Encoder
Model: "model_31"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_32 (InputLayer)       [(None, 1264)]            0         
                                                                 
 input_31 (InputLayer)       multiple                  0         
                                                                 
 dense_30 (Dense)            (None, 3160)              3997400   
                                                                 
 batch_normalization_30 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_30 (ReLU)             (None, 3160)              0         
                                                                 
 bottleneck (Dense)          (None, 1011)              3195771   
                                                                 
=================================================================
Total params: 7,205,811
Trainable params: 7,199,491
Non-trainable params: 6,320
_________________________________________________________________
Decoder
Model: "model_32"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_33 (InputLayer)       [(None, 1011)]            0         
                                                                 
 batch_normalization_31 (Bat  (None, 1011)             4044      
 chNormalization)                                                
                                                                 
 re_lu_31 (ReLU)             (None, 1011)              0         
                                                                 
 dense_31 (Dense)            (None, 3160)              3197920   
                                                                 
 batch_normalization_32 (Bat  (None, 3160)             12640     
 chNormalization)                                                
                                                                 
 re_lu_32 (ReLU)             (None, 3160)              0         
                                                                 
 dense_32 (Dense)            (None, 1264)              3995504   
                                                                 
=================================================================
Total params: 7,210,108
Trainable params: 7,201,766
Non-trainable params: 8,342
_________________________________________________________________
['2.5custom_n_b', 'mse', 64, 200, 0.0005, 0.8, 1011, 7.949701102916151e-05, 7.584418926853687e-05, 0.0008559743054084763, 0.0006741350141058676, 0.004875494632869959, 0.008708854205906391, 0.995080446868171, 0.23411466903540806] [<class 'str'>, <class 'str'>, <class 'int'>, <class 'int'>, <class 'float'>, <class 'numpy.float64'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]
Fri Dec 30 10:51:56 CET 2022
done
